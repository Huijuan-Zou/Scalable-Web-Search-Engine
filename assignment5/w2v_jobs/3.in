b'ifacnet the knowledgenet for professional accountants is the global multilingual search engine developed by the international federation of accountants ifac and its members to provide professional accountants worldwide with one stop access to good practice guidance articles management tools and other resources this enterprise search engine was launched on october 2 2006 by indez originally marketed to professional accountants in business ifacnet was expanded in march 2007 to provide resources and information relevant to small and medium accounting practices it now includes resources and information for accountants in all sectors of the profession the following 31 organizations participate in ifacnet american institute of certified public accountants aicpa association of chartered certified accountants acca canadian institute of chartered accountants certified general accountants association of canada chartered institute of management accountants cima chartered institute of public finance and accountancy cma canada compagnie nationale des commissaires aux comptes conseil sup\xc3\xa9rieur de l ordre des experts comptables consiglio nazionale dottori commercialisti cpa australia d\xc3\xa9l\xc3\xa9gation internationale pour l audit et la comptabilit\xc3\xa9 hong kong institute of certified public accountants hkicpa international federation of accountants ifac institut der wirtschaftspruefer in deutschland e v idw institute of certified public accountants in ireland institute of certified public accountants of singapore institute of chartered accountants of australia institute of chartered accountants in england wales icaew institute of chartered accountants in ireland institute of chartered accountants of india institute of chartered accountants of pakistan institute of chartered accountants of scotland icas institute of management accountants japanese institute of certified public accountants jicpa koninklijk nederlands instituut van registeraccountants royal nivra malaysian institute of accountants malta institute of accountants national association of state boards of accountancy nasba south african institute of chartered accountants saica union of chambers of certified public accountants of turkey t\xc3\xbcrmob external links http www ifacnet com ifacnet a knowledgenet for professional accountants http www ifac org international federation of accountants homepage category information retrieval organizations category internet search engines category accounting organizations'
b'infobox non profit non profit name the international society for music information retrieval non profit logo image logointernationalsocietymir png 250px non profit type non profit organization founded date 2008 founder location canada origins international symposium for music information retrieval key people area served worldwide focus music information retrieval music information retrieval mir method conferences publications revenue endowment num volunteers num employees num members owner non profit slogan the world s leading research forum on processing searching organising and accessing music related data homepage url http www ismir net tax exempt dissolved footnotes the http www ismir net international society for music information retrieval ismir is an international forum for research on the organization of music related data it started as an informal group steered by an ad hoc committee in 2000 ref http www ismir net texts byrd02 html donald byrd and michael fingerhut the history of ismir a short happy tale d lib magazine vol 8 no 11 issn 1082 9873 ref which established a yearly symposium whence ismir which meant international symposium on music information retrieval it was turned into a conference in 2002 while retaining the acronym ismir was incorporated in canada on july 4 2008 ref http www ismir net ismir letters patent pdf ismir letters patent canada july 4 2008 ref purpose given the tremendous growth of digital music and music metadata in recent years methods for effectively extracting searching and organizing music information have received widespread interest from academia and the information and entertainment industries the purpose of ismir is to provide a venue for the exchange of news ideas and results through the presentation of original theoretical or practical work by bringing together researchers and developers educators and librarians students and professional users all working in fields that contribute to this multidisciplinary domain the conference also serves as a discussion forum provides introductory and in depth information on specific domains and showcases current products as the term music information retrieval music information retrieval mir indicates this research is motivated by the desire to provide music lovers music professionals and music industry with robust effective and usable methods and tools to help them locate retrieve and experience the music they wish to have access to mir is a truly interdisciplinary area involving researchers from the disciplines of musicology cognitive science library and information science computer science electrical engineering and many others annual conferences since its inception in 2000 ismir has been the world s leading forum for research on the modelling creation searching processing and use of musical data researchers across the globe meet at the annual conference conducted by the society it is known by the same acronym as the society ismir following is the list of previous conferences held by the society ismir 2019 delft the netherlands ismir 2018 paris france ismir 2017 suzhou china http ismir2016 ismir net ismir 2016 8 12 august 2016 new york city usa http dblp uni trier de db conf ismir ismir2016 html proceedings http ismir2015 ismir net ismir 2015 26 30 october 2015 malaga spain http www informatik uni trier de ley db conf ismir ismir2015 html proceedings http ismir2014 ismir net ismir 2014 27 31 october 2014 taipei taiwan http www informatik uni trier de ley db conf ismir ismir2014 html proceedings http ismir2013 ismir net ismir 2013 4 8 november 2013 curitiba brazil http www informatik uni trier de ley db conf ismir ismir2013 html proceedings http ismir2012 ismir net ismir 2012 8 12 october 2012 porto portugal http www ismir net proceedings index php table name papers function search where clause papers year 2012 page 0 order authors order type asc proceedings http ismir2011 ismir net ismir 2011 24 28 october 2011 miami usa http www ismir net proceedings index php table name papers function search where clause papers year 2011 page 0 order authors order type asc proceedings http ismir2010 ismir net ismir 2010 9 13 august 2010 utrecht the netherlands http www ismir net proceedings index php table name papers function search where clause papers year 2010 page 0 order authors order type asc proceedings http ismir2009 ismir net ismir 2009 26 30 october 2009 kobe japan http www ismir net proceedings index php table name papers function search where clause papers year 2009 page 0 order authors order type asc proceedings http ismir2008 ismir net ismir 2008 14 18 september 2008 philadelphia usa http www ismir net proceedings index php table name papers function search where clause papers year 2008 page 0 order authors order type asc proceedings http ismir2007 ismir net ismir 2007 23 30 september 2007 vienna austria http www ismir net proceedings index php table name papers function search where clause papers year 2007 page 0 order authors order type asc proceedings http ismir2006 ismir net ismir 2006 8 12 october 2006 victoria bc canada http www ismir net proceedings index php table name papers function search where clause papers year 2006 page 0 order authors order type asc proceedings http ismir2005 ismir net ismir 2005 11 15 september 2005 london uk http www ismir net proceedings index php table name papers function search where clause papers year 2005 page 0 order authors order type asc proceedings http ismir2004 ismir net ismir 2004 10 15 october 2004 barcelona spain http www ismir net proceedings index php table name papers function search where clause papers year 2004 page 0 order authors order type asc proceedings http ismir2003 ismir net ismir 2003 26 30 october 2003 baltimore maryland usa http www ismir net proceedings index php table name papers function search where clause papers year 2003 page 0 order authors order type asc proceedings http ismir2002 ismir net ismir 2002 13 17 october 2002 paris france http www ismir net proceedings index php table name papers function search where clause papers year 2002 page 0 order authors order type asc proceedings http ismir2001 ismir net ismir 2001 15 17 october 2001 bloomington indiana usa http www ismir net proceedings index php table name papers function search where clause papers year 2001 page 0 order authors order type asc proceedings http ismir2000 ismir net ismir 2000 23 25 october 2000 plymouth massachusetts usa http www ismir net proceedings index php table name papers function search where clause papers year 200 page 0 order authors order type asc proceedings the http www ismir net official webpage provides a more up to date information on past and future conferences and provides access to all past websites and to the http www ismir net proceedings cumulative database of all papers posters and tutorials presented at these conferences an overview of all papers published at ismir can be found at http dblp uni trier de db conf ismir index html dblp research areas and topics the following list gives an overview of the main research areas and topics that are within the scope of music information retrieval mir data and fundamentals music signal processing symbolic music processing metadata linked data and semantic web social tags and user generated data natural language processing text and web mining multi modal approaches to mir methodology methodological issues and philosophical foundations evaluation methodology corpus creation legal social and ethical issues domain knowledge representation of musical knowledge and meaning music perception and cognition computational music theory computational musicology and ethnomusicology musical features and properties melody and motives harmony chords and tonality rhythm beat tempo structure segmentation and form timbre instrumentation and voice musical style and genre musical affect emotion and mood expression and performative aspects of music music processing sound source separation music transcription and annotation optical music recognition alignment synchronization and score following music summarization music synthesis and transformation fingerprinting automatic classification indexing and querying pattern matching and detection similarity metrics application user behavior and modelling user interfaces and interaction digital libraries and archives music retrieval systems music recommendation and playlist generation music and health well being and therapy music training and education mir applications in music composition performance and production music and gaming mir in business and marketing mirex the music information retrieval evaluation exchange mirex is an annual evaluation campaign for mir algorithms coupled to the ismir conference since it started in 2005 mirex has fostered advancements both in specific areas of mir and in the general understanding of how mir systems and algorithms are to be evaluated ref name downieebj10 citation author1 j stephen downie author2 andreas f ehmann author3 mert bay author4 m cameron jones title the music information retrieval evaluation exchange some observations and insights journal advances in music information retrieval springer year 2010 pages 93 115 doi 10 1007 978 3 642 11674 2 5 ref ref name downieeev05 ismir cite journal last1 downie first1 j stephen last2 west first2 kris last3 ehmann first3 andreas f last4 vincent first4 emmanuel title the 2005 music information retrieval evaluation exchange mirex 2005 preliminary overview journal proceedings of the international conference on music information retrieval year 2005 pages 320 323 ref mirex is to the mir community what the text retrieval conference trec is to the text information retrieval community a set of community defined formal evaluations through which a wide variety of state of the art systems algorithms and techniques are evaluated under controlled conditions mirex is managed by the international music information retrieval systems evaluation laboratory imirsel at the university of illinois at urbana champaign uiuc ref name downieimirsel cite web last1 downie first1 j stephen title the international music information retrieval systems evaluation laboratory imirsel project url http www music ir org evaluation publisher university of illinois accessdate 22 april 2016 ref related conferences acm multimedia international computer music conference international computer music conference icmc international conference on acoustics speech and signal processing international conference on acoustics speech and signal processing icassp international conference on digital audio effects international conference on digital audio effects dafx new interfaces for musical expression international conference on new interfaces for musical expression nime international symposium on computer music modeling and retrieval cmmr sound and music computing conference sound and music computing conference smc related journals computer music journal computer music journal cmj http asmp eurasipjournals springeropen com eurasip journal on audio speech and music processing http www signalprocessingsociety org publications periodicals taslp ieee acm transactions on audio speech and language processing taslp http www signalprocessingsociety org tmm ieee transactions on multimedia tmm http mp ucpress edu music perception journal of new music research journal of new music research jnmr further links audio engineering society http www signalprocessingsociety org technical committees list audio tc audio and acoustic signal processing music technology http www ismir net international society for music information retrieval ismir sound and music computing sound and music computing references reflist category music information retrieval category computer science conferences category music technology category multimedia category information retrieval organizations category music search engines'
b'the european summer school in information retrieval essir is a scientific event founded in 1990 which starts off a series of summer schools to provide high quality teaching of information retrieval on advanced topics essir is typically a week long event consisting of guest lectures and seminars from invited lecturers who are recognized experts in the field the aim of essir is to give to its participants a common ground in different aspects of information retrieval ir maristella agosti in 2008 stated that the term ir identifies the activities that a person the user has to conduct to choose from a collection of documents those that can be of interest to him to satisfy a specific and contingent information need ref agosti m information access using the guide of user requirements in information access through search engines and digital libraries agosti m ed springer verlag berlin heidelberg pp 1 12 2008 ref ir is a discipline with many facets and at the same time influences and is influenced by many other scientific disciplines indeed ir ranges from computer science to information science and beyond moreover a large number of ir methods and techniques are adopted and absorbed by several technologies the ir core methods and techniques are those for designing and developing ir systems web search engines and tools for information storing and querying in digital libraries ir core subjects are system architectures algorithms formal theoretical models and evaluation of the diverse systems and services that implement functionalities of storing and retrieving documents from multimedia document collections and over wide area networks such as the internet essir aims to give a deep and authoritative insight of the core ir methods and subjects along these three dimensions and also for this reason it is intended for researchers starting out in ir for industrialists who wish to know more about this increasingly important topic and for people working on topics related to management of information on the internet two books have been prepared as readings in ir from editions of essir the first one is lectures on information retrieval ref agosti m crestani f and pasi g eds lectures on information retrieval revised lectures of third european summer school essir 2000 varenna italy september 11 15 2000 lncs vol 1980 springer verlag berlin heidelberg 2001 ref the second one is advanced topics in information retrieval ref melucci m and baeza yates r eds advanced topics in information retrieval the information retrieval series vol 33 springer verlag berlin heidelberg 2011 ref essir editions essir series started in 1990 coming out from the successful experience of the summer school in information retrieval ssir conceived and designed by http www dei unipd it agosti maristella agosti university of padua italy and nick belkin rutgers university u s a for an italian audience in 1989 class wikitable border 1 edition web site location organiser s 10th http mklab iti gr essir2015 essir 2015 thessaloniki greece ioannis yiannis kompatsiaris symeon papadopoulos theodora tsikrika and stefanos vrochidis 9th http www ugr es essir2013 essir 2013 granada spain juan m fernadez luna and juan f huete 8th http essir uni koblenz de essir 2011 koblenz germany sergej sizov and steffen staab 7th http essir2009 dei unipd it essir 2009 padua italy massimo melucci and ricardo baeza yates 6th http www dcs gla ac uk essir2007 essir 2007 glasgow scotland united kingdom iadh ounis and keith van rijsbergen 5th http www cdvp dcu ie essir2005 essir 2005 dublin ireland alan smeaton 4th http www clips imag fr mrim essir03 main essir html essir 2003 aussois savoie france catherine berrut and yves chiaramella 3rd http www itim mi cnr it eventi essir2000 index htm essir 2000 varenna italy maristella agosti fabio crestani and gabriella pasi 2nd http www dcs gla ac uk essir essir 1995 glasgow united kingdom keith van rijsbergen 1st http ims dei unipd it websites essir essir1990 html essir 1990 brixen italy maristella agosti notes reflist external links http ims dei unipd it websites essir home html essir presentation page of the ims research group http ims dei unipd it ims research group department of information engineering university of padua italy http www dei unipd it department of information engineering university of padua italy http www unipd it en index htm university of padua italy category information retrieval organizations category summer schools'
b'the european conference on information retrieval ecir is the main european research conference for the presentation of new results in the field of information retrieval ir it is organized by the information retrieval specialist group of the british computer society bcs irsg the event started its life as the annual colloquium on information retrieval research in 1978 and was held in the uk each year until 1998 when it was hosted in grenoble france since then the venue has alternated between the united kingdom and continental europe to mark the metamorphosis from a small informal colloquium to a major event in the ir research calendar the bcs irsg later renamed the event to european conference on information retrieval in recent years ecir has continued to grow and has become the major european forum for the discussion of research in the field of information retrieval some of the topics dealt with include ir models techniques and algorithms ir applications ir system architectures test and evaluation methods for ir natural language processing for ir distributed ir multimedia and cross media ir time and location traditionally the ecir is held in spring near the easter weekend a list of locations and planned venues are presented below padova italy 2016 http ecir2016 dei unipd it vienna austria 2015 http www ecir2015 org amsterdam netherlands 2014 http ecir2014 org moscow russia 2013 http ecir2013 org barcelona spain 2012 http ecir2012 upf edu dublin ireland 2011 http www ecir2011 dcu ie milton keynes 2010 http kmi open ac uk events ecir2010 toulouse 2009 http ecir09 irit fr glasgow 2008 http ecir2008 dcs gla ac uk rome 2007 http ecir2007 fub it london 2006 http ecir2006 soi city ac uk santiago de compostela santiago 2005 http www gsi dec usc es ecir05 sunderland tyne and wear sunderland 2004 http ecir04 sunderland ac uk pisa 2003 http ecir03 isti cnr it glasgow 2002 http irsg bcs org past ecir php darmstadt 2001 organized by gmd cambridge 2000 organized by microsoft research glasgow 1999 grenoble 1998 aberdeen scotland aberdeen 1997 manchester 1996 crewe 1995 organized by manchester metropolitan university drymen scotland 1994 organized by strathclyde university glasgow 1993 organized by strathclyde university lancaster lancashire lancaster 1992 lancaster lancashire lancaster 1991 huddersfield 1990 huddersfield 1989 huddersfield 1988 glasgow 1987 glasgow 1986 bradford 1985 bradford 1984 sheffield 1983 sheffield 1982 birmingham 1981 leeds 1980 leeds 1979 br as the annual colloquium on information retrieval research external links http irsg bcs org ecir php official page at the website of the british computer society category information retrieval organizations category computer science conferences'
b'lowercase infobox company name dtsearch corp slogan the smart choice for text retrieval since 1991 type private company foundation 1991 location bethesda maryland bethesda maryland united states us key people david thede president industry software homepage http www dtsearch com www dtsearch com dtsearch corp is a software company which specializes in text retrieval software it was founded in 1991 and is headquartered in bethesda maryland bethesda maryland its current range of software includes products for enterprise desktop search intranet internet spidering and search and search engines for developers software development kit sdk to integrate into other software applications history dtsearch corp was founded by david thede ref http www lets talk computers com guests dtsearch 6 2 index htm lets talk computers interview may 31 2003 ref ref https www google com patents us6782380 method and system for indexing and searching contents of extensible mark up language xml documents us 6782380 b1 ref ref https www google com patents us7464098 method for rapidly searching elements or attributes or for rapidly filtering fragments in binary representations of structured for example xml based documents us 7464098 b2 ref the company started research and development in text retrieval in 1988 and incorporated in virginia in 1991 as d t software marketing of dtsearch 1 0 a dos text retrieval software product began in the first quarter of 1991 initially it was distributed as association of shareware professionals approved shareware the product was featured in an article entitled text retrieval software in an early edition of pc magazine ref text retrieval software july 1992 pc magazine uk ed ref as a shareware alternative to the commercial products reviewed these included isys search software isys zylab technologies zyindex strix asksam idealist assassin pc folio corporation folio views and lotus smarttext in the first few years after its initial release dtsearch was an end user application only then in 1994 symantec approached dtsearch about including its search technology into one of the first applications for 32 bit windows the dtsearch end user application was developed into a dynamic link library dll which symantec embedded in norton navigator which was released alongside microsoft s initial release of its 32 bit windows operating system windows 95 ref http www processor com editorial article asp article articles 2fp3012 2f11p12 2f11p12 asp dtsearch performs incredible feats processor mag march 21 2008 dead link date december 2016 bot internetarchivebot fix attempted yes ref in 2007 the company was listed in the econtent 100 list a list of companies that matter most in the digital content industry ref http www econtentmag com articles articlereader aspx articleid 40160 pagenum 22007 econtent 100 list ref products the current v 7 7 product range is unicode based and has an index that can handle over 1 terabyte tb of data per index dtsearch desktop with spider windows client desktop search software 32 and 64 bit indexers dtsearch network with spider as dtsearch desktop but licensed for network use 32 and 64 bit indexers dtsearch web with spider browser based search only client for intranet internet usage based on microsoft iis 32 and 64 bit indexers dtsearch engine with spider sdk with c net com java delphi apis 32 bit and 64 bit versions dtsearch engine for linux sdk with c and java apis dtsearch publish ref http www law com jsp lawtechnologynews pubarticleltn jsp id 1202463957873 slreturn 1 hbxlogin 1 dtsearch publish for edd production law technology news july 29 2010 ref a search front end for cd dvd publishing 32 and 64 bit indexers licensing partners company product docupoint llc drawingsearcher filehold systems inc filehold document management system see also enterprise search list of enterprise search vendors references reflist external links http www dtsearch com company website http www searchtools com tools dtsearch html product description on searchtools com http www windowsitpro com article desktop management dtsearch 7 desktop with spider aspx the index is mightier than the sword windows it pro august 27 2008 http www infoworld com t platforms desktop search gets down business 610 desktop search gets down to business infoworld september 01 2005 http www ncbi nlm nih gov pmc articles pmc150357 integrating query of relational and textual data in clinical databases j am med inform assoc 2003 jan feb http radiographics rsna org content 29 5 1233 full pdf informatics in radiology render an online searchable radiology study repository radiographics 2009 29 1233 1246 http jms ndmctsgh edu tw fdarticlee 5c2606199 pdf use of intelligent computer search for the patterns of abnormal lymphatic uptake by f 18 fdg pet in primary lung cancers j med sci 2006 26 6 199 204 dead link date december 2016 bot internetarchivebot fix attempted yes defaultsort dtsearch corp category desktop search engines category information retrieval organizations category software companies based in maryland'
b'infobox company name coveo solutions inc logo image coveo logo png 120px type private slogan foundation 2005 location city quebec city canada key people louis t\xc3\xaatu chairman and ceo br laurent simoneau president and cto num employees 200 industry enterprise search products coveo search relevance platform br coveo for sitecore br coveo for salesforce homepage http www coveo com coveo is a provider of enterprise search and website search technologies with integrated plug ins for salesforce com sitecore cep and microsoft outlook and sharepoint apis also allow for custom integration with other applications history coveo solutions inc was founded in 2005 as a spin off of copernic copernic technologies inc laurent simoneau coveo s president and chief executive officer was formerly copernic s chief operating officer about 30 employees moved into the new company with offices at that time in quebec city and montreal in canada and in palo alto calif ref http www eweek com c a enterprise applications copernic ready to take on google in enterprise search product ref products coveo search relevance platform coveo search relevance platform is a modular enterprise search technology that can index information stored in diverse repositories throughout the company perform text analytics and metadata enrichment on the indexed content and make the content findable through search driven interfaces coveo for sitecore coveo for sitecore is an integrated website search product to be used in conjunction with sitecore s customer experience platform the product enables the unified indexing of multiple repositories contextual search and search management via the sitecore console coveo for salesforce coveo for salesforce is an integrated crm search product to be used in conjunction with salesforce com service cloud and communities editions the product enables the unified indexing of multiple repositories contextual search and search management via the salesforce console customers coveo claims its clients include more than 700 implementations including amerisourcebergen ca california water service co deloitte espn haley aldrich geico lockheed martin p g prtm pricewaterhousecoopers rabobank snc lavalin spencer stuart theodoor gilissen and the u s navy ref cite web url http www coveo com en media files about us coveo corporate fact sheet q109 ashx title coveo corporate fact sheet date accessdate 2011 02 27 ref these companies were also mentioned while not confirmed by a citation hp pwc netezza corporation nato nasa ac nielsen among many others citation needed date february 2010 references reflist external links http www coveo com coveo com category companies based in quebec city category information retrieval organizations category blackberry development software'
b'the clearinghouse for networked information discovery and retrieval or cnidr was an organization funded by the u s national science foundation from 1993 to 1997 and based at the microelectronics center of north carolina mcnc in research triangle park ref national science foundation http www nsf gov awardsearch showaward awd id 9216963 award abstract 9216963 clearinghouse for network information discovery retrieval ref ref brett george http grantome com grant nsf cns 9315306 clearinghouse for networked information discovery and retrieval cnidr ref cnidr was active in the research and development of open source software and open standards centered on information discovery and retrieval in the emerging internet among the software developed at cnidr were isite an open source z39 50 implementation and successor to the free version of wide area information server wais ref gamiel kevin and nassar nassib 1995 structural components of the isite information system in z39 50 implementation experiences p over r denenberg w e moen and l stovel eds national institute of standards and technology special publication 500 229 us department of commerce gaithersburg md 71 74 ref ref nebert douglas d and fullton james http www csdl tamu edu dl95 papers nebert nebert html use of the isite z39 50 software to search and retrieve spatially referenced data ref ref http inkdroid org tmp www talk 8133 html cnidr announces isite v1 00 integrated information system ref ref http isite awcubed com isite html the isite information system ref ref http www loc gov z3950 mums html library of congress search form ref and isearch an open source text retrieval system cnidr staff were involved in the development of open standards in the internet engineering task force the z39 50 implementors group and dublin core ref https www ietf org meeting past html ietf past meetings ref ref http www loc gov z3950 agency zig meetings output html zig meeting output ref ref http dublincore org workshops dc1 dc1 oclc ncsa metadata workshop the essential elements of network object description ref cnidr collaborated with the united states patent and trademark office u s patent and trademark office uspto to develop the uspto s first internet based patent search systems one of these provided full text searching and images of medical patents related to the research and treatment of hiv aids and issued by the us japanese and european patent offices another system known as the us patent bibliographic database provided searching of front page bibliographic information for all us patents since 1976 ref miller annetta 1994 http www newsweek com new online aids database 186740 a new online aids database in newsweek november 13 1994 ref ref http www pubzpro com pubz search a 6105 mcnc and u s patent office launch internet aids library ref ref kawakami alice k http www istl org 98 summer article5 html patents and patent searching ref ref http www2 iastate edu cyberstacks hyb t 7 htm patents and trademarks ref references reflist category information retrieval organizations category internet standards category internet protocols category internet search engines category organizations established in 1992 category computer related organizations'
b'infobox company name concept searching limited logo image conceptsearching jpg slogan retrieval just got smarter type privately held company private foundation 2002 location uk united states area served global industry information retrieval products conceptsearch br conceptclassifier br conceptclassifier for sharepoint br conceptclassifier for sharepoint online br taxonomy manager br taxonomy workflow homepage http www conceptsearching com www conceptsearching com concept searching limited is a software company which specializes in information retrieval software it has products for enterprise search taxonomy management and statistical classification history concept searching was founded in 2002 in the uk and now has offices in the usa and south africa in august 2003 the company introduced the idea of using compound term processing ref http direct bl uk bld placeorder do uin 138451913 etoc rn lateral thinking in information retrieval information management and technology 2003 vol 36 part 4 pp 169 173 ref ref http www conceptsearching com web userfiles file concept 20searching 20lateral 20thinking pdf lateral thinking in information retrieval ref compound term processing allows statistical information retrieval applications to perform matching using multi word concepts this can improve the quality of search results and also allows unstructured information to be automatically classified with semantic metadata ref http airforcemedicine afms mil 711hswom intersymp2008 afms 20 20intersymp 202008 html us air force medical service presentation at intersymp 2008 ref the company s products run on the microsoft net framework net platform the products integrate with microsoft sharepoint and many other platforms ref http pinpoint microsoft com en us partners concept searching inc 4297066101 microsoft partner profile ref concept searching has developed the smart content framework which is a toolset that provides an enterprise framework to mitigate risk automate processes manage information protect privacy and address compliance issues the smart content framework is used by many large organizations including 23 000 users at the nasa safety center ref http www aiim org about news cs nasa safety nasa safety center using smart content framework ref awards 100 companies that matter in knowledge management 2009 2010 2011 2012 2013 2014 2015 ref cite web url http www kmworld com articles editorial features kmworld 100 companies that matter in knowledge management 102189 aspx title kmworld magazine ref kmworld trend setting products of 2009 2010 2011 2012 2013 2014 2015 ref cite web url http www kmworld com articles editorial features kmworld trend setting products of 2015 105783 aspx title trend setting products ref see also compound term processing enterprise search full text search information retrieval concept search references reflist external links http www conceptsearching com company website category information retrieval organizations category privately held companies of the united kingdom'
b'the conference and labs of the evaluation forum formerly cross language evaluation forum or clef is an organization promoting research in multilingual information access currently focusing on european commissioner for multilingualism european languages its specific functions are to maintain an underlying framework for testing information retrieval systems and to create digital library repositories of data for researchers to use in developing comparable technical standard standards ref name peters cite conference first1 carol last1 peters first2 martin last2 braschler first3 khalid last3 choukri first4 julio last4 gonzalo first5 michael last5 kluck title the future of evaluation for cross language information retrieval systems conference second workshop of the cross language evaluation forum clef 2001 citeseerx 10 1 1 109 7647 ref the organization holds a forum meeting every september in europe prior to each forum participants receive a set of challenge tasks the tasks are designed to test various aspects of information retrieval systems and encourage their development groups of researchers propose and organize campaigns to satisfy those tasks the results are used as benchmark computing benchmarks for the state of the art in the specific areas ref cite journal url http www springerlink com content l7v0354471u53385 title special issue on clef journal information retrieval volume 7 issue 1 2 year 2004 ref ref fredric c gey noriko kando and carol peters cross language information retrieval the way ahead in information processing management vol 41 no 3 p 415 431 may 2005 doi 10 1016 j ipm 2004 06 006 ref for example the 2010 medical retrieval task focuses on retrieval of computed tomography mri and radiographic images ref name imageclefmed cite web last mueller first henning authorlink coauthors title medical retrieval task work publisher imageclef cross language image retrieval evaluations date 20 may 2010 url http www imageclef org 2010 medical format doi accessdate 27 may 2010 ref references reflist external links http www clef initiative eu clef homepage category information retrieval organizations compu conference stub'
b'more footnotes date january 2014 dandelon com is a collaborative community of libraries in multiple countries as well as a search engine computing search engine a search or discovery service a library information system for the academic community it is additionally a platform allowing registered libraries to exchange library catalogue enrichment data tables of content of monographs deep indexing data cover pages and bibliographic descriptions of articles published in periodicals with abstracts and or full texts provided for part of the items the domain name was created in 2004 it is derived from the plant taraxacum dandelion the name is an allusion to the flower s worldwide occurrence it is thought to spread around the world as easily as human words and thoughts dandelon s aim is to uncover knowledge assets for students from around the world it is free of charge for private use and without user tracking or advertising ref http www dandelon com dandelon com bot generated title ref traditionally the number of searchable relevant subject words comes up to about five semantically different subjects words located in titles and generated by human indexing a book registered at dandelon com typically is assigned between 20 and 500 subject words depending on the size of the book and the knowledge domain based on this extended set of terms representing each library item queries can be more specific and relevance ranking can be more efficient dandelon com also expands user queries by adding closely related words default synonyms and translations optionally narrower terms from multilingual thesaurus thesauri from various knowledge domains search results can be restricted to a specific library automatic backlinks to the related library management system allows online access or requesting a book dandelon com does not replace library management systems it is an additional option for searching and first of all a platform for data exchange between libraries associated with its community its user interface supports a number of languages and it provides content in about 130 languages the core of dandelon com is the content production software intelligentcapture mobile employed by all member libraries it reads from and sends data to each library management system receiving text content via digitization and optical character recognition ocr for close to 200 languages or via native digital content import additionally it automatically extracts major subject words which are translated into 60 languages by machine translation computers and scanners can be placed in a special mobile furniture to be used between shelves and narrow compactus the provider of production software and search and distribution services is the german based company agi information management consultants ref http www agi imc de bot generated title ref as well as the hosting center of gbv gemeinsamer bibliotheksverbund a state owned german library service center for more than 800 libraries ref http www gbv de bot generated title ref the solution was invented in 2001 by manfred hauer of agi and karl raedler from vorarlberger landesbibliothek austria ref http vlb vorarlberg at bot generated title ref dandelon com shares part of its data with gbv gbv in turn exchanges some of its catalogue enrichment data with oclc worldcat and other service centers hebis ref http www hebis de bot generated title ref another state owned service center shares with the german national library german national library charges fees for enrichment content ref http www dnb de kataloganreicherung bot generated title ref agi and a number of the producing libraries have been pioneering catalogue enrichment in europe since 2001 and form one of the largest communities of producers of digitalized tables of content of monographs in europe in 2013 close to 2 nbsp million tables of contents were digitalized not all of which are available on dandelon com for the general public the large collection produced for the german national library is not yet shared and was announced for public use in 2014 dandelon com and intelligentcapture are ibm lotus domino ibm domino and notes applications dandelon com runs apache lucene as retrieval engine references reflist manfred hauer 2012 http www agi imc de internet nsf dda9df579aa6429dc12567f5004ad7ed 659e168d74f0bc38c12579bb004ea5b8 file hauer sla bahrain 2012 gb pdf web 2 0 which features are wanted by academic library clients a hebis survey report pdf 172 nbsp kb gulf special library association sla conference proceeding on cd nienerza heike sunckel bettina meier berthold 2011 http www degruyter com view j abitech 2011 31 issue 3 abi 2011 020 abi 2011 020 xml format int unser katalog soll besser werden kataloge und portale im web 2 0 zeitalter ergebnisse einer online umfrage im hebis verbund abi technik de gruyter berlin issue 31 pp 130 149 doi 10 1515 abi 2011 020 manfred hauer 2013 http www agi imc de internet nsf 26efb65f701b0871c125751a00413614 3d26118ce2a8ebccc1257b1800356e8b opendocument zur bedeutung normierter terminologien in zeiten moderner sprach und information retrieval technologien pdf 205 nbsp kb http www degruyter com view j abitech abi technik de gruyter berlin issue 1 pp 2 6 manfred hauer rainer diedrichs 2010 http www agi imc de internet nsf 26efb65f701b0871c125751a00413614 3f191bb231f0d57ec1257749004a9e7d file kataloganreicherung in europa 2010 c pdf kataloganreicherung in europa pdf 525 nbsp kb buch und bibliothek http www b u b de issue 5 pp nbsp 394 397 manfred hauer 2005 http www agi imc de internet nsf 94280a18b17ee318c12567d2003c3bb2 3267dae6428c5f02c125711600527ffd opendocument vergleich der retrievalleistungen von bibliothekskatalogen gegen erweiterte und neue konzept benchmarking google scholar dandelon com vorarlberger landesbibliothek weitere opacs in http www degruyter com view j abitech abi technik de gruyter berlin december pp nbsp 295 301 category information retrieval organizations category information retrieval systems category digital library projects'
b'unreferenced date january 2010 the information retrieval specialist group irsg or bcs irsg is a specialist group of the british computer society concerned with supporting communication between researchers and practitioners promoting the use of information retrieval ir methods in industry and raising public awareness there is a newsletter called the informer an annual european conference ecir and continual organisation and sponsorship of conferences workshops and seminars the current chair is dr andy macfarlane citation needed date january 2010 european conference on information retrieval organising european conference on information retrieval ecir is one of the major activities of the information retrieval specialist group the conference began in 1979 and has grown to become one of the major information retrieval conferences alongside special interest group on information retrieval sigir receiving hundreds of paper and poster submissions every year from around the world citation needed date january 2010 ecir was initially established by the irsg under the name annual colloquium on information retrieval research and held in the uk until 1997 it was renamed ecir in 2003 to better reflect its status as an international conference external links http irsg bcs org irsg website category information retrieval organizations category bcs specialist groups'
b'infobox organization name acm special interest group on information retrieval image sig information retrieval logo png size 140px alt acm sigir parent organization association for computing machinery website url sigir org sigir is the association for computing machinery s special interest group on information retrieval the scope of the group s specialty is the theory and application of computers to the acquisition organization storage information retrieval retrieval and distribution of information emphasis is placed on working with non numeric information ranging from natural language to highly structured data bases conferences the annual international sigir conference which began in 1978 is considered the most important in the field of information retrieval sigir also sponsors the annual joint conference on digital libraries jcdl in association with acm sigweb sigweb the conference on information and knowledge management cikm and the international conference on web search and data mining wsdm in association with sigkdd sigmod and acm sigweb sigweb sigir conference locations class wikitable border 1 number year location 22 1999 berkeley california 23 2000 athens 24 2001 new orleans 25 2002 tampere 26 2003 toronto 27 2004 sheffield 28 2005 salvador bahia 29 2006 seattle 30 2007 amsterdam 31 2008 singapore 32 2009 boston 33 2010 geneva 34 2011 beijing 35 2012 portland oregon 36 2013 dublin 37 2014 gold coast queensland 38 2015 santiago 39 2016 pisa 40 2017 tokyo 41 2018 ann arbor awards the group gives out several awards to contributions to the field of information retrieval the most important award is the gerard salton award named after the computer scientist gerard salton which is awarded every three years to an individual who has made significant sustained and continuing contributions to research in information retrieval additionally sigir presents a best paper award ref cite web url http sigir org awards awards html bestpaper title sigir conference best paper awards accessdate 2012 08 29 ref to recognize the highest quality paper at each conference test of time award ref cite web url http sigir org awards test of time awards title sigir conference test of time awards accessdate 2015 12 29 ref is a recent award that is given to a paper that has had long lasting influence including impact on a subarea of information retrieval research across subareas of information retrieval research and outside of the information retrieval research community this award is selected from a set of full papers presented at the main sigir conference 10 12 years before see also conference on information and knowledge management references reflist external links official website http www sigir org authority control category association for computing machinery special interest groups category information retrieval organizations'
b'multiple issues advert date june 2015 coi date june 2015 notability companies date november 2015 infobox company name smartlogic logo slogan the content intelligence company type privately held company private foundation 2006 location united states uk area served global industry information retrieval products semaphore cloud semaphore ontology editor semaphore classification server semaphore semantic enhancement server advanced language packs search appliance framework text miner classification review tool classification analysis tool num employees 55 homepage http www smartlogic com smartlogic is a software company which specializes in developing information retrieval text analytics and knowledge management solutions history smartlogic was founded in the united kingdom in 2006 it is a privately held company and has offices in san jose ca alexandria va cambridge ma and london uk the company develops and sells a suite of products semaphore ontology editor classification server advanced language packs semantic enhancement server text miner classification review tool and classification analysis tool products semaphore ontology editor semaphore ontology editor is a web based tool used to build taxonomies ontologies controlled vocabularies as well as other knowledge organization systems models are used by organizations to enhance the capabilities of enterprise search engines ref http www cmswire com events item webinar leverage metadata to drive critical business processes 022370 php cmswire leverage metadata to drive critical business processes ref content management and workflow systems deployed by clients to augment and enhance their investment semaphore classification server semaphore classification server uses the model structure from semaphore ontology editor and auto classifies unstructured information assets by applying metadata tags to the unstructured information semaphore advanced language packs semantic enhancement server integrations semaphore integrates with microsoft sharepoint ref http www cmswire com cms information management sharepoint 2013 office 365 get semantic search with smartlogic semaphore 018353 php cmswire sharepoint 2013 office 365 get semantic search with smartlogic semaphore ref google search appliance ref https www google com enterprise marketplace viewvendorlistings vendorid 33 pli 1 google enterprise catalogue ref apache solr ref http www flatironssolutions com blog alfresco semaphore integration alfresco semaphore integration ref fast esp ref http arnoldit com wordpress 2009 10 23 smartlogic and fast esp integration stephen e arnold beyond search ref and others references reflist external links http www smartlogic com smartlogic category software companies of the united kingdom category information retrieval organizations category analytics companies category knowledge management'
b'multiple issues citation style date december 2011 technical date october 2012 abbreviations date october 2012 automatic content extraction ace is a research program for developing advanced information extraction technologies convened by the national institute of standards and technology nist from 1999 to 2008 succeeding message understanding conference muc and preceding http www nist gov tac text analysis conference goals and efforts in general objective the ace program is motivated by and addresses the same issues as the muc program that preceded it the ace program however defines the research objectives in terms of the target objects i e the entities the relations and the events rather than in terms of the words in the text for example the so called named entity task as defined in muc is to identify those words on the page that are names of entities in ace on the other hand the corresponding task is to identify the entity so named this is a different task one that is more abstract and that involves inference more explicitly in producing an answer in a real sense the task is to detect things that aren t there while the ace program is directed toward extraction of information from sound audio and image sources in addition to pure text the research effort is restricted to information extraction from text the actual transduction machine learning transduction of audio and image data into text is not part of the ace research effort although the processing of speech recognition asr and optical character recognition ocr output from such transducers is the effort involves defining the research tasks in detail collecting and annotating data needed for training development and evaluation supporting the research with evaluation tools and research workshop s topics and exercises given a text in natural language the ace challenge is to detect entities mentioned in the text such as persons organizations locations facilities weapons vehicles and geo political entities relations between entities such as person a is the manager of company b relation types include role part located near and social events mentioned in the text such as interaction movement transfer creation and destruction the program relates to english language english arabic language arabic and chinese language chinese texts the ace corpus is one of the standard benchmarks for testing new information extraction algorithm s references george doddington nis t alexis mitchell ld c mark przybocki nis t lance ramshaw bb n stephanie strassel ld c ralph weischedel bb n http www citeulike org user erelsegal halevi article 10003935 the automatic content extraction ace program tasks data and evaluation 2004 external links http www itl nist gov iaui 894 02 related projects muc muc ace s predecessor http projects ldc upenn edu ace ace ldc http www itl nist gov iad 894 01 tests ace ace nist category information retrieval organizations'
b'infobox company name artificial solutions logo image artificial solutions logo png type private company foundation 2001 founder johan \xc3\xa5hlund johan gustavsson and michael s\xc3\xb6derstr\xc3\xb6m location barcelona spain locations offices worldwide with r d centers in barcelona hamburg london mountain view california mountain view milan utrecht and stockholm industry computer software natural language intelligent software assistant products teneo platform homepage http www artificial solutions com www artificial solutions com artificial solutions is a multinational software company that develops and sells natural language interaction products for enterprise and consumer use ref cite web last ion first florence url http arstechnica com gadgets 2013 06 review indigo brings siri like conversation to the android platform title review indigo wants to bring siri like conversation to the android platform publisher ars technica date 2013 06 05 accessdate 2013 09 08 ref the company s natural language solutions have been deployed in a wide range of industries including finance ref cite web last thompson first scott title agria working with artificial solutions url http www fstech co uk fst agriadjurf c3 b6rs c3 a4kring artificialsolutions php work fstech publisher perspective publishing accessdate 12 september 2013 ref ref cite web last savvas first antony title co operative bank uses mia to speed up contact centre calls url http www computerworlduk com news it business 3316914 co operative bank uses mia to speed up contact centre calls work computerworld uk publisher idg accessdate 12 september 2013 ref ref cite web last thompson first scott title 2012 fstech awards winners announced url http www fstech co uk fst 2012 fstechawards winners php work fstech publisher perspective publishing accessdate 12 september 2013 ref telecoms ref cite web last westerholm first joel title telenors elektroniska kundtj\xc3\xa4nst pressar kostnaderna url http computersweden idg se 2 2683 1 143425 work computersweden publisher idg accessdate 12 september 2013 ref ref cite web title artificial solutions powers online iva for vodafone url http langtechnews hivefire com articles 262940 artificial solutions powers online iva for vodafon work langtechnews accessdate 12 september 2013 ref the public sector ref cite web last brax first sofia title digitala kolleger alltid till tj\xc3\xa4nst url http www publikt se artikel digitala kolleger alltid till tjanst 38087 work publik publisher fackforbundet st accessdate 12 september 2013 ref ref cite web last nilsson first orjan title cyber damene husker deg url http www nettavisen no innenriks ibergen article1609734 ece work nettavisen publisher ibergen ref retail ref cite web author aaron travis url http techcrunch com 2013 01 05 in defense of the humble walkthrough title in defense of the humble app walkthrough publisher techcrunch date 2013 01 05 accessdate 2013 09 08 ref and travel ref cite web last fox first linda title cwt brings virtual face to mobile service url http www tnooz com 2013 04 16 news cwt brings virtual face to mobile service work tnooz accessdate 12 september 2013 ref history artificial solutions was founded in stockholm in 2001 by friends johan \xc3\xa5hlund johan gustavsson and michael s\xc3\xb6derstr\xc3\xb6m to create interactive web assistants using a combination of artificial intelligence and natural language processing though \xc3\xa5hlund initially took some persuading he thought it sounded ridiculous to be talking to a virtual agent on the internet ref cite web url http it24 idg se 2 2275 1 143922 title l\xc3\xb6jlig aff\xc3\xa4rside vinstlott f\xc3\xb6r artificial solutions publisher it24 date accessdate 2013 09 08 ref the company expanded with the development of online customer service optimization products and by 2005 it had several offices throughout europe supporting the development and sales of its online virtual assistants ref cite web url http www elnuevolunes es historico 2008 1294 1294 20al 20grano html title al grano publisher elnuevolunes es date accessdate 2013 09 08 ref artificial solutions was placed as visionary in the latest gartner magic quadrant for crm web customer service applications ref cite web author barry levine url http www cmswire com cms customer experience gartner mq for crm web customer service kana moxie software oraclerightnow among leaders 019626 php title gartner mq for crm web customer service kana moxie software oracle rightnow among leaders publisher cmswire com date accessdate 2013 09 08 ref in 2006 artificial solutions acquired kiwilogic a german software house creating its own virtual assistants ref cite web url http www earlybird com en companies tech exited kiwilogic html title venture capital kiwilogic com ag publisher earlybird date accessdate 2013 09 08 ref elbot artificial solutions test bed to explore the psychology of human machine communication won the loebner prize in 2008 and is the closest contestant of the annual competition based on the turing test to reach the 30 threshold by fooling 25 of the human judges ref loebner prize ref ref cite web url http news bbc co uk 2 hi uk news england berkshire 7666246 stm title uk 124 england 124 berkshire 124 test explores if robots can think publisher bbc news date 2008 10 13 accessdate 2013 09 08 ref ref cite web last robson first david title almost human interview with a chatbot url http www newscientist com article dn14925 almost human interview with a chatbot html ujhkztdbum9 work new scientist publisher reed business information ltd ref with a change in management in 2010 the company started to focus the basis of its technology on natural language interaction and launched the teneo platform which allows people to hold humanlike intelligent conversations with applications and services running on electronic devices ref cite web author mike elgan url http www computerworld com s article 9237448 smart apps think so you don t have to title smart apps think so you don t have to publisher computerworld date 2013 03 09 accessdate 2013 09 08 ref ref cite web url http www speechtechmag com articles news industry news artificial solutions unveils a software toolkit for adding speech to mobile apps 80015 aspx title artificial solutions unveils a software toolkit for adding speech to mobile apps publisher speechtechmag com date 2012 01 17 accessdate 2013 09 08 ref ref cite web author url http www computerworld dk art 220859 saa effektiv er ikeas chat robot har vaeret paa efteruddannelse title s\xc3\xa5 effektiv er ikeas chat robot har v\xc3\xa6ret p\xc3\xa5 efteruddannelse computerworld publisher computerworld dk date accessdate 2013 09 08 ref in 2013 artificial solutions launched indigo virtual assistant indigo a mobile personal assistant that is able to operate and remember the context of the conversation across different platforms and operating systems ref cite web last hoyle first andrew url http reviews cnet com 8301 13970 7 57570960 78 indigo brings siri like assistance to android for free hands on title indigo brings siri like assistance to android for free hands on 124 mobile world congress cnet reviews publisher reviews cnet com date 2013 02 24 accessdate 2013 09 08 ref ref cite web author url http lifehacker com indigo wants to be your personal assistant across devic 484924277 title indigo wants to be your personal assistant across devices publisher lifehacker com date accessdate 2013 09 08 ref ref cite web last wollman first dana url http www engadget com 2013 02 26 indigo personal assistant hands on title indigo is a cloud based cross platform personal assistant for android and windows phone 8 hands on publisher engadget com date 2013 02 26 accessdate 2013 09 08 ref a new round of funding was announced in june 2013 the 9 4m will be used to support expansion in the us market ref cite web url http www altassets net private equity news by news type deal news artificial solutions raises 9 4m in scope led round for us expansion html title artificial solutions raises 9 4m in scope led round for us expansion 124 altassets private equity news publisher altassets net date 2013 06 25 accessdate 2013 09 08 ref in february 2014 artificial solutions announced the teneo network of knowledge a patented intelligent framework that enables users to interact using natural language with private shared and public ecosystem of devices also known as the internet of things ref cite web last1 trenholm first1 rich title next generation of personal assistant takes a step towards her style super siri url http www cnet com news next generation of personal assistant takes a step towards her style super siri website cnet publisher cbs interactive ref references reflist 30em external links http www hello indigo com indigo http www elbot com elbot category natural language processing software category intelligent software assistants category user interfaces category artificial intelligence applications category natural language processing category computational linguistics category information retrieval organizations'
b'the gerard salton award is presented by the association for computing machinery acm special interest group on information retrieval sigir every three years to an individual who has made significant sustained and continuing contributions to research in information retrieval sigir also co sponsors with sigweb the vannevar bush award for the best paper at the joint conference on digital libraries chronological honorees and lectures 1983 gerard salton cornell university about the future of automatic information retrieval 1988 karen sp\xc3\xa4rck jones university of cambridge a look back and a look forward 1991 cyril cleverdon cranfield institute of technology the significance of the cranfield tests on index languages 1994 william s cooper university of california berkeley the formalism of probability theory in ir a foundation or an encumbrance 1997 tefko saracevic rutgers university users lost summary reflections on the past future and limits of information science 2000 stephen robertson computer scientist stephen e robertson city university london city university london on theoretical argument in information retrieval br for thirty years of significant sustained and continuing contributions to research in information retrieval of special importance are the theoretical and empirical contributions to the development refinement and evaluation of probabilistic models of information retrieval 2003 w bruce croft university of massachusetts amherst information retrieval and computer science an evolving relationship br for more than twenty years of significant sustained and continuing contributions to research in information retrieval his contributions to the theoretical development and practical use of bayesian inference networks and language modelling for retrieval and to their evaluation through extensive experiment and application are particularly important the center for intelligent information retrieval which he founded illustrates the strong synergies between fundamental research and its application to a wide range of practical information management problems 2006 c j van rijsbergen university of glasgow quantum haystacks 2009 susan dumais microsoft research an interdisciplinary perspective on information retrieval 2012 norbert fuhr university of duisburg essen information retrieval as engineering science 2015 nicholas j belkin rutgers university people interacting with information external links http www acm org sigir acm sigir homepage http www sigir org awards awards html acm sigir awards category association for computing machinery category computer science awards category information retrieval organizations'
b'notability companies date july 2011 ness computing was a personal search company it was acquired by opentable in march 2014 and was shut down later that year ref cite web last lunden first ingrid title opentable buys ness for 17 3m url http techcrunch com 2014 02 06 opentable ness work techcrunch accessdate 26 march 2014 ref it was founded in october 2009 by corey reese ref http www linkedin com in coreyreese ref paul twohey ref http www linkedin com in twohey ref nikhil raghavan ref http www linkedin com in nikhilraghavan ref and steven schlansker ref http www linkedin com in stevenschlansker ref the company was headquartered in los altos california ness aimed to help people make decisions about dining nightlife entertainment shopping music travel and more the company referred to its technology as the likeness engine a combination of a recommendation engine that used machine learning to look at data from diverse sources and a traditional search engine that served up results based on these signals the free ness dining app for iphone was referred to as the netflix ref http eater com archives 2011 08 26 ness iphone app recommends restaurants using likeness score php ref or pandora radio pandora ref http gigaom com 2011 08 25 ness restaurant app ref for restaurants based on a user s ratings and preferences the service delivered recommendations for a particular time location price range and cuisine preference users could view the menu for a place via singleplatform ref http www singleplatform com ref browse instagram photos tagged at the restaurant and make reservations in the app via opentable references reflist category information retrieval organizations category software companies based in california'
b'advert date may 2012 image irf logo 350x350 png thumb 200px right irf logo the information retrieval facility irf founded 2006 and located in vienna austria was a research platform for networking and collaboration for professionals in the field of information retrieval it ceased operations in 2012 the irf had members in the following categories researchers in information retrieval ir or related scientific areas industrial corporate information management professionals patent authorities and governmental institutions students of one of the above the scientific board maristella agosti professor http www dei unipd it wdyn idsezione 1 department of information engineering university of padova gerhard budin director of the http transvienna univie ac at forschung professuren dr gerhard budin center of translation studies at the university of vienna director of the http www oeaw ac at icltt department of corpuslinguistics and text technology austrian academy of sciences jamie callan professor http www cs cmu edu callan bio html language technologies institute cmu carnegie mellon university yves chiaramella professor emeritus http www clips imag fr mrim user yves chiaramella department of computer science and applied mathematics joseph fourier university kilnam chon professor computer science department http cosmos kaist ac kr salab professor index02 html korea advanced institute of science and technology kaist w bruce croft distinguished professor http ciir cs umass edu personnel croft html department of computer science and director center for intelligent ir university of massachusetts amherst hamish cunningham research professor http www dcs shef ac uk hamish computer science department university sheffield norbert fuhr chairman of the scientific board professor http www is informatik uni duisburg de staff fuhr html institute of informatics and interactive systems university duisburg essen david hawking science leader project leader http es csiro au people dave csiro ict centre noriko kando professor http www nii ac jp index shtml en software engineering research software research division national institute of informatics nii arcot desai narasimhalu associate dean http www sis smu edu sg faculty infosys arcotdesai asp school of information systems singapore management university john tait chief scientific officer of the irf http www johntait net until july 2007 professor of intelligent information systems and associate dean of the school of computing and technology benjamin t sou director http www cityu edu hk language information sciences research centre city university of hong kong c j van rijsbergen c j van rijsbergen http www dcs gla ac uk keith dept computer science at the university of glasgow scientific goals modelling innovative and specialised information retrieval systems for global patent document collections investigating and developing an adequate technical infrastructure that allows interactive experimentation with formal mathematical retrieval concepts for very large scale document collections studying the usability of multi modal user interfaces to very large scale information retrieval systems integrating real users with actual information needs into the research process of modelling information retrieval systems to allow accurate performance evaluation ability to create different views of patent data depending on the focus of the information need defining standardised methods for benchmarking the information retrieval process in patent document collections ability to handle text and non text parts of a patent in a coherent manner designing experimenting and evaluating search engines able to retrieve structured and semi structured documents in very large scale patent collections integrating the temporal dimension of patent documents in retrieval strategies improving effectiveness and precision of patent retrieval based on ontologies and natural language understanding techniques refining ir methods that allow unstructured querying by exploiting available structure within the patent documents formal mathematical identification and specification of relevant business information needs in the field of intellectual property information investigating efficient scaling mechanisms for information retrieval taking into account the characteristics of patent data investigating and experimenting with computing architectures for very high capacity information management establishing an open escience platform that enables a standardised and easy way of creating and performing ir experiments on a common research infrastructure discovering and investigating novel use cases and business applications deriving from intellectual property information enabling the formal information retrieval natural language and semantic processing research to grow into the field of applied sciences in the global industrial context development and integration of different information access methods research on effective methods for interactive information retrieval semantic supercomputing current technologies to extract concepts from unstructured documents are extremely computational intensive to allow interactive experimentation with rich and huge text corpora the irf has built a high performance computing environment into which the latest technological advances have been implemented multi node clusters currently 80 cores up to 1024 highest speed interconnect technology single system image with large compound memory currently 320 gb up to 4 tb fully integrated configurable computing currently 4 fpga cores up to 256 the combination of these hpc features to accelerate text mining represents the irf implementation of semantic supercomputing the world patent corpus the irf aims to bring state of the art information retrieval technology to the community of patent information professionals we expect information retrieval ir technology to become the focus of information technology very soon all industry sectors can profit from applying modern and future text mining processes to the special requirements of patent research although all ideas and concepts are universally applicable to all sorts of intellectual property information patents require the most sophistication and confront us with challenging technical and organisational problems the entire body of patent related documents possibly constitutes the largest corpus of compound documents making it a rewarding target for text mining scientists and end users alike what s more patents have become a crucial issue in particular for large global corporations and universities the industrial users of patent data are among the most demanding and important information professionals as a consequence they could benefit the most from technology that relieves the burden of researching the large body of patent information research collections the irf provides a number of test data collections that have either been developed by the irf by one of its members or by third parties these data collections can be used freely for scientific experimentations the matrixware research collection marec is the first standardised patent data corpus for research purposes it consists of 19 million patent documents in different languages normalised to a highly specific xml format the collection has been developed by matrixware for the irf the clueweb09 collection is a 25 terabyte dataset of about 1 billion web pages crawled in january and february 2009 it has been created by the language technologies institute at carnegie mellon university to support research on information retrieval and related human language technologies references http www iwr co uk information world review analysis 2231880 patent medicine info retrievers page 2 patent medicine for information retrievers information world review http ecir2008 dcs gla ac uk industry html the irf and its role in professional information research ecir 2008 external links http www ir facility org official site ir facility org https www youtube com watch v xpxtru0xfea youtube the future of information retrieval part1 https www youtube com watch v dratetahbsi youtube the future of information retrieval part2 category organizations established in 2006 category computer science organizations category information retrieval organizations category education in vienna'
b'use mdy dates date september 2011 datanet or sustainable digital data preservation and access network partner was a research program of the u s national science foundation office of cyberinfrastructure the office announced a request for proposals with this title on september 28 2007 ref name datanetprogram cite web url http www nsf gov funding pgm summ jsp pims id 503141 publisher national science foundation title sustainable digital data preservation and access network partners datanet program summary date september 28 2007 accessdate october 3 2007 ref the lead paragraph of its synopsis describes the program as blockquote science and engineering research and education are increasingly digital and increasingly data intensive digital data are not only the output of research but provide input to new hypotheses enabling new scientific insights and driving innovation therein lies one of the major challenges of this scientific generation how to develop the new methods management structures and technologies to manage the diversity size and complexity of current and future data sets and data streams this solicitation addresses that challenge by creating a set of exemplar national and global data research infrastructure organizations dubbed datanet partners that provide unique opportunities to communities of researchers to advance science and or engineering research and learning blockquote the introduction in the solicitation ref name datanetsolicitation cite web url http www nsf gov publications pub summ jsp ods key nsf07601 publisher national science foundation title sustainable digital data preservation and access network partners program announcements information date september 28 2007 accessdate october 3 2007 ref goes on to say blockquote chapter 3 data data analysis and visualization of http www nsf gov pubs 2007 nsf0728 index jsp nsf s cyberinfrastructure vision for 21st century discovery presents a vision in which science and engineering digital data are routinely deposited in well documented form are regularly and easily consulted and analyzed by specialists and non specialists alike are openly accessible while suitably protected and are reliably preserved the goal of this solicitation is to catalyze the development of a system of science and engineering data collections that is open extensible and evolvable blockquote the initial plan called for a 100 million initiative five awards of 20 nbsp million each over five years with the possibility of continuing funding awards were given in two rounds in the first round for which full proposals were due on march 21 2008 two datanet proposals were awarded dataone ref cite web author william michener url https www dataone org title dataone observation network for earth publisher www dataone org accessdate 2013 01 19 display authors etal ref led by william michener at the university of new mexico covers ecology evolutionary and earth science the data conservancy ref cite web author sayeed choudhury url https dataconservancy org title data conservancy publisher dataconservancy org accessdate 2013 01 19 display authors etal ref led by sayeed choudhury of johns hopkins university focuses on astronomy earth science life sciences and social science for the second round preliminary proposals were due on october 6 2008 and full proposals on february 16 2009 awards from the second round were greatly delayed and funding was reduced substantially from 20 million per project to 8 million ref cite web author national science foundation url http www nsf gov awardsearch simplesearchresult querytext 22datanet full proposal 3a 22 title nsf datanet awards publisher www nsf gov accessdate 2013 01 19 ref funding for three second round projects began in fall 2011 sead sustainable environment through actionable data ref cite web author margaret hedstrom url http sead data net title sead sustainable environment actionable data publisher sead data net accessdate 2013 01 19 display authors etal ref led by margaret hedstrom of the university of michigan seeks to provide data curation software and services for the long tail of small and medium scale data producers in the domain of sustainability science the datanet federation consortium ref cite web author reagan moore url http datafed org title datanet federation consortium publisher datafed org accessdate 2013 01 19 display authors etal ref led by reagan moore of the university of north carolina uses the integrated rule oriented data system irods to provide data grid infrastructure for science and engineering terra populus ref cite web author steven ruggles url http www terrapop org title terra populus integrated data on population and the environment publisher terrapop org accessdate 2013 01 19 display authors etal ref led by steven ruggles of the university of minnesota focuses on tools for data integration across the domains of social science and environmental data allowing interoperability of the three major data formats used in these domains microdata areal data and raster data references reflist 30em external links http www dataone org dataone http dataconservancy org data conservancy http sead data net sead sustainable environment actionable data http datafed org datanet federation consortium http www terrapop org terra populus integrated data on population and the environment category national science foundation category science and technology in the united states category information retrieval organizations category digital library projects'
b'telqas telecommunication literature question answering system is an experimental question answering system developed for answering english questions in the telecommunications domain ref mahmoud r hejazi maryam s mirian kourosh neshatian azam jalali and bahadorreza ofoghi a telecommunication literature question answering system benefits from a text categorization mechanism international conference on information and knowledge engineering ike2003 july 2003 usa ref architecture telqas includes three main subsystems an online subsystem an offline subsystem and an ontology the online subsystem answers questions submitted by users in real time during the online process telqas processes the question using a natural language processing component that implements part of speech tagging and simple syntactic parsing the online subsystem also utilizes an inference engine in order to carry out necessary inference on small elements of knowledge the offline subsystem automatically indexes documents collected by a focused web crawler from the web an ontology server along with its api is used for knowledge representation ref kourosh neshatian and mahmoud r hejazi an object oriented ontology interface for information retrieval purposes in telecommunication domain international symposium on telecommunication ist2003 ref the main concepts and classes of the ontology are created by domain experts some of these classes however can be instantiated automatically by the offline components references references category computational linguistics category information retrieval systems category natural language processing software'
b'for the canadian magazine exclaim the extensible cross linguistic automatic information machine exclaim was an integrated tool for cross language information retrieval clir created at the university of california santa cruz in early 2006 with some support for more than a dozen languages the lead developers were justin nuger and jesse saba kirchner early work on clir depended on manually constructed parallel corpora for each pair of languages this method is labor intensive compared to parallel corpora created automatically a more efficient way of finding data to train a clir system is to use matching pages on the world wide web web which are written in different languages ref cite web title cross language information retrieval based on parallel texts and automatic mining of parallel texts in the web url http www iro umontreal ca 7enie publication nie sigir99 pdf format pdf publisher acm sigir 1999 accessdate 2006 12 02 ref exclaim capitalizes on the idea of latent parallel corpora on the world wide web web by automating the alignment of such corpora in various domains the most significant of these is wikipedia itself which includes articles in http meta wikimedia org wiki complete list of language wikipedias available 250 languages the role of exclaim is to use semantics and linguistics linguistic analytic tools to align the information in these wikipedias so that they can be treated as parallel corpora exclaim is also extensible to incorporate information from many other sources such as the chinese community health resource center cchrc one of the main goals of the exclaim project is to provide the kind of computational tools and clir tools for minority languages and endangered languages which are often available only for powerful or prosperous majority languages current status in 2009 exclaim was in a beta state with varying degrees of functionality for different languages support for clir using the wikipedia dataset and the most current version of exclaim v 0 5 including full utf 8 support and porter stemming for the english component was available for the following twenty three languages class wikitable albanian language albanian amharic bengali language bengali gothic language gothic greek language greek icelandic language icelandic indonesian language indonesian irish language irish javanese language javanese latvian language latvian malagasy language malagasy mandarin chinese nahuatl navajo language navajo quechua languages quechua sardinian language sardinian swahili language swahili tagalog language tagalog standard tibetan tibetan turkish language turkish welsh language welsh wolof language wolof yiddish support using the wikipedia dataset and an earlier version of exclaim v 0 3 is available for the following languages class wikitable dutch language dutch spanish language spanish significant developments in the most recent version of exclaim include support for mandarin chinese by developing support for this language exclaim has added solutions to text segmentation segmentation and character encoding encoding problems which will allow the system to be extended to many other languages written with non european orthographic conventions this support is supplied through the trimming and reformatting modular system tarms toolkit future versions of exclaim will extend the system to additional languages other goals include incorporation of available latent datasets in addition to the wikipedia dataset the exclaim development plan calls for an integrated clir instrument usable searching from english for information in any of the supported languages or searching from any of the supported languages for information in english when exclaim 1 0 is released future versions will allow searching from any supported language into any other and searching from and into multiple languages further applications exclaim has been incorporated into several projects which rely on cross language query expansion as part of their front and back ends backend s one such project is a cross linguistic readability software generation framework detailed in work presented at association for computational linguistics acl 2009 ref cite web title a crosslinguistic readability framework url http www aclweb org anthology w w09 w09 3103 pdf format pdf publisher acl ijnlp 2009 accessdate 2009 09 04 ref notes and references reflist external links http www soe ucsc edu jnuger cgi bin exclaim cgi exclaim website dead link http www w3 org designissues semantic html semantic web roadmap http www cchphmo com cchrchealth index e html chinese cultural health resource center http ju st in justin nuger s professional webpage defaultsort exclaim category information retrieval systems'
b'orphan date february 2009 infobox website name chemrefer logo image chemrefer png screenshot caption url http www chemrefer com commercial yes type search engine language english registration not applicable owner chemrefer limited author william james griffiths launch date 2006 current status offline revenue chemrefer is a service that allows searching of freely available and full text chemical and pharmaceutical literature that is published by authoritative sources ref citation journal science articles title science news forum publisher sciscoop date may 19 2006 url http www sciscoop com story 2006 5 19 95844 6293 ref features include basic and advanced search options mouseover detailed view an integrated chemical structure drawing and search tool downloadable toolbar customized rss feeds and newsletter chemrefer is primarily of use to readers who do not have subscriptions for accessing restricted chemical literature and to publishers who offer either open access publishing open access or hybrid open access journal s and seek to attract further subscriptions by publicly releasing part of their archive see also google scholar windows live academic base search engine base pubmed references reflist external links recommendations reviews https web archive org web 20060902072725 http www rowland harvard edu resources library lnn archive 031706 php cited as an internet site of the week by the library of the rowland institute for science at harvard university https web archive org web 20070804051550 http infoweb nrl navy mil 80 index cfm i 156 recommended in the list of chemical literature databases by the library of the united states naval research laboratory https web archive org web 20070212122105 http www mta ca 80 library subject chemistry html recommended in the list of chemical literature databases by the library of mount allison university http depth first com articles 2007 01 15 chemrefer free direct access to the primary literature review of chemrefer at depth first chemoinformatics magazine https web archive org web 20080917155607 http recherche technologie wallonie be 80 fr particulier menu revue athena l annuaire de liens internet moteurs de recherche www chemrefer com html profil part recommended in the list of chemical literature databases by the technology research portal belgium http www certh gr 0e9bf53c en aspx recommended in the list of chemical literature databases by the centre for research and technology thessaloniki background http www reactivereports com 56 56 0 html interview with william james griffiths at reactive reports chemistry magazine http www earlham edu peters fos overview htm open access overview by professor peter suber earlham college category scholarly search services category chemistry literature category information retrieval systems category open access projects searchengine website stub'
b'multiple issues coi date september 2014 notability products date september 2014 autindex is a commercial text mining software package based on sophisticated linguistics ref ripplinger b\xc3\xa4rbel 2001 das indexierungssystem autindex in gldv tagung giessen ref ref paul schmidt mahmoud gindiyeh gintare grigonyte 2009 language technology for information systems in proceedings of kdir the international joint conference on knowledge discovery knowledge engineering and knowledge management madeira 6 8 october 2009 portugal ref ref paul schmidt mahmoud gindiyeh 2009 language technology for multilingual information and document management in proceedings of aslib london 19 20 november ref autindex resulting from research in information extraction ref paul schmidt thomas b\xc3\xa4hr dr ing jens biesterfeld thomas risse kerstin denecke claudiu firan 2008 linsearch aufbereitung von fachwissen f\xc3\xbcr die gezielte informationsversorgung in proceedings of knowtech frankfurt ref ref ursula deriu j\xc3\xb6rn lehmann paul schmidt 2009 \xe2\x80\x9aerstellung einer technik ontologie auf der basis ausgefeilter sprachtechnologie in proceedings knowtech frankfurt ref is a product of the institute of applied information sciences iai which is a non profit institute that has been researching and developing language technology since its foundation in 1985 iai is an institute affiliated to saarland university in saarbr\xc3\xbccken germany autindex is the result of a number of research projects funded by the eu project bindex ref www lrec conf org proceedings lrec2002 pdf 255 pdf dieter maas nuebel rita catherine pease paul schmidt bilingual indexing for information retrieval with autindex lrec 2002 ref by deutsche forschungsgemeinschaft and the german ministry for economy amongst the latter there are the projects linsearch ref www l3s de ar07 layout l3s ar2007 screen pdf project linsearch p 32 ref and wissmer ref www wissmer info index php de project wissmer ref see also the reference to iai webite ref www iai sb de forschung content view 67 89 wissmer project on iai site ref the basic functionality of autindex is the extraction of key words from a document to represent the semantics of the document ref paul schmidt mahmoud gindiyeh gintare grigonyte language technology for information systems in proceedings of kdir the international joint conference on knowledge discovery knowledge engineering and knowledge management madeira 6 8 oktober 2009 portugal 2009 s 259 262 ref ideally the system is integrated with a thesaurus that defines the standardised terms to be used for key word assignment br autindex is used in library applications e g integrated in dandelon com as well as in high quality expert information systems ref www wti frankfurt de wti information system ref and in document management and content management environments br together with autindex a number of additional software comes along such as an integration with apache solr lucene to provide a complete information retrieval environment a classification and categorisation system on the basis of a machine learning ref mahmoud gindiyeh anwendung wahrscheinlichkeitstheoretischer methoden in der linguistischen informationsverarbeitung logos verlag berlin 2013 ref software that assigns domains to the document and a system for searching with semantically similar terms that are collected in so called tag clouds ref www wissmer info electro mobility information system ref see also information retrieval linguistics knowledge management natural language processing semantics references reflist publications ripplinger b\xc3\xa4rbel 2001 das indexierungssystem autindex in gldv tagung giessen paul schmidt thomas b\xc3\xa4hr dr ing jens biesterfeld thomas risse kerstin denecke claudiu firan 2008 linsearch aufbereitung von fachwissen f\xc3\xbcr die gezielte informationsversorgung in proceedings of knowtech frankfurt paul schmidt mahmoud gindiyeh gintare grigonyte language technology for information systems in proceedings of kdir the international joint conference on knowledge discovery knowledge engineering and knowledge management madeira 6 8 oktober 2009 portugal 2009 s 259 262 paul schmidt mahmoud gindiyeh language technology for multilingual information and document management in proceedings of aslib london 19 20 november 2009 r\xc3\xb6sener christoph ulrich herb automatische schlagwortvergabe aus der swd f\xc3\xbcr repositorien zusammen mit ulrich herb in proceedings berufsverband information bibliothek bibliothekartage 97 deutscher bibliothekartag mannheim 2008 svenja siedle suchst du noch oder wei\xc3\x9ft du schon inhaltserschlie\xc3\x9fung leicht gemacht mit automatischer indexierung in tekom jahrestagung und tcworld conference 2013 michael gerards adreas gerards peter weiland der einsatz der automatischen indexierungssoftware autindex im zentrum f\xc3\xbcr psychologische information und dokumentation zpid 2006 http zpid de download psyndexmaterial autindex pdf online bei zpid de pdf datei mahmoud gindiyeh anwendung wahrscheinlichkeitstheoretischer methoden in der linguistischen informationsverarbeitung logos verlag berlin 2013 external links http www iai sb de institute for applied information sciences category natural language processing category information retrieval systems'
b'lowercase title agrep infobox software name agrep logo image name is enough logo caption logo size logo alt screenshot image name is enough caption screenshot size screenshot alt collapsible developer plainlist udi manber sun wu released start date and age yyyy mm dd df yes no discontinued latest release version latest release date start date and age yyyy mm dd df yes no latest preview version latest preview date start date and age yyyy mm dd df yes no frequently updated do not include this parameter unless you know what it does status programming language c operating system plainlist unix like os 2 dos microsoft windows windows platform size language language footnote genre pattern matching license https raw githubusercontent com wikinaut agrep master copyright isc open source license standard website url http www tgries de agrep agrep approximate grep is an open source approximate string matching program developed by udi manber and sun wu between 1988 and 1991 for use with the unix operating system it was later ported to os 2 dos and microsoft windows windows it selects the best suited algorithm for the current query from a variety of the known fastest built in string searching algorithm s including manber and wu s bitap algorithm based on levenshtein distance s agrep is also the search engine computing search engine in the indexer program glimpse agrep is under a free isc license ref http webglimpse net sublicensing licensing html webglimpse glimpse and also agrep license since 18 09 2014 http opensource org licenses isc isc license ref alternative implementations a more recent agrep is the command line tool provided with the tre computing tre regular expression library tre agrep is more powerful than wu manber agrep since it allows weights and total costs to be assigned separately to individual groups in the pattern it can also handle unicode ref cite web title tre tre regexp matching package features url http laurikari net tre about ref unlike wu manber agrep tre agrep is licensed under a bsd licenses bsd style licenses 2 clause bsd like license frej fuzzy regular expressions for java open source library provides command line interface which could be used in the way similar to agrep unlike agrep or tre it could be used for constructing complex substitutions for matched text ref cite web title frej fuzzy regular expressions for java guide and examples url http frej sf net rules html ref however its syntax and matching abilities differs significantly from ones of ordinary regular expression s references reflist external links wu manber agrep http www tgries de agrep agrep home page ftp ftp cs arizona edu agrep for unix to compile under osx 10 8 add code wno return type code to the code cflags o code line in the makefile http wiki christophchamp com index php agrep command entry for agrep in christoph s personal wiki see also http laurikari net tre tre regexp matching package https web archive org web 20080513225010 http www1 bell labs com project wwexptools cgrep cgrep a defunct command line approximate string matching tool http www dcc uchile cl gnavarro software nrgrep a command line approximate string matching tool http finzi psych upenn edu r library base html agrep html agrep as implemented in r category information retrieval systems category unix text processing utilities category software using the isc license'
b'ibm omnifind was an enterprise search platform from ibm it did come in several packages adapted to different business needs including omnifind enterprise edition omnifind enterprise starter edition and omnifind discovery edition ref http www 01 ibm com software ecm omnifind library html ibm omnifind library ref ibm omnifind as a standalone product was withdrawn in april 2011 ref http www 01 ibm com common ssi cgi bin ssialias subtype ca infotype an appname isource supplier 897 letternum enus911 075 ibm us announcement letter ref and is now part of ibm watson content analytics with enterprise search ref http www 01 ibm com common ssi cgi bin ssialias infotype an subtype ca htmlfid 897 enus211 133 ibm us announcement letter ref ibm omnifind yahoo edition was a free of charge version that could handle up to 500 000 documents in its index and was intended for small businesses ibm omnifind yahoo edition was simple to install provided a user friendly front end for administration and incorporated technology from the open source lucene project ibm withdrew this product from marketing effective september 22 2010 and withdrew support effective june 30 2011 ref http www 01 ibm com common ssi cgi bin ssialias subtype ca infotype an appname isource supplier 897 letternum enus910 115 ibm us announcement letter ref ibm omnifind personal e mail search was a research product launched in 2007 for doing semantic search over personal emails by extracting and organizing concepts and relationships such as phone numbers and addresses the project appears to have been silently abounded sometimes around 2010 see also languageware uima comparison of enterprise search software list of enterprise search vendors external links http www ibm com software data enterprise search ibm omnifind http omnifind ibm yahoo com ibm omnifind yahoo edition dead link date may 2012 https web archive org web 20071030125647 http www alphaworks ibm com tech emailsearch ibm omnifind personal e mail search http www opentestsearch com search engines ibm omnifind yahoo edition review online demo and review of ibm omnifind yahoo edition notes reflist category ibm software omnifind category information retrieval systems'
b'unreferenced stub auto yes date december 2009 lowercase title ptx ptx is a unix utility named for the permuted index which can perform the function of the keyword in context kwic search mode there is a corresponding ibm mainframe utility which performs the same function permuted indexes are often used in such places as bibliographic or medical databases thesaurus es or web sites to aid in locating entries of interest see also concordancer category information retrieval systems category unix text processing utilities unix stub'
b'lowercase code locate code is a unix utility which serves to find computer file file s on filesystem s it searches through a prebuilt database of files generated by the code updatedb code command or by a daemon computing daemon and compressed using incremental encoding it operates significantly faster than code find code but requires regular updating of the database this sacrifices overall efficiency because of the regular interrogation of filesystems even when no user needs information and absolute accuracy since the database does not update in real time computing real time for significant speed improvements particularly on very large filesystems code locate code was first created in 1982 ref cite magazine last woods first james a date 1983 01 15 title finding files fast url https archive org stream login feb83 login feb83 issue page n9 mode 2up magazine login volume 8 issue 1 pages 8 10 publisher usenix access date 2016 03 27 ref the bsd and gnu findutils versions derive from the original implementation ref cite web url https www gnu org software findutils manual html node find html introduction html introduction title finding files date 2012 11 17 website gnu publisher free software foundation access date 2016 03 27 quote gnu locate and its associated utilities were originally written by james woods with enhancements by david mackenzie ref their primary database is world readable so the index is built as an unprivileged user code mlocate code merging locate and the earlier code slocate code secure locate use a restricted access database only showing filenames accessible to the user ref cite web url http carolina mff cuni cz trmac blog mlocate archive url https web archive org web 20060411074142 http carolina mff cuni cz trmac blog mlocate archive date 2006 04 11 title mlocate date 2005 author miloslav trma\xc4\x8d access date 2016 03 27 quote faster and does not trash the system caches as much attempts to be compatible to gnu locate when it does not conflict with slocate compatibility dead url yes ref ref cite web url http www geekreview org slocate archive url https web archive org web 20050507092723 http www geekreview org slocate archive date 2005 05 07 title secure locate date 1999 author kevin lindsay access date 2016 03 27 quote will also check file permissions and ownership so that users will not see files they do not have access to dead url yes ref references reflist external links https www gnu org software findutils findutils html gnu findutils https fedorahosted org mlocate mlocate man 1 locate freebsd man 1 locate openbsd variants http rlocate sourceforge net rlocate variant using kernel module and daemon for continuous updates http www kde apps org content show php kwickfind locate gui frontend content 54817 kwickfind kde gui frontend for locate http www locate32 net locate32 for windows gpl ed graphical windows variant unix commands category gnu project software category unix file system related software category information retrieval systems unix stub'
b'other uses refimprove date june 2016 lowercase title find in unix like and some other operating system s code find code is a command line utility that search engine computing searches one or more directory tree s of a file system locates computer file file s based on some user computing user specified criteria and applies a user specified action on each matched file the possible search criteria include a pattern matching pattern to match against the filename or a time range to match against the modification time or access time of the file by default code find code returns a list of all files below the current working directory the related code locate unix locate code programs use a database of indexed files obtained through code find code updated at regular intervals typically by code cron code job to provide a faster method of searching the entire file system for files by name history code find code appeared in version 5 unix as part of the pwb unix programmer s workbench project and was written by dick haight alongside cpio ref name reader cite techreport first1 m d last1 mcilroy authorlink1 doug mcilroy year 1987 url http www cs dartmouth edu doug reader pdf title a research unix reader annotated excerpts from the programmer s manual 1971 1986 series cstr number 139 institution bell labs ref which were designed to be used together ref cite web title libarchive libarchive url https github com libarchive libarchive wiki formatcpio website github accessdate 2015 10 04 ref find syntax expand section date august 2008 source lang bash find h l p path expression source the three options control how the code find code command should treat symbolic links the default behaviour is never to follow symbolic links this can be explicitly specified using the p flag the l flag will cause the code find code command to follow symbolic links the h flag will only follow symbolic links while processing the command line arguments these flags are not available with some older versions of code find code at least one path must precede the expression code find code is capable of interpreting wildcard character wildcards internally and commands must be constructed carefully in order to control glob programming shell globbing expression elements are whitespace separated and evaluated from left to right they can contain logical elements such as and x2011 and or x2011 a and or x2011 or x2011 o as well as more complex predicates the gnu find utilities gnu code find code has a large number of additional features not specified by posix posix protection from infinite output real world file systems often contain looped structures created through the use of hard link hard or symbolic link soft links the posix posix standard requires that quotation the code find code utility shall detect infinite loops that is entering a previously visited directory that is an ancestor of the last file encountered when it detects an infinite loop code find code shall write a diagnostic message to standard error and shall either recover its position in the hierarchy or terminate operators operators can be used to enhance the expressions of the find command operators are listed in order of decreasing precedence expr forces precedence expr true if expr is false expr1 expr2 or expr1 a expr2 and expr2 is not evaluated if expr1 is false expr1 o expr2 or expr2 is not evaluated if expr1 is true source lang bash find name filea o name fileb source this command searches the current working directory tree for files whose names start with filea or fileb source lang bash find name foo cpp path svn source this command searches the current working directory tree except the subdirectory tree svn for files whose name is foo cpp we quote the code code so that it s not interpreted by the shell as the history substitution character type filter explanation various type filters are supported by code find code they are activated using the configuration switch source lang bash find type x source where x may be any of b device file block device buffered c device file character device unbuffered d directory computing directory f regular file l symbolic link this is never true if the l option or the follow operator is in effect unless the symbolic link is broken if you want to search for symbolic links when l is in effect use xtype though that is a gnu extension p named pipe s unix domain socket socket d doors computing door the configuration switches listed in bold are most commonly used examples howto section date september 2016 from the current working directory source lang bash find name my source this searches the current working directory tree for files whose names start with my the single quotes avoid the shell computing shell expansion without them the shell would replace my with the list of files whose names begin with my in the current working directory in newer versions of the program the directory may be omitted and it will imply the current working directory regular files only source lang bash find name my type f source this limits the results of the above search to only regular files therefore excluding directories special files symbolic links etc my is enclosed in single quotes apostrophes as otherwise the shell would replace it with the list of files in the current working directory starting with my \xe2\x80\xa6 commands the previous examples created listings of results because by default code find code executes the code print code action note that early versions of the code find code command had no default action at all therefore the resulting list of files would be discarded to the bewilderment of users source lang bash find name my type f ls source this prints extended file information search all directories source lang bash find name myfile type f print source this searches every directory for a regular file whose name is myfile and prints it to the screen it is generally not a good idea to look for files this way this can take a considerable amount of time so it is best to specify the directory more precisely some operating systems may mount dynamic file systems that are not congenial to code find code more complex filenames including characters special to the shell may need to be enclosed in single quotes search all but one subdirectory tree source lang bash find path excluded path prune o type f name myfile print source this searches every directory except the subdirectory tree excluded path full path including the leading that is pruned by the code prune code action for a regular file whose name is myfile specify a directory source lang bash find home weedly name myfile type f print source this searches the home weedly directory tree for regular files named myfile you should always specify the directory to the deepest level you can remember search several directories source lang bash find local tmp name mydir type d print source this searches the local subdirectory tree of the current working directory and the tmp directory tree for directories named mydir ignore errors if you re doing this as a user other than root you might want to ignore permission denied and any other errors since errors are printed to stderr they can be suppressed by redirecting the output to dev null the following example shows how to do this in the bash shell source lang bash find name myfile type f print 2 dev null source if you are a c shell csh or tcsh user you cannot redirect stderr without redirecting stdout as well you can use sh to run the code find code command to get around this source lang bash sh c find name myfile type f print 2 dev null source an alternate method when using c shell csh or tcsh is to pipe the output from stdout and stderr into a grep command this example shows how to suppress lines that contain permission denied errors source lang bash find name myfile grep v permission denied source find any one of differently named files source lang bash find name jsp o name java type f ls source the code ls code operator prints extended information and the example finds any regular file whose name ends with either jsp or java note that the parentheses are required tin many shells the parentheses must be escaped with a backslash code code and code code to prevent them from being interpreted as special shell characters the code ls code operator is not available on all versions of code find code execute an action source lang bash find var ftp mp3 name mp3 type f exec chmod 644 source this command changes the file system permissions permissions of all regular files whose names end with mp3 in the directory tree var ftp mp3 the action is carried out by specifying the statement code exec chmod 644 code in the command for every regular file whose name ends in code mp3 code the command code chmod 644 code is executed replacing code code with the name of the file the semicolon backslashed to avoid the shell interpreting it as a command separator indicates the end of the command permission code 644 code usually shown as code rw r r code gives the file owner full permission to read and write the file while other users have read only access in some shells the code code must be quoted the trailing is customarily quoted with a leading but could just as effectively be enclosed in single quotes note that the command itself should not be quoted otherwise you get error messages like source lang console find echo mv 3bfn rel071204 no such file or directory source which means that code find code is trying to run a file called echo mv 3bfn rel071204 and failing if you will be executing over many results it is more efficient to use a variant of the exec primary that collects filenames up to arg max and then executes command with a list of filenames source lang bash find exec command source this will ensure that filenames with whitespaces are passed to the executed command without being split up by the shell delete files and directories the code delete code action is a gnu extension and using it turns on code depth code so if you are testing a find command with code print code instead of code delete code in order to figure out what will happen before going for it you need to use code depth print code delete empty files and print the names note that code empty code is a vendor unique extension from gnu code find code that may not be available in all code find code implementations source lang bash find empty delete print source delete empty regular files source lang bash find type f empty delete source delete empty directories source lang bash find type d empty delete source delete empty files named bad source lang bash find name bad empty delete source warning the code delete code action should be used with conditions such as code empty code or code name code source lang bash find delete this deletes all in source search for a string this command will search all files from the tmp directory tree for a string source lang bash find tmp type f exec grep search string dev null source the tt dev null tt argument is used to show the name of the file before the text that is found without it only the text found is printed gnu code grep code can be used on its own to perform this task source lang bash grep r search string tmp source example of search for log in jsmith s home directory tree source lang bash find jsmith exec grep log dev null print home jsmith scripts errpt sh cp log fixedlogname home jsmith scripts errpt sh cat log home jsmith scripts title user logname source example of search for the string error in all xml files in the current working directory tree source lang bash find name xml exec grep error dev null source the double quotes surrounding the search string and single quotes nowiki nowiki surrounding the braces are optional in this example but needed to allow spaces and some other special characters in the string note with more complex text notably in most popular shells descended from sh and csh single quotes are often the easier choice since double quotes do not prevent all special interpretation quoting filenames which have english contractions demonstrates how this can get rather complicated since a string with an apostrophe in it is easier to protect with double quotes source lang bash find name file containing can t exec grep can t print source search for all files owned by a user source lang bash find user userid source search in case insensitive mode note that code iname code is not in the standard and may not be supported by all implementations source lang bash find iname myfile source if the code iname code switch is not supported on your system then workaround techniques may be possible such as source lang bash find name mm yy ff ii ll ee source this uses perl to build the above command for you though in general this kind of usage is dangerous since special characters are not properly quoted before being fed into the standard input of sh source lang bash echo myfile perl pe s a za z l 1 u 1 g s find name 1 sh source search files by size searching files whose size is between 100 kilobytes and 500 kilobytes source lang bash find size 100k a size 500k source searching empty files source lang bash find size 0k source searching non empty files source lang bash find size 0k source search files by name and size source lang bash find usr src name v o name v print source this command will search the usr src directory tree all files that are of the form v and v are excluded important arguments to note are in the tooltip that is displayed on mouse over source lang bash enclose div for file in find opt name error log o name access log o name ssl engine log o name rewrite log o name catalina out size 300000k a size 5000000k do cat dev null file done source the units should be one of bckw b means 512 byte blocks c means byte k means kilobytes and w means 2 byte words the size does not count indirect blocks but it does count blocks in sparse files that are not actually allocated related utilities code locate unix locate code is a unix search tool that searches a prebuilt database of files instead of directory trees of a file system this is faster than code find code but less accurate because the database may not be up to date code grep code is a command line utility for searching plain text data sets for lines matching a regular expression and by default reporting matching lines on standard output code tree unix tree code is a command line utility that recursively lists files found in a directory tree indenting the filenames according to their position in the file hierarchy gnu find utilities also known as findutils is a gnu package which contains implementations of the tools code find code and xargs busybox is a utility that provides several stripped down unix tools in a single executable file intended for embedded operating systems with very limited resources it also provides a version of code find code code dir command dir code has the s option that recursively searches for files or directories see also mdfind a similar utility that utilizes metadata for mac os x and darwin operating system darwin list of unix programs list of dos commands filter higher order function find command a dos and windows command that is very different from unix code find code references reflist external links man cu find sus find files https www gnu org software findutils manual html mono find html official webpage for gnu find http www librebyte net en gnulinux command find 25 practical examples command find 25 practical examples unix commands category information retrieval systems category standard unix programs category unix sus2008 utilities'
b'redirect reverse dns java like naming convention reverse domain name notation refimprove date september 2016 in computer networking reverse dns lookup or reverse dns resolution rdns is the determination of a domain name associated with an ip address via querying domain name system dns the reverse of the usual forward dns lookup of an ip from a domain name the process of reverse resolving an ip address uses ptr record s the reverse dns database of the internet is rooted in the arpa arpa top level domain although the informational rfc 1912 section 2 1 specifies that every internet reachable host should have a name and that for every ip address there should be a matching ptr record it is not an internet standard requirement and not all ip addresses have a reverse entry implementation details ipv4 reverse resolution reverse dns lookups for ipv4 addresses use the special domain code in addr arpa code in this domain an ipv4 address is represented as a concatenated sequence of four decimal numbers separated by dots to which is appended the second level domain suffix code in addr arpa code the four decimal numbers are obtained by splitting the 32 bit ipv4 address into four octet computing octet s and converting each octet into a decimal number these decimal numbers are then concatenated in the order least significant octet first leftmost most significant octet last rightmost it is important to note that this is the reverse order to the usual dotted decimal convention for writing ipv4 addresses in textual form for example to do a reverse lookup of the ip address code 8 8 4 4 code the ptr record for the domain name code 4 4 8 8 in addr arpa code would be looked up and found to point to code google public dns b google com code if the a record for code google public dns b google com code in turn pointed back to code 8 8 4 4 code then it would be said to be forward confirmed reverse dns forward confirmed classless reverse dns method historically internet registries and internet service providers allocated ip addresses in blocks of 256 for class c or larger octet based blocks for classes b and a by definition each block fell upon an octet boundary the structure of the reverse dns domain was based on this definition however with the introduction of classless inter domain routing ip addresses were allocated in much smaller blocks and hence the original design of pointer records was impractical since autonomy of administration of smaller blocks could not be granted rfc 2317 devised a methodology to address this problem by using cname record s ipv6 reverse resolution reverse dns lookups for ipv6 addresses use the special domain code ip6 arpa code previously code ip6 int code ref rfc 4159 ref an ipv6 address appears as a name in this domain as a sequence of nibble s in reverse order represented as hexadecimal digits as subdomains for example the pointer domain name corresponding to the ipv6 address code 2001 db8 567 89ab code is code b a 9 8 7 6 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 b d 0 1 0 0 2 ip6 arpa code multiple pointer records while most rdns entries only have one ptr record dns does not restrict the number however having multiple ptr records for the same ip address is generally not recommended by whom date august 2016 unless there is a specific need for example if a web server supports many virtual host s there may be one ptr record for each host and some versions of name server software will allocate this automatically multiple ptr records can cause problems however including triggering bugs in programs that only expect single ptr records ref http sources redhat com bugzilla show bug cgi id 5790 glibc bug 5790 ref in the case of a large web server having hundreds of ptr records can cause the dns packets to be much larger than normal which can cause the query to be requested over tcp when they exceed the dns 512 byte udp message limit records other than ptr records record types other than ptr records may also appear in the reverse dns tree for example encryption keys may be placed there for ipsec secure shell ssh and internet key exchange ike zero configuration networking dns sd dns based service discovery uses specially named records in the reverse dns tree to provide hints to clients about subnet specific service discovery domains ref citation publisher ietf title rfc 6763 url http tools ietf org html rfc6763 section 11 ref less standardized usages include comments placed in txt record s and loc record s to identify the geophysical location of an ip address uses the most common uses of the reverse dns include the original use of the rdns network troubleshooting via tools such as traceroute ping networking utility ping and the received trace header field for smtp e mail web sites tracking users especially on internet forum s etc one anti spam techniques e mail ptr 2freverse dns checks e mail anti spam technique checking the domain names in the rdns to see if they are likely from dialup users or dynamically assigned addresses unlikely to be used by legitimate mail servers owners of such ip addresses typically assign them generic rdns names such as 1 2 3 4 dynamic ip example com some anti spam filters assume that email that originates from such addresses is likely to be spam and may refuse connection ref http www spamhaus org faq answers lasso section isp 20spam 20issues 131 spamhaus s faq ref ref http postmaster aol com info rdns html reference page from aol webarchive url https web archive org web 20061210223820 http postmaster aol com info rdns html date december 10 2006 ref a forward confirmed reverse dns fcrdns verification can create a form of authentication showing a valid relationship between the owner of a domain name and the owner of the server that has been given an ip address while not very thorough this validation is strong enough to often be used for whitelist ing purposes since spam electronic spammers and phishing phishers usually cannot achieve forward validation when they use zombie computer s to forge domain records system logging or monitoring tools often receive entries with the relevant devices specified only by ip addresses to provide more human usable data these programs often perform a reverse lookup before writing the log thus writing a name rather than the ip address references reflist external links dmoz computers internet protocols dns web tools web based dns lookup tools http dns icann org icann dns operations https tools ietf org html rfc3596 rfc 3596 dns extensions to support ip version 6 rdns policies https web archive org web 20121106162649 http postmaster aol com 80 postmaster errors php 554rlyb1 whatisrdns aol http customer comcast com help and support internet fix a 554 error comcast http www craigslist org about help rdns failure craigslist https www misk com kb reverse dns misk com category information retrieval systems category domain name system nl domain name system omgekeerde lookups'
b'a statistically improbable phrase sip is a phrase or set of words that occurs more frequently in a document or collection of documents than in some larger text corpus corpus ref cite web url http courses cms caltech edu cs145 2011 wikipedia pdf title sipping wikipedia website courses cms caltech edu accessdate 2017 01 01 ref ref cite web url https www plagiarismtoday com 2012 07 03 how long should a statistically improbably phrase be title how long should a statistically improbably phrase be author jonathan bailey date 3 july 2012 work plagiarism today ref ref cite journal url http bioinformatics oxfordjournals org content 26 11 1453 title identifying duplicate content using statistically improbable phrases first1 mounir last1 errami first2 zhaohui last2 sun first3 angela c last3 george first4 tara c last4 long first5 michael a last5 skinner first6 jonathan d last6 wren first7 harold r last7 garner date 1 june 2010 publisher journal bioinformatics volume 26 issue 11 pages 1453 1457 accessdate 1 january 2017 via bioinformatics oxfordjournals org doi 10 1093 bioinformatics btq146 pmid 20472545 pmc 2872002 ref amazon com uses this concept in determining keywords for a given book or chapter since keywords of a book or chapter are likely to appear disproportionately within that section ref cite web url http www amazon com gp search inside sipshelp html title what are statistically improbable phrases accessdate 2007 12 18 publisher amazon com ref ref cite news url http www washingtonpost com wp dyn content article 2005 08 29 ar2005082901873 html title amazon s vital statistics show how books stack up last weeks first linton work the washington post date august 30 2005 accessdate september 8 2015 ref christian rudder has also used this concept with data from online dating service online dating profiles and twitter posts to determine the phrases most characteristic of a given race or gender in his book dataclysm ref cite book last rudder first christian date 2014 title dataclysm who we are when we think no one s looking location new york publisher crown publishers page isbn 978 0 385 34737 2 ref example in a document about computer s the most common word is likely to be the word the but since the is the most commonly used word in the english language it is likely that any given document will have the word the used very frequently however a word like program might occur in the document at a much higher rate than its average rate in the english language hence it is a word unlikely to occur in any given document but did occur in the document given program would be a statistically improbable phrase the statistically improbable phrases of darwin s on the origin of species are temperate productions genera descended transitional gradations unknown progenitor fossiliferous formations our domestic breeds modified offspring doubtful forms closely allied forms profitable variations enormously remote transitional grades very distinct species and mongrel offspring ref http crookedtimber org 2005 04 02 sociologically improbable phrases sociologically improbable phrases crooked timber april 2005 ref see also googlewhack a pair of words occurring on a single webpage as indexed by google tf idf a statistic used in information retrieval and text mining references reflist amazon category amazon com category bookselling category information retrieval systems'
b'distinguish indexing and abstracting service use dmy dates date february 2011 infobox windows component name indexing service screenshot indexing service query form png screenshot size 300px caption the indexing service query form used to query indexing service catalogs hosted in microsoft management console type desktop search service name indexing service service description indexes contents and properties of files on local and remote computers provides rapid access to files through flexible querying language replaced by windows search included with windows nt 4 0 option pack windows nt 4 0 option pack ref name mis intro br windows 2000 ref name mis v3 br windows xp ref name tnc 144 br windows server 2003 ref name tnc 144 br windows server 2008 ref name wis install2008 indexing service originally called index server was a windows service that maintained an index of most of the computer file files on a computer to improve searching performance on pcs and corporate computer network s it updated indexes without user intervention in windows 7 it has been replaced by a newer windows search indexer the ifilter plugins to extend the indexing capabilities to more file formats and protocols are compatible between the legacy indexing service and the newer windows search indexer history indexing service was a desktop search service included with windows nt 4 0 option pack windows nt 4 0 option pack ref name mis intro as well as windows 2000 and later ref name mis v3 ref name tnc 144 ref name wis what the first incarnation of the indexing service was shipped in august 1996 ref name mis intro as a content search system for microsoft s web server software internet information services citation needed date february 2011 its origins however date further back to microsoft s cairo operating system cairo operating system project with the component serving as the content indexer for the object file system cairo was eventually shelved but the content indexing capabilities would go on to be included as a standard component of later windows desktop and server operating systems starting with windows 2000 which includes indexing service 3 0 citation needed date february 2011 in windows vista the content indexer was replaced with the windows search indexer which was enabled by default indexing service is still included with windows server 2008 but is not installed or running by default ref name wis install2008 indexing service has been deprecated in windows 7 and windows server 2008 r2 ref cite web title deprecated features for windows 7 and windows server 2008 r2 url http technet microsoft com en us library ee681698 28ws 10 29 aspx work windows 7 technical library publisher microsoft corporation accessdate 8 november 2011 location indexing service date october 16 2009 ref it has been removed from windows 8 search interfaces comprehensive searching is available after initial building of the index which can take up to hours or days depending on the size of the specified directories the speed of the hard drive user activity indexer settings and other factors searching using indexing service works also on uniform naming convention unc paths and or mapped network drives if the sharing server indexes appropriate directory and is aware of its sharing once the indexing service has been turned on and has built its index it can be searched in three ways the search option available from the start menu on the microsoft windows windows taskbar will use the indexing service if it is enabled and will even accept complex queries queries can also be performed using either the indexing service query form in the microsoft management console common snap ins computer management snap in of microsoft management console or alternatively using third party applications such as aim at file or grokker desktop microsoft index server 2 0 does not detect changes to a catalog if the data is located on a volume mount point mounted partition it does not support mounted volumes because of technical limitations in the file system ref cite web url http support microsoft com kb 319506 title info index server does not support mounted volumes revision 1 0 work microsoft support publisher 10 may 2002 accessdate 1 february 2011 ref references reflist refs ref name mis intro cite web url http msdn microsoft com en us library ms951563 aspx title introduction to microsoft index server work microsoft developer network publisher microsoft corporation date 15 october 1997 accessdate 1 february 2011 first1 krishna last1 nareddy ref ref name mis v3 cite web url http msdn microsoft com en us library ms689644 aspx title indexing service version 3 0 work microsoft developer network publisher microsoft corporation date accessdate 1 february 2011 first1 last1 ref ref name wis what cite web url http msdn microsoft com en us library ms689718 aspx title what is indexing service work microsoft developer network publisher microsoft corporation date accessdate 1 february 2011 first1 last1 ref ref name wis install2008 cite web url http support microsoft com kb 954822 title how to install and configure the indexing service on a windows server 2008 based computer revision 3 0 work microsoft support publisher microsoft corporation date 3 may 2010 accessdate 1 february 2011 ref ref name tnc 144 cite book url http www microsoft com downloads en details aspx familyid 1b6acf93 147a 4481 9346 f93a4081eea8 displaylang en format microsoft word title threats and countermeasures security settings in windows server 2003 and windows xp edition 2 0 publisher microsoft corporation page 144 date december 2005 first1 mike last1 danseglio first2 kurt last2 dillard first3 jos\xc3\xa9 last3 maldonado first4 paul last4 robichaux editor1 first reid editor1 last bannecker editor2 first john editor2 last cobb editor3 first jon editor3 last tobey editor4 first steve display editors 3 editor4 last wacker ref microsoft windows components defaultsort indexing service category windows communication and services category desktop search engines desktop search engines category information retrieval systems category windows components'
b'contextual query language cql previously known as common query language ref http www loc gov standards sru cql spec html cql the contextual query language specifications sru search retrieval via url standards library of congress ref is a formal language for representing queries to information retrieval systems such as search engine s bibliography bibliographic catalogs and museum collection information based on the semantics of z39 50 its design objective is that queries be human readable and writable and that the language be intuitive while maintaining the expressiveness of more complex query language s it is being developed and maintained by the z39 50 maintenance agency part of the library of congress examples of query syntax simple queries blockquote tt dinosaur br complete dinosaur br title complete dinosaur br title exact the complete dinosaur tt blockquote queries using boolean logic blockquote tt dinosaur or bird br palomar assignment and ice age br dinosaur not reptile br dinosaur and bird or dinobird br bird or dinosaur and feathers or scales br feathered dinosaur and yixian or jehol tt blockquote queries accessing index publishing publication indexes blockquote tt publicationyear 1980 br lengthoffemur 2 4 br biomass 100 tt blockquote queries based on the proximity of words to each other in a document blockquote tt ribs prox distance 5 chevrons br ribs prox unit sentence chevrons br ribs prox distance 0 unit paragraph chevrons tt blockquote queries across multiple dimension data warehouse dimensions blockquote tt date within 2002 2005 br daterange encloses 2003 tt blockquote queries based on relevance information retrieval relevance blockquote tt subject any relevant fish frog br subject any rel lr fish frog tt blockquote the latter example specifies using a specific algorithm for logistic regression ref http srw cheshire3 org contextsets rel relevance ranking context set version 1 1 ref references reflist external links http www loc gov standards sru cql cql home page http www loc gov z3950 agency z39 50 maintenance agency http zing z3950 org cql intro html a gentle introduction to cql query languages usgovernment sourceurl http www loc gov standards sru cql loc stub category information retrieval systems category library science category library of congress category query languages category knowledge representation languages'
b'other uses the ma trixware re search c ollection marec is a standardised patent data corpus available for research purposes marec seeks to represent patent documents of several languages in order to answer specific research questions ref merz c 2003 a corpus query tool for syntactically annotated corpora licentiate thesis the university of zurich department of computation linguistic switzerland ref ref biber d conrad s and reppen r 2000 corpus linguistics investigating language structure and use cambridge university press 2nd edition ref it consists of 19 million patent documents in different languages normalised to a highly specific xml schema marec is intended as raw material for research in areas such as information retrieval natural language processing or machine translation which require large amounts of complex documents ref manning c d and sch\xc3\xbctze h 2002 foundations of statistical natural language processing cambridge ma massachusetts institute of technology mit isbn 0 262 13360 1 ref the collection contains documents in 19 languages the majority being english german and french and about half of the documents include full text in marec the documents from different countries and sources are normalised to a common xml format with a uniform patent numbering scheme and citation format the standardised fields include dates countries languages references person names and companies as well as subject classifications such as international patent classification ipc codes ref european patent office 2009 http documents epo org projects babylon eponet nsf 0 1afc30805e91d074c125758a0051718a file guidelines 2009 complete en pdf guidelines for examination in the european patent office published by european patent office germany april 2009 ref marec is a comparable corpus where many documents are available in similar versions in other languages a comparable corpus can be defined as consisting of texts that share similar topics news text from the same time period in different countries while a parallel corpus is defined as a collection of documents with aligned translations from the source to the target language ref j\xc3\xa4rvelin a talvensaari t j\xc3\xa4rvelin anni 2008 data driven methods for improving mono and cross lingual ir performance in noisy environments proceedings of the second workshop on analytics for noisy unstructured text data singapore ref since the patent document refers to the same invention or concept of idea the text is a translation of the invention but it does not have to be a direct translation of the text itself text parts could have been removed or added for clarification reasons the 19 386 697 xml files measure a total of 621 gb and are hosted by the information retrieval facility access and support are free of charge for research purposes use cases marec is used in the patent language translations online pluto project references reflist external links http www ir facility org prototypes marec user guide and statistics http ir facility org information retrieval facility category corpora category information retrieval systems category machine translation category natural language processing category xml'
b'use mdy dates date october 2014 infobox website name wolfram alpha logo wolfram alpha december 2016 svg caption wolfram alpha is based on the computational platform mathematica written by british scientist stephen wolfram in 1988 url url http www wolframalpha com slogan making the world s knowledge computable ref http www wolframalpha com about html wolfram alpha about page ref commercial yes type answer engine registration optional owner wolfram alpha llc author wolfram research alexa decrease 1 932 as of 2015 26 31 alt march 2015 ref name alexa cite web url http www alexa com siteinfo wolframalpha com title wolframalpha com site info publisher alexa internet accessdate 2015 03 31 ref num employees \xe2\x89\x88 200 as of 2012 programming language wolfram language launch date start date and age 2009 5 18 ref name launch date cite web author the wolfram 124 alpha launch team url http blog wolframalpha com 2009 05 08 so much for a quiet launch title so much for a quiet launch work wolfram 124 alpha blog publisher wolfram alpha date may 8 2009 accessdate 2013 02 09 ref official launch br start date 2009 5 15 ref name updated launch detail cite web author the wolfram 124 alpha launch team url http blog wolframalpha com 2009 05 12 going live and webcasting it work wolfram 124 alpha blog title going live and webcasting it publisher wolfram alpha date may 12 2009 accessdate 2013 02 09 ref public launch current status active wolfram alpha also styled wolframalpha and wolfram alpha is a computational knowledge engine ref name guardiandatasource cite news title where does wolfram alpha get its information author bobbie johnson publisher the guardian date may 21 2009 accessdate 2013 03 08 url https www theguardian com technology 2009 may 21 1 ref or answer engine developed by wolfram research which was founded by stephen wolfram it is an online service that answers factual queries directly by computing the answer from externally sourced curated data ref cite web title about wolfram alpha making the world s knowledge computable url http www wolframalpha com about html website wolframalpha com accessdate 2015 11 25 ref rather than providing a list of documents or web pages that might contain the answer as a search engine might ref cite news url https www theguardian com technology 2009 mar 09 search engine google title british search engine could rival google last johnson first bobbie date march 9 2009 work the guardian publisher guardian news and media location uk accessdate 2013 02 09 ref wolfram alpha which was released on may 18 2009 is based on wolfram s earlier flagship product wolfram mathematica a computational platform or toolkit that encompasses computer algebra symbolic and numerical computation visualization and statistics capabilities ref name launch date additional data is gathered from both academic and commercial websites such as the cia s the world factbook the united states geological survey a cornell university library publication called all about birds chambers biographical dictionary dow jones the catalogue of life ref name guardiandatasource crunchbase ref name techcrunch cite news last dillet first romain title wolfram alpha makes crunchbase data computable just in time for disrupt sf url http techcrunch com 2012 09 07 wolfram alpha makes crunchbase data computable just in time for disrupt publisher techcrunch date september 7 2012 accessdate 2013 02 09 ref best buy ref cite news last golson first jordan title wolfram delivers siri enabled shopping results from best buy url http www macrumors com 2011 12 16 wolfram delivers siri enabled shopping results from best buy publisher macrumors date december 16 2011 accessdate 2013 02 09 ref the federal aviation administration faa ref cite news last barylick first chris title wolfram alpha search engine now tracks flight paths trajectory information url http www engadget com 2011 11 19 wolfram alpha search engine now tracks flight paths trajectory publisher engadget date november 19 2011 accessdate 2013 02 09 ref and optionally a user s facebook account overview users submit queries and computation requests via a text field wolfram alpha then computes answers and relevant visualizations from a knowledge base of data curation curated structured data that come from other sites and books the site use s a portfolio of automated and manual methods including statistics visualization source cross checking and expert review ref cite web title data in wolfram 124 alpha url http www wolframalpha com faqs5 html website wolfram alpha accessdate 4 august 2015 ref the curated data makes alpha different from semantic search engines which index a large number of answers and then try to match the question to one wolfram alpha can only provide robust query results based on computational facts not queries on the social sciences cultural studies or even many questions about history where responses require more subtlety and complexity it is able to respond to particularly phrased natural language understanding natural language fact based questions such as where was mary robinson born or more complex questions such as how old was queen elizabeth ii in 1974 it displays its input interpretation of such a question using standardized phrases such as age of queen elizabeth ii royalty in 1974 the answer of which is age at start of 1974 47 years and a biography link wolfram alpha does not answer queries which require a narrative response such as what is the difference between the julian and the gregorian calendars but will answer factual or computational questions such as june 1 in julian calendar mathematical symbolism can be parsed by the engine which typically responds with more than the numerical results for example lim x 0 sin x x yields the correct limit functions limit ing value of 1 as well as a plot up to 235 terms as of 2013 lc y of the taylor series and for registered users a possible derivation using l h\xc3\xb4pital s rule it is also able to perform calculations on data using more than one source for example what is the list of countries by gdp nominal per capita fifty second smallest country by gdp per capita yields nicaragua 1160 per year technology wolfram alpha is written in 15 million lines of wolfram language code ref cite web author wolframresearch url https www youtube com watch v 56isaies6ws t 927s title stephen wolfram the background and vision of mathematica publisher youtube com date october 10 2011 accessdate 2013 02 09 ref and runs on more than 10 000 cpus ref cite news first frederic last lardinois url http readwrite com 2009 04 25 wolframalpha our first impressions title wolfram 124 alpha our first impressions date april 25 2009 publisher readwriteweb accessdate 2013 02 09 ref ref cite news first stephen last wolfram url http blog wolframalpha com 2009 05 15 wolframalpha is launching made possible by mathematica title wolfram 124 alpha is launching made possible by mathematica work wolframalpha blog publisher wolfram alpha date may 15 2009 accessdate 2013 02 09 ref the database currently includes hundreds of datasets such as all current and historical weather the datasets have been accumulated over several years ref cite web title taking a first bite out of wolfram alpha first jane fae last ozimek work the register date may 18 2009 url http www theregister co uk 2009 05 18 wolfram alpha accessdate 2013 02 09 ref the curated as distinct from auto generated datasets are checked for quality either by a scientist or other expert in a relevant field or someone acting in a clerical capacity who simply verifies that the datasets are acceptable ref name semanticabyss cite web title the semantic abyss plumbing the semantic web exploring the depths of the semantic gap between the semantic web and real world users and consumers url http semanticabyss blogspot ca 2009 03 what is curated data html year 2009 author jack krupansky ref unreliable source date september 2015 one example of a live dataset that wolfram alpha can use is the profile of a facebook user through inputting the facebook report query if the user authorizes facebook to share his or her account details with the wolfram site alpha can generate a personal analytics report containing the age distribution of friends the frequency of words used in status updates and other detailed information ref name techland cite news first thomas e last weber url http techland time com 2012 09 05 wolfram alphas facebook analytics tool digs deep into your social life title wolfram alpha s facebook analytics tool digs deep into your social life work tech publisher time magazine date september 5 2012 accessdate 2013 02 09 ref within two weeks of launching the facebook analytics service 400 000 users had used it ref cite news last r first a title visualising facebook who am i url http www economist com blogs graphicdetail 2012 09 visualising facebook publisher the economist work graphic detail date september 21 2012 accessdate 2013 02 09 ref downloadable query results are behind a pay wall but summaries are accessible to free accounts ref name publiclibraries cite web url http publiclibrariesonline org 2013 03 a wolf or a ram what is wolfram alpha title a wolf or a ram what is wolfram alpha author joanna nelson date march 4 2013 publisher public libraries online ref licensing partners wolfram alpha has been used to power some searches in the microsoft bing search engine bing and duckduckgo search engines ref cite news first tom last krazit url http news cnet com 8301 30684 3 10315117 265 html title bing strikes licensing deal with wolfram alpha publisher cnet date august 21 2009 accessdate 2013 02 09 ref ref cite web author the wolfram 124 alpha team date april 18 2011 url http blog wolframalpha com 2011 04 18 wolframalpha and duckduckgo partner on api binding and search integration title wolfram 124 alpha and duckduckgo partner on api binding and search integration work wolfram 124 alpha blog publisher wolfram alpha accessdate 2013 02 09 ref for factual question answering it is also queried by apple s siri software siri samsung s s voice as well as dexetra s speech recognition software for the android operating system android platform iris and the voice control software on blackberry 10 ref cite web url http www berryreview com 2013 10 21 blackberry teams up with wolfram alpha for blackberry 10 voice control title blackberry teams up with wolfram alpha for blackberry 10 voice control work berryreview ref history launch preparations began on may 15 2009 at 7 nbsp pm central daylight time north america central daylight time cdt and were broadcast live on justin tv the plan was to publicly launch the service a few hours later with expected issues due to extreme load the service was officially launched on may 18 2009 ref name bbc cite news url http news bbc co uk 1 hi technology 8052798 stm title wolfram search engine goes live publisher bbc news date may 18 2009 accessdate 2013 02 09 ref wolfram alpha has received mixed reviews ref name spivack cite web first nova last spivack title wolfram alpha is coming and it could be as important as google date march 7 2009 url http www novaspivack com uncategorized wolfram alpha is coming and it could be as important as google accessdate 2013 02 09 publisher nova spivack minding the planet ref ref cite news first ryan last singel title wolfram 124 alpha fails the cool test date may 18 2009 url http www wired com epicenter 2009 05 wolframalpha fails the cool test publisher wired accessdate 2013 02 09 ref wolfram alpha advocates point to its potential some even stating that how it determines results is more important than current usefulness ref name spivack on december 3 2009 an iphone app was introduced some users ref name ios price cite web first mg last siegler url http techcrunch com 2009 12 03 wolfram alpha iphone app title nice try wolfram alpha still not paying 50 for your app publisher techcrunch date december 3 2009 accessdate 2013 02 09 ref considered the initial 50 price of the ios app unnecessarily high since the same features could be freely accessed by using a web browser instead they also complained about the simultaneous removal of the mobile formatting option for the site ref name mobile format cite news url http www tuaw com 2009 12 03 wolframalpha iphone formatted web page no longer available first tj last luoma title wolframalpha iphone formatted web page no longer available publisher tuaw date december 3 2009 accessdate 2013 02 09 ref wolfram responded by lowering the price to 2 offering a refund to existing customers ref name refund cite web last broida first rick url http reviews cnet com 8301 19512 7 10471978 233 html title get wolfram alpha app for 1 99 and a refund if you paid more publisher cnet date april 1 2010 accessdate 2012 02 28 ref and re instating the mobile site on october 6 2010 an android version of the app was released ref cite news url http techcrunch com 2010 10 06 wolframalphas android app now available title wolfram alpha s android app now available first leena last rao publisher techcrunch date october 6 2010 accessdate 2013 02 09 ref and it is now available for kindle fire and nook the nook version is not available outside the us a further 71 apps are available which use the wolfram alpha engine for specialized tasks ref cite web url http products wolframalpha com mobile title wolfram 124 alpha mobile tablet apps year 2013 accessdate 2013 02 09 publisher wolfram alpha ref wolfram alpha pro on february 8 2012 wolfram alpha pro was released ref name waproannounce cite news first stephen last wolfram url http blog wolframalpha com 2012 02 08 announcing wolframalpha pro title announcing wolfram 124 alpha pro date february 8 2012 work wolfram 124 alpha blog publisher wolfram alpha accessdate 2013 02 09 ref offering users additional features for a monthly subscription fee a key feature is the ability to upload many common file types and data including raw tabular data images audio xml and dozens of specialized scientific medical and mathematical formats for automatic analysis other features include an extended keyboard interactivity with computable document format cdf data downloads in depth step by step solution the ability to customize and save graphical and tabular results ref name hachman cite news last hachman first mark title data geeks meet wolfram alpha pro publisher pc magazine date february 7 2012 url http www pcmag com article2 0 2817 2399911 00 asp accessdate 2012 02 15 ref and extra computation time ref name waproannounce along with new premium features wolfram alpha pro has led to some changes in the free version of the site an increase in advertisements on the free site text and pdf export options now require the user to set up a free account ref name waproannounce even though they existed before the introduction of wolfram alpha accounts ref cite web url http hplusmagazine com 2009 06 24 users guide wolframalpha title a user s guide to wolfram alpha first surfdaddy last orca publisher h magazine date 2009 06 24 accessdate 2013 04 24 ref the option to request extra time for a long calculation used to be free ref name extra time before cite web url http web mst edu jkmq53 school fall 2011 english 160 files marlowe usability test docx title wolfram alpha usability test survey first james last marlowe year 2011 accessdate 2013 04 24 ref but is now only available to subscribers ref name waproannounce step by step limited to 3 for free users previously uncapped no longer available ref name stepbystep cite web url http blog wolframalpha com 2009 12 01 step by step math title step by step math ref copyright claims infoworld published an article ref name copyright cite web last mcallister first neil url http www infoworld com d developer world how wolfram alpha could change software 248 title how wolfram alpha could change software publisher infoworld date july 29 2009 accessdate 2012 02 28 ref warning readers of the potential implications of giving an automated website proprietary rights to the data it generates free software movement free software advocate richard stallman also opposes the idea of recognizing the site as a copyright holder and suspects that wolfram would not be able to make this case under existing copyright law ref name fsf cite mailing list url http lists essential org pipermail a2k 2009 august 004865 html title how wolfram alpha s copyright claims could change software date august 4 2009 accessdate 2012 02 17 mailinglist http lists essential org mailman listinfo a2k access 2 knowledge archiveurl https web archive org web 20130428041345 http lists essential org pipermail a2k 2009 august 004865 html archivedate april 28 2013 last stallman first richard authorlink richard stallman ref see also commonsense knowledge problem artificial general intelligence strong ai watson computer references reflist colwidth 30em further reading http www businessweek com the thread techbeat archives 2009 03 wolfram alpha a html wolfram alpha a new way to search stephen wildstrom businessweek march 9 2009 http www informationweek com news internet search showarticle jhtml articleid 215801388 subsection news stephen wolfram s answer to google if wolfram alpha works as advertised it will be able to do something google can t provide answers that don t already exist in indexed documents by thomas claburn informationweek march 10 2009 http bits blogs nytimes com 2009 03 09 better search doesnt mean beating google better search doesn t mean beating google by saul hansell the new york times march 9 2009 http www pcworld com article 160904 wolfram alpha will take your questions any questions html wolfram alpha will take your questions any questions ian paul pc world march 9 2009 http www hplusmagazine com articles ai wolframalpha searching truth wolfram alpha searching for truth stephen wolfram talks with rudy rucker about his upcoming release by rudy rucker h magazine http www boston com business technology articles 2009 05 05 a hungry little number cruncher a hungry little number cruncher wolfram alpha search tool mines databases to yield math based replies by hiawatha bray the boston globe may 5 2009 http newsbreaks infotoday com newsbreaks wolfram alpha semantic search is born 53892 asp wolfram alpha semantic search is born by woody evans may 21 2009 external links official website wolfram research state uncollapsed computable knowledge intelligent personal assistant software category agent based software category computer algebra systems category educational math software category educational websites category information retrieval systems category intelligent software assistants category internet properties established in 2009 category mathematics education category natural language processing software category open educational resources category physics education category semantic web category software calculators category web analytics category websites which mirror wikipedia category wolfram research'
b'attention this is an outline part of the set of 700 outlines listed at portal contents outlines wikipedia outlines are a special type of list article they make up one of wikipedia s content navigation systems see wikipedia outlines for more details further improvements to this outline are on the way the following outline list outline is provided as an overview of and topical guide to search engines search engine computing search engine ndash information retrieval information retrieval system designed to help find information stored on a computer system the search results are usually presented as a list and are commonly called hits toc limit limit 2 what type of thing is a search engine a search engine can be described as all of the following software ndash computer program ndash application software ndash computer software designed to help the user to perform specific tasks also known as an application or an app types of search engines database search engine ndash desktop search engine ndash distributed search engine ndash search engine where there is no central server unlike traditional centralized search engines work such as crawling data mining indexing and query processing is distributed among several peers in decentralized manner where there is no single point of control enterprise search engine ndash search engine employed on and for access to the information on an organization s computer network human search engine ndash uses human participation to filter the search results and assist users in clarifying their search request the goal is to provide users with a limited number of relevant results as opposed to traditional search engines that often return a large number of results that may or may not be relevant hybrid search engine ndash uses different types of data with or without ontologies to produce the algorithmically generated results based on web crawling previous types of search engines only use text to generate their results intelligent medical search engine metasearch engine ndash search tool 1 that sends user requests to several other search engines and or databases and aggregates the results into a single list or displays them according to their source metasearch engines enable users to enter search criteria once and access several search engines simultaneously search aggregator organic search engine ndash manually operated search service which uses a combination of computer algorithms and human researchers to look up a search query a search query submitted to an organic search engine is analysed by a human operator who researches the query then formats the response to the user web search engine ndash designed to search for information on the world wide web and ftp servers the search results are generally presented in a list of results often referred to as serps or search engine results pages audio search engine ndash web based search engine which crawls the web for audio content collaborative search engine ndash emerging trend for web search and enterprise search within company intranets cses let users concert their efforts in information retrieval ir activities share information resources collaboratively using knowledge tags and allow experts to guide less experienced people through their searches social search engine ndash type of web search that takes into account the social graph of the person initiating the search query video search engine ndash web based search engine which crawls the web for video content some video search engines parse externally hosted content while others allow content to be uploaded and hosted on their own servers visual search engine ndash designed to search for information on the world wide web through the input of an image or a search engine with a visual display of the search results information may consist of web pages locations other images and other types of documents this type of search engines is mostly used to search on the mobile internet through an image of an unknown object unknown search query specific search engines main list of search engines search engine software list of search engine software search based applications search based application ndash bibliographic database online database list of online databases list of academic databases and search engines digital library list of digital library projects list of online magazines wikipedia list of online newspaper archives electronic journal lists of academic journals list of open access journals digital encyclopedia internet encyclopedia list of online encyclopedias wiki list of wikis digital dictionary online dictionary list of online dictionaries search engine technology search engine technology search algorithm search engine image protection search engine indexing search engine optimization search engine results page list of search engine software search engine software search engine submission search engine optimization copywriting web crawler search engine marketing search engine marketing pay per click cost per impression search analytics web analytics persons influential in search engines sergey brin larry page eric schmidt see also outline of the internet outline of google human flesh search engine clear references reflist external links sisterlinks search engine http wikimindmap com viewmap php wiki en wikipedia org topic outline of search engines submit search this outline displayed as a mindmap at wikimindmap com dmoz computers internet searching search engines search engines outline footer category information retrieval systems category wikipedia outlines search engines category articles created via the article wizard search engines'
b'cleanup list date june 2014 the following tables compare the major list of enterprise search vendors enterprise search software vendors in their classes general information class wikitable sortable product formerly k a vendor software release life cycle stable release update platforms api target customer software license open source multilingual website mindbreeze inspire mindbreeze inspire mindbreeze 2016 summer release october 17th 2016 windows server linux rest soap net java push api information insight knowledge management for departments organizations big data search analytics no yes including languages like cjk www mindbreeze com lookeen desktop search lookeen server lookeen server ref http www lookeen server com produkt overview lookeen server enterprise search ref lookeen server axonic informationssysteme gmbh 1 3 1 1118 april 2014 windows server net framework net no yes http www lookeen server com intergator intergator enterprise search intergator interface projects gmbh 5 3 march 2016 windows server linux server java groovy und xml json enterprise search knowledge management content analytics big data yes no yes http www intergator de coveo enterprise search coveo platform coveo coveo solutions inc 7 0 february 6 2014 windows rest soap net framework net web customer service customer interaction hubs no yes yes multilingual user interfaces http www coveo com en advanced enterprise search 3rdi search 3rdi search the digital group inc 1 0 na generic supported enterprise search knowledge management big data bi analytics commercial no yes http www 3rdisearch com endeca guided search oracle corporation oracle 6 2 2 march 2012 http www oracle com us products applications commerce endeca endeca guided search overview index html exalead cloudview dassault syst\xc3\xa8mes r2014 july 2013 windows server linux server push api papi no yes yes br 125 languages supported http www 3ds com products services exalead datafari france labs 2 2 1 april 2016 linux server windows for test rest enterprise search knowledge management big data bi analytics no yes yes nowiki http www datafari com en nowiki fast for sharepoint 2010 f4sp fast search transfer microsoft 2010 sp1 windows server sharepoint net framework net no sharepoint 2013 fast search transfer microsoft 2010 sp1 windows server sharepoint net framework net no google search appliance gsa google 7 4 march 2015 net framework net java yes https www google com enterprise search products gsa html hp idol ref http www8 hp com us en software solutions information data analytics idol hp idol ref hewlett packard enterprise hpe bigdata 11 march 2016 windows hp ux linux solaris soap rest big data and analytics enterprise search video image or audio analytics knowledge management info governance yes licensed by volume starting on 250gb of metadata no yes http www8 hp com us en software solutions information data analytics idol haven search ondemand ref http search havenondemand com haven search ondemand ref hewlett packard enterprise hpe bigdata 20160329 march 2016 saas offering rest consumption based pricing no yes http search havenondemand com funnelback search panoptic search funnelback 15 6 june 2016 saas offering windows server linux server rest enterprise search website search vertical search document and server based licensing no yes yes multi lingual support includes indexing querying and localised uis https www funnelback com ibm infosphere data explorer vivisimo vivisimo velocity ibm big data and analytics projects yes http www 01 ibm com software data information optimization swiftype search swiftype swiftype september 2014 windows and linux macos rest apis websites and mobile applications no no https swiftype com lucidworks fusion n a lucidworks lucidworks inc 2 1 4 march 2016 windows linux macos rest apis enterprise search online retail search based data analytics licensed by cpu cores no yes https lucidworks com products fusion perceptive search isys enterprise server lexmark lexmark perceptive software 4 2 windows linux solaris mac os hp ux and aix rest soap yes http www perceptivesoftware com products perceptive search secure enterprise search ses oracle corporation oracle 11 2 2 2 january 2014 windows linux oracle redhat and suse 32 bit and 64 bit solaris http www oracle com technetwork search oses documentation ses 096384 html ravn connect ravn systems 3 3 february 2014 windows server linux server rest api no yes http www ravn co uk capabilities enterprise search features content collection indexing this section compares the ability of the products to collect and index content both textual and non textual from different data source types and document types formats indexing and connectivity this is about indexing pipeline tools and processes included connectors support for connectors etc web based class wikitable sortable description lookeen server ref http www lookeen server com produkt overview lookeen server enterprise search ref hp idol ref http www ndm net archiving hp autonomy information connectivity autonomy information connectivity ref coveo for advanced enterprise search ref http www coveo com en platform features connect connectorssection coveo connectors ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer swiftype search lucidworks fusion perceptive search secure enterprise search ref http www oracle com technetwork search oses overview ses11222ds 1969734 pdf ses 11 2 2 2 datasheet oracle ref ravn connect intergator funnelback search http for crawling of web servers yes yes yes yes yes yes yes yes yes yes yes https for crawling of secured web servers yes yes yes yes yes yes yes yes yes yes yes yes yes xml for indexing any xml compliant data source yes yes yes yes yes yes yes yes yes yes yes yes file based class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search 6 2 2 sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search netware file system netware file systems for incremental indexing of netware file systems yes yes yes no samba unix file system unix file systems yes yes yes yes yes yes yes yes yes windows file system windows file systems windows nt filesystems ntfs yes yes yes yes yes yes yes yes yes yes yes archiving directory class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 administrator what connectors are available with ces htm what connectors are available with coveo ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search ldap for indexing a company directory stored on a ldap v2 or v3 server yes yes yes yes yes yes yes yes yes microsoft active directory supports microsoft active directory yes yes yes yes yes yes yes yes yes symantec enterprise vault yes yes yes yes yes yes no messaging class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator akonix yes facetime yes ibm lotus connections yes yes yes yes imap for indexing e mail messages and attached files stored on an imap server yes yes yes yes yes yes yes yes yes ibm lotus notes for indexing e mail messages and attached files stored on a lotus notes server yes yes yes yes yes br trigram cln yes yes yes yes microsoft exchange server microsoft exchange ability to retrieve and index e mail messages and attached files br mailboxes public folders yes yes yes yes br exchange 2003 2007 2010 2013 servers yes yes yes br trigram cxg yes yes yes br via adhere solutions partner yes yes br exchange 2003 servers yes yes microsoft exchange server microsoft exchange online yes yes yes yes imap yes yes nntp for real time indexing of usenet news groups yes yes gmail yes yes yes yes yes content management system cms document management system dms social class wikitable sortable description lookeen server hp idol ref http www8 hp com us en software solutions asset software asset viewer html asset 1997065 module 1970565 docname 4aa5 8715enw page 1970341 keyview idol product brief ref coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 administrator what connectors are available with ces htm what connectors are available with coveo ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator alfresco software alfresco yes yes yes yes yes yes but no native support yes yes yes via incentro partner yes yes yes emc documentum emc documentum server yes yes yes yes yes br trigram cdo yes yes yes yes yes episerver episerver yes yes no no yes ibm content manager yes yes yes yes br via adhere solutions partner yes yes ibm filenet yes yes yes p8 yes yes br via adhere solutions partner yes yes websphere ibm websphere yes yes yes yes yes informatica powercenter 9 x connectivity yes yes via adhere solutions partner yes yes jalios yes yes yes br trigram cja sharepoint yes yes yes yes yes br trigram cxg yes yes microsoft sharepoint portal server br microsoft sharepoint services yes yes yes sharepoint online yes yes yes yes yes dropbox service dropbox yes yes yes yes yes windows file share yes yes yes yes yes yes yes google docs yes yes yes yes yes yes yes jive yes yes yes yes plumtree software plumtree yes yes no yes lithium yes yes confluence yes yes yes yes yes yes via partner yes yes twitter yes yes yes yes yes yes yes facebook yes yes no yes linkedin yes yes yes databases class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search ref http www arnoldit com search wizards speak coveo html coveo solutions inc an interview with laurent simoneau ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search ibm db2 yes yes yes yes yes br etl informatica powercenter br db2 for linux yes yes yes yes yes yes jdbc yes yes yes yes yes br translates sql database fields br into xml documents br than are then indexed together br with the document metadata yes yes yes yes yes yes microsoft sql server yes yes yes yes yes br etl informatica powercenter yes yes yes yes yes yes mysql yes yes yes yes yes yes yes yes yes odbc yes yes yes yes yes br etl informatica powercenter yes yes yes yes yes oracle rdbms yes yes yes yes yes br etl informatica powercenter yes yes yes yes yes yes sybase yes yes yes yes br etl informatica powercenter yes yes yes yes no customer relationship management crm enterprise resource planning erp product lifecycle management plm business intelligence bi class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ref https www google com enterprise marketplace viewlisting productlistingid 3905631 7212827882376498737 ibm db2 content manager od connector for google search appliance by adhere solutions ref ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator salesforce com salesforce yes yes yes yes yes br trigram csf yes via partner yes yes via partner yes yes sap business suite sap yes yes yes yes yes siebel systems siebel oracle yes yes yes yes yes etl informatica yes yes yes microsoft dynamics yes yes yes business objects business object yes yes yes yes yes ibm cognos yes yes yes yes informatica informatica powercenter yes yes br trigram cja microstrategy yes yes yes yes via partners windchill software ptc windchill yes yes enovia matrixone enovia support for matrixone enovia data yes yes yes br trigram cen yes yes via partner yes miscellaneous class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search 6 2 2 sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator jira software jira yes yes yes yes github yes yes slack software slack yes mantis bug tracker mantis yes yes yes jd edwards oracle enterpriseone world yes yes yes br etl informatica powercenter peoplesoft oracle yes yes yes br etl informatica powercenter coming soon supported formats class wikitable sortable file type description lookeen server hp idol coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 user supported file formats htm coveo platform 7 supported file formats ref endeca guided search sinequa enterprise search exalead cloudview ref http 3ds exalead com software common pdfs products cloudview exalead connectors and formats pdf exalead cloudview connectors formats ref datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search adobe pdf includes adobe acrobat or other pdf documents yes yes yes yes br version 1 0 to 1 7 yes yes yes yes yes yes yes web pages html xhtml etc yes yes yes br versions v 3 4 5 yes asp aspx cgi col br dochtml dothtml fphtml br hta htm html jsp php br pothtml ppthtml shtm br shtml xlshtml yes yes yes br versions v 4 01 and above and xhtml yes yes yes yes xml extensible markup language xml yes yes yes yes yes yes br any document type definition dtd yes yes yes yes text raw text yes yes yes ascx bat cmd config br csv dic exc inf ini br js jsl log nfo scp br sdl sln txt vbdproj br vbs vdp vdproj vjp br vjsproj vjsprojdata br wsdl wsf wtx xsd br ansi ascii unicode yes yes yes yes yes yes microsoft excel microsoft excel charts xls br microsoft excel xml xlsx xltm xltx br others xlam xlb xlm xlsm yes yes yes br version 5 0 95 7 0 97 2000 xp 2003 2007 2010 br indexes excel 2010 attachments yes yes yes yes yes yes yes yes microsoft word microsoft word doc br microsoft word xml docx dotx dotm yes yes yes br for mac windows multiple versions yes version 6 0 6 0 for mac 95 7 0 97 98 for mac 2000 br xp 2003 2007 2010 br indexes word 2010 attachments yes yes yes yes yes yes yes microsoft powerpoint pot potm potx ppam br pps ppsm ppsx ppt br pptm pptx yes yes yes yes br indexes powerpoint 2010 attachments yes yes yes yes yes yes yes microsoft access mdb yes yes yes yes yes yes yes microsoft project mpp yes yes yes yes yes no microsoft visio vsd yes yes br multiple versions yes yes no microsoft outlook message archives and templates msg oft pst yes yes yes yes yes yes yes no mime mime documents multipurpose internet mail extension yes yes yes br microsoft outlook express mac and pc multiple versions eml yes email eml ews mime br mime converter available with ces 7 0 5935 yes yes yes yes yes no staroffice sun staroffice yes yes yes no lotus 1 2 3 yes yes no lotus freehand yes yes no corel wordperfect corel wordperfect linux wps br corel wordperfect macintosh wps br corel wordperfect windows wo br corel wordperfect windows wpd yes yes yes br version 6 and 7 yes yes yes no archive files yes 7z dmg hqx bizip2 gz iso jar br emx bin bkf cab lzh lha br zip rar rtfd tar z uue br multiple versions yes yes rar zip yes yes yes yes rtf rich text format yes yes yes br multiple versions yes yes yes yes yes yes image files br text extraction yes yes yes br bmp jpeg max pcx dcx br pdf png tiff tiff fx br requires the optical character recognition ocr module yes via partner yes yes no images br metadata extraction creation of thumbnail yes yes yes bmp emf exif gif br icon jpeg png tiff br wmf yes yes yes br jpeg png gif png yes yes yes yes audio br text extraction yes aif aifc aiff asf au br cda mid midi mp1 mp3 br mpga rmi snd wav wma br requires the coveo audio video search cavs module yes via partner yes yes no audio metadata creation of thumbnail yes yes yes br mp3 ogg yes yes yes yes video yes 264 video 3gpp 3mm 4mp br avi m1v mov mp2 yes avi m1v mov mp2 mp2v br mpa mpeg mpg mpv2 qt br rec rm rnx wm wmv br requires the coveo audio video search cavs module yes metadata yes yes yes yes metadata extraction macromedia flash yes yes br macromedia flash text section and hypertext links yes yes no autovue 2d 3d cad files yes yes br open cad files directly inside autovue yes no autocad drawing autocad drawing dwf autocad drawing exchange dxf yes yes br multiple versions yes yes yes no catia versions 4 and 5 drawing document catdrawing part document catpart br assembly document catproduct model v4 only yes yes yes br any 5 version yes no solidworks v1 drawing slddrw assembly sldasm br part sldprt yes yes yes br 2003 to 2013 releases yes yes no pro engineer part prt assembly asm yes yes br any release from r16 to 2001 from wf1 to wf5 yes no cad open formats yes yes br iges version 5 2 and 5 3 step file yes metadata from the dwg cad format yes yes yes yes metadata from dwg cad text analytics class wikitable sortable linguistics description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ref http www bainsight com resources google vs microsoft fast search whitepaper pdf microsoft and google ba insight ref ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ref http docs oracle com cd e14507 01 admin 1112 e14130 pdf oracle secure enterprise search administrator s guide ref ravn connect intergator funnelback search language detection ability to identify the languages at indexing time yes yes yes yes yes yes yes yes yes yes yes synonyms stemming ability to treat as synonyms variations of keywords yes yes yes yes yes yes yes yes yes yes entity extraction named entity extraction ability to automatically extract entities such as persons locations and organizations from indexed content yes yes br named eduction yes yes yes yes yes yes yes yes yes yes yes br with automatic entity linking yes yes stop words ability to exclude stop words e g an the in order to improve relevance yes yes yes yes yes yes yes yes yes yes audio video analytics class wikitable sortable multimedia description lookeen server hp idol coveo for advanced enterprise search endeca guided search 6 2 2 sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator audio analytics ability to understand topics being discussed genders and emotional tones of speech music etc no yes yes br speech topics music keyword spotting video analytics ability to understand the content of the video without relying on metadata e g key framing facial identification logo recognition etc yes no yes image analytics ability to detect patterns in image e g faces bodies gender age range expression etc yes yes via partner yes search experience this section compares the ability of the products to enable the user to enter and execute the query present the data to the user within seconds after the query is parsed and processed so that the user can find what he seeks quickly and act on it search language class wikitable sortable query parser description lookeen server hp idol coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 user search prefix and operators htm search prefixes and operators ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect ref http www ravn co uk wp content uploads 2014 02 core whitepaper w v pdf ravn connect core white paper ref intergator funnelback search ref https docs funnelback com query language help html ref wildcard search does the system use the asterisk and question mark character as a wildcard yes yes yes yes yes yes yes yes yes yes fuzzy search does the system offer phonetic and approximate spelling search distinctions of syntax and semantics yes yes yes yes yes yes yes yes yes exact phrase search does the system enable to find words as a phrase yes yes yes yes yes yes yes yes yes proximity search text proximity search support for advanced proximity operators near before after yes yes yes yes yes yes range search ability to match all terms which are lexically between square brackets and curly braces yes yes yes yes yes boosting a term automatic bigram and trigram relevancy boosting yes yes yes yes yes yes boolean search does the system interprets boolean operators yes yes yes yes yes yes yes yes yes yes graph search does the system keep relationships between fields and allows searching for them while enabling full text search yes yes no usability search query this is the process of searching querying class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search ref http www coveo com en news releases coveo reports accelerated demand for search and relevance technology coveo reports accelerated demand for search relevance technology in 2013 ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search auto complete does the system provide an automatic query guidance in the search box while typing yes yes yes yes yes yes yes yes yes yes yes yes yes ref https docs funnelback com auto completion collection cfg html ref spell checking does the system checks if the words in the query are spelled correctly and suggest corrections yes yes yes yes yes yes yes yes yes yes yes ref https docs funnelback com spelling suggestions html ref federated search the ability to send the same query simultaneously to several searchable sources yes yes yes yes yes yes yes yes yes yes yes yes yes ref https docs funnelback com ui modern extra searches collection cfg html ref advanced search page does the system allow users to perform complex and sophisticated queries yes yes yes yes yes yes yes yes yes yes result list this is the process of scanning the content of any document directly from the result lists class wikitable sortable description lookeen server hp idol ref http www ndm net archiving pdf 20130902 pi b hp autn idol10 web pdf autonomy keyview idol product brief ndm net ref coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ref http static googleusercontent com media www google com fr support enterprise static gsa docs admin 70 gsa doc set quick start quick start pdf getting the most from your google search appliance ref ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator relevance ranking ability to find the highest quality and most relevant documents and bring them to the top of a search results list yes yes yes yes yes yes yes yes br google site search factors in more than 100 variables br for each query yes yes yes yes find similar ability to find similar links yes yes yes yes yes yes hit highlighting ability to highlight query key terms within the document in search result yes yes yes yes yes yes no no yes yes yes yes summarization br view as html does the system offer content preview in the search result so that users can judge relevance of results yes yes yes yes yes partial only available for office file types powerpoint excel visio etc partial yes yes br converts over 220 file formats into html yes yes yes does the system enable to copy paste from within the preview yes yes yes yes yes no no yes yes yes thumbnails and preview ability to generate thumbnails for a large amount of different file types yes yes br 100 doc types yes yes yes yes but low resolution for catproducts br no thumbnails for pro e assemblies yes partial only available for office file types docx docx pptx pptx br first page thumbnail preview partial yes yes full document graphical preview ability to access the content of any document without having to open a windows client application yes yes yes br regardless of the file s original application yes partial only available for powerpoint file types yes yes yes br asynchronous loading yes document comparison ability to compare yes yes br for version management signature identification among other features yes yes yes yes clustering ability to dynamically organize search results into groups yes yes yes yes yes yes br group search results by topic yes yes sort by fields ability to sort all results by order of date or other attribute yes yes yes yes yes yes yes yes br \xe2\x80\x9ehard sort\xe2\x80\x9f yes yes faceted navigation this is the process of browsing the content by narrowing search results quickly in clicking filters that refine results based on related categories so that users extract more meaning and insight from the content class wikitable sortable faceted search facets description lookeen server hp idol coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 user about facets htm coveo facets ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator multiple filters does the system enable the user to filter results in selecting multiple facet values yes yes yes yes yes yes yes yes yes facet values and counts ability to display the term and the number of documents containing that term in the search results yes yes yes yes yes yes yes yes faceted classification hierarchical and range facets yes yes yes yes yes yes yes date number and string types ability to filter by date time number and string data types yes yes yes yes yes yes yes yes social and collaborative this is the process of asking social network class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 ref http www hcsolutions at produkte ontolica documents ontolica 2010 feature matrix pdf search solution for microsoft sharepoint ref sharepoint 2013 ref http www slideshare net surfray new sharepoint server 2013 search features introduction to sharepoint 2013 search ref google search appliance ibm infosphere data explorer lucidworks fusion perceptive search ref http www perceptivesoftware com images psi ds perceptiveenterprisesearch pdf perceptive enterprise search product datasheet ref secure enterprise search ravn connect intergator funnelback search search result tagging ability to improve relevancy by creating or adding existing tags yes yes yes no yes yes yes yes br real time yes no no deprecated in v14 0 1 tag searching ability to search for a tag yes yes yes yes yes yes yes yes personalization audience targeting ability to deliver more accurate targeted results yes yes br browse histories content contributors and interactions etc yes yes yes yes yes yes br source date metadata and entities biaising yes yes yes yes expertise location ability to find experts in users organization by searching on related keywords yes yes yes yes yes br with software development kit sdk yes yes yes yes yes saved search ability to save searches yes yes yes yes yes br with software development kit sdk no no no yes yes yes yes yes saved alerts ability to save alerts in order to notified when new content matching your queries has been added to the system yes yes no yes yes yes no saved rss feeds ability to save rss feeds yes yes no no yes yes yes mobile support class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search mobile search does the system support mobile device access and search yes yes yes yes yes yes yes yes mobile ui does the system detect the user device desktop smartphone tablet etc and adapt itself based on it yes yes yes yes yes yes yes admin ui and default public ui use responsive designs geolocation does the system enable from the end user s geolocation to provide additional context to filter yes yes yes yes yes compatibility is the system compatible with ios yes yes yes yes yes is the system compatible with android yes yes yes yes yes is the system compatible with windows phone yes yes yes administration architecture this section compares the flexibility in the underlying architecture application development the scalability and the administrative services of the products management search analytics this table is about the ability to report on usage and activity most popular queries documents not found etc class wikitable sortable search analytics description lookeen server hp idol coveo for advanced enterprise search endeca guided search ref http docs oracle com cd e35643 01 workbench 211 pdf workbenchuserguide pdf endeca\xc2\xae workbench user s guide oracle documentation ref sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search web based administration interfaces br html yes yes yes yes yes yes yes yes search statistics does the system collect search statistics yes yes yes yes yes yes yes yes search reports does the system enable to report search statistics yes yes yes yes yes yes yes br most popular queries yes yes yes portal usage reports does the system enable to report on portal usage yes yes br popular navigation yes yes yes br with software development kit sdk no yes yes no document storage reports yes yes yes no yes yes br for documents not found yes yes custom reports yes yes yes br with software development kit sdk yes no yes yes yes click scoring ability to improve relevancy by enabling to track which results are most often clicked yes yes yes yes yes yes interface flexibility this is about tools to customize the interface so that it adds value to any industry or business process class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator funnelback search standard based open interface does the system support all client platforms yes yes br http and xml json yes yes yes yes yes br xml json and http yes yes yes yes html json xml rss and opensearch page layout helper ability to change easily to global attributes logo fonts header and footer and to the look of the search box and search results yes yes no no action menu on search results not configurable yes yes yes yes no stylesheet editor ability to make more extensive changes using xslt stylesheet yes yes yes yes br full customization with css or java api xml yes yes yes yes yes br xslt stylesheet editor yes yes yes yes yes full results customisation via freemarker ref https docs funnelback com freemarker html ref and css js cached copies of xml templated via xslt ref https docs funnelback com xslt processing html ref scalability class wikitable sortable description lookeen server hp idol coveo for advanced enterprise search ref http onlinehelp coveo com en ces 7 0 administrator coveo scalability model htm scalability ref endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator index capacity how many total documents can be indexed into the system up to 10 million up to 100 million up to 100 million scalable to billions scalable to billions indexing rate how rapidly documents can be added or reprocessed into the index real time depends on setup and hardware per requirement scalable query processing speed how many queries per second queries per second qps the engine can process 2 000 br across all indexed data with sub second response times depends on setup and hardware scalable depands on the datasource sub second times platform readiness class wikitable sortable search analytics description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator general system requirement minimum of available disk space 100 mb 25 gb 10 gb 25 gb minimum ram 8gb 8 gb 8 gb 4 gb hard drives to store the data files scsi sas san over fc or ssd disks br as opposed to sata disks optimised for throughput br scsi sas san scsi sas san ssd hdd vendor intangibles this section compares each software investment class wikitable sortable investment description lookeen server hp idol coveo for advanced enterprise search endeca guided search sinequa enterprise search exalead cloudview datafari fast for sharepoint 2010 sharepoint 2013 google search appliance ibm infosphere data explorer lucidworks fusion perceptive search secure enterprise search ravn connect intergator hardware costs total costs of servers 0 depands on the base licence installation costs license costs 0 500 000 documents 28 387 br 1 million documents 66 236 br upgrade from 1 million to 2 million documents 1 971 br 2 million documents 123 010 br 2 million documents 123 010 br 3 million documents 113 548 br 3 million documents 158 967 br 5 million documents 433 766 br 10 million documents 305 066 br 10 million 423 913 br 15 million documents 533 896 br 15 million documents with hot backup 615 053 br 30 million documents with hot backup 993 548 annual maintenance annual maintenance fees per server references reflist first version category information retrieval systems'
b'phynd find is a lan indexing search engine used to facilitate peer to peer file sharing over a local area network it was developed by rensselaer polytechnic institute student researcher jesse jordan to solve various problems experienced by microsoft browsers and networks when trying to index files within a large network one of the results of jordan s file indexing exercise was that large numbers of downloaded music files were found on other users local systems jordan was relatively unconcerned with the nature of the content he was indexing his objective was enabling a network to index all its files without crashing any elements of the network ref lessig 2004 p 48 ref although jordan s search engine phynd merely indexed public data that users elected to share through an integrated sharing feature in microsoft windows jordan was sued by riaa for copyright infringement the original phynd search engine rpi phynd net defunct existing years before and months after jesse s lawsuit was shut down by the enormous pressure that the riaa in november 2003 brought upon jordan and his family the riaa was demanding 15 000 000 to settle ref lessig 2004 p 51 ref as a student researcher jordan had only modest life savings of approximately 12 000 and his family had only modest assets his limited options were to fight the riaa at enormous personal expense or to settle jordan chose to settle outside of court for 12 000 his entire life savings from student employment he subsequently raised 12 005 67 via contributions on a personal web site in july 2003 references lessig lawrence 2004 free culture isbn 1 59420 006 8 the penguin press new york notes reflist external links http poly rpi edu old article view php3 view 2599 part 1 phynd server shut down by threat of lawsuit webarchive date 2013 01 20 url http archive is 20130120043253 http news com com 2100 1027 995429 html tag fd lede1 hed title riaa sues campus file swappers http www isp planet com news 2003 riaa 030505 html students to pay in riaa song swapping suit http articles chicagotribune com 2003 07 07 news 0307080008 1 recording industry donations settlement 12 005 67 amount jesse jordan sued by the recording category information retrieval systems compu network stub'
b'infobox dot com company name quandl inc logo file quandl logo png 100px company type private company private founder plainlist tammer kamel abraham thomas location toronto canada area served worldwide key people plainlist tammer kamel small ceo small abraham thomas small cdo small industry internet products quandl data marketplace services data subscriptions num employees 16 url url quandl com programming language ruby programming language ruby and java programming language java website type e commerce language english launch date start date and age 2013 01 01 df yes quandl ipac en \xcb\x88 k w \xc9\x91\xcb\x90 n d \xc9\x99l is a toronto based platform for financial economic and alternative data serving investment professionals quandl sources data from over 500 publishers ref cite web url https www producthunt com tech quandl title quandl product hunt website product hunt language en us access date 2016 09 01 ref all quandl s data are accessible via an api ref cite web url http www econometricsbysimulation com 2013 05 quandl package 5000000 free datasets at html title quandl package 5 000 000 free datasets at the tip of your fingers date 5 may 2013 publisher econbs ref api access is possible through packages for multiple programming languages including r programming language r python programming language python matlab maple software and stata ref cite web url http blogs computerworld com business intelligenceanalytics 21881 quandl wikipedia data title quandl wikipedia for data date 8 march 2013 publisher computer world last machlis first sharon ref ref cite web url https www quandl com tools full list title full list of tools supported on quandl ref an excel add in allows access to data including stock price information quandl s sources include the united nations un worldbank cls group zacks and several hundred more ref cite web url http gigaom com 2013 05 31 its a beautiful thing when free data meets free analytics title it s a beautiful thing when free data meets free analytics date 31 may 2013 publisher gigaom last harris first derrick ref ref cite web url http www quandl com resources data sources title quandl data sources ref history quandl was founded in 2012 by tammer kamel and abraham thomas ref cite web url https www quandl com about title quandl financial and economic data website www quandl com access date 2016 09 01 ref in march 2013 quandl raised 1 5m ref cite web url https www crunchbase com organization quandl title quandl crunchbase website www crunchbase com access date 2016 09 01 ref in seed funding followed by a 5 4m series a from august capital in 2014 ref cite web url http blogs wsj com venturecapital 2014 11 13 quandl raises 5 4 million for its financial data marketplace title quandl raises 5 4 million for its financial data marketplace last gage first deborah access date 2016 09 01 ref since its launch quandl has been discussed as a disruptive force in the anachronistic financial data sector ref cite web url http mattturck com 2014 03 19 can the bloomberg terminal be toppled title can the bloomberg terminal be toppled date 2014 03 19 website matt turck access date 2016 09 01 ref with over 100 000 users ref cite web url https www integrity research com new data provider quandl title new data provider quandl moves toward alternative data \xe2\x80\xa2 integrity research language en us access date 2016 09 01 ref quandl is positioning itself as a possible replacement for both bloomberg and reuters terminals ref cite web url http www huffingtonpost com irene aldridge blindsided by innovation b 9025960 html title blindsided by innovation like bloomberg don t become a statistic last ablemarkets com first irene aldridge quantitative portfolio manager md at last2 speaker date 2016 01 22 website the huffington post access date 2016 09 01 last3 author last4 trading first4 high frequency ref quandl is an alternative for people who are unable to afford the expensive licensing fees of bloomberg and reuters ref cite web url https openforum hbs org challenge understand digital transformation of business data quandl a marketplace for financial data title quandl a marketplace for financial data access date 2016 09 01 ref products quandl s main focus and area of expertise is in the realm of alternative data ref name 0 cite web url http www waterstechnology com inside market data news 2462823 quandl embarks on quest for alternative data title quandl embarks on quest for alternative data access date 2016 09 01 ref quandl sells alternative datasets defined as any data that is not typically made available to wall street firms by traditional sources ref name 0 quandl sources evaluates and productizes undiscovered data and then sells it to financial institutions who use it to enhance their trading strategies ref cite web url https www quandl com institutions title quandl financial and economic data website www quandl com access date 2016 09 01 ref quandl also offers market data through its marketplace some data sets are free while others require a subscription different datasets have different prices they have hundreds of databases and providers ranging from stock price history to global fundamentals to commodities data to asian market data ref cite web url http www quandl com vendors title quandl financial and economic data website www quandl com access date 2016 09 01 ref quandl has an exclusive relationship with cls group in london and is the only source of commercial foreign exchange market fx volume data ref cite web url http www waterstechnology com inside market data news 2465222 quandl adds cls fx trade volume data to online platform title quandl adds cls fx trade volume data to online platform access date 2016 09 01 ref references reflist 30em category information retrieval systems'
b'coi date june 2009 infobox software name retrievalware logo screenshot caption developer fast search transfer convera excalibur technologies conquest software microsoft latest release version 8 2 latest release date release date 2006 10 13 latest preview version latest preview date operating system cross platform programming language c programming language c c java programming language java genre search algorithm search and index search engine index website retrievalware is an enterprise search enterprise search engine emphasizing natural language processing and semantic networks which was commercially available from 1992 to 2007 and is especially known for its use by government intelligence agencies ref cite news url http www washingtonpost com ac2 wp dyn a30161 2004dec2 title agencies find what they re looking for publisher the washington post date 2004 12 03 first david a last vise accessdate 2010 05 22 ref history retrievalware was initially created by http www linkedin com pub paul nelson 3 316 146 paul nelson http kenclark7 home comcast net kenclark7 kenneth clark and http www linkedin com in edaddison edwin addison as part of conquest software development began in 1989 but the software was not commercially available on a wide scale until 1992 early funding was provided by rome laboratory via a small business innovation research grant ref citation title fy 1991 sbir solicitation phase i award abstracts air force projects volume iii pages 70 71 date 1992 07 06 url http www dtic mil cgi bin gettrdoc ad ada252509 location u2 doc gettrdoc pdf note that synchronetics was the original name for conquest software incorporated ref on july 6 1995 conquest software was merged with excalibur technologies ref cite press release title excalibur technologies to merge with conquest software text and multimedia information retrieval leaders join forces to expand products channels and markets publisher business wire date 1995 07 06 url http findarticles com p articles mi m0ein is 1995 july 6 ai 17215774 tag content col1 ref and the product was rebranded as retrievalware on december 21 2000 excalibur technologies was combined with intel intel corporation s interactive media services division to form the convera convera corporation ref cite news title intel and excalibur form convera corporation publisher silicon valley san jose business journal date 2000 12 21 url http sanjose bizjournals com sanjose stories 2000 12 25 daily5 html ref finally on april 9 2007 the retrievalware software and business was purchased by fast search transfer at which point the product was officially retired ref name fastpurchase cite news title fast acquires convera s retrievalware business publisher information today inc date 2007 04 09 url http newsbreaks infotoday com newsbreaks fast acquires converas retrievalware business 35840 asp quote while fast will continue to support the retrievalware platform it will not continue development on it or add new features retrievalware customers will be offered an upgrade path to fast s own offering ref microsoft microsoft corporation continues to maintain the product for its existing customer base annual revenues for retrievalware peaked in 2001 at around 40 million us dollars ref citation title convera corp \xc2\xb7 10 k \xc2\xb7 for 1 1 01 date 2001 01 01 url http www secinfo com d12b5f 4f89a c htm indicates that convera products accounted for 85 of the total revenue of 51 5 million ref use of natural language techniques retrievalware is a relevancy ranking text search system with processing enhancements drawn from the fields of natural language processing natural language processing nlp and semantic networks nlp algorithms include dictionary based stemming also known as lemmatisation and dictionary based phrase identification semantic networks are used by retrievalware to expand the query words entered by the user to related terms with terms weights determined by the distance from the user s original terms in addition to automatic expansion a feedback mode whereby users could choose the meaning of the word before performing the expansion was available the first semantic networks were built using wordnet in addition retrievalware implemented a form of n gram search branded as aprp adaptive pattern recognition processing ref http www thefreelibrary com excalibur announces excalibur retrievalware 6 5 featuring a019849416 excalibur announces excalibur retrievalware 6 5 featuring retrievalware fileroom contains a description of aprp ref designed to search over documents with optical character recognition ocr errors query terms are divided into sets of 2 grams which are used to locate similarly matching terms from the inverted index the resulting matches are weighted based on similarly measures and then used to search for documents all of these features were available no later than 1993 ref name trec2 http trec nist gov pubs trec2 papers txt 25 txt site report for the text retrieval conference by conquest software inc trec2 find the complete proceedings http trec nist gov pubs trec2 t2 proceedings html here ref and conquest software has claimed that it was the first commercial text search system to implement these techniques ref cite press release title homework helper debuts on prodigy using conquest search engine publisher business wire date 1995 02 09 url http findarticles com p articles mi m0ein is 1995 feb 9 ai 16432681 quote conquest is the only search engine which uses dictionaries thesauri and other lexical resources to build in a semantic knowledgebase of over 440 000 word meanings and 1 6 million word relationships ref other notable features other notable features of retrievalware include distributed search servers ref name trec2 synchronizers for indexing external content management system s and relational database s ref name kmref cite news url http www kmworld com articles editorial feature excalibur retrievalware more than information retrieval 9139 aspx title excalibur retrievalware more than information retrieval publisher kmworld date 1999 10 01 ref a heterogeneous security model ref name kmref document classification document categorization ref name kmref real time document query matching profiling ref name trec2 multi lingual searches queries containing terms from multiple languages searching for documents containing terms from multiple languages and cross lingual searches queries in one language searching for documents in a different language ref cite news title multimedia search retrieval categorization url http www kmworld com articles news breaking news multimedia search retrieval categorization 12763 aspx date 2002 03 25 publisher kmworld ref participation in trec retrievalware participated in the text retrieval conference trec text retrieval conference in 1992 trec 1 1993 trec 2 and 1995 trec 4 in trec 1 ref name trec1 http trec nist gov pubs trec1 papers 21 txt site report for the text retrieval conference by conquest software inc trec 1 find the complete proceedings http trec nist gov pubs trec1 t1 proceedings html here ref and trec 4 ref http trec nist gov pubs trec4 papers excalibur ps gz the excalibur trec 4 system preparations and results a pdf version of which can be found http www pnelsoncomposer com writings excalibur trec4 pdf here and the complete proceedings can be found http trec nist gov pubs trec4 t4 proceedings html here ref the retrievalware runs for manually entered queries produced the best results based on the 11 point averages over all search engines which participated in the ad hoc category where search engines are allowed a single opportunity to process previously unknown queries against an existing database references reflist external links http www saoug org za archive 1999 9907 pdf marketing presentation on retrievalware semantic networks and adaptive pattern recognition algorithms defaultsort retrievalware category information retrieval systems'
b'trex is a search engine in the netweaver sap netweaver integrated technology platform produced by sap ag using columnar storage ref cite journal url http db csail mit edu pubs abadi column stores pdf doi 10 1561 1900000024 title the design and implementation of modern column oriented database systems author1 daniel abadi author2 peter boncz author3 stavros harizopoulos author4 stratos idreos author5 samuel madden journal foundations and trends in databases volume 5 issue 3 year 2012 pages 197 280 ref the trex engine is a standalone component that can be used in a range of system environments but is used primarily as an integral part of such sap products as enterprise portal knowledge warehouse and business intelligence bi formerly sap business information warehouse in sap netweaver bi the trex engine powers the bi accelerator which is a plug in appliance for enhancing the performance of online analytical processing the name trex stands for text retrieval and information extraction but it is not a registered trade mark of sap and is not used in marketing collateral search functions trex supports various kinds of text search including exact search boolean search wildcard search linguistic search grammatical variants are normalized for the index search and fuzzy search input strings that differ by a few letters from an index term are normalized for the index search result sets are ranked using term frequency inverse document frequency tf idf weighting and results can include snippets with the search terms highlighted trex supports text mining and classification using a vector space model groups of documents can be classified using query based classification example based classification or a combination of these plus keyword management trex supports structured data search not only for document metadata but also for mass business data and data in sap business objects indexes for structured data are implemented compactly using data compression and the data can be aggregated in linear time to enable large volumes of data to be processed entirely in memory recent developments include a join engine to join structured data from different fields in business objects a fast update capability to write a delta index beside a main index and to merge them offline while a second delta index takes updates a data mining feature pack for advanced mathematical analysis history the first code for the engine was written in 1998 and trex became an sap component in 2000 the sap netweaver bi accelerator was first rolled out in 2005 as of q1 2013 the current release of trex is sap nw 7 1 references reflist external links http www sap com platform netweaver index epx sap netweaver http www sap com platform netweaver components bi index epx sap netweaver business intelligence http www sap com platform netweaver businessinformation epx sap netweaver business information management http scn sap com docs doc 8489 search and classification trex on sap community network category sap netweaver category information retrieval systems category business intelligence'
b'infobox software name trip logo screenshot caption developer trip database ltd latest release version latest release date latest preview version latest preview date operating system genre search engine language license freeware website http www tripdatabase com trip trip is a free illness clinical search engine its primary function is to help clinician s identify the best available evidence with which to answer clinical questions its roots are firmly in the world of evidence based medicine history the site was created in 1997 as a search tool to help the staff of attract ref http www attract wales nhs uk attract ref answer clinical questions for general practitioner gp s in gwent county gwent south wales shortly afterwards bandolier journal bandolier highlighted the trip database and this helped establish the site in 2003 after a period of steady growth trip became a subscription only service this was abandoned in september 2006 and since then the growth in usage has been significant originally trip stood for turning research into practice but the system is now simply called trip ref cite web url http www tripdatabase com about title about work trip publisher trip database ltd accessdate 3 april 2013 ref process the core to trip s system is the identification and incorporation of new evidence the people behind trip are heavily involved in clinical question answering systems e g nlh q a service therefore if resources are identified that are useful in the q a process they tend to be added to trip users a site survey september 2007 showed that the site was searched over 500 000 times per month with 69 from health professional s and 31 from members of the public of the health professionals around 43 are doctors most users come from either the united kingdom or the united states in september 2008 the site was searched 1 4 million times to date the site has been searched over 100 millions times recent updates at the end of 2012 trip had a major upgrade which saw significant new enhancements new content widening the coverage new design advanced search pico search to help users formulate focused searches improved filtering search history timeline recording all a user activity on the site related articles education tracker trip has an education tracker which allows users to record their activity on trip which can then be used subject to local regulations for revalidation re licensing future areas of work trip is exploring numerous innovative technologies to improve the site these include link out to full text articles via trip rct database rapid within a week systematic review quality reviews learning from users prior use of the site and that of similar users to improve search results trip answers in november 2008 trip released a new website trip answers this is a repository of clinical q as from a variety of q a services at launch it had over 5 000 q as and currently has over 6 300 this content has been integrated into trip references reflist external links http www tripdatabase com trip http www ncbi nlm nih gov pmc articles pmc1852632 using the turning research into practice trip database how do clinicians really search an evaluation of the website http libguides lhl uab edu content php pid 108596 sid 1099056 reviews from systematic to narrative review of the site http guides library manoa hawaii edu content php pid 250484 sid 2157277 evidence based pyramid a pictorial representation of trip s approach to the evidence category medical websites category information retrieval systems'
b'coi date april 2010 the online portal greenpilot is a service provided by the german national library of medicine zb med the project is funded by the german research foundation deutsche forschungsgemeinschaft and gets its technical support from averbis ltd the portal first went online may 29 2009 and currently runs in the updated beta version in the context of the germany land of ideas deutschland land der ideen initiative under the patronage of the president of germany horst k\xc3\xb6hler the zb med was awarded the distinction selected landmark 2009 ausgew\xc3\xa4hlter ort 2009 ref http idw online de pages de news315583 pressemitteilung im informationsdienst wissenschaft vom 15 mai 2009 ref objective the greenpilot portal is a digital library specialised in the fields of nutritional agricultural and environmental sciences it aims to provide researchers in the three fields with a collection of scientific literature which is easy to access and of high quality especially the gray literature is often difficult to find and retrieve for the average user so greenpilot also aims to make access to these sources easier the service addresses itself not only to scientists and students but also to the broadly interested public greenpilot has been modelled after the corresponding digital library for medicine medpilot ref http www medpilot de medpilot portal ref also a project of the german national library of medicine the zb med has chosen the slogan greenpilot all about life and science as a motto in greenpilot scientifically relevant databases library catalogues and websites can be searched by entering a search term and the results are presented in a standardised web interface technical background greenpilot is a search engine based on intuitive search engine technology the portal s software was developed in the programming language perl the search engine technology is based upon the averbis search platform software developed by the averbis ltd and uses the open source software lucene functionally this is an expert search engine which centres around the intelligent semantic connection of search terms by means of a standardised vocabulary this is made possible by averbis s msi software which provides semantic search optimised for the fields of medicine and life sciences a contextual analysis of texts taking synonyms and compounds into account multilingual and cross language search linking of lay and expert vocabulary the search results are generated from a search index additionally a metasearch can be conducted in order to search other databases not contained in the index this search is based upon individual results from the specific database searched contents the greenpilot portal integrates various scientifically relevant information resources under a uniform search interface these resources are diverse and encompass national and international expert databases library catalogues of national libraries with a focus on specific topics full text documents from open access publishing open access journals as well as information contained on about one thousand scientifically relevant websites selected for greenpilot the following is a list of sources from november 2009 ref http www greenpilot de beta2 app misc help 8cafcf93601eb861aaef86b5ce99ecdc datenbanken list of databases in greenpilot ref library catalogues catalogue of the german national library of medicine zb med nutrition environment agriculture catalogue of the german national library of medicine zb med medicine health catalogue of the bonn university library library catalogues of scientifically relevant departments within the collective library network gbv catalogue of the federal ministry of food agriculture and consumer protection bmelv catalogue of the johann heinrich von th\xc3\xbcnen institut vti federal research institute for rural areas forestry and fisheries catalogue of the julius k\xc3\xbchn institut federal research centre for cultivated plants catalogue of the friedrich l\xc3\xb6ffler institut federal research institute for animal health catalogue of the max rubner institut federal research institute for nutrition and food catalogue of the federal institute for risk assessment catalogue of the leibniz institute for marine science ifm geomar catalogue of the leibniz institute for plant genetics and crop plant research ipk plant genetics and crop plant catalogue of the leibniz institute for plant biochemistry ipb plant chemistry catalogue of the special collection inshore and deep sea fishery catalogue of the university of veterinary medicine hannover tiho veterinary sciences catalogue of the german national library of economics zbw bibliographic databases agris 1975 2008 fao food and agriculture organization of the united nations vitis vea viticulture and enology abstracts medline 2004 2009 ufordat environmental research database uba ulidat environmental literature database uba elfis international information system for the agricultural sciences and technology relevant internet sources reviewed list of url s selected by the zb med nutrition environment agriculture open access journals with full text documents metasearch getinfo the knowledge portal for technical science provided by the library for technical sciences tib and the professional information centres fiz technik frankfurt fiz karlsruhe and fiz chemie berlin econis catalogue of the german national library of economics zbw other features search and results page search and advanced search context sensitive help function truncation and boolean function s personalised refining of search results by filtering for a specific document type language or database bookmark s document ordering ordering directly from the results page is made possible by using the document delivery service of the zb med or the electronic journals library elektronische zeitschriftenbibliothek personalisation my greenpilot a feature requiring the user to sign up for an account the service is free of charge and offers an overview of ordered documents as well as enabling individual managing of customer data see also list of digital library projects vascoda references references external links http www greenpilot de greenpilot website http www zbmed de home html lang en website of the german national library of medicine zb med http www land of ideas org germany land of ideas website coord missing germany category libraries in germany category information retrieval systems category internet search engines'
b'infobox software name pleade infoxbox title pleade logo file pleade logo png logo caption logo de pleade screenshot file caption collapsible author ajlsm developer ajlsm released start date yyyy mm dd df yes no discontinued latest release version 3 4 latest release date start date and age yyyy mm dd df yes no latest preview version 3 5 latest preview date start date and age yyyy mm dd df yes no frequently updated do not include this parameter unless you know what it does programming language java xslt apache cocoon cocoon operating system unix like microsoft windows platform size language french english german chinese language count do not include this parameter unless you know what it does language footnote status active genre digital library license gnu general public license alexa website url http www pleade com pleade is an open source search engine and browser for finding aid archival finding aids encoded in encoded archival description ead an xml standard for encoding archival finding aids based on the secure document exchange sdx platform it is a very flexible web application history the software was jointly started by the companies ajlsm and anaphore and was originally intended for publication and dissemination only of archival research tools like ead finding aids but it has become a library portal and a medium for digital libraries ref http www digicult info downloads dc info issue6 december 20031 pdf digicult info issue 6 page 16 ref technologies pleade is published in gpl 3 it is based on the apache cocoon apache cocoon framework and it works with the search engine sdx it is able to publish and distribute the following format encoded archival description ead comma separated values csv internally converted to xml xmlmarc text encoding initiative tei dublin core support for metadata encoding and transmission standard mets and alto xml alto is under active development ref http pleade com pleade 2012 les imprim\xc3\xa9s num\xc3\xa9ris\xc3\xa9s et les formats xml mets alto ref features customizable publication customizable index creation customizable search form simple and advanced search among publish documents federate search among different bases e g ead mets basket for database and for images a search history printing etc document viewer supporting jpeg tiff and for high resolution tiff and jpeg2000 it use http iipimage sourceforge net iipimage image server oai pmh repositories and expose them by default the format ead dublin core and dublin core qualified dublin core qualified dc the viewer has a pleade indexing module paleographic that can be used to permit correction of the ocr this tool is a tei export of data input a workflow management allows annotators and validation records seized printing resulting and finding aids as pdf documents with embedded images compatible with standard archival format text encoding initiative tei biblioml ability to import metadata from an integrated library system ils pleade entreprise pleade entreprise extended features to others xml format such as metadata encoding and transmission standard mets and alto xml alto examples these are examples of websites based on pleade columns list 2 archival portals http archives inventaires loire atlantique fr departmental records of loire atlantique ad 44 ad 44 http gael gironde fr gael gael gironde archives online http odysseo org odysseo resources for the history of immigration http taubira anaphore org parliamentary work of christiane taubira http archivesetmanuscrits bnf fr archives and manuscrits of the bnf french national library http jubilotheque upmc fr jubiloth\xc3\xa8que upmc s scientific digital library http lbf ehess ens lyon fr pages fonds html michel foucault s library les mots et les choses ens portals documentary http www michael culture org fr home michael http www numerique culture fr mpf pub fr index html digital heritage digital libraries digital library of lille lille iii http archivesetmanuscrits bnf fr bnf archives and manuscripts french national library related resources official website http pleade com http demo pleade com official demo http www pleadeenpratique org pleade in practice http www ajlsm com produits sdx sdx http www ajlsm com ajlsm company references references category digital library software category free software category information retrieval systems category archival science'
b'poliqarp is an open source search engine designed to process text corpus text corpora among others the national corpus of polish created at the institute of computer science polish academy of sciences features custom query language two level regular expressions operating at the level of characters in words operating at the level of words in statements paragraphs good performance compact corpus representation compared to similar projects portability across operating systems linux bsd win32 lack of portability across endianness current release works only on little endian devices external links http www korpus pl index php lang en page welcome polish corpus website in english http poliqarp sourceforge net project website on sourceforge http poliqarp suxx pl search plugin for firefox category information retrieval systems'
b'recommender systems collaborative search engines cse are web search engine s and enterprise search es within company intranets that let users combine their efforts in information retrieval ir activities share information resources collaboratively using knowledge tags and allow experts to guide less experienced people through their searches collaboration partners do so by providing query terms collective tagging adding comments or opinions rating search results and links clicked of former successful ir activities to users having the same or a related information need models of collaboration collaborative search engines can be classified along several dimensions intent explicit and implicit and synchronization ref name golo2007 citation title collaborative exploratory search year 2007 author golovchinsky gene author2 pickens jeremy journal proceedings of hcir 2007 workshop pages volume issue doi isbn url http projects csail mit edu hcir web hcir07 pdf ref and depth of mediation ref name pickens2008 citation title collaborative exploratory search year 2008 author pickens jeremy author2 golovchinsky gene author3 shah chirag author4 qvarfordt pernilla author5 back maribeth booktitle sigir 08 proceedings of the 31st annual international acm sigir conference on research and development in information retrieval pages 315 322 volume issue doi 10 1145 1390334 1390389 isbn 9781605581644 url http portal acm org citation cfm id 1390389 chapter algorithmic mediation for collaborative exploratory search ref task vs trait ref name morris2008 citation contribution understanding groups properties as a means of improving collaborative search systems year 2008 author morris meredith author2 teevan jaime title 1st international workshop on collaborative information retrieval held in conjunction with joint confrence on digital libraries jcdl 2008 pages volume issue doi isbn contribution url http workshops fxpal com jcdl2008 submissions tmpdf pdf ref and division of labor and sharing of knowledge ref name foley2008 citation title division of labour and sharing of knowledge for synchronous collaborative information retrieval year 2008 author foley colum booktitle phd thesis dublin city university pages volume issue doi isbn url http www computing dcu ie cfoley cfoley phd thesis pdf ref explicit vs implicit collaboration implicit collaboration characterizes collaborative filtering and recommendation systems in which the system infers similar information needs i spy ref name smith2003 citation title collaborative web search year 2003 author barry smyth author2 evelyn balfe author3 peter briggs author4 maurice coyle author5 jill freyne journal ijcai pages 1417 1419 volume issue doi isbn url ref jumper 2 0 seeks the community search assistant ref name glance2001 citation title community search assistant year 2001 author natalie s glance journal workshop on ai for web search aaai 02 pages volume issue doi isbn url ref the cse of burghardt et al ref name burghardtwi2008 citation title discovering the scope of privacy needs in collaborative search year 2008 author thorben burghardt author2 erik buchmann author3 klemens b\xc3\xb6hm journal web intelligence wi pages 910 volume issue doi 10 1109 wiiat 2008 165 isbn 978 0 7695 3496 1 ref and the works of longo et al ref name longo2009a citation title toward social search from explicit to implicit collaboration to predict users interests year 2009 author longo luca author2 barrett stephen author3 dondio pierpaolo journal webist 2009 proceedings of the fifth international conference on web information systems and technologies lisbon portugal march 23 26 2009 pages 693 696 volume 1 issue doi isbn 978 989 8111 81 4 url ref ref name longo2010 citation title enhancing social search a computational collective intelligence model of behavioural traits trust and time year 2010 author longo luca author2 barrett stephen author3 dondio pierpaolo journal transaction computational collective intelligence ii pages 46 69 volume 2 issue doi 10 1007 978 3 642 17155 0 3 isbn 978 3 642 17154 3 url http www springerlink com content e12233858017h042 series lecture notes in computer science ref ref name longo2009b citation title information foraging theory as a form of collective intelligence for social search year 2009 author longo luca author2 barrett stephen author3 dondio pierpaolo journal computational collective intelligence semantic web social networks and multiagent systems first international conference iccci 2009 wroclaw poland october 5 7 2009 proceedings pages 63 74 volume 1 issue doi isbn 978 3 642 04440 3 url http dl acm org citation cfm id 1692026 ref all represent examples of implicit collaboration systems that fall under this category identify similar users queries and links clicked automatically and recommend related queries and links to the searchers explicit collaboration means that users share an agreed upon information need and work together toward that goal for example in a chat like application query terms and links clicked are automatically exchanged the most prominent example of this class is searchtogether ref name morris2007 citation title searchtogether an interface for collaborative web search year 2007 author meredith ringel morris author2 eric horvitz journal uist url http portal acm org citation cfm id 1294211 1294215 ref published in 2007 searchtogether offers an interface that combines search results from standard search engines and a chat to exchange queries and links reddy et al ref name redy2008 citation title the role of communication in collaborative information searching year 2008 author madhu c reddy author2 bernhard j jansen author3 rashmi krishnappa journal astis ref 2008 follow a similar approach and compares two implementations of their cse called muse and must reddy et al focuses on the role of communication required for efficient cses representatives for the class of implicit collaboration are i spy ref name smith2003 the community search assistant ref name glance2001 and the cse of burghardt et al ref name burghardtwi2008 cerciamo ref name pickens2008 supports explicit collaboration by allowing one person to concentrate on finding promising groups of documents while having the other person make in depth judgments of relevance on documents found by the first person however in papagelis et al ref name papagelis2007 citation title searchius a collaborative search engine year 2007 author athanasios papagelis author2 christos zaroliagis journal enc 07 proceedings of the eighth mexican international conference on current trends in computer science pages 88 98 doi 10 1109 enc 2007 34 url http portal acm org citation cfm id 1302894 isbn 0 7695 2899 6 ref terms are used differently they combine explicitly shared links and implicitly collected browsing histories of users to a hybrid cse community of practice recent work in collaborative filtering and information retrieval has shown that sharing of search experiences among users having similar interests typically called a community of practice or community of interest reduces the effort put in by a given user in retrieving the exact information of interest ref name rohini ambati citation title a collaborative filtering based re ranking strategy for search in digital libraries year 2002 author rohini u author2 vamshi ambati journal icadl2005 the 8th international conference on asian digital libraries pages volume issue doi isbn url http www aaai org papers workshops 2006 ws 06 10 ws06 10 004 pdf ref collaborative search deployed within a community of practice deploys novel techniques for exploiting context during search by indexing and ranking search results based on the learned preferences of a community of users ref name coyle2008 citation title social aspects of a collaborative community based search network editor4 first eelco editor3 first pearl editor2 first judy editor1 first wolfgang year 2008 editor1 last nejdl author maurice coyle author2 barry smyth last author amp yes journal adaptive hypermedia and adaptive web based systems pages 103 112 volume 5149 2008 issue series doi 10 1007 978 3 540 70987 9 isbn 978 3 540 70984 8 url http portal acm org citation cfm id 1485050 editor2 last kay editor4 last herder editor3 last pu display editors 3 ref the users benefit by sharing information experiences and awareness to personalize result lists to reflect the preferences of the community as a whole the community representing a group of users who share common interests similar professions the best known example is the open source project apexkb previously known as jumper 2 0 ref name jumper2010 citation title jumper networks releases jumper 2 0 1 5 platform with new community search features year 2010 author jumper networks inc journal press release pages volume issue doi isbn url http www trilexnet com labs jumper ref depth of mediation this refers to the degree that the cse mediates search ref name pickens2008 searchtogether ref name morris2007 is an example of ui level mediation users exchange query results and judgments of relevance but the system does not distinguish among users when they run queries cerchiamo ref name pickens2008 and recommendation systems such as i spy ref name smith2003 keep track of each person s search activity independently and use that information to affect their search results these are examples of deeper algorithmic mediation task vs trait this model classifies people s membership in groups based on the task at hand vs long term interests these may be correlated with explicit and implicit collaboration ref name morris2008 privacy aware collaborative search engines search terms and links clicked that are shared among users reveal their interests habits social relations and intentions ref name euarticle29 citation title article 29 eu data protection working party year 2008 author data protection working party journal eu pages volume issue doi isbn url ref in other words cses put the privacy of the users at risk studies have shown that cses increase efficiency ref name morris2007 ref name smith2005 citation title a live user evaluation of collaborative web search year 2005 author barry smyth author2 evelyn balfe author3 oisin boydell author4 keith bradley author5 peter briggs author6 maurice coyle author7 jill freyne journal ijcai pages volume issue doi isbn url ref ref name smith2006 citation title anonymous personalization in collaborative web search year 2005 author smyth barry author2 balfe evelyn last author amp yes journal inf retr pages 165 190 volume 9 issue 2 doi 10 1007 s10791 006 7148 z isbn url ref ref name jung2004 citation title applying collaborative filtering for efficient document search year 2004 author seikyung jung author2 juntae kim author3 herlocker jl journal inf retr pages 640 643 volume issue doi isbn url ref unfortunately by the lack of privacy enhancing technologies a privacy aware user who wants to benefit from a cse has to disclose his entire search log note even when explicitly sharing queries and links clicked the whole former log is disclosed to any user that joins a search session thus sophisticated mechanisms that allow on a more fine grained level which information is disclosed to whom are desirable as cses are a new technology just entering the market identifying user privacy preferences and integrating privacy enhancing technologies pets into collaborative search are in conflict on one hand pets have to meet user preferences on the other hand one cannot identify these preferences without using a cse i e implementing pets into cses today the only work addressing this problem comes from burghardt et al ref name burghardtcc2008 citation title collaborative search and user privacy how can they be reconciled year 2008 author thorben burghardt author2 erik buchmann author3 klemens b\xc3\xb6hm author4 chris clifton journal collaboratecom pages volume issue doi isbn url http dbis ipd uni karlsruhe de 1184 php ref they implemented a cse with experts from the information system domain and derived the scope of possible privacy preferences in a user study with these experts results show that users define preferences referring to i their current context e g being at work ii the query content e g users exclude topics from sharing iii time constraints e g do not publish the query x hours after the query has been issued do not store longer than x days do not share between working time and that users intensively use the option to iv distinguish between different social groups when sharing information further users require v anonymization and vi define reciprocal constraints i e they refer to the behavior of other users e g if a user would have shared the same query in turn references reflist 2 internet search category information retrieval systems'
b'primary sources date october 2011 dynatext is an sgml publishing tool it was introduced in 1990 and was the first system to handle arbitrarily large sgml documents and to render them according to multiple style sheets that could be switched at will dynatext and its web sibling dynaweb won multiple seybold and other awards http xml coverpages org ebt award html http xml coverpages org dynaweb3 dvi html and there are eleven us patents related to the dynatext technology 5 557 722 5 644 776 5 708 806 5 893 109 5 983 248 6 055 544 6 101 511 6 101 512 6 105 044 6 167 409 and 6 546 406 dynatext was developed by electronic book technologies incorporated of providence rhode island ebt was founded by louis reynolds steven derose jeffrey vogel and andries van dam and was sold to inso corporation in 1996 when it had about 150 employees dynatext heavily influenced stylesheet technologies such as dsssl and css and xml chairman jon bosak cites ebt chief architect steven derose as one of the originators of the notion of well formed document well formedness formalized in xml as well as dynatext for influencing the design of web browsers in general http www ibiblio org bosak cv htm inso corporation went out of business in 2002 technology dynatext accepted sgml as input and built a binary representation of the structure similar to document object model dom for xml but persistent as well as a full text inverted index of the text elements and attributes customers typically distributed such compiled e books on cd rom or via network servers later versions of dynatext could also read sgml on the fly providing exactly the same interface unlike many prior systems dynatext was not limited to any particular document type definition dtd or xml schema schema rather customers could build style sheets in a simple language also sgml based using properties very much like the later dsssl css and xsl fo however every property could have an expression as its value which would be evaluated if necessary for each element the style applied to graphics tables formulae and plug ins could be included in documents unlike nearly all prior sgml systems dynatext was not limited to documents that could fit in ram on the viewing or serving computer system users commonly created documents in the tens to hundreds of mb dynatext customers included aerospace workstation and other computer industry firms government literary and technical publishers and others full text searches were based on an inverted index of words and other tokens except for japanese text which was handled specially dynatext could report the number of hits for a given search that occur within each section in the table of contents by default the table of contents appeared in a separate pane as an expandable outline and clicking on any entry scrolled the full text pane to the start of the corresponding section searches could also restrict hits to particular sgml element types or sequences of types refer to attributes and use boolean operators and parentheses the and operator restricted its operands to occurring near each other by default in the same paragraph or comparable element references http www w3 org history 19921103 hypertext hypertext products dynatext overview html dynatext notes by tim berners lee this note refers to a pre release or very early release of dynatext cite journal id ms last smith first mackenzie title review dynatext an electronic publishing system journal computers and the humanities volume 27 issue 5 6 pages 415 420 publisher springer location date 1993 jstor http www jstor org stable 30204569 issn 0010 4817 cite book url http techpubs sgi com library dynaweb docs 0630 sgi enduser books iidweb ug sgi html ch05 html title iris insight\xe2\x84\xa2 dynaweb\xe2\x84\xa2 user s guide chapter 5 introduction to the dynatext search language publisher silicon graphics inc document number 007 3229 001 cite journal url http www w3 org conferences www4 ora 951122 112 html title dynaweb interfacing large sgml repositories and the www journal fourth international world wide web conference the web revolution date 1995 location boston first gavin thomas last nicol category information retrieval systems'
b'a database search engine is a search engine that operates on material stored in a digital database search engines categories of search engine software include web search or full text search e g lucene database or structured data search e g dieselpoint mixed or enterprise search e g google search appliance the largest online directories such as google and yahoo utilize thousands of computers to process billions of website documents using web crawlers or spiders software returning results for thousands of searches per second processing high query volumes requires software to run in a distributed environment with redundancy components searching for textual content in databases or structured data formats such as xml and comma separated values csv presents special challenges and opportunities which specialized search engines resolve databases allow logical queries such as the use of multi field boolean logic while full text searches do not crawling a human by eye search is not necessary to find information stored in a database because the data is already structured index datatbase indexing the data allows for faster searches database search engines are usually included with major database software products applications database search technology is used by large public and private entities including government database services e commerce companies online advertising platforms telecommunications service providers and other consumers with a need to access information in large repositories see also outline of search engines list of search engines external links http www searchtools com info database search html searching for text information in databases defaultsort search engine technology category information retrieval systems'
b'multiple issues more footnotes date august 2014 one source date august 2014 a search engine is an information retrieval information retrieval system designed to help find information stored on a computer system the search results are usually presented in a list and are commonly called hits search engines help to minimize the time required to find information and the amount of information which must be consulted akin to other techniques for managing information overload citation needed date december 2007 the most public visible form of a search engine is a web search engine which searches for information on the world wide web how search engines work search engines provide an interface computer science interface to a group of items that enables users to specify criteria about an item of interest and have the engine find the matching items the criteria are referred to as a web search query search query in the case of text search engines the search query is typically expressed as a set of words that identify the desired concept that one or more document s may contain ref voorhees e m http www indexnist gov itl iad 894 02 works papers nlp ir ps natural language processing and information retrieval national institute of standards and technology march 2000 ref there are several styles of search query syntax that vary in strictness it can also switch names within the search engines from previous sites whereas some text search engines require users to enter two or three words separated by whitespace computer science white space other search engines may enable users to specify entire documents pictures sounds and various forms of natural language some search engines apply improvements to search queries to increase the likelihood of providing a quality set of items through a process known as query expansion image search engine diagram en svg right thumb index based search engine the list of items that meet the criteria specified by the query is typically sorted or ranked ranking items by relevance from highest to lowest reduces the time required to find the desired information probability probabilistic search engines rank items based on measures of string metric similarity between each item and the query typically on a scale of 1 to 0 1 being most similar and sometimes popularity or authority see bibliometrics or use relevance feedback boolean logic boolean search engines typically only return items which match exactly without regard to order although the term boolean search engine may simply refer to the use of boolean style syntax the use of operators logical conjunction and logical disjunction or not and exclusive nor gate xor in a probabilistic context to provide a set of matching items that are sorted according to some criteria quickly a search engine will typically collect metadata about the group of items under consideration beforehand through a process referred to as index search engine indexing the index typically requires a smaller amount of computer storage which is why some search engines only store the indexed information and not the full content of each item and instead provide a method of navigating to the items in the serpent album search engine result page alternatively the search engine may store a copy of each item in a cache computing cache so that users can see the state of the item at the time it was indexed or for archive purposes or to make repetitive processes work more efficiently and quickly other types of search engines do not store an index crawler or spider type search engines a k a real time search engines may collect and assess items at the time of the search query dynamically considering additional items based on the contents of a starting item known as a seed or seed url in the case of an internet crawler meta search engine s store neither an index nor a cache and instead simply reuse the index or results of one or more other search engines to provide an aggregated final set of results types of search engines by source desktop search federated search human search engine metasearch engine multisearch search aggregator web search engine by content type full text search image search video search engine by interface incremental search instant answer semantic search selection based search by topic bibliographic database enterprise search medical literature retrieval vertical search see also portal computer science div col colwidth 30em automatic summarization emanuel goldberg inventor of early search engine index search engine inverted index list of search engines list of enterprise search vendors search engine optimization search suggest drop down list solver computer science spamdexing sql text mining div col end references reflist internet search authority control defaultsort search engine computing category information retrieval systems'
b'other uses relevance disambiguation in information science and information retrieval relevance denote how well a retrieved document or set of documents meets the information need of the user relevance may include concerns such as timeliness authority or novelty of the result history the concern with the problem of finding relevant information dates back at least to the first publication of scientific journals in the 17th century citation needed date june 2015 the formal study of relevance began in the 20th century with the study of what would later be called bibliometrics in the 1930s and 1940s s c bradford used the term relevant to characterize articles relevant to a subject cf bradford s law in the 1950s the first information retrieval systems emerged and researchers noted the retrieval of irrelevant articles as a significant concern in 1958 b c vickery made the concept of relevance explicit in an address at the international conference on scientific information ref mizzaro s 1997 relevance the whole history journal of the american society for information science 48 810\xe2\x80\x90832 ref since 1958 information scientists have explored and debated definitions of relevance a particular focus of the debate was the distinction between relevance to a subject or topical relevance and user relevance citation needed date june 2015 evaluation main article information retrieval performance and correctness measures the information retrieval community has emphasized the use of test collections and benchmark tasks to measure topical relevance starting with the cranfield experiments of the early 1960s and culminating in the text retrieval conference trec evaluations that continue to this day as the main evaluation framework for information retrieval research citation needed date june 2015 in order to evaluate how well an information retrieval system retrieved topically relevant results the relevance of retrieved results must be quantified in cranfield experiments cranfield style evaluations this typically involves assigning a relevance level to each retrieved result a process known as relevance assessment relevance levels can be binary indicating a result is relevant or that it is not relevant or graded indicating results have a varying degree of match between the topic of the result and the information need once relevance levels have been assigned to the retrieved results information retrieval performance measures information retrieval performance measures can be used to assess the quality of a retrieval system s output in contrast to this focus solely on topical relevance the information science community has emphasized user studies that consider user relevance citation needed date june 2015 these studies often focus on aspects of human computer interaction see also human computer information retrieval clustering and relevance the cluster hypothesis proposed by c j van rijsbergen in 1979 asserts that two documents that are similar to each other have a high likelihood of being relevant to the same information need with respect to the embedding similarity space the cluster hypothesis can be interpreted globally or locally ref name diazthesis f diaz autocorrelation and regularization of query based retrieval scores phd thesis university of massachusetts amherst amherst ma february 2008 chapter 3 ref the global interpretation assumes that there exist some fixed set of underlying topics derived from inter document similarity these global clusters or their representatives can then be used to relate relevance of two documents e g two documents in the same cluster should both be relevant to the same request methods in this spirit include cluster based information retrieval ref name croftcbir w b croft a model of cluster searching based on classification information systems vol 5 pp 189 195 1980 ref ref name griffithscbir a griffiths h c luckhurst and p willett using interdocument similarity information in document retrieval systems journal of the american society for information science vol 37 no 1 pp 3 11 1986 ref cluster based document expansion such as latent semantic analysis or its language modeling equivalents ref name lmcbir x liu and w b croft cluster based retrieval using language models in sigir 04 proceedings of the 27th annual international conference on research and development in information retrieval new york ny usa pp 186 193 acm press 2004 ref it is important to ensure that clusters either in isolation or combination successfully model the set of possible relevant documents a second interpretation most notably advanced by ellen voorhees ref name voorheescbir e m voorhees the cluster hypothesis revisited in sigir 85 proceedings of the 8th annual international acm sigir conference on research and development in information retrieval new york ny usa pp 188 196 acm press 1985 ref focuses on the local relationships between documents the local interpretation avoids having to model the number or size of clusters in the collection and allow relevance at multiple scales methods in this spirit include multiple cluster retrieval ref name griffithscbir ref name voorheescbir spreading activation ref name preece s preece a spreading activation network model for information retrieval phd thesis university of illinois urbana champaign 1981 ref and relevance propagation ref name relprop t qin t y liu x d zhang z chen and w y ma a study of relevance propagation for web search in sigir 05 proceedings of the 28th annual international acm sigir conference on research and development in information retrieval new york ny usa pp 408 415 acm press 2005 ref methods local document expansion ref name docexpansion a singhal and f pereira document expansion for speech retrieval in sigir 99 proceedings of the 22nd annual international acm sigir conference on research and development in information retrieval new york ny usa pp 34 41 acm press 1999 ref score regularization ref name diazreg f diaz regularizing query based retrieval scores information retrieval vol 10 pp 531 562 december 2007 ref local methods require an accurate and appropriate document similarity measure problems and alternatives the documents which are most relevant are not necessarily those which are most useful to display in the first page of search results for example two duplicate documents might be individually considered quite relevant but it is only useful to display one of them a measure called maximal marginal relevance mmr has been proposed to overcome this shortcoming it considers the relevance of each document only in terms of how much new information it brings given the previous results ref cite journal last1 carbonell first1 jaime last2 goldstein first2 jade title the use of mmr diversity based reranking for reordering documents and producing summaries journal proceedings of the 21st annual international acm sigir conference on research and development in information retrieval date 1998 doi 10 1145 290941 291025 url http dl acm org citation cfm id 291025 ref in some cases a query may have an ambiguous interpretation or a variety of potential responses providing a diversity of results can be a consideration when evaluating the utility of a result set ref http www dcs gla ac uk workshops ddr2012 ref references reflist additional reading hj\xc3\xb8rland b 2010 the foundation of the concept of relevance journal of the american society for information science and technology 61 2 217 237 relevance communication and cognition by dan sperber deirdre wilson 2nd ed oxford cambridge ma blackwell publishers 2001 isbn 978 0 631 19878 9 saracevic t 2007 relevance a review of the literature and a framework for thinking on the notion in information science part ii nature and manifestations of relevance journal of the american society for information science and technology 58 3 1915 1933 http www scils rutgers edu tefko saracevic 20relevance 20pt 20ii 20jasist 20 2707 pdf pdf saracevic t 2007 relevance a review of the literature and a framework for thinking on the notion in information science part iii behavior and effects of relevance journal of the american society for information science and technology 58 13 2126 2144 http www scils rutgers edu tefko saracevic 20relevance 20pt 20iii 20jasist 20 2707 pdf pdf saracevic t 2007 relevance in information science invited annual thomson scientific lazerow memorial lecture at school of information sciences university of tennessee september 19 2007 http www sis utk edu lazerow2007 video introduction to information retrieval evaluation stanford http web stanford edu class cs276 handouts evaluationnew handout 6 per pdf presentation in pdf category information retrieval evaluation'
b'the s\xc3\xb8rensen dice index also known by other names see s\xc3\xb8rensen dice coefficient name name below is a statistic used for comparing the similarity of two sample statistics samples it was independently developed by the botanist s thorvald s\xc3\xb8rensen ref cite journal last s\xc3\xb8rensen first t year 1948 title a method of establishing groups of equal amplitude in plant sociology based on similarity of species and its application to analyses of the vegetation on danish commons journal kongelige danske videnskabernes selskab volume 5 issue 4 pages 1 34 doi ref and lee raymond dice ref cite journal last dice first lee r title measures of the amount of ecologic association between species jstor 1932409 journal ecology volume 26 issue 3 year 1945 pages 297 302 doi 10 2307 1932409 ref who published in 1948 and 1945 respectively the s\xc3\xb8rensen dice is also known as f1 score or dice similarity coefficient dsc name the index is known by several other names usually s\xc3\xb8rensen index or dice s coefficient both names also see similarity coefficient index and other such variations common alternate spellings for s\xc3\xb8rensen are sorenson soerenson index and s\xc3\xb6renson index and all three can also be seen with the sen ending other names include jan czekanowski czekanowski s binary non quantitative index ref name gallagher formula s\xc3\xb8rensen s original formula was intended to be applied to presence absence data and is math qs frac 2 x cap y x y math where x and y are the numbers of elements in the two samples based on what is written here math dsc frac 2 tp 2 tp fp fn math as compared with the jaccard index which omits true negatives from both the numerator and the denominator qs is the quotient of similarity and ranges between 0 and nbsp 1 ref http www sekj org pdf anbf40 anbf40 415 pdf ref it can be viewed as a similarity measure over sets similarly to the jaccard index the set operations can be expressed in terms of vector operations over binary vectors a and b math s v frac 2 a cdot b a 2 b 2 math which gives the same outcome over binary vectors and also gives a more general similarity metric over vectors in general terms for sets x and y of keywords used in information retrieval the coefficient may be defined as twice the shared information intersection over the sum of cardinalities ref cite book last van rijsbergen first cornelis joost year 1979 title information retrieval url http www dcs gla ac uk keith preface html publisher butterworths location london isbn 3 642 12274 4 ref when taken as a string similarity measure the coefficient may be calculated for two strings x and y using bigram s as follows ref cite conference last kondrak first grzegorz author2 marcu daniel author3 knight kevin year 2003 title cognates can improve statistical translation models booktitle proceedings of hlt naacl 2003 human language technology conference of the north american chapter of the association for computational linguistics pages 46 48 url http aclweb org anthology n n03 n03 2016 pdf ref math s frac 2 n t n x n y math where n sub t sub is the number of character bigrams found in both strings n sub x sub is the number of bigrams in string x and n sub y sub is the number of bigrams in string y for example to calculate the similarity between code night code code nacht code we would find the set of bigrams in each word code ni code code ig code code gh code code ht code code na code code ac code code ch code code ht code each set has four elements and the intersection of these two sets has only one element code ht code inserting these numbers into the formula we calculate s nbsp nbsp 2 nbsp \xc2\xb7 nbsp 1 nbsp nbsp 4 nbsp nbsp 4 nbsp nbsp 0 25 difference from jaccard this coefficient is not very different in form from the jaccard index however since it doesn t satisfy the triangle inequality it can be considered a metric mathematics generalized metrics semimetric version of the jaccard index ref name gallagher the function ranges between zero and one like jaccard unlike jaccard the corresponding difference function math d 1 frac 2 x cap y x y math is not a proper distance metric as it does not possess the property of triangle inequality ref name gallagher gallagher e d 1999 http citeseerx ist psu edu viewdoc download doi 10 1 1 9 1334 rep rep1 type pdf compah documentation university of massachusetts boston ref the simplest counterexample of this is given by the three sets a b and a b the distance between the first two being 1 and the difference between the third and each of the others being one third to satisfy the triangle inequality the sum of any two of these three sides must be greater than or equal to the remaining side however the distance between a and a b plus the distance between b and a b equals 2 3 and is therefore less than the distance between a and b which is 1 applications the s\xc3\xb8rensen dice coefficient is useful for ecological community data e g looman campbell 1960 ref http links jstor org sici sici 0012 9658 28196007 2941 3a3 3c409 3aaosk 28f 3e2 0 co 3b2 1 looman j and campbell j b 1960 adaptation of sorensen s k 1948 for estimating unit affinities in prairie vegetation ecology 41 3 409 416 ref justification for its use is primarily empirical rather than theoretical although it can be justified theoretically as the intersection of two fuzzy set s ref http dx doi org 10 1007 bf00039905 roberts d w 1986 ordination on the basis of fuzzy set theory vegetatio 66 3 123 131 ref as compared to euclidean distance s\xc3\xb8rensen distance retains sensitivity in more heterogeneous data sets and gives less weight to outliers ref mccune bruce grace james 2002 analysis of ecological communities mjm software design isbn 0 9721290 0 6 ref recently the dice score and its variations e g logdice taking a logarithm of it has become popular in computer lexicography for measuring the lexical association score of two given words ref http nlp fi muni cz raslan 2008 raslan08 pdf page 14 rychl\xc3\xbd p 2008 a lexicographer friendly association score proceedings of the second workshop on recent advances in slavonic natural language processing raslan 2008 6 9 ref it is also commonly used in image segmentation in particular for comparing algorithm output against reference masks in medical applications citation needed reason some seminal works need to be cited to show how dice coefficient is used date december 2016 abundance version the expression is easily extended to abundance ecology abundance instead of presence absence of species this quantitative version is known by several names quantitative s\xc3\xb8rensen dice index ref name gallagher quantitative s\xc3\xb8rensen index ref name gallagher quantitative dice index ref name gallagher bray curtis dissimilarity bray curtis similarity 1 minus the bray curtis dissimilarity ref name gallagher jan czekanowski czekanowski s quantitative index ref name gallagher steinhaus index ref name gallagher e c pielou pielou s percentage similarity ref name gallagher 1 minus the hellinger distance ref cite journal first j roger last bray first2 j t last2 curtis year 1957 title an ordination of the upland forest communities of southern wisconsin journal ecological monographs volume 27 issue 4 pages 326 349 doi 10 2307 1942268 ref see also correlation jaccard index hamming distance mantel test morisita s overlap index most frequent k characters overlap coefficient renkonen similarity index due to olavi renkonen tversky index universal adaptive strategy theory uast references reflist external links wikibooks algorithm implementation strings dice s coefficient dice s coefficient defaultsort sorensen dice coefficient category information retrieval evaluation category string similarity measures category measure theory'
b'relevance feedback is a feature of some information retrieval systems the idea behind relevance feedback is to take the results that are initially returned from a given query and to use information about whether or not those results are relevant to perform a new query we can usefully distinguish between three types of feedback explicit feedback implicit feedback and blind or pseudo feedback explicit feedback explicit feedback is obtained from assessors of relevance indicating the relevance of a document retrieved for a query this type of feedback is defined as explicit only when the assessors or other users of a system know that the feedback provided is interpreted as relevance information retrieval relevance judgments users may indicate relevance explicitly using a binary or graded relevance system binary relevance feedback indicates that a document is either relevant or irrelevant for a given query graded relevance feedback indicates the relevance of a document to a query on a scale using numbers letters or descriptions such as not relevant somewhat relevant relevant or very relevant graded relevance may also take the form of a cardinal ordering of documents created by an assessor that is the assessor places documents of a result set in order of usually descending relevance an example of this would be the searchwiki feature implemented by google on their search website the relevance feedback information needs to be interpolated with the original query to improve retrieval performance such as the well known rocchio classification algorithm rocchio algorithm a performance metric mathematics metric which became popular around 2005 to measure the usefulness of a ranking algorithm based on the explicit relevance feedback is ndcg other measures include precision information retrieval precision at k and mean average precision mean average precision mean average precision implicit feedback implicit feedback is inferred from user behavior such as noting which documents they do and do not select for viewing the duration of time spent viewing a document or page browsing or scrolling actions http www scils rutgers edu etc mongrel kelly belkin sigir2001 pdf there are many signals during the search process that one can use for implicit feedback and the types of information to provide in response ref jansen b j and mcneese m d 2005 https faculty ist psu edu jjansen academic pubs jansen assistance jasist2005 pdf evaluating the effectiveness of and patterns of interactions with automated assistance in ir systems journal of the american society for information science and technology 56 14 1480 1503 ref ref kelly diane and jaime teevan implicit feedback for inferring user preference a bibliography acm sigir forum vol 37 no 2 acm 2003 ref the key differences of implicit relevance feedback from that of explicit include http haystack lcs mit edu papers kelly sigirforum03 pdf the user is not assessing relevance for the benefit of the ir system but only satisfying their own needs and the user is not necessarily informed that their behavior selected documents will be used as relevance feedback an example of this is dwell time information retrieval dwell time which is a measure of how long a user spends viewing the page linked to in a search result it is an indicator of how well the search result met the query intent of the user and is used as a feedback mechanism to improve search results another example of this is the surf canyon browser extension which advances search results from later pages of the result set based on both user interaction clicking an icon and time spent viewing the page linked to in a search result blind feedback pseudo relevance feedback also known as blind relevance feedback provides a method for automatic local analysis it automates the manual part of relevance feedback so that the user gets improved retrieval performance without an extended interaction the method is to do normal retrieval to find an initial set of most relevant documents to then assume that the top k ranked documents are relevant and finally to do relevance feedback as before under this assumption the procedure is take the results returned by initial query as relevant results only top k with k being between 10 and 50 in most experiments select top 20 30 indicative number terms from these documents using for instance tf idf weights do query expansion add these terms to query and then match the returned documents for this query and finally return the most relevant documents some experiments such as results from the cornell smart system published in buckley et al 1995 show improvement of retrieval systems performances using pseudo relevance feedback in the context of trec 4 experiments this automatic technique mostly works evidence suggests that it tends to work better than global analysis ref jinxi xu and w bruce croft http portal acm org citation cfm id 243202 query expansion using local and global document analysis in proceedings of the 19th annual international acm sigir conference on research and development in information retrieval sigir 1996 ref through a query expansion some relevant documents missed in the initial round can then be retrieved to improve the overall performance clearly the effect of this method strongly relies on the quality of selected expansion terms it has been found to improve performance in the trec ad hoc task citation needed date march 2011 but it is not without the dangers of an automatic process for example if the query is about copper mines and the top several documents are all about mines in chile then there may be query drift in the direction of documents on chile in addition if the words added to the original query are unrelated to the query topic the quality of the retrieval is likely to be degraded especially in web search where web documents often cover multiple different topics to improve the quality of expansion words in pseudo relevance feedback a positional relevance feedback for pseudo relevance feedback has been proposed to select from feedback documents those words that are focused on the query topic based on positions of words in feedback documents ref yuanhua lv and chengxiang zhai http portal acm org citation cfm id 1835546 positional relevance model for pseudo relevance feedback in proceedings of the 33rd international acm sigir conference on research and development in information retrieval sigir 2010 ref specifically the positional relevance model assigns more weights to words occurring closer to query words based on the intuition that words closer to query words are more likely to be related to the query topic blind feedback automates the manual part of relevance feedback and has the advantage that assessors are not required using relevance information relevance information is utilized by using the contents of the relevant documents to either adjust the weights of terms in the original query or by using those contents to add words to the query relevance feedback is often implemented using the rocchio classification algorithm rocchio algorithm further reading http www umiacs umd edu jimmylin lbsc796 infm718r 2006 spring lecture7 ppt relevance feedback lecture notes jimmy lin s lecture notes adapted from doug oard s http www ischool berkeley edu hearst irbook chapters chap10 html chapter from modern information retrieval stefan b\xc3\xbcttcher charles l a clarke and gordon v cormack http www ir uwaterloo ca book information retrieval implementing and evaluating search engines mit press cambridge mass 2010 references reflist 2 category internet search algorithms category information retrieval evaluation zh \xe7\x9b\xb8\xe5\x85\xb3\xe5\x8f\x8d\xe9\xa6\x88'
b'file precisionrecall svg thumb 350px precision and recall in pattern recognition and information retrieval with binary classification precision also called positive predictive value is the fraction of retrieved instances that are relevant while recall also known as sensitivity and specificity sensitivity is the fraction of relevant instances that are retrieved both precision and recall are therefore based on an understanding and measure of relevance suppose a computer program for recognizing dogs in scenes from a video identifies 7 dogs in a scene containing 9 dogs and some cats if 4 of the identifications are correct but 3 are actually cats the program s precision is 4 7 while its recall is 4 9 when a search engine computing search engine returns 30 pages only 20 of which were relevant while failing to return 40 additional relevant pages its precision is 20 30 2 3 while its recall is 20 60 1 3 so in this case precision is how useful the search results are and recall is how complete the results are in statistics if the null hypothesis is that all and only the relevant items are retrieved absence of type i and type ii errors corresponds respectively to maximum precision no false positive and maximum recall no false negative the above pattern recognition example contained 7 minus 4 3 type i errors and 9 minus 4 5 type ii errors precision can be seen as a measure of exactness or quality whereas recall is a measure of completeness or quantity in simple terms high precision means that an algorithm returned substantially more relevant results than irrelevant ones while high recall means that an algorithm returned most of the relevant results introduction in an information retrieval scenario the instances are documents and the task is to return a set of relevant documents given a search term or equivalently to assign each document to one of two categories relevant and not relevant in this case the relevant documents are simply those that belong to the relevant category recall is defined as the number of relevant documents retrieved by a search divided by the total number of existing relevant documents while precision is defined as the number of relevant documents retrieved by a search divided by the total number of documents retrieved by that search in a classification machine learning classification task the precision for a class is the number of true positives i e the number of items correctly labeled as belonging to the positive class divided by the total number of elements labeled as belonging to the positive class i e the sum of true positives and type i and type ii errors false positives which are items incorrectly labeled as belonging to the class recall in this context is defined as the number of true positives divided by the total number of elements that actually belong to the positive class i e the sum of true positives and type i and type ii errors false negatives which are items which were not labeled as belonging to the positive class but should have been in information retrieval a perfect precision score of 1 0 means that every result retrieved by a search was relevant but says nothing about whether all relevant documents were retrieved whereas a perfect recall score of 1 0 means that all relevant documents were retrieved by the search but says nothing about how many irrelevant documents were also retrieved in a classification task a precision score of 1 0 for a class c means that every item labeled as belonging to class c does indeed belong to class c but says nothing about the number of items from class c that were not labeled correctly whereas a recall of 1 0 means that every item from class c was labeled as belonging to class c but says nothing about how many other items were incorrectly also labeled as belonging to class c often there is an inverse relationship between precision and recall where it is possible to increase one at the cost of reducing the other brain surgery provides an illustrative example of the tradeoff consider a brain surgeon tasked with removing a cancerous tumor from a patient s brain the surgeon needs to remove all of the tumor cells since any remaining cancer cells will regenerate the tumor conversely the surgeon must not remove healthy brain cells since that would leave the patient with impaired brain function the surgeon may be more liberal in the area of the brain she removes to ensure she has extracted all the cancer cells this decision increases recall but reduces precision on the other hand the surgeon may be more conservative in the brain she removes to ensure she extracts only cancer cells this decision increases precision but reduces recall that is to say greater recall increases the chances of removing healthy cells negative outcome and increases the chances of removing all cancer cells positive outcome greater precision decreases the chances of removing healthy cells positive outcome but also decreases the chances of removing all cancer cells negative outcome usually precision and recall scores are not discussed in isolation instead either values for one measure are compared for a fixed level at the other measure e g precision at a recall level of 0 75 or both are combined into a single measure examples for measures that are a combination of precision and recall are the precision and recall f measure f measure the weighted harmonic mean of precision and recall or the matthews correlation coefficient which is a geometric mean of the chance corrected variants the regression coefficient s informedness deltap and markedness deltap ref name powers2011 ref cite journal first1 p last1 perruchet first2 r last2 peereman year 2004 title the exploitation of distributional information in syllable processing journal j neurolinguistics volume 17 pages 97 119 doi 10 1016 s0911 6044 03 00059 9 ref accuracy and precision in binary classification accuracy is a weighted arithmetic mean of precision and inverse precision weighted by bias as well as a weighted arithmetic mean of recall and inverse recall weighted by prevalence ref name powers2011 inverse precision and recall are simply the precision and recall of the inverse problem where positive and negative labels are exchanged for both real classes and prediction labels recall and inverse recall or equivalently true positive rate and false positive rate are frequently plotted against each other as receiver operating characteristic roc curves and provide a principled mechanism to explore operating point tradeoffs outside of information retrieval the application of recall precision and f measure are argued to be flawed as they ignore the true negative cell of the contingency table and they are easily manipulated by biasing the predictions ref name powers2011 the first problem is solved by using accuracy and precision in binary classification accuracy and the second problem is solved by discounting the chance component and renormalizing to cohen s kappa but this no longer affords the opportunity to explore tradeoffs graphically however informedness and markedness are kappa like renormalizations of recall and precision ref cite conference first david m w last powers date 2012 title the problem with kappa booktitle conference of the european chapter of the association for computational linguistics eacl2012 joint robus unsup workshop ref and their geometric mean matthews correlation coefficient thus acts like a debiased f measure definition information retrieval context in information retrieval contexts precision and recall are defined in terms of a set of retrieved documents e g the list of documents produced by a web search engine for a query and a set of relevant documents e g the list of all documents on the internet that are relevant for a certain topic cf relevance the measures were defined in harvtxt perry kent berry 1955 precision in the field of information retrieval precision is the fraction of retrieved documents that are relevance information retrieval relevant to the query math display block text precision frac text relevant documents cap text retrieved documents text retrieved documents math precision takes all retrieved documents into account but it can also be evaluated at a given cut off rank considering only the topmost results returned by the system this measure is called precision at n or p n for example for a text search on a set of documents precision is the number of correct results divided by the number of all returned results precision is also used with recall information retrieval recall the percent of all relevant documents that is returned by the search the two measures are sometimes used together in the f1 score or f measure to provide a single measurement for a system note that the meaning and usage of precision in the field of information retrieval differs from the definition of accuracy and precision within other branches of science and technology recall recall in information retrieval is the fraction of the documents that are relevant to the query that are successfully retrieved math display block text recall frac text relevant documents cap text retrieved documents text relevant documents math for example for text search on a set of documents recall is the number of correct results divided by the number of results that should have been returned in binary classification recall is called sensitivity and specificity sensitivity sensitivity so it can be looked at as the probability that a relevant document is retrieved by the query it is trivial to achieve recall of 100 by returning all documents in response to any query therefore recall alone is not enough but one needs to measure the number of non relevant documents also for example by computing the precision definition classification context for classification tasks the terms true positives true negatives false positives and false negatives see type i and type ii errors for definitions compare the results of the classifier under test with trusted external judgments the terms positive and negative refer to the classifier s prediction sometimes known as the expectation and the terms true and false refer to whether that prediction corresponds to the external judgment sometimes known as the observation let us define an experiment from p positive instances and n negative instances for some condition the four outcomes can be formulated in a 2\xc3\x972 contingency table or confusion matrix as follows diagnostictesting diagram confusion matrix terms border 0 align center style text align center background ffffff colspan 2 style background ddffdd actual class br observation rowspan 2 style background ffdddd predicted class br expectation tp br true positive br correct result fp br false positive br unexpected result bgcolor efefef fn br false negative br missing result tn br true negative br correct absence of result precision and recall are then defined as ref name olsondelen olson david l and delen dursun 2008 advanced data mining techniques springer 1st edition february 1 2008 page 138 isbn 3 540 76916 1 ref math display block text precision frac tp tp fp math math display block text recall frac tp tp fn math recall in this context is also referred to as the true positive rate or sensitivity and specificity sensitivity and precision is also referred to as positive predictive value ppv other related measures used in classification include true negative rate and accuracy and precision in binary classification accuracy ref name olsondelen true negative rate is also called specificity tests specificity specificity math display block text true negative rate frac tn tn fp math math display block text accuracy frac tp tn tp tn fp fn math probabilistic interpretation it is possible to interpret precision and recall not as ratios but as probabilities precision is the probability that a randomly selected retrieved document is relevant recall is the probability that a randomly selected relevant document is retrieved in a search note that the random selection refers to a uniform distribution over the appropriate pool of documents i e by randomly selected retrieved document we mean selecting a document from the set of retrieved documents in a random fashion the random selection should be such that all documents in the set are equally likely to be selected note that in a typical classification system the probability that a retrieved document is relevant depends on the document the above interpretation extends to that scenario also needs explanation another interpretation for precision and recall is as follows precision is the average probability of relevant retrieval recall is the average probability of complete retrieval here we average over multiple retrieval queries f measure main article f1 score a measure that combines precision and recall is the harmonic mean of precision and recall the traditional f measure or balanced f score math display block f 2 cdot frac mathrm precision cdot mathrm recall mathrm precision mathrm recall math this measure is approximately the average of the two when they are close and is more generally the harmonic mean which for the case of two numbers coincides with the square of the geometric mean divided by the arithmetic mean there are several reasons that the f score can be criticized in particular circumstances due to its bias as an evaluation metric ref name powers2011 this is also known as the math f 1 math measure because recall and precision are evenly weighted it is a special case of the general math f beta math measure for non negative real values of nbsp math beta math math display block f beta 1 beta 2 cdot frac mathrm precision cdot mathrm recall beta 2 cdot mathrm precision mathrm recall math two other commonly used math f math measures are the math f 2 math measure which weights recall higher than precision and the math f 0 5 math measure which puts more emphasis on precision than recall the f measure was derived by van rijsbergen 1979 so that math f beta math measures the effectiveness of retrieval with respect to a user who attaches math beta math times as much importance to recall as precision it is based on van rijsbergen s effectiveness measure math e alpha 1 frac 1 frac alpha p frac 1 alpha r math the second term being the weighted harmonic mean of precision and recall with weights math alpha 1 alpha math their relationship is math f beta 1 e alpha math where math alpha frac 1 1 beta 2 math limitations as goals there are other parameters and strategies for performance metric of information retrieval system such as the area under the precision recall curve auc ref zygmunt zaj\xc4\x85c what you wanted to know about auc http fastml com what you wanted to know about auc ref for web document retrieval if the user s objectives are not clear the precision and recall can t be optimized as summarized by lopresti ref lopresti daniel 2001 http www csc liv ac uk wda2001 panel presentations lopresti lopresti files v3 document htm wda 2001 panel ref quote browsing is a comfortable and powerful paradigm the serendipity serendipity effect search results don t have to be very good recall not important as long as you get at least some good hits precision not important as long as at least some of the hits on the first page you return are good see also uncertainty coefficient also called proficiency sensitivity and specificity references reflist refbegin baeza yates ricardo ribeiro neto berthier 1999 modern information retrieval new york ny acm press addison wesley seiten 75 ff isbn 0 201 39829 x hj\xc3\xb8rland birger 2010 the foundation of the concept of relevance journal of the american society for information science and technology 61 2 217 237 makhoul john kubala francis schwartz richard and weischedel ralph 1999 http citeseerx ist psu edu viewdoc summary doi 10 1 1 27 4637 performance measures for information extraction in proceedings of darpa broadcast news workshop herndon va february 1999 cite journal title machine literature searching x machine language factors underlying its design and development year 1955 doi 10 1002 asi 5090060411 van rijsbergen cornelis joost keith 1979 information retrieval london gb boston ma butterworth 2nd edition isbn 0 408 70929 4 refend external links http www dcs gla ac uk keith preface html information retrieval c j van rijsbergen 1979 http www text analytics101 com 2014 10 computing precision and recall for html computing precision and recall for a multi class classification problem category information retrieval evaluation category information science category bioinformatics de beurteilung eines klassifikators anwendung im information retrieval'
b'orphan date january 2011 a champion list also called top doc or fancy list is a precomputed list sometimes used with the vector space model to avoid computing relevancy rankings for all documents each time a document collection is queried the champion list contains a set of n documents with the highest weights for the given term the number n can be chosen to be different for each term and is often higher for rarer terms the weights can be calculated by for example tf idf category information retrieval evaluation computing stub'
b'unreferenced date june 2016 the overlap coefficient or szymkiewicz simpson coefficient is a string metric similarity measure related to the jaccard index that measures the overlap between two sets and is defined as the size of the intersection set theory intersection divided by the smaller of the size of the two sets math mathrm overlap x y frac x cap y min x y math if set x is a subset of y or the converse then the overlap coefficient is equal to one references references category information retrieval techniques category information retrieval evaluation category string similarity measures category measure theory'
b'refimprove date june 2007 the mean reciprocal rank is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries ordered by probability of correctness the reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer the mean reciprocal rank is the average of the reciprocal ranks of results for a sample of queries q ref cite conference title proceedings of the 8th text retrieval conference booktitle trec 8 question answering track report author e m voorhees year 1999 pages 77 ndash 82 ref math text mrr frac 1 q sum i 1 q frac 1 text rank i math where math text rank i math refers to the rank position of the first relevant document for the i th query the reciprocal value of the mean reciprocal rank corresponds to the harmonic mean of the ranks example for example suppose we have the following three sample queries for a system that tries to translate english words to their plurals in each case the system makes three guesses with the first one being the one it thinks is most likely correct class wikitable query results correct response rank reciprocal rank cat catten cati cats cats 3 1 3 tori torii tori toruses tori 2 1 2 virus viruses virii viri viruses 1 1 given those three samples we could calculate the mean reciprocal rank as 1 3 nbsp nbsp 1 2 nbsp nbsp 1 3 11 18 or about 0 61 this basic definition does not specify what to do if none of the proposed results are correct though reciprocal rank 0 could be used in this situation it also does not specify what do to if there are multiple correct answers in the list in this case information retrieval mean average precision mean average precision is a potential alternative metric see also information retrieval question answering references reflist external links cite conference title evaluating web based question answering systems booktitle proceedings of lrec author1 d r radev author2 h qi author3 h wu author4 w fan year 2002 category summary statistics category information retrieval evaluation'
b'discounted cumulative gain dcg is a measure of ranking quality in information retrieval it is often used to measure effectiveness of world wide web web search engine algorithm s or related applications using a relevance information retrieval graded relevance scale of documents in a search engine result set dcg measures the usefulness or gain of a document based on its position in the result list the gain is accumulated from the top of the result list to the bottom with the gain of each result discounted at lower ranks ref kalervo jarvelin jaana kekalainen cumulated gain based evaluation of ir techniques acm transactions on information systems 20 4 422 446 2002 ref overview two assumptions are made in using dcg and its related measures highly relevant documents are more useful when appearing earlier in a search engine result list have higher ranks highly relevant documents are more useful than marginally relevant documents which are in turn more useful than non relevant documents dcg originates from an earlier more primitive measure called cumulative gain cumulative gain cumulative gain cg is the predecessor of dcg and does not include the position of a result in the consideration of the usefulness of a result set in this way it is the sum of the graded relevance values of all results in a search result list the cg at a particular rank position math p math is defined as math mathrm cg p sum i 1 p rel i math where math rel i math is the graded relevance of the result at position math i math the value computed with the cg function is unaffected by changes in the ordering of search results that is moving a highly relevant document math d i math above a higher ranked less relevant document math d j math does not change the computed value for cg based on the two assumptions made above about the usefulness of search results dcg is used in place of cg for a more accurate measure discounted cumulative gain the premise of dcg is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result the discounted cg accumulated at a particular rank position math p math is defined as ref name stanfordireval cite web title introduction to information retrieval evaluation url http www stanford edu class cs276 handouts evaluationnew handout 6 per pdf publisher stanford university accessdate 23 march 2014 date 21 april 2013 ref math mathrm dcg p sum i 1 p frac rel i log 2 i 1 rel 1 sum i 2 p frac rel i log 2 i 1 math previously there has not been any theoretically sound justification for using a logarithm ic reduction factor ref name cms2009 cite book title search engines information retrieval in practice author1 b croft author2 d metzler author3 t strohman year 2010 publisher addison wesley ref other than the fact that it produces a smooth reduction but wang et al 2013 ref yining wang liwei wang yuanzhi li di he wei chen tie yan liu 2013 a theoretical analysis of normalized discounted cumulative gain ndcg ranking measures in proceedings of the 26th annual conference on learning theory colt 2013 ref give theoretical guarantee for using the logarithmic reduction factor in ndcg the authors show that for every pair of substantially different ranking functions the ndcg can decide which one is better in a consistent manner an alternative formulation of dcg ref chris burges tal shaked erin renshaw ari lazier matt deeds nicole hamilton and greg hullender 2005 learning to rank using gradient descent in proceedings of the 22nd international conference on machine learning icml 05 acm new york ny usa 89 96 doi 10 1145 1102351 1102363 http doi acm org 10 1145 1102351 1102363 ref places stronger emphasis on retrieving relevant documents math mathrm dcg p sum i 1 p frac 2 rel i 1 log 2 i 1 math the latter formula is commonly used in industry including major web search companies ref name stanfordireval and data science competition platform such as kaggle ref cite web title normalized discounted cumulative gain url https www kaggle com wiki normalizeddiscountedcumulativegain accessdate 23 march 2014 ref these two formulations of dcg are the same when the relevance values of documents are binary function binary ref name cms2009 rp 320 math rel i in 0 1 math note that croft et al 2010 and burges et al 2005 present the second dcg with a log of base e while both versions of dcg above use a log of base 2 when computing ndcg with the second formulation of dcg the base of the log does not matter but the base of the log does affect the value of ndcg for the first formulation clearly the base of the log affects the value of dcg in both formulations not very clear does it affect or no the value of dcg normalized dcg search result lists vary in length depending on the web search query query comparing a search engine s performance from one query to the next cannot be consistently achieved using dcg alone so the cumulative gain at each position for a chosen value of math p math should be normalized across queries this is done by sorting all relevant documents in the corpus by their relative relevance producing the maximum possible dcg through position math p math also called ideal dcg idcg through that position for a query the normalized discounted cumulative gain or ndcg is computed as math mathrm ndcg p frac dcg p idcg p math where math mathrm idcg p sum i 1 rel frac 2 rel i 1 log 2 i 1 math and rel represents the list of relevant documents ordered by their relevance in the corpus up to position p the ndcg values for all queries can be averaged to obtain a measure of the average performance of a search engine s ranking algorithm note that in a perfect ranking algorithm the math dcg p math will be the same as the math idcg p math producing an ndcg of 1 0 all ndcg calculations are then relative values on the interval 0 0 to 1 0 and so are cross query comparable the main difficulty encountered in using ndcg is the unavailability of an ideal ordering of results when only partial relevance feedback is available example presented with a list of documents in response to a search query an experiment participant is asked to judge the relevance of each document to the query each document is to be judged on a scale of 0 3 with 0 meaning not relevant 3 meaning highly relevant and 1 and 2 meaning somewhere in between for the documents ordered by the ranking algorithm as math d 1 d 2 d 3 d 4 d 5 d 6 math the user provides the following relevance scores math 3 2 3 0 1 2 math that is document 1 has a relevance of 3 document 2 has a relevance of 2 etc the cumulative gain of this search result listing is math mathrm cg 6 sum i 1 6 rel i 3 2 3 0 1 2 11 math changing the order of any two documents does not affect the cg measure if math d 3 math and math d 4 math are switched the cg remains the same 11 dcg is used to emphasize highly relevant documents appearing early in the result list using the logarithmic scale for reduction the dcg for each result in order is class wikitable border 1 math i math math rel i math math log 2 i 1 math math frac rel i log 2 i 1 math 1 3 1 3 2 2 1 585 1 262 3 3 2 1 5 4 0 2 322 0 5 1 2 585 0 387 6 2 2 807 0 712 so the math dcg 6 math of this ranking is math mathrm dcg 6 sum i 1 6 frac rel i log 2 i 1 3 1 262 1 5 0 0 387 0 712 6 861 math now a switch of math d 3 math and math d 4 math results in a reduced dcg because a less relevant document is placed higher in the ranking that is a more relevant document is discounted more by being placed in a lower rank the performance of this query to another is incomparable in this form since the other query may have more results resulting in a larger overall dcg which may not necessarily be better in order to compare the dcg values must be normalized to normalize dcg values an ideal ordering for the given query is needed for this example that ordering would be the monotonic monotonically decreasing sort of the relevance judgments provided by the experiment participant which is math 3 3 2 2 1 0 math the dcg of this ideal ordering or idcg ideal dcg is then math mathrm idcg 6 7 141 math and so the ndcg for this query is given as math mathrm ndcg 6 frac dcg 6 idcg 6 frac 6 861 7 141 0 961 math limitations normalized dcg metric does not penalize for bad documents in the result for example if a query returns two results with scores math 1 1 1 math and math 1 1 1 0 math respectively both would be considered equally good even if the latter contains a bad result one way to take into account this limitation is to use math 1 2 rel i math in the numerator for scores for which we want to penalize and math 2 rel i 1 math for all others for example for the ranking judgments math excellent fair bad math one might use numerical scores math 1 0 1 math instead of math 2 1 0 math normalized dcg does not penalize for missing documents in the result for example if a query returns two results with scores math 1 1 1 math and math 1 1 1 1 1 math respectively both would be considered equally good one way to take into account this limitation is to enforce fixed set size for the result set and use minimum scores for the missing documents in previous example we would use the scores math 1 1 1 0 0 math and math 1 1 1 1 1 math and quote ndcg as ndcg 5 normalized dcg may not be suitable to measure performance of queries that may typically often have several equally good results this is especially true when this metric is limited to only first few results as it is done in practice for example for queries such as restaurants ndcg 1 would account for only first result and hence if one result set contains only 1 restaurant from the nearby area while the other contains 5 both would end up having same score even though latter is more comprehensive references reflist 1 category information retrieval evaluation'
b'for the observation regarding integrated circuits moore s law refimprove date september 2011 mooers law is an empirical observation of behavior made by american computer scientist calvin mooers in 1959 the observation is made in relation to information retrieval and the interpretation of the observation is used commonly throughout the information profession both within and outside its original context quote an information retrieval system will tend not to be used whenever it is more painful and troublesome for a customer to have information than for him not to have it calvin mooers ref name morville cite book url https books google com books id xjnljxxbhusc printsec frontcover dq isbn 9780596007652 hl en sa x ei qvwht5dfhits2qx1rnzpca ved 0cdaq6aewaa v onepage q mooers 20law f false title ambient findability series o reilly series marketing technology society author peter morville edition illustrated publisher o reilly media year 2005 page 44 isbn 978 0 596 00765 2 ref original interpretation mooers argued that information is at risk of languishing unused due not only on the effort required to assimilate it but also to any fallout that could arise from the discovery of information that conflicts with the user s personal academic or corporate interests in interacting with new information a user runs the risk of proving their work incorrect or even irrelevant instead mooers argued users prefer to remain in a state of safety in which new arguments are ignored in an attempt to save potential embarrassment or reprisal from supervisors ref cite web last mooers first calvin title mooers law or why some retrieval systems are used and others are not url http findarticles com p articles mi qa3633 is 199610 ai n8749122 work business library accessdate 25 october 2011 ref out of context interpretation the more commonly used interpretation of mooers law is considered to be a derivation of the principle of least effort first stated by george kingsley zipf this interpretation focuses on the amount of effort that will be expended to use and understand a particular information retrieval system before the information seeker gives up and the law is often paraphrased to increase the focus on the retrieval system quote the more difficult and time consuming it is for a customer to use an information system the less likely it is that he will use that information system j michael pemberton quote mooers law tells us that information will be used in direct proportion to how easy it is to obtain roger k summit ref name morville in this interpretation painful and troublesome comes from using the retrieval system references reflist cite journal last austin first brice date june 2001 title mooers law in and out of context journal journal of the american society for information science and technology volume 25 issue 8 pages 607 609 url http spot colorado edu norcirc mooers html accessdate 2007 05 23 doi 10 1002 asi 1114 external links http special lib umn edu findaid xml cbi00081 xml calvin n mooers papers 1930 1992 at the charles babbage institute university of minnesota http purl umn edu 107510 oral history interview with calvin n mooers and charlotte d mooers at the charles babbage institute interview discusses information retrieval and programming language research from world war ii through the early 1990s category empirical laws category information retrieval evaluation'
b'distinguish redirect query rate query throughput queries per second qps is a common measure of the amount of search traffic an information retrieval system such as a search engine or a database receives during one second ref http www microsoft com enterprisesearch en us search glossary aspx q microsoft s search glossary ref the term is used more broadly for any request response system more correctly called requests per second rps high traffic systems must watch their qps in order to know when to scale the system to handle more load references reflist category units of frequency category information retrieval evaluation computer stub'
b'the matthews correlation coefficient is used in machine learning as a measure of the quality of binary two class binary classification classifications introduced by biochemist brian matthews biochemist brian w matthews in 1975 ref name matthews1975 cite journal last matthews first b w title comparison of the predicted and observed secondary structure of t4 phage lysozyme journal biochimica et biophysica acta bba protein structure date 1975 volume 405 issue 2 pages 442 451 doi 10 1016 0005 2795 75 90109 9 ref it takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes the mcc is in essence a correlation coefficient between the observed and predicted binary classifications it returns a value between minus 1 and 1 a coefficient of 1 represents a perfect prediction 0 no better than random prediction and minus 1 indicates total disagreement between prediction and observation the statistic is also known as the phi coefficient mcc is related to the pearson s chi square test chi square statistic for a 2\xc3\x972 contingency table math text mcc sqrt frac chi 2 n math where n is the total number of observations while there is no perfect way of describing the confusion matrix of true and false positives and negatives by a single number the matthews correlation coefficient is generally regarded as being one of the best such measures ref name powers2011 other measures such as the proportion of correct predictions also termed accuracy are not useful when the two classes are of very different sizes for example assigning every object to the larger set achieves a high proportion of correct predictions but is not generally a useful classification the mcc can be calculated directly from the confusion matrix using the formula math text mcc frac tp times tn fp times fn sqrt tp fp tp fn tn fp tn fn math in this equation tp is the number of true positive s tn the number of true negative s fp the number of false positive s and fn the number of false negative s if any of the four sums in the denominator is zero the denominator can be arbitrarily set to one this results in a matthews correlation coefficient of zero which can be shown to be the correct limiting value the original formula as given by matthews was ref name matthews1975 math text n tn tp fn fp math math text s frac tp fn n math math text p frac tp fp n math math text mcc frac tp n s times p sqrt p s 1 s 1 p math this is equal to the formula given above as a correlation and dependence correlation coefficient the matthews correlation coefficient is the geometric mean of the regression coefficient s of the problem and its dual mathematics dual the component regression coefficients of the matthews correlation coefficient are markedness \xce\xb4p and youden s j statistic informedness or \xce\xb4p ref name powers2011 cite journal first david m w last powers date 2011 title evaluation from precision recall and f measure to roc informedness markedness correlation journal journal of machine learning technologies volume 2 issue 1 pages 37 63 url http www flinders edu au science engineering fms school csem publications tech reps research artfcts trra 2007 pdf ref ref name perruchet2004 cite journal first1 p last1 perruchet first2 r last2 peereman year 2004 title the exploitation of distributional information in syllable processing journal j neurolinguistics volume 17 pages 97 119 doi 10 1016 s0911 6044 03 00059 9 ref markedness and informedness correspond to different directions of information flow and generalize youden s j statistic the deltap statistics and as their geometric mean the matthews correlation coefficient to more than two classes ref name powers2011 confusion matrix main article confusion matrix confusion matrix terms recall let us define an experiment from p positive instances and n negative instances for some condition the four outcomes can be formulated in a 2\xc3\x972 contingency table or confusion matrix as follows diagnostictesting diagram multiclass case the matthews correlation coefficient has been generalized to the multiclass case this generalization was called the math r k math statistic for k different classes by the author and defined in terms of a math k times k math confusion matrix math c math ref name gorodkin2004comparing cite journal last gorodkin first jan title comparing two k category assignments by a k category correlation coefficient journal computational biology and chemistry date 2004 volume 28 number 5 pages 367 374 publisher elsevier ref ref name gorodkinrk2006 cite web last1 gorodkin first1 jan title the rk page url http rk kvl dk introduction index html website the rk page accessdate 28 december 2016 ref math text mcc frac sum k sum l sum m c kk c lm c kl c mk sqrt sum k sum l c kl sum k k neq k sum l c k l sqrt sum k sum l c lk sum k k neq k sum l c l k math when there are more than two labels the mcc will no longer range between 1 and 1 instead the minimum value will be between 1 and 0 depending on the true distribution the maximum value is always 1 todo potentially un comment later for now just stick with referenced version this formula can be more easily understood by defining intermediate variables math t k sum i c ik math the number of times class k truly occurred math p k sum i c ki math the number of times class k was predicted math c sum k c kk math the total number of samples correctly predicted math s sum i sum j c ij math the total number of samples this allows the formula to be expressed as math text mcc frac cs vec t cdot vec p sqrt s 2 vec p cdot vec p sqrt s 2 vec t cdot vec t math see also phi coefficient f1 score cram\xc3\xa9r s v statistics cram\xc3\xa9r s v a similar measure of association between nominal variables cohen s kappa references reflist should reference in the main text general references pierre baldi baldi p brunak s chauvin y andersen c a f nielsen h assessing the accuracy of prediction algorithms for classification an overview bioinformatics 2000 16 412 ndash 424 http bioinformatics oxfordjournals org cgi content abstract 16 5 412 carugo o detailed estimation of bioinformatics prediction reliability through the fragmented prediction performance plots bmc bioinformatics 2007 http www ncbi nlm nih gov pmc articles pmc2148069 defaultsort matthews correlation coefficient category machine learning category information retrieval evaluation category statistical classification category computational chemistry category cheminformatics category bioinformatics category statistical ratios category summary statistics for contingency tables'
b'file spearman fig1 svg 300px thumb a spearman correlation of 1 results when the two variables being compared are monotonically related even if their relationship is not linear this means that all data points with greater x values than that of a given data point will have greater y values as well in contrast this does not give a perfect pearson correlation file spearman fig2 svg 300px thumb when the data are roughly elliptically distributed and there are no prominent outliers the spearman correlation and pearson correlation give similar values file spearman fig3 svg 300px thumb the spearman correlation is less sensitive than the pearson correlation to strong outliers that are in the tails of both samples that is because spearman s rho limits the outlier to the value of its rank in statistics spearman s rank correlation coefficient or spearman s rho named after charles spearman and often denoted by the greek letter rho letter math rho math rho or as math r s math is a non parametric statistics nonparametric measure of rank correlation correlation and dependence statistical dependence between the ranking of two variable mathematics applied statistics variables it assesses how well the relationship between two variables can be described using a monotonic function the spearman correlation between two variables is equal to the pearson product moment correlation coefficient pearson correlation between the rank values of those two variables while pearson s correlation assesses linear relationships spearman s correlation assesses monotonic relationships whether linear or not if there are no repeated data values a perfect spearman correlation of 1 or \xe2\x88\x921 occurs when each of the variables is a perfect monotone function of the other intuitively the spearman correlation between two variables will be high when observations have a similar or identical for a correlation of 1 ranking rank i e relative position label of the observations within the variable 1st 2nd 3rd etc between the two variables and low when observations have a dissimilar or fully opposed for a correlation of 1 rank between the two variables spearman s coefficient is appropriate for both continuous variable continuous and discrete variable s including level of measurement ordinal scale ordinal variables ref level of measurement typology scale types ref ref cite book title jmp for basic univariate and multivariate statistics a step by step guide last lehman first ann publisher sas press year 2005 isbn 1 59047 576 3 location cary nc page 123 ref both spearman s math rho math and kendall tau rank correlation coefficient kendall s math tau math can be formulated as special cases of a more general correlation coefficient definition and calculation the spearman correlation coefficient is defined as the pearson product moment correlation coefficient pearson correlation coefficient between the ranking ranked variables ref name myers2003 cite book last1 myers first1 jerome l first2 arnold d last2 well title research design and statistical analysis publisher lawrence erlbaum year 2003 edition 2nd isbn 0 8058 4037 0 pages 508 ref for a sample of size n the n raw score s math x i y i math are converted to ranks math operatorname rg x i operatorname rg y i math and math r s math is computed from math r s rho operatorname rg x operatorname rg y frac operatorname cov operatorname rg x operatorname rg y sigma operatorname rg x sigma operatorname rg y math where math rho math denotes the usual pearson product moment correlation coefficient pearson correlation coefficient but applied to the rank variables math operatorname cov operatorname rg x operatorname rg y math is the covariance of the rank variables math sigma operatorname rg x math and math sigma operatorname rg y math are the standard deviation s of the rank variables only if all n ranks are distinct integers it can be computed using the popular formula math r s 1 frac 6 sum d i 2 n n 2 1 math where math d i operatorname rg x i operatorname rg y i math is the difference between the two ranks of each observation n is the number of observations identical values are usually citation needed date may 2016 each assigned ranking fractional ranking 28 221 2 5 2 5 4 22 ranking 29 fractional ranks equal to the average of their positions in the ascending order of the values which is equivalent to averaging over all possible permutations if ties are present in the data set this equation yields incorrect results only if in both variables all ranks are distinct then math sigma operatorname rg x sigma operatorname rg y operatorname var operatorname rg x operatorname var operatorname rg y n n 2 1 6 math cf tetrahedral number math t n 1 math the first equation normalizing by the standard deviation may even be used even when ranks are normalized to 0 1 relative ranks because it is insensitive both to translation and linear scaling for example if 1 2 3 4 5 vs 1 3 3 3 5 has r s 0 894 but the simplified formula yields 0 877 this method should also not be used in cases where the data set is truncated that is when the spearman correlation coefficient is desired for the top x records whether by pre change rank or post change rank or both the user should use the pearson correlation coefficient formula given above citation needed date september 2015 the standard error of the coefficient \xcf\x83 was determined by pearson in 1907 and gosset in 1920 it is math sigma r s frac 0 6325 sqrt n 1 math related quantities main article correlation and dependence there are several other numerical measures that quantify the extent of statistical dependence between pairs of observations the most common of these is the pearson product moment correlation coefficient which is a similar correlation method to spearman s rank that measures the linear relationships between the raw numbers rather than between their ranks an alternative name for the spearman rank correlation is the grade correlation ref name yule and kendall cite book last yule first g u last2 kendall first2 m g orig year 1950 title an introduction to the theory of statistics edition 14th year 1968 publisher charles griffin co page 268 ref in this the rank of an observation is replaced by the grade in continuous distributions the grade of an observation is by convention always one half less than the rank and hence the grade and rank correlations are the same in this case more generally the grade of an observation is proportional to an estimate of the fraction of a population less than a given value with the half observation adjustment at observed values thus this corresponds to one possible treatment of tied ranks while unusual the term grade correlation is still in use ref cite journal last piantadosi first j last2 howlett first2 p last3 boland first3 j year 2007 title matching the grade correlation coefficient using a copula with maximum disorder journal journal of industrial and management optimization volume 3 issue 2 pages 305 312 doi url http aimsciences org journals pdfs jsp paperid 2265 mode abstract ref interpretation style float right positive and negative spearman rank correlations file spearman fig5 svg 300px left thumb a positive spearman correlation coefficient corresponds to an increasing monotonic trend between x and y file spearman fig4 svg 300px thumb a negative spearman correlation coefficient corresponds to a decreasing monotonic trend between x and y the sign of the spearman correlation indicates the direction of association between x the independent variable and y the dependent variable if y tends to increase when x increases the spearman correlation coefficient is positive if y tends to decrease when x increases the spearman correlation coefficient is negative a spearman correlation of zero indicates that there is no tendency for y to either increase or decrease when x increases the spearman correlation increases in magnitude as x and y become closer to being perfect monotone functions of each other when x and y are perfectly monotonically related the spearman correlation coefficient becomes 1 a perfect monotone increasing relationship implies that for any two pairs of data values math x sub i sub y sub i sub and math x sub j sub y sub j sub that math x sub i sub \xe2\x88\x92 x sub j sub and math y sub i sub \xe2\x88\x92 y sub j sub always have the same sign a perfect monotone decreasing relationship implies that these differences always have opposite signs the spearman correlation coefficient is often described as being nonparametric this can have two meanings first a perfect spearman correlation results when x and y are related by any monotonic function contrast this with the pearson correlation which only gives a perfect value when x and y are related by a linear function the other sense in which the spearman correlation is nonparametric in that its exact sampling distribution can be obtained without requiring knowledge i e knowing the parameters of the joint probability distribution of x and y example in this example the raw data in the table below is used to calculate the correlation between the iq of a person with the number of hours spent in front of tv per week class wikitable sortable style text align right iq math x i math hours of tv per week math y i math 106 7 86 0 100 27 101 50 99 28 103 29 12 97 20 113 12 112 6 110 17 firstly evaluate math d 2 i math to do so use the following steps reflected in the table below sort the data by the first column math x i math create a new column math x i math and assign it the ranked values 1 2 3 n next sort the data by the second column math y i math create a fourth column math y i math and similarly assign it the ranked values 1 2 3 n create a fifth column math d i math to hold the differences between the two rank columns math x i math and math y i math create one final column math d 2 i math to hold the value of column math d i math squared class wikitable sortable style text align right iq math x i math hours of tv per week math y i math rank math x i math rank math y i math math d i math math d 2 i math 86 0 1 1 0 0 97 20 2 6 \xe2\x88\x924 16 99 28 3 8 \xe2\x88\x925 25 100 27 4 7 \xe2\x88\x923 9 101 50 5 10 \xe2\x88\x925 25 103 29 6 9 \xe2\x88\x923 9 106 7 7 3 4 16 110 17 8 5 3 9 112 6 9 2 7 49 113 12 10 4 6 36 with math d 2 i math found add them to find math sum d i 2 194 math the value of n is 10 these values can now be substituted back into the equation math rho 1 frac 6 sum d i 2 n n 2 1 math to give math rho 1 frac 6 times194 10 10 2 1 math which evaluates to math 1 \xcf\x81 29 165 \xe2\x88\x920 175757575 with a p value 0 627188 using the student s t distribution t distribution file spearman s rank chart png thumb chart of the data presented it can be seen that there might be a negative correlation but that the relationship does not appear definitive this low value shows that the correlation between iq and hours spent watching tv is very low although the negative value suggests that the longer the time spent watching television the lower the iq in the case of ties in the original values this formula should not be used instead the pearson correlation coefficient should be calculated on the ranks where ties are given ranks as described above determining significance one approach to test whether an observed value of \xcf\x81 is significantly different from zero r will always maintain \xe2\x88\x921 \xe2\x89\xa4 r \xe2\x89\xa4 1 is to calculate the probability that it would be greater than or equal to the observed r given the null hypothesis by using a resampling statistics permutation tests permutation test an advantage of this approach is that it automatically takes into account the number of tied data values there are in the sample and the way they are treated in computing the rank correlation another approach parallels the use of the fisher transformation in the case of the pearson product moment correlation coefficient that is confidence intervals and hypothesis test s relating to the population value \xcf\x81 can be carried out using the fisher transformation math f r 1 over 2 ln 1 r over 1 r operatorname artanh r math if f r is the fisher transformation of r the sample spearman rank correlation coefficient and n is the sample size then math z sqrt frac n 3 1 06 f r math is a standard score z score for r which approximately follows a standard normal distribution under the null hypothesis of statistical independence math 1 \xcf\x81 0 ref cite journal last choi first s c year 1977 title tests of equality of dependent correlation coefficients journal biometrika volume 64 issue 3 pages 645 647 doi 10 1093 biomet 64 3 645 ref ref cite journal last fieller first e c last2 hartley first2 h o last3 pearson first3 e s year 1957 title tests for rank correlation coefficients i journal biometrika volume 44 issue pages 470 481 doi 10 1093 biomet 44 3 4 470 ref one can also test for significance using math t r sqrt frac n 2 1 r 2 math which is distributed approximately as student s t distribution with math n \xe2\x88\x92 2 degrees of freedom under the null hypothesis ref cite book last press last2 vettering last3 teukolsky last4 flannery year 1992 title numerical recipes in c the art of scientific computing edition 2nd page 640 ref a justification for this result relies on a permutation argument ref cite book last kendall first m g last2 stuart first2 a year 1973 title the advanced theory of statistics volume 2 inference and relationship publisher griffin isbn 0 85264 215 6 sections 31 19 31 21 ref pvrank ref cite web last1 amerise first1 i l last2 marozzi first2 m last3 tarsitano first3 a title r package pvrank url https cran r project org web packages pvrank index html ref is a very recent r programming language r package that computes rank correlations and their p values with various options for tied ranks it is possible to compute exact spearman coefficient test p values for n \xe2\x89\xa4 26 a generalization of the spearman coefficient is useful in the situation where there are three or more conditions a number of subjects are all observed in each of them and it is predicted that the observations will have a particular order for example a number of subjects might each be given three trials at the same task and it is predicted that performance will improve from trial to trial a test of the significance of the trend between conditions in this situation was developed by e b page ref cite journal author page e b title ordered hypotheses for multiple treatments a significance test for linear ranks journal journal of the american statistical association volume 58 pages 216 230 year 1963 doi 10 2307 2282965 issue 301 ref and is usually referred to as page s trend test for ordered alternatives correspondence analysis based on spearman s rho classic correspondence analysis is a statistical method that gives a score to every value of two nominal variables in this way the pearson pearson product moment correlation coefficient correlation coefficient between them is maximized there exists an equivalent of this method called grade correspondence analysis which maximizes spearman s rho or kendall s tau ref cite book editor1 last kowalczyk editor1 first t editor2 last pleszczy\xc5\x84ska editor2 first e editor3 last ruland editor3 first f year 2004 title grade models and methods for data analysis with applications for the analysis of data populations series studies in fuzziness and soft computing volume 151 publisher springer verlag location berlin heidelberg new york isbn 978 3 540 21120 4 ref see also portal statistics kendall tau rank correlation coefficient chebyshev s sum inequality rearrangement inequality these two articles may shed light on the mathematical properties of spearman s \xcf\x81 distance correlation references reflist 30em further reading corder g w foreman d i 2014 nonparametric statistics a step by step approach wiley isbn 978 1118840313 cite book last daniel first wayne w chapter spearman rank correlation coefficient title applied nonparametric statistics location boston publisher pws kent edition 2nd year 1990 isbn 0 534 91976 6 pages 358 365 chapterurl https books google com books id 0hpvaaaamaaj pg pa358 cite journal author spearman c title the proof and measurement of association between two things journal american journal of psychology volume 15 year 1904 pages 72 101 doi 10 2307 1412159 cite journal author bonett dg wright ta title sample size requirements for pearson kendall and spearman correlations journal psychometrika volume 65 year 2000 pages 23 28 doi 10 1007 bf02294183 cite book author kendall mg title rank correlation methods location london publisher griffin year 1970 edition 4th isbn 978 0 852 6419 96 oclc 136868 cite book vauthors hollander m wolfe da title nonparametric statistical methods location new york publisher wiley year 1973 isbn 978 0 471 40635 8 oclc 520735 cite journal vauthors caruso jc cliff n title empirical size coverage and power of confidence intervals for spearman s rho journal educational and psychological measurement volume 57 year 1997 pages 637 654 doi 10 1177 0013164497057004009 external links wikiversity http www crystalballservices com resources consultantscornerblog entryid 73 copulas vs correlation aspx understanding correlation vs copulas in excel by eric torkia technology partnerz 2011 http www sussex ac uk users grahamh rm1web rhotable htm table of critical values of \xcf\x81 for significance with small samples http www maccery com maths spearman s rank online calculator https www answerminer com calculators correlation test spearman correlation calculator with human readable explanation http faculty vassar edu lowry webtext html chapter 3 part 1 shows the formula to be used when there are ties http statistical research com wp content uploads 2012 08 spearman pdf an example of how to calculate spearman s rho along with basic r code https www rgs org nr rdonlyres 4844e3ab b36d 4b14 8a20 3a3c28fac087 0 oaspearmansrankexcelguidepdf pdf spearman s rank correlation coefficient excel guide sample data and formulae for excel developed by the royal geographical society http udel edu mcdonald statspearman html spearman s rank correlation simple notes for students with an example of usage by biologists and a spreadsheet for microsoft excel for calculating it a part of materials for a research methods in biology course statistics descriptive defaultsort spearman s rank correlation coefficient category covariance and correlation category information retrieval evaluation category nonparametric statistics category statistical tests'
b'the cranfield experiments were computer information retrieval experiments conducted by cyril w cleverdon at cranfield university in the 1960s to evaluate the efficiency of indexing systems ref cleverdon c w 1960 aslib cranfield research project on the comparative efficiency of indexing systems aslib proceedings xii 421 431 ref ref cleverdon c w 1967 the cranfield tests on index language devices aslib proceedings 19 6 173 194 ref ref cleverdon c w keen e m 1966 factors determining the performance of indexing systems vol 1 design vol 2 results cranfield uk aslib cranfield research project ref they represent the prototypical evaluation model of information retrieval systems and this model has been used in large scale information retrieval evaluation efforts such as the text retrieval conference trec see also aslib information history references reflist external links http ir dcs gla ac uk resources test collections cran cranfield 1400 corpus category experiments category information retrieval evaluation database stub'
b'multiple issues refimprove date april 2011 orphan date april 2010 in computer science universal information retrieval evaluation ir information retrieval evaluation aims to develop measures of database retrieval performance that shall be comparable across all information retrieval tasks measures of relevance information retrieval evaluation ir information retrieval evaluation begins whenever a user submits a query search term to a database if the user is able to determine the relevance information retrieval relevance of each document in the database relevant or not relevant then for each query the complete set of documents is naturally divided into four distinct mutually exclusive subsets relevant documents that are retrieved not relevant documents that are retrieved relevant documents that are not retrieved and not relevant documents that are not retrieved these four subsets of documents are denoted by the letters a b c d respectively and are called swets variables named after their inventor ref swets j a 1969 effectiveness of information retrieval methods american documentation 20 1 72 89 ref in addition to the swets definitions four relevance metrics have also been defined precision information retrieval precision refers to the fraction of relevant documents that are retrieved a a b and precision information retrieval recall refers to the fraction of retrieved documents that are relevant a a c these are the most commonly used and well known relevance metrics found in the ir evaluation literature two less commonly used metrics include the fallout i e the fraction of not relevant documents that are retrieved b b d and the miss which refers to the fraction of relevant documents that are not retrieved c c d during any given search universal ir evaluation techniques universal ir evaluation addresses the mathematical possibilities and relationships among the four relevance metrics precision recall fallout and miss denoted by p r f and m respectively one aspect of the problem involves finding a mathematical derivation of a complete set of universal ir evaluation points ref schatkun m 2010 a second look at egghe s universal ir surface and a simple derivation of a complete set of universal ir evaluation points information processing management 46 1 110 114 ref the complete set of 16 points each one a quadruple of the form p r f m describes all the possible universal ir outcomes for example many of us have had the experience of querying a database and not retrieving any documents at all in this case the precision would take on the undetermined form 0 0 the recall and fallout would both be zero and the miss would be any value greater than zero and less than one assuming a mix of relevant and not relevant documents were in the database none of which were retrieved this universal ir evaluation point would thus be denoted by 0 0 0 0 m which represents only one of the 16 possible universal ir outcomes the mathematics of universal ir evaluation is a fairly new subject since the relevance metrics p r f m were not analyzed collectively until recently within the past decade a lot of the theoretical groundwork has already been formulated but new insights in this area await discovery for a detailed mathematical analysis a query in the sciencedirect database for universal ir evaluation retrieves several relevant peer reviewed papers see also information retrieval web search query references reflist external links http www sciencedirect com science direct defaultsort universal ir evaluation category databases category information retrieval evaluation'
b'the query likelihood model is a language model used in information retrieval a language model is constructed for each document in the collection it is then possible to rank each document by the probability of specific documents given a query this is interpreted as being the likelihood function likelihood of a document being relevant given a query calculating the likelihood using bayes theorem bayes rule the probability math p math of a document math d math given a query math q math can be written as follows math p d q frac p q d p d p q math since the probability of the query p q is the same for all documents this can be ignored further it is typical to assume that the probability of documents is uniform thus p d is also ignored math p d q p q d math documents are then ranked by the probability that a query is observed as a random sample from the document model the multinomial unigram language model is commonly used to achieve this we have math p q m d k q prod t in v p t m d tf t q math where the multinomial coefficient is math k q l q tf t1 q tf t2 q tf tn q math for query math q and math l q sum 1 leq i leq n tf t i q math is the length of query math q given the term frequencies math tf in the query vocabulary math n in practice the multinomial coefficient is usually removed from the calculation the reason is that it is a constant for a given bag of words such as all the words from a specific document math d math the language model math m d math should be the true language model calculated from the distribution of words underlying each retrieved document in practice this language model is unknown so it is usually approximated by considering each term unigram from the retrieved document together with its probability of appearance so math p t m d math is the probability of term math t math being generated by the language model math m d math of document math d math this probability is multiplied for all terms from query math q math to get a rank for document math d math in the interval math 0 1 math the calculation is repeated for all documents to create a ranking of all documents in the document collection ref christopher d manning prabhakar raghavan hinrich sch\xc3\xbctze an introduction to information retrieval page 241 cambridge university press 2009 ref references references category information retrieval techniques'
b'refimprove date june 2012 controlled vocabularies provide a way to organize knowledge for subsequent retrieval they are used in subject indexing schemes subject heading s thesauri ref https web archive org web 20101204132228 http www imresources fit qut edu au 80 vocab controlled vocabularies links to examples of thesauri and classification schemes ref ref https web archive org web 20090314094707 http www fao org aims kos list type htm controlled vocabularies links to examples of thesauri and classification schemes used in the domain of agriculture fisheries forestry etc ref taxonomy general taxonomies and other forms of knowledge organization system s controlled vocabulary schemes mandate the use of predefined authorised terms that have been preselected by the designers of the schemes in contrast to natural language vocabularies which have no such restriction in library and information science in library and information science controlled vocabulary is a carefully selected list of word linguistics word s and phrase s which are used to tag metadata tag units of information document or work so that they may be more easily retrieved by a search ref amy warner http www ischool utexas edu i385e readings warner ataxonomyprimer html a taxonomy primer ref ref karl fast fred leise and mike steckel http boxesandarrows com what is a controlled vocabulary ref controlled vocabularies solve the problems of homographs synonyms and polyseme s by a bijection between concepts and authorized terms in short controlled vocabularies reduce ambiguity inherent in normal human languages where the same concept can be given different names and ensure consistency for example in the library of congress subject headings a subject heading system that uses a controlled vocabulary authorized terms subject headings in this case have to be chosen to handle choices between variant spellings of the same word american versus british choice among scientific and popular terms cockroach versus periplaneta americana and choices between synonyms automobile versus car among other difficult issues choices of authorized terms are based on the principles of user warrant what terms users are likely to use literary warrant what terms are generally used in the literature and documents and structural warrant terms chosen by considering the structure scope of the controlled vocabulary controlled vocabularies also typically handle the problem of homographs with qualifiers for example the term pool has to be qualified to refer to either swimming pool or the game pool to ensure that each authorized term or heading refers to only one concept there are two main kinds of controlled vocabulary tools used in libraries subject headings and thesauri while the differences between the two are diminishing there are still some minor differences historically subject headings were designed to describe books in library catalogs by catalogers while thesauri were used by indexers to apply index terms to documents and articles subject headings tend to be broader in scope describing whole books while thesauri tend to be more specialized covering very specific disciplines also because of the card catalog system subject headings tend to have terms that are in indirect order though with the rise of automated systems this is being removed while thesaurus terms are always in direct order subject headings also tend to use more pre coordination of terms such that the designer of the controlled vocabulary will combine various concepts together to form one authorized subject heading e g children and terrorism while thesauri tend to use singular direct terms lastly thesauri list not only equivalent terms but also narrower broader terms and related terms among various authorized and non authorized terms while historically most subject headings did not for example the library of congress subject heading itself did not have much syndetic structure until 1943 and it was not until 1985 when it began to adopt the thesauri type term hypernym broader term and hyponym narrow term the terminology terms are chosen and organized by trained professionals including librarians and information scientists who possess expertise in the subject area controlled vocabulary terms can accurately describe what a given document is actually about even if the terms themselves do not occur within the document s text well known subject heading systems include the library of congress subject headings library of congress system medical subject headings mesh and sears subject headings sears well known thesauri include the art and architecture thesaurus and the education resources information center eric thesaurus choosing authorized terms to be used is a tricky business besides the areas already considered above the designer has to consider the specificity of the term chosen whether to use direct entry inter consistency and stability of the language lastly the amount of pre co ordinate in which case the degree of enumeration versus synthesis becomes an issue and post co ordinate in the system is another important issue controlled vocabulary elements terms phrases employed as tag metadata tags to aid in the content identification process of documents or other information system entities e g dbms web services qualifies as metadata indexing languages there are three main types of indexing languages controlled indexing language only approved terms can be used by the indexer to describe the document natural language indexing language any term from the document in question can be used to describe the document free indexing language any term not only from the document can be used to describe the document when indexing a document the indexer also has to choose the level of indexing exhaustivity the level of detail in which the document is described for example using low indexing exhaustivity minor aspects of the work will not be described with index terms in general the higher the indexing exhaustivity the more terms indexed for each document in recent years free text search as a means of access to documents has become popular this involves using natural language indexing with an indexing exhaustively set to maximum every word in the text is indexed many studies have been done to compare the efficiency and effectiveness of free text searches against documents that have been indexed by experts using a few well chosen controlled vocabulary descriptors controlled vocabularies are often claimed to improve the accuracy of free text searching such as to reduce relevance information retrieval irrelevant items in the retrieval list these irrelevant items false positives are often caused by the inherent ambiguity of natural language take the english word football word football for example football is the name given to a number of different team sport s worldwide the most popular of these team sports is football soccer association football which also happens to be called soccer in several countries the word football is also applied to rugby football rugby union and rugby league american football australian rules football gaelic football and canadian football a search for football therefore will retrieve documents that are about several completely different sports controlled vocabulary solves this problem by tag metadata tagging the documents in such a way that the ambiguities are eliminated compared to free text searching the use of a controlled vocabulary can dramatically increase the performance of an information retrieval system if performance is measured by precision the percentage of documents in the retrieval list that are actually relevance relevant to the search topic in some cases controlled vocabulary can enhance recall as well because unlike natural language schemes once the correct authorized term is searched you don t need to worry about searching for other terms that might be synonyms of that term however a controlled vocabulary search may also lead to unsatisfactory recall information retrieval recall in that it will fail to retrieve some documents that are actually relevant to the search question this is particularly problematic when the search question involves terms that are sufficiently tangential to the subject area such that the indexer might have decided to tag it using a different term but the searcher might consider the same essentially this can be avoided only by an experienced user of controlled vocabulary whose understanding of the vocabulary coincides with the way it is used by the indexer another possibility is that the article is just not tagged by the indexer because indexing exhaustivity is low for example an article might mention football as a secondary focus and the indexer might decide not to tag it with football because it is not important enough compared to the main focus but it turns out that for the searcher that article is relevant and hence recall fails a free text search would automatically pick up that article regardless on the other hand free text searches have high exhaustivity you search on every word so it has potential for high recall assuming you solve the problems of synonyms by entering every combination but will have much lower precision controlled vocabularies are also quickly out dated and in fast developing fields of knowledge the authorized terms available might not be available if they are not updated regularly even in the best case scenario controlled language is often not as specific as using the words of the text itself indexers trying to choose the appropriate index terms might misinterpret the author while a free text search is in no danger of doing so because it uses the author s own words the use of controlled vocabularies can be costly compared to free text searches because human experts or expensive automated systems are necessary to index each entry furthermore the user has to be familiar with the controlled vocabulary scheme to make best use of the system but as already mentioned the control of synonyms homographs can help increase precision numerous methodologies have been developed to assist in the creation of controlled vocabularies including faceted classification which enables a given data record or document to be described in multiple ways applications controlled vocabularies such as the library of congress subject headings are an essential component of bibliography the study and classification of books they were initially developed in library and information science in the 1950s government agencies began to develop controlled vocabularies for the burgeoning journal literature in specialized fields an example is the medical subject headings mesh developed by the united states national library of medicine u s national library of medicine subsequently for profit firms called abstracting and indexing services emerged to index the fast growing literature in every field of knowledge in the 1960s an online bibliographic database industry developed based on dialup x 25 networking these services were seldom made available to the public because they were difficult to use specialist librarians called search intermediaries handled the searching job in the 1980s the first full text databases appeared these databases contain the full text of the index articles as well as the bibliographic information online bibliographic databases have migrated to the internet and are now publicly available however most are proprietary and can be expensive to use students enrolled in colleges and universities may be able to access some of these services without charge some of these services may be accessible without charge at a public library in large organizations controlled vocabularies may be introduced to improve technical communication the use of controlled vocabulary ensures that everyone is using the same word to mean the same thing this consistency of terms is one of the most important concepts in technical writing and knowledge management where effort is expended to use the same word throughout a document or organization instead of slightly different ones to refer to the same thing web searching could be dramatically improved by the development of a controlled vocabulary for describing web pages the use of such a vocabulary could culminate in a semantic web in which the content of web pages is described using a machine readable metadata scheme one of the first proposals for such a scheme is the dublin core initiative an example of a controlled vocabulary which is usable for web indexing indexing web pages is polythematic structured subject heading system psh it is unlikely that a single metadata scheme will ever succeed in describing the content of the entire web ref cory doctorow http www well com doctorow metacrap htm metacrap ref to create a semantic web it may be necessary to draw from two or more metadata systems to describe a web page s contents the exchangeable faceted metadata language xfml is designed to enable controlled vocabulary creators to publish and share metadata systems xfml is designed on faceted classification principles ref mark pilgrim http petervandijck com xfml exchangeable faceted metadata language ref controlled vocabularies of the semantic web define the concepts and relationships terms used to describe a field of interest or area of concern for instance to declare a person in a machine readable format a vocabulary is needed that has the formal definition of person such as the friend of a friend foaf vocabulary which has a person class that defines typical properties of a person including but not limited to name honorific prefix affiliation email address and homepage or the person vocabulary of schema org ref cite web url http schema org person title the person vocabulary of schema org accessdate 13 march 2015 ref similarly a book can be described using the book vocabulary of schema org ref cite web url http schema org book title the book vocabulary of schema org accessdate 13 march 2015 ref and general publication terms from the dublin core vocabulary ref cite web url http dublincore org documents dces title dublin core metadata element set version 1 1 accessdate 13 march 2015 ref an event with the event vocabulary of schema org ref cite web url http schema org event title the event vocabulary of schema org accessdate 13 march 2015 ref and so on to use machine readable terms from any controlled vocabulary web designers can choose from a variety of annotation formats including rdfa microdata html html5 microdata or json ld in the markup or resource description framework rdf serializations rdf xml turtle n3 trig trix in external files see also authority control controlled natural language ims vdex ims vocabulary definition exchange named entity recognition nomenclature ontology computer science terminology thesaurus universal data element framework vocabulary based transformation references reflist 2 external links http www controlledvocabulary com controlledvocabulary com explains how controlled vocabularies are useful in describing images and information for classifying content in electronic databases http www photo keywords com photo keywords com useful guides to creating and editing your own controlled vocabulary suitable for image cataloging http www niso org standards resources z39 19 html ansi niso z39 19 2005 guidelines for the construction format and management of monolingual controlled vocabularies lexicography category information retrieval techniques category library cataloging and classification category knowledge representation category technical communication category semantic web category ontology information science category controlled vocabularies category information science'
b'in the field of information retrieval divergence from randomness is one type of probabilistic model term weights are computed by measuring the divergence between a term distribution produced by a random process and the actual term distribution external links http terrier org docs v3 5 dfr description html terrier s dfr web page http ir dcs gla ac uk wiki divergencefromrandomness glasgow ir group wiki dfr page category ranking functions category information retrieval techniques category probabilistic models comp sci stub'
b'in applied mathematics specifically in fuzzy logic the ordered weighted averaging owa operators provide a parameter ized class of mean type aggregation operators they were introduced by ronald r yager many notable mean operators such as the max arithmetic average median and min are members of this class they have been widely used in computational intelligence because of their ability to model linguistically expressed aggregation instructions definition formally an owa operator of dimension math n math is a mapping math f r n rightarrow r math that has an associated collection of weights math w w 1 ldots w n math lying in the unit interval and summing to one and with math f a 1 ldots a n sum j 1 n w j b j math where math b j math is the j sup th sup largest of the math a i math by choosing different w one can implement different aggregation operators the owa operator is a non linear operator as a result of the process of determining the b sub j sub properties the owa operator is a mean operator it is bounded operator bounded monotonic symmetric operator symmetric and idempotent as defined below class wikitable bounded operator bounded math min a 1 ldots a n le f a 1 ldots a n le max a 1 ldots a n math monotonic math f a 1 ldots a n ge f g 1 ldots g n math if math a i ge g i math for math i 1 2 ldots n math symmetric operator symmetric math f a 1 ldots a n f a boldsymbol pi 1 ldots a boldsymbol pi n math if math boldsymbol pi math is a permutation map idempotent math f a 1 ldots a n a math if all math a i a math notable owa operators math f a 1 ldots a n max a 1 ldots a n math if math w 1 1 math and math w j 0 math for math j ne 1 math math f a 1 ldots a n min a 1 ldots a n math if math w n 1 math and math w j 0 math for math j ne n math characterizing features two features have been used to characterize the owa operators the first is the attitudinal character orness this is defined as math a c w frac 1 n 1 sum j 1 n n j w j math it is known that math a c w in 0 1 math in addition a nbsp minus nbsp c max 1 a nbsp minus nbsp c ave a nbsp minus nbsp c med 0 5 and a nbsp minus nbsp c min 0 thus the a nbsp minus nbsp c goes from 1 to 0 as we go from max to min aggregation the attitudinal character characterizes the similarity of aggregation to or operation or is defined as the max the second feature is the dispersion this defined as math h w sum j 1 n w j ln w j math an alternative definition is math e w sum j 1 n w j 2 math the dispersion characterizes how uniformly the arguments are being used \xc3\xa0\xc4\x9b a literature survey owa 1988 2014 the historical reconstruction of scientific development of the owa field the identification of the dominant direction of knowledge accumulation that emerged since the publication of the first owa paper and to discover the most active lines of research has recently been published see http onlinelibrary wiley com doi 10 1002 int 21673 full the results suggest as expected that yager s paper 1 ieee trans systems man cybernet 18 1 183 190 1988 is the most influential paper and the starting point of all other research using owa starting from his contribution other lines of research developed and we describe them full list of papers published in owa is also available at http onlinelibrary wiley com doi 10 1002 int 21673 full type 1 owa aggregation operators the above yager s owa operators are used to aggregate the crisp values can we aggregate fuzzy sets in the owa mechanism the type 1 owa operators have been proposed for this purpose so the type 1 owa operators provides us with a new technique for directly aggregating uncertain information with uncertain weights via owa mechanism in soft decision making and data mining where these uncertain objects are modelled by fuzzy sets the type 1 owa operators type 1 owa operator is defined according to the alpha cuts of fuzzy sets as follows given the n linguistic weights math left w i right i 1 n math in the form of fuzzy sets defined on the domain of discourse math u 0 1 math then for each math alpha in 0 1 math an math alpha math level type 1 owa operator with math alpha math level sets math left w alpha i right i 1 n math to aggregate the math alpha math cuts of fuzzy sets math left a i right i 1 n math is given as math phi alpha left a alpha 1 ldots a alpha n right left frac sum limits i 1 n w i a sigma i sum limits i 1 n w i left w i in w alpha i a i right in a alpha i i 1 ldots n right math where math w alpha i w mu w i w geq alpha a alpha i x mu a i x geq alpha math and math sigma 1 ldots n to 1 ldots n math is a permutation function such that math a sigma i ge a sigma i 1 forall i 1 ldots n 1 math i e math a sigma i math is the math i math th largest element in the set math left a 1 ldots a n right math the computation of the type 1 owa operators type 1 owa output is implemented by computing the left end points and right end points of the intervals math phi alpha left a alpha 1 ldots a alpha n right math math phi alpha left a alpha 1 ldots a alpha n right math and math phi alpha left a alpha 1 ldots a alpha n right math where math a alpha i a alpha i a alpha i w alpha i w alpha i w alpha i math then membership function of resulting aggregation fuzzy set is math mu g x mathop vee alpha x in phi alpha left a alpha 1 cdots a alpha n right alpha alpha math for the left end points we need to solve the following programming problem math phi alpha left a alpha 1 cdots a alpha n right min limits begin array l w alpha i le w i le w alpha i a alpha i le a i le a alpha i end array sum limits i 1 n w i a sigma i sum limits i 1 n w i math while for the right end points we need to solve the following programming problem math phi alpha left a alpha 1 cdots a alpha n right max limits begin array l w alpha i le w i le w alpha i a alpha i le a i le a alpha i end array sum limits i 1 n w i a sigma i sum limits i 1 n w i math http dx doi org 10 1109 tkde 2010 191 this paper has presented a fast method to solve two programming problem so that the type 1 owa aggregation operation can be performed efficiently references yager r r on ordered weighted averaging aggregation operators in multi criteria decision making ieee transactions on systems man and cybernetics 18 183 190 1988 yager r r and kacprzyk j http www amazon com dp 079239934x the ordered weighted averaging operators theory and applications kluwer norwell ma 1997 liu x the solution equivalence of minimax disparity and minimum variance problems for owa operators international journal of approximate reasoning 45 68 81 2007 emrouznejad 2009 sas owa ordered weighted averaging in sas optimization soft computing http www springerlink com content 7277l73334r108x5 emrouznejad a and m marra 2014 ordered weighted averaging operators 1988 2014 a citation based literature survey international journal of intelligent systems 29 994 1014 http onlinelibrary wiley com doi 10 1002 int 21673 full http onlinelibrary wiley com store 10 1002 int 21673 asset supinfo int21673 sup 0001 supmat docx v 1 s c0d8bdd220a31c876eb5885521cfa16d191f334d torra v and narukawa y modeling decisions information fusion and aggregation operators springer berlin 2007 majlender p owa operators with maximal r\xc3\xa9nyi entropy fuzzy sets and systems 155 340 360 2005 szekely g j and buczolich z when is a weighted average of ordered sample elements a maximum likelihood estimator of the location parameter advances in applied mathematics 10 1989 439 456 s m zhou f chiclana r i john and j m garibaldi type 1 owa operators for aggregating uncertain information with uncertain weights induced by type 2 linguistic quantifiers fuzzy sets and systems vol 159 no 24 pp nbsp 3281 3296 2008 http dx doi org 10 1016 j fss 2008 06 018 s m zhou f chiclana r i john and j m garibaldi alpha level aggregation a practical approach to type 1 owa operation for aggregating uncertain information with applications to breast cancer treatments ieee transactions on knowledge and data engineering vol 23 no 10 2011 pp nbsp 1455 1468 http dx doi org 10 1109 tkde 2010 191 s m zhou r i john f chiclana and j m garibaldi on aggregating uncertain information by type 2 owa operators for soft decision making international journal of intelligent systems vol 25 no 6 pp nbsp 540 558 2010 http dx doi org 10 1002 int 20420 category artificial intelligence category logic in computer science category fuzzy logic category information retrieval techniques'
b'distinguish safeword in computing stop words are words which are filtered out before or after natural language processing processing of natural language data text ref cite book last1 rajaraman first1 a last2 ullman first2 j d doi 10 1017 cbo9781139058452 002 chapter data mining title mining of massive datasets pages 1 17 year 2011 isbn 9781139058452 pmid pmc url http i stanford edu ullman mmds ch1 pdf ref though stop words usually refer to the most common words in a language there is no single universal list of stop words used by all natural language processing tools and indeed not all tools even use such a list some tools specifically avoid removing these stop words to support phrase search any group of words can be chosen as the stop words for a given purpose for some search engine s these are some of the most common short function word s such as the is at which and on in this case stop words can cause problems when searching for phrases that include them particularly in names such as the who the the or take that other search engines remove some of the most common words including lexical word s such as want from a query in order to improve performance ref http blog stackoverflow com 2008 12 podcast 32 stackoverflow one of our major performance optimizations for the related questions query is removing the top 10 000 most common english dictionary words as determined by google search before submitting the query to the sql server 2008 full text engine it s shocking how little is left of most posts once you remove the top 10k english dictionary words this helps limit and narrow the returned results which makes the query dramatically faster ref hans peter luhn one of the pioneers in information retrieval is credited with coining the phrase and using the concept ref cite book title keyword in context index for technical literature kwic index last luhn first h p publisher international business machines corp year 1959 isbn location yorktown heights ny pages doi 10 1002 asi 5090110403 ref the phrase stop word which is not in luhn s 1959 presentation and the associated terms stop list and stoplist appear in the literature shortly afterwards ref cite journal last1 flood first1 barbara j title historical note the start of a stop list at biological abstracts journal journal of the american society for information science date 1999 volume 50 issue 12 page 1066 doi 10 1002 sici 1097 4571 1999 50 12 1066 aid asi5 3 0 co 2 a url http dx doi org 10 1002 sici 1097 4571 1999 50 12 1066 aid asi5 3 0 co 2 a accessdate 16 february 2016 ref a predecessor concept was used in creating some bible concordance concordance s for example the first hebrew concordance me ir nativ contained a one page list of unindexed words with nonsubstantive prepositions and conjunctions which are similar to modern stop words ref cite journal last1 weinberg first1 bella hass title predecessors of scientific indexing structures in the domain of religion journal second conference on the history and heritage of scientific and technical information systems date 2004 pages 126 134 url https www asis org history 11 weinberg pdf accessdate 17 february 2016 ref see also div col cols 3 text mining concept mining information extraction natural language processing query expansion stemming index search engine search engine indexing poison words function words filler linguistics filler div col end references reflist 2 external links http xpo6 com list of english stop words list of english stop words php array csv http dev mysql com doc refman 5 5 en fulltext stopwords html full text stopwords in mysql http www textfixer com resources common english words txt english stop words csv http mail sarai net private prc week of mon 20080204 001656 html hindi stop words http solariz de de deutsche stopwords htm german stop words http aniol consulting de uebersicht deutscher stop words german stop words and phrases another list of http www ranks nl stopwords german html german stop words pl wikipedia stopwords polish stop words https code google com p stop words collection of stop words in 29 languages https web archive org web http tonyb sk my ir stop words collection 2014 02 24 zip http www text analytics101 com 2014 10 all about stop words for text mining html a detailed explanation of stop words by kavita ganesan natural language processing searchengineoptimization category information retrieval techniques'
b'about the skiing technique stem skiing the climbing technique glossary of climbing terms stem expert needed date october 2010 in linguistic morphology and information retrieval stemming is the process of reducing inflected or sometimes derived words to their word stem base or root linguistics root form generally a written word form the stem need not be identical to the morphological root of the word it is usually sufficient that related words map to the same stem even if this stem is not in itself a valid root algorithm s for stemming have been studied in computer science since the 1960s many search engine s treat words with the same stem as synonym s as a kind of query expansion a process called conflation stemming programs are commonly referred to as stemming algorithms or stemmers examples a stemmer for english for example should identify the string literal string cats and possibly catlike catty etc as based on the root cat and stems stemmer stemming stemmed as based on stem a stemming algorithm reduces the words fishing fished and fisher to the root word fish on the other hand argue argued argues arguing and argus reduce to the stem argu illustrating the case where the stem is not itself a word or root but argument and arguments reduce to the stem argument using the porter algorithm history the first published stemmer was written by julie beth lovins in 1968 ref cite journal first julie beth last lovins year 1968 title development of a stemming algorithm journal mechanical translation and computational linguistics volume 11 pages 22 31 ref this paper was remarkable for its early date and had great influence on later work in this area a later stemmer was written by martin porter and was published in the july 1980 issue of the journal program this stemmer was very widely used and became the de facto standard algorithm used for english stemming dr porter received the tony kent strix award in 2000 for his work on stemming and information retrieval many implementations of the porter stemming algorithm were written and freely distributed however many of these implementations contained subtle flaws as a result these stemmers did not match their potential to eliminate this source of error martin porter released an official free software mostly bsd licenses bsd licensed implementation ref http tartarus org martin porterstemmer ref of the algorithm around the year 2000 he extended this work over the next few years by building snowball programming language snowball a framework for writing stemming algorithms and implemented an improved english stemmer together with stemmers for several other languages algorithms there are several types of stemming algorithms which differ in respect to performance and accuracy and how certain stemming obstacles are overcome a simple stemmer looks up the inflected form in a lookup table the advantages of this approach are that it is simple fast and easily handles exceptions the disadvantages are that all inflected forms must be explicitly listed in the table new or unfamiliar words are not handled even if they are perfectly regular e g ipads ipad and the table may be large for languages with simple morphology like english table sizes are modest but highly inflected languages like turkish may have hundreds of potential inflected forms for each root a lookup approach may use preliminary part of speech tagging to avoid overstemming ref yatsko v a http yatsko zohosites com y stemmer html y stemmer ref the production technique the lookup table used by a stemmer is generally produced semi automatically for example if the word is run then the inverted algorithm might automatically generate the forms running runs runned and runly the last two forms are valid constructions but they are unlikely suffix stripping algorithms suffix stripping algorithms do not rely on a lookup table that consists of inflected forms and root form relations instead a typically smaller list of rules is stored which provides a path for the algorithm given an input word form to find its root form some examples of the rules include if the word ends in ed remove the ed if the word ends in ing remove the ing if the word ends in ly remove the ly suffix stripping approaches enjoy the benefit of being much simpler to maintain than brute force algorithms assuming the maintainer is sufficiently knowledgeable in the challenges of linguistics and morphology and encoding suffix stripping rules suffix stripping algorithms are sometimes regarded as crude given the poor performance when dealing with exceptional relations like ran and run the solutions produced by suffix stripping algorithms are limited to those lexical category lexical categories which have well known suffixes with few exceptions this however is a problem as not all parts of speech have such a well formulated set of rules lemmatisation attempts to improve upon this challenge prefix stripping may also be implemented of course not all languages use prefixing or suffixing additional algorithm criteria suffix stripping algorithms may differ in results for a variety of reasons one such reason is whether the algorithm constrains whether the output word must be a real word in the given language some approaches do not require the word to actually exist in the language lexicon the set of all words in the language alternatively some suffix stripping approaches maintain a database a large list of all known morphological word roots that exist as real words these approaches check the list for the existence of the term prior to making a decision typically if the term does not exist alternate action is taken this alternate action may involve several other criteria the non existence of an output term may serve to cause the algorithm to try alternate suffix stripping rules it can be the case that two or more suffix stripping rules apply to the same input term which creates an ambiguity as to which rule to apply the algorithm may assign by human hand or stochastically a priority to one rule or another or the algorithm may reject one rule application because it results in a non existent term whereas the other overlapping rule does not for example given the english term friendlies the algorithm may identify the ies suffix and apply the appropriate rule and achieve the result of friendl friendl is likely not found in the lexicon and therefore the rule is rejected one improvement upon basic suffix stripping is the use of suffix substitution similar to a stripping rule a substitution rule replaces a suffix with an alternate suffix for example there could exist a rule that replaces ies with y how this affects the algorithm varies on the algorithm s design to illustrate the algorithm may identify that both the ies suffix stripping rule as well as the suffix substitution rule apply since the stripping rule results in a non existent term in the lexicon but the substitution rule does not the substitution rule is applied instead in this example friendlies becomes friendly instead of friendl diving further into the details a common technique is to apply rules in a cyclical fashion recursively as computer scientists would say after applying the suffix substitution rule in this example scenario a second pass is made to identify matching rules on the term friendly where the ly stripping rule is likely identified and accepted in summary friendlies becomes via substitution friendly which becomes via stripping friend this example also helps illustrate the difference between a rule based approach and a brute force approach in a brute force approach the algorithm would search for friendlies in the set of hundreds of thousands of inflected word forms and ideally find the corresponding root form friend in the rule based approach the three rules mentioned above would be applied in succession to converge on the same solution chances are that the rule based approach would be slower as lookup algorithms have a direct access to the solution while rule based should try several options and combinations of them and then choose which result seems to be the best lemmatisation algorithms a more complex approach to the problem of determining a stem of a word is lemmatisation this process involves first determining the part of speech of a word and applying different normalization rules for each part of speech the part of speech is first detected prior to attempting to find the root since for some languages the stemming rules change depending on a word s part of speech this approach is highly conditional upon obtaining the correct lexical category part of speech while there is overlap between the normalization rules for certain categories identifying the wrong category or being unable to produce the right category limits the added benefit of this approach over suffix stripping algorithms the basic idea is that if the stemmer is able to grasp more information about the word being stemmed then it can apply more accurate normalization rules which unlike suffix stripping rules can also modify the stem stochastic algorithms stochastic algorithms involve using probability to identify the root form of a word stochastic algorithms are trained they learn on a table of root form to inflected form relations to develop a probabilistic model this model is typically expressed in the form of complex linguistic rules similar in nature to those in suffix stripping or lemmatisation stemming is performed by inputting an inflected form to the trained model and having the model produce the root form according to its internal ruleset which again is similar to suffix stripping and lemmatisation except that the decisions involved in applying the most appropriate rule or whether or not to stem the word and just return the same word or whether to apply two different rules sequentially are applied on the grounds that the output word will have the highest probability of being correct which is to say the smallest probability of being incorrect which is how it is typically measured some lemmatisation algorithms are stochastic in that given a word which may belong to multiple parts of speech a probability is assigned to each possible part this may take into account the surrounding words called the context or not context free grammars do not take into account any additional information in either case after assigning the probabilities to each possible part of speech the most likely part of speech is chosen and from there the appropriate normalization rules are applied to the input word to produce the normalized root form n gram analysis some stemming techniques use the n gram context of a word to choose the correct stem for a word ref name ceur proceedings cite journal last1 mcnamee first1 paul title exploring new languages with haircut at clef 2005 journal ceur workshop proceedings date september 21 22 2005 volume 1171 url http ceur ws org vol 1171 clef2005wn adhoc mcnamee2005 pdf accessdate 3 6 15 ref hybrid approaches hybrid approaches use two or more of the approaches described above in unison a simple example is a suffix tree algorithm which first consults a lookup table using brute force however instead of trying to store the entire set of relations between words in a given language the lookup table is kept small and is only used to store a minute amount of frequent exceptions like ran run if the word is not in the exception list apply suffix stripping or lemmatisation and output the result affix stemmers in linguistics the term affix refers to either a prefix or a suffix in addition to dealing with suffixes several approaches also attempt to remove common prefixes for example given the word indefinitely identify that the leading in is a prefix that can be removed many of the same approaches mentioned earlier apply but go by the name affix stripping a study of affix stemming for several european languages can be found here ref jongejan b and dalianis h automatic training of lemmatization rules that handle morphological changes in pre in and suffixes alike in the proceeding of the acl 2009 joint conference of the 47th annual meeting of the association for computational linguistics and the 4th international joint conference on natural language processing of the asian federation of natural language processing singapore august 2 7 2009 pp 145 153 http www aclweb org anthology p p09 p09 1017 pdf ref matching algorithms such algorithms use a stem database for example a set of documents that contain stem words these stems as mentioned above are not necessarily valid words themselves but rather common sub strings as the brows in browse and in browsing in order to stem a word the algorithm tries to match it with stems from the database applying various constraints such as on the relative length of the candidate stem within the word so that for example the short prefix be which is the stem of such words as be been and being would not be considered as the stem of the word beside language challenges while much of the early academic work in this area was focused on the english language with significant use of the porter stemmer algorithm many other languages have been investigated ref dolamic ljiljana and savoy jacques http clef isti cnr it 2007 working notes dolamicclef2007 pdf stemming approaches for east european languages clef 2007 ref ref savoy jacques http portal acm org citation cfm doid 1141277 1141523 light stemming approaches for the french portuguese german and hungarian languages acm symposium on applied computing sac 2006 isbn 1 59593 108 2 ref ref popovi\xc4\x8d mirko and willett peter 1992 http onlinelibrary wiley com doi 10 1002 28sici 291097 4571 28199206 2943 5 3c384 aid asi6 3e3 0 co 2 l abstract the effectiveness of stemming for natural language access to slovene textual data journal of the american society for information science volume 43 issue 5 june pp 384 390 ref ref http staff science uva nl mdr publications files clef2005 proc adhoc pdf stemming in hungarian at clef 2005 ref ref viera a f g virgil j 2007 http informationr net ir 12 3 paper315 html uma revis\xc3\xa3o dos algoritmos de radicaliza\xc3\xa7\xc3\xa3o em l\xc3\xadngua portuguesa information research 12 3 paper 315 ref hebrew and arabic are still considered difficult research languages for stemming english stemmers are fairly trivial with only occasional problems such as dries being the third person singular present form of the verb dry axes being the plural of axe as well as axis but stemmers become harder to design as the morphology orthography and character encoding of the target language becomes more complex for example an italian stemmer is more complex than an english one because of a greater number of verb inflections a russian one is more complex more noun declension s a hebrew one is even more complex due to nonconcatenative morphology a writing system without vowels and the requirement of prefix stripping hebrew stems can be two three or four characters but not more and so on multilingual stemming multilingual stemming applies morphological rules of two or more languages simultaneously instead of rules for only a single language when interpreting a search query commercial systems using multilingual stemming exist citation needed date october 2013 error metrics there are two error measurements in stemming algorithms overstemming and understemming overstemming is an error where two separate inflected words are stemmed to the same root but should not have been a false positive understemming is an error where two separate inflected words should be stemmed to the same root but are not a false negative stemming algorithms attempt to minimize each type of error although reducing one type can lead to increasing the other for example the widely used porter stemmer stems universal university and universe to univers this is a case of overstemming though these three words are etymologically related their modern meanings are in widely different domains so treating them as synonyms in a search engine will likely reduce the relevance of the search results an example of understemming in the porter stemmer is alumnus \xe2\x86\x92 alumnu alumni \xe2\x86\x92 alumni alumna alumnae \xe2\x86\x92 alumna this english word keeps latin morphology and so these near synonyms are not conflated applications stemming is used as an approximate method for grouping words with a similar basic meaning together for example a text mentioning daffodils is probably closely related to a text mentioning daffodil without the s but in some cases words with the same morphological stem have idiom atic meanings which are not closely related a user searching for marketing will not be satisfied by most documents mentioning markets but not marketing information retrieval stemmers are common elements in information retrieval query systems such as world wide web web search engine s the effectiveness of stemming for english query systems were soon found to be rather limited however and this has led early information retrieval researchers to deem stemming irrelevant in general ref baeza yates ricardo and ribeiro neto berthier 1999 modern information retrieval acm press addison wesley ref an alternative approach based on searching for n gram s rather than stems may be used instead also stemmers may provide greater benefits in other languages than english ref kamps jaap monz christof de rijke maarten and sigurbj\xc3\xb6rnsson b\xc3\xb6rkur 2004 language dependent and language independent approaches to cross lingual text retrieval in peters c gonzalo j braschler m and kluck m eds comparative evaluation of multilingual information access systems springer verlag pp 152 165 ref ref airio eija 2006 word normalization and decompounding in mono and bilingual ir information retrieval 9 249 271 ref domain analysis stemming is used to determine domain vocabularies in domain analysis ref frakes w prieto diaz r fox c 1998 dare domain analysis and reuse environment annals of software engineering 5 pp 125 141 ref use in commercial products many commercial companies have been using stemming since at least the 1980s and have produced algorithmic and lexical stemmers in many languages ref http www dtsearch co uk language htm language extension packs dtsearch ref ref http technet2 microsoft com office en us library 87065c9d d39d 479d 909b 02160ec6d7791033 mspx mfr true building multilingual solutions by using sharepoint products and technologies microsoft technet ref the snowball programming language snowball stemmers have been compared with commercial lexical stemmers with varying results ref http clef isti cnr it 2003 wn web 19 pdf clef 2003 stephen tomlinson compared the snowball stemmers with the hummingbird lexical stemming lemmatization system ref ref http clef isti cnr it 2004 working notes workingnotes2004 21 pdf clef 2004 stephen tomlinson finnish portuguese and russian retrieval with hummingbird searchserver ref google search adopted word stemming in 2003 ref http www google com support bin static py page searchguides html ctx basics stemming the essentials of google search web search help center google google inc ref previously a search for fish would not have returned fishing other software search algorithms vary in their use of word stemming programs that simply search for substrings obviously will find fish in fishing but when searching for fishes will not find occurrences of the word fish see also root linguistics linguistic definition of the term root stem linguistics linguistic definition of the term stem morphology linguistics lemma morphology linguistic definition lemmatization lexeme inflection derivation linguistics derivation stemming is a form of reverse derivation natural language processing stemming is generally regarded as a form of nlp text mining stemming algorithms play a major role in commercial nlp software computational linguistics snowball programming language designed for creating stemming algorithms natural language processing references reflist 2 further reading refbegin 2 dawson j l 1974 suffix removal for word conflation bulletin of the association for literary and linguistic computing 2 3 33 46 frakes w b 1984 term conflation for information retrieval cambridge university press frakes w b fox c j 2003 strength and similarity of affix removal stemming algorithms sigir forum 37 26 30 frakes w b 1992 stemming algorithms information retrieval data structures and algorithms upper saddle river nj prentice hall inc hafer m a weiss s f 1974 word segmentation by letter successor varieties information processing management 10 11 12 371 386 harman d 1991 how effective is suffixing journal of the american society for information science 42 1 7 15 hull d a 1996 stemming algorithms nbsp a case study for detailed evaluation jasis 47 1 70 84 hull d a grefenstette g 1996 a detailed analysis of english stemming algorithms xerox technical report kraaij w pohlmann r 1996 viewing stemming as recall enhancement in frei h p harman d schauble p and wilkinson r eds proceedings of the 17th acm sigir conference held at zurich august 18 22 pp nbsp 40 48 krovetz r 1993 viewing morphology as an inference process in proceedings of acm sigir93 pp nbsp 191 203 lennon m pierce d s tarry b d willett p 1981 an evaluation of some conflation algorithms for information retrieval journal of information science 3 177 183 lovins j 1971 http www eric ed gov sitemap html 0900000b800c571a html error evaluation for stemming algorithms as clustering algorithms jasis 22 28 40 lovins j b 1968 development of a stemming algorithm mechanical translation and computational linguistics 11 22 31 jenkins marie claire and smith dan 2005 http www uea ac uk polopoly fs 1 85493 stemmer25feb pdf conservative stemming for search and indexing paice c d 1990 http www comp lancs ac uk computing research stemming paice article htm another stemmer sigir forum 24 56 61 paice c d 1996 http www3 interscience wiley com cgi bin abstract 57804 abstract method for evaluation of stemming algorithms based on error counting jasis 47 8 632 649 popovi\xc4\x8d mirko and willett peter 1992 http onlinelibrary wiley com doi 10 1002 28sici 291097 4571 28199206 2943 5 3c384 aid asi6 3e3 0 co 2 l abstract the effectiveness of stemming for natural language access to slovene textual data journal of the american society for information science volume 43 issue 5 june pp nbsp 384 390 porter martin f 1980 http telemat det unifi it book 2001 wchange download stem porter html an algorithm for suffix stripping program 14 3 130 137 savoy j 1993 http www3 interscience wiley com cgi bin abstract 10049824 abstract cretry 1 sretry 0 stemming of french words based on grammatical categories journal of the american society for information science 44 1 1 9 ulmschneider john e doszkocs tamas 1983 http www eric ed gov sitemap html 0900000b8007ea83 html a practical stemming algorithm for online search assistance online review 7 4 301 318 xu j croft w b 1998 http portal acm org citation cfm doid 267954 267957 corpus based stemming using coocurrence of word variants acm transactions on information systems 16 1 61 81 refend external links http opennlp apache org index html apache opennlp includes porter and snowball stemmers http smile stemmer appspot com smile stemmer free online service includes porter and paice husk lancaster stemmers java api http code google com p ir themis themis open source ir framework includes porter stemmer implementation postgresql java api http snowballstem org snowball free stemming algorithms for many languages includes source code including stemmers for five romance languages http www iveonik com blog 2011 08 snowball stemmers on csharp free download snowball on c port of snowball stemmers for c 14 languages http snowball tartarus org wrappers guide html python bindings to snowball api http locknet ro archive 2009 10 29 ann ruby stemmer html ruby stemmer ruby extension to snowball api http pecl php net package stem pecl php extension to the snowball api http www oleandersolutions com stemming html oleander porter s algorithm stemming library in c released under bsd http www cs waikato ac nz eibe stemmers index html unofficial home page of the lovins stemming algorithm with source code in a couple of languages http www tartarus org martin porterstemmer index html official home page of the porter stemming algorithm including source code in several languages http www comp lancs ac uk computing research stemming index htm official home page of the lancaster stemming algorithm lancaster university uk https www uea ac uk computing word stemming official home page of the uea lite stemmer university of east anglia uk http www comp lancs ac uk computing research stemming general index htm overview of stemming algorithms http code google com p ptstemmer ptstemmer a java python net stemming toolkit for the portuguese language http mazko github com jssnowball jssnowball open source javascript implementation of snowball stemming algorithms for many languages http trimc nlp blogspot com 2013 08 snowball stemmer for java html snowball stemmer implementation for java http hlt di fct unl pt luis hindi stemmer hindi stemmer open source stemmer for hindi http hlt di fct unl pt luis czech stemmer czech stemmer open source stemmer for czech http www comp leeds ac uk eric sawalha08coling pdf comparative evaluation of arabic language morphological analysers and stemmers https github com rdamodharan tamil stemmer tamil stemmer foldoc category linguistic morphology category natural language processing category tasks of natural language processing category computational linguistics category information retrieval techniques'
b'refimprove date june 2015 vocabulary mismatch is a common phenomenon in the usage of natural languages occurring when different people name the same thing or concept differently furnas et al 1987 were perhaps the first to quantitatively study the vocabulary mismatch problem ref furnas g et al the vocabulary problem in human system communication communications of the acm 1987 30 11 pp 964 971 ref their results show that on average 80 of the times different people experts in the same field will name the same thing differently there are usually tens of possible names that can be attributed to the same thing this research motivated the work on latent semantic indexing the vocabulary mismatch between user created queries and relevant documents in a corpus causes the term mismatch problem in information retrieval zhao and callan 2010 ref zhao l and callan j term necessity prediction proceedings of the 19th acm conference on information and knowledge management cikm 2010 toronto canada 2010 ref were perhaps the first to quantitatively study the vocabulary mismatch problem in a retrieval setting their results show that an average query term fails to appear in 30 40 of the documents that are relevant to the user query they also showed that this probability of mismatch is a central probability in one of the fundamental probabilistic retrieval models the binary independence model they developed novel term weight prediction methods that can lead to potentially 50 80 accuracy gains in retrieval over strong keyword retrieval models further research along the line shows that expert users can use boolean conjunctive normal form expansion to improve retrieval performance by 50 300 over unexpanded keyword queries ref name cnf zhao l and callan j automatic term mismatch diagnosis for selective query expansion sigir 2012 ref techniques that solve mismatch stemming full text indexing instead of only indexing keywords or abstracts indexing text on inbound links from other documents or other social tagging query expansion a 2012 study by zhao and callan ref name cnf using expert created manual conjunctive normal form queries has shown that searchonym expansion in the boolean conjunctive normal form is much more effective than the traditional bag of word expansion e g rocchio algorithm rocchio expansion translation based models references reflist category linguistic research category information retrieval techniques category natural language processing'
b'uncertain inference was first described by c j van rijsbergen ref cite author c j van rijsbergen title a non classical logic for information retrieval publisher the computer journal pages 481 485 year 1986 ref as a way to formally define a query and document relationship in information retrieval this formalization is a logical consequence logical implication with an attached measure of uncertainty definitions rijsbergen proposes that the measure of uncertainty of a document d to a query q be the probability of its logical implication i e math p d to q math a user s query can be interpreted as a set of assertions about the desired document it is the system s task to inference infer given a particular document if the query assertions are true if they are the document is retrieved in many cases the contents of documents are not sufficient to assert the queries a knowledge base of facts and rules is needed but some of them may be uncertain because there may be a probability associated to using them for inference therefore we can also refer to this as plausible inference the plausibility of an inference math d to q math is a function of the plausibility of each query assertion rather than retrieving a document that exactly matches the query we should rank the documents based on their plausibility in regards to that query since d and q are both generated by users they are error prone thus math d to q math is uncertain this will affect the plausibility of a given query by doing this it accomplishes two things separate the processes of revising probabilities from the logic separate the treatment of relevance from the treatment of requests multimedia documents like images or videos have different inference properties for each datatype they are also different from text document properties the framework of plausible inference allows us to measure and combine the probabilities coming from these different properties uncertain inference generalizes the notions of autoepistemic logic where truth values are either known or unknown and when known they are true or false example if we have a query of the form math q a wedge b wedge c math where a b and c are query assertions then for a document d we want the probability math p d to a wedge b wedge c math if we transform this into the conditional probability math p a wedge b wedge c d math and if the query assertions are independent we can calculate the overall probability of the implication as the product of the individual assertions probabilities further work croft and krovetz ref cite title interactive retrieval office documents url http doi acm org 10 1145 45410 45435 author1 w b croft author2 r krovetz year 1988 ref applied uncertain inference to an information retrieval system for office documents they called officer in office documents the independence assumption is valid since the query will focus on their individual attributes besides analysing the content of documents one can also query about the author size topic or collection for example they devised methods to compare document and query attributes infer their plausibility and combine it into an overall rating for each document besides that uncertainty of document and query contents also had to be addressed probabilistic logic network s is a system for performing uncertain inference crisp true false truth values are replaced not only by a probability but also by a confidence level indicating the certitude of the probability markov logic network s allow uncertain inference to be performed uncertainties are computed using the maximum entropy principle in analogy to the way that markov chain s describe the uncertainty of finite state machine s see also fuzzy logic probabilistic logic plausible reasoning imprecise probability references reflist category fuzzy logic category information retrieval techniques category inference'
b'underlinked date july 2016 the ordered weighted averaging aggregation operator yager s owa ordered weighted averaging operators r yagerowa are used to aggregate the crisp values in decision making schemes such as multi criteria decision making multi expert decision making and multi criteria multi expert decision making r yager yagerbeliakov it is widely accepted that fuzzy set s r zadeh are more suitable for representing preferences of criteria in decision making the type 1 owa operators r fsst1owa kdet1owa have been proposed for this purpose the type 1 owa operators provides a technique for directly aggregating uncertain information with uncertain weights via owa mechanism in soft decision making and data mining where these uncertain objects are modelled by fuzzy sets the two definitions for type 1 owa operators are based on zadeh s extension principle and math alpha math cuts of fuzzy sets the two definitions lead to equivalent results definitions definition 1 let math f x math be the set of fuzzy sets with domain of discourse math x math a type 1 owa operator is defined as follows r kdet1owa given n linguistic weights math left w i right i 1 n math in the form of fuzzy sets defined on the domain of discourse math u 0 1 math a type 1 owa operator is a mapping math phi math math phi colon f x times cdots times f x longrightarrow f x math math a 1 cdots a n mapsto y math such that math mu y y displaystyle sup displaystyle sum k 1 n bar w i a sigma i y left begin array 1 l mu w 1 w 1 wedge cdots wedge mu w n w n wedge mu a 1 a 1 wedge cdots wedge mu a n a n end array right math where math bar w i frac w i sum i 1 n w i math and math sigma colon 1 cdots n longrightarrow 1 cdots n math is a permutation function such that math a sigma i geq a sigma i 1 forall i 1 cdots n 1 math i e math a sigma i math is the math i math th highest element in the set math left a 1 cdots a n right math definition 2 using the alpha cuts of fuzzy sets r kdet1owa given the n linguistic weights math left w i right i 1 n math in the form of fuzzy sets defined on the domain of discourse math u 0 1 math then for each math alpha in 0 1 math an math alpha math level type 1 owa operator with math alpha math level sets math left w alpha i right i 1 n math to aggregate the math alpha math cuts of fuzzy sets math left a i right i 1 n math is math phi alpha left a alpha 1 ldots a alpha n right left frac sum limits i 1 n w i a sigma i sum limits i 1 n w i left w i in w alpha i a i right in a alpha i i 1 ldots n right math where math w alpha i w mu w i w geq alpha a alpha i x mu a i x geq alpha math and math sigma 1 cdots n to 1 cdots n math is a permutation function such that math a sigma i ge a sigma i 1 forall i 1 cdots n 1 math i e math a sigma i math is the math i math th largest element in the set math left a 1 cdots a n right math representation theorem of type 1 owa operators given the n linguistic weights math left w i right i 1 n math in the form of fuzzy sets defined on the domain of discourse math u 0 1 math and the fuzzy sets math a 1 cdots a n math then we have that r kdet1owa math y g math where math y math is the aggregation result obtained by definition 1 and math g math is the result obtained by in definition 2 programming problems for type 1 owa operators according to the representation theorem of type 1 owa operators a general type 1 owa operator can be decomposed into a series of math alpha math level type 1 owa operators in practice this series of math alpha math level type 1 owa operators is used to construct the resulting aggregation fuzzy set so we only need to compute the left end points and right end points of the intervals math phi alpha left a alpha 1 cdots a alpha n right math then the resulting aggregation fuzzy set is constructed with the membership function as follows math mu g x operatorname bigvee limits alpha x in phi alpha left a alpha 1 cdots a alpha n right alpha alpha math for the left end points we need to solve the following programming problem math phi alpha left a alpha 1 cdots a alpha n right operatorname min limits begin array l w alpha i le w i le w alpha i a alpha i le a i le a alpha i end array sum limits i 1 n w i a sigma i sum limits i 1 n w i math while for the right end points we need to solve the following programming problem math phi alpha left a alpha 1 cdots a alpha n right operatorname max limits begin array l w alpha i le w i le w alpha i a alpha i le a i le a alpha i end array sum limits i 1 n w i a sigma i sum limits i 1 n w i math a fast method has been presented to solve two programming problem so that the type 1 owa aggregation operation can be performed efficiently for details please see the paper r kdet1owa alpha level approach to type 1 owa operation three step process r kdet1owa step 1 mdash to set up the math alpha math level resolution in 0 1 step 2 mdash for each math alpha in 0 1 math step 2 1 mdash to calculate math rho alpha i 0 ast math let math i 0 1 math if math rho alpha i 0 ge a alpha sigma i 0 math stop math rho alpha i 0 math is the solution otherwise go to step 2 1 3 math i 0 leftarrow i 0 1 math go to step 2 1 2 step 2 2 to calculate math rho alpha i 0 ast math let math i 0 1 math if math rho alpha i 0 ge a alpha sigma i 0 math stop math rho alpha i 0 math is the solution otherwise go to step 2 2 3 math i 0 leftarrow i 0 1 math go to step step 2 2 2 step 3 mdash to construct the aggregation resulting fuzzy set math g math based on all the available intervals math left rho alpha i 0 ast rho alpha i 0 ast right math math mu g x operatorname bigvee limits alpha x in left rho alpha i 0 ast rho alpha i 0 ast right alpha math special cases any owa operators like maximum minimum mean operators ref name yagerowa join operators of type 1 fuzzy sets r mt i e fuzzy maximum operators meet operators of type 1 fuzzy sets r mt zadehj i e fuzzy minimum operators join like operators of type 1 fuzzy sets r kdet1owa bookt1owa meet like operators of type 1 fuzzy sets r kdet1owa bookt1owa generalizations type 2 owa operators r zhou have been suggested to aggregate the type 2 fuzzy sets and systems type 2 fuzzy sets for soft decision making references reflist 30em refs ref name yagerowa cite journal last yager first r r title on ordered weighted averaging aggregation operators in multi criteria decision making journal ieee transactions on systems man and cybernetics year 1988 volume 18 pages 183 190 doi 10 1109 21 87068 ref ref name yager cite book last yager first r r and kacprzyk j title the ordered weighted averaging operators theory and applications year 1997 publisher kluwer norwell ma ref ref name yagerbeliakov cite book last yager first r r kacprzyk j and beliakov g title recent developments in the ordered weighted averaging operators theory and practice year 2011 publisher springer ref ref name zadeh cite journal last zadeh first l a title fuzzy sets journal information and control year 1965 volume 8 pages 338 353 doi 10 1016 s0019 9958 65 90241 x ref ref name kdet1owa cite journal last zhou first s m author2 f chiclana author3 r i john author4 j m garibaldi title alpha level aggregation a practical approach to type 1 owa operation for aggregating uncertain information with applications to breast cancer treatments journal ieee transactions on knowledge and data engineering year 2011 volume 23 issue 10 pages 1455 1468 doi 10 1109 tkde 2010 191 ref ref name fsst1owa cite journal last zhou first s m author2 f chiclana author3 r i john author4 j m garibaldi title type 1 owa operators for aggregating uncertain information with uncertain weights induced by type 2 linguistic quantifiers journal fuzzy sets and systems year 2008 volume 159 issue 24 pages 3281 3296 doi 10 1016 j fss 2008 06 018 ref ref name mt cite journal last mizumoto first m author2 k tanaka title some properties of fuzzy sets of type 2 journal information and control year 1976 volume 31 pages 312 40 doi 10 1016 s0019 9958 76 80011 3 ref ref name zadehj cite journal last zadeh first l a title the concept of a linguistic variable and its application to approximate reasoning 1 journal information sciences year 1975 volume 8 pages 199 249 doi 10 1016 0020 0255 75 90036 5 ref ref name bookt1owa cite journal last zhou first s m author2 f chiclana author3 r i john author4 j m garibaldi title fuzzificcation of the owa operators in aggregating uncertain information journal r r yager j kacprzyk and g beliakov ed recent developments in the ordered weighted averaging operators theory and practice year 2011 volume springer pages 91 109 doi 10 1007 978 3 642 17910 5 5 ref ref name zhou cite journal last zhou first s m author2 r i john author3 f chiclana author4 j m garibaldi title on aggregating uncertain information by type 2 owa operators for soft decision making journal international journal of intelligent systems year 2010 volume 25 issue 6 pages 540 558 doi 10 1002 int 20420 ref category artificial intelligence category fuzzy logic category information retrieval techniques category logic in computer science'
b'about thesauri used to support indexing tagging or searching for information thesauri used in general literary applications thesaurus the clare fischer album thesaurus album in the context of information retrieval a thesaurus plural thesauri is a form of controlled vocabulary that seeks to dictate semantic manifestations of metadata in the indexing of content objects a thesaurus serves to minimise semantic ambiguity by ensuring uniformity and consistency in the storage and retrieval of the manifestations of content objects ansi niso z39 19 2005 defines a content object as any item that is to be described for inclusion in an information retrieval system website or other source of information ref ansi niso 2005 guidelines for the construction format and management of monolingual controlled vocabularies niso maryland u s a p 11 ref the thesaurus aids the assignment of preferred terms to convey semantic metadata associated with the content object ref ansi niso 2005 guidelines for the construction format and management of monolingual controlled vocabularies niso maryland u s a p 12 ref a thesaurus serves to guide both an indexer and a searcher in selecting the same preferred term or combination of preferred terms to represent a given subject iso 25964 the international standard for information retrieval thesauri defines a thesaurus as a controlled and structured vocabulary in which concepts are represented by terms organized so that relationships between concepts are made explicit and preferred terms are accompanied by lead in entries for synonyms or quasi synonyms a thesaurus is composed by at least three elements 1 a list of words or terms 2 the relationship amongst the words or terms indicated by their hierarchical relative position e g parent broader term child narrower term synonym etc 3 a set of rules on how to use the thesaurus history wherever there have been large collections of information whether on paper or in computers scholars have faced a challenge in pinpointing the items they seek the use of classification schemes to arrange the documents in order was only a partial solution another approach was to index the contents of the documents using words or terms rather than classification codes in the 1940s and 1950s some pioneers such as calvin mooers charles l bernier http pubs acs org cen priestley recipients 1951crane html evan j crane and hans peter luhn collected up their index terms in various kinds of list that they called a thesaurus by analogy with the well known thesaurus developed by peter roget ref roberts n the pre history of the information retrieval thesaurus journal of documentation 40 4 1984 p 271 285 ref the first such list put seriously to use in information retrieval was the thesaurus developed in 1959 at the e i dupont de nemours company ref aitchison j and dextre clarke s the thesaurus a historical viewpoint with a look to the future cataloging classification quarterly 37 3 4 2004 p 5 21 ref ref krooks d a and lancaster f w the evolution of guidelines for thesaurus construction libri 43 4 1993 p 326 342 ref the first two of these lists to be published were the thesaurus of astia descriptors 1960 and the chemical engineering thesaurus of the american institute of chemical engineers 1961 a descendant of the dupont thesaurus more followed culminating in the influential thesaurus of engineering and scientific terms test published jointly by the engineers joint council and the us department of defense in 1967 test did more than just serve as an example its appendix 1 presented thesaurus rules and conventions that have guided thesaurus construction ever since hundreds of thesauri have been produced since then perhaps thousands the most notable innovations since test have been a extension from monolingual to multilingual capability and b addition of a conceptually organized display to the basic alphabetical presentation here we mention only some of the national and international standards that have built steadily on the basic rules set out in test unesco guidelines for the establishment and development of monolingual thesauri 1970 followed by later editions in 1971 and 1981 din 1463 guidelines for the establishment and development of monolingual thesauri 1972 followed by later editions iso 2788 guidelines for the establishment and development of monolingual thesauri 1974 revised 1986 ansi american national standard for thesaurus structure construction and use 1974 revised 1980 and superseded by ansi niso z39 19 1993 iso 5964 guidelines for the establishment and development of multilingual thesauri 1985 ansi niso z39 19 guidelines for the construction format and management of monolingual thesauri 1993 revised 2005 and renamed guidelines for the construction format and management of monolingual controlled vocabularies iso 25964 thesauri and interoperability with other vocabularies part 1 thesauri for information retrieval published 2011 part 2 interoperability with other vocabularies published 2013 the most clearly visible trend across this history of thesaurus development has been from the context of small scale isolation to a networked world ref dextre clarke stella g and zeng marcia lei http www niso org publications isq 2012 v24no1 clarke from iso 2788 to iso 25964 the evolution of thesaurus standards towards interoperability and data modeling information standards quarterly 24 1 2012 p 20 26 ref access to information was notably enhanced when thesauri crossed the divide between monolingual and multilingual applications more recently as can be seen from the titles of the latest iso and niso standards there is a recognition that thesauri need to work in harness with other forms of vocabulary or knowledge organization system such as subject heading schemes classification schemes taxonomies and ontologies the official website for iso 25964 gives more information including a reading list ref http www niso org schemas iso25964 iso 25964 the international standard for thesauri and interoperability with other vocabularies national information standards organization 2013 ref purpose refimprove section small z date march 2016 in information retrieval a thesaurus can be used as a form of controlled vocabulary to aid in the indexing of appropriate metadata for information bearing entities a thesaurus helps with expressing the manifestations of a concept in a prescribed way to aid in improving precision and recall this means that the semantic conceptual expressions of information bearing entities are easier to locate due to uniformity of language additionally a thesaurus is used for maintaining a hierarchical listing of terms usually single words or bound phrases that aid the indexer in narrowing the terms and limiting semantic ambiguity the art and architecture thesaurus art architecture thesaurus for example is used by countless museums around the world to catalogue their collections agrovoc the thesaurus of the un s food and agriculture organization is used to index and or search its agris database of worldwide literature on agricultural research structure refimprove section small z date march 2016 information retrieval thesauri are formally organized so that existing relationships between concepts are made clear for example citrus fruits might be linked to the broader concept of fruits and the narrower ones of oranges lemons etc when the terms are displayed online the links between them make it very easy to surf around the thesaurus selecting useful terms for a search when a single term could have more than one meaning like tables furniture or tables data these are listed separately so that the user can choose which concept to search for and avoid retrieving irrelevant results for any one concept all the known synonyms are listed such as mad cow disease bovine spongiform encephalopathy bse etc the idea is to guide all the indexers and all the searchers to use the same term for the same concept so that search results will be as complete as possible if the thesaurus is multilingual equivalent terms in other languages are shown too following international standards concepts are generally arranged hierarchically within facets or grouped by themes or topics unlike a general thesaurus used for literary purposes information retrieval thesauri typically focus on one discipline subject or field of study see also controlled vocabulary iso 25964 thesaurus references reflist external links http www niso org schemas iso25964 official site for iso 25964 http www taxonomywarehouse com taxonomy warehouse category information retrieval techniques category thesauri'
b'term discrimination is a way to rank keywords in how useful they are for information retrieval overview this is a method similar to tf idf but it deals with finding keywords suitable for information retrieval and ones that are not please refer to vector space model first this method uses the concept of vector space density that the less dense an occurrence matrix is the better an information retrieval query will be an optimal index term is one that can distinguish two different documents from each other and relate two similar documents on the other hand a sub optimal index term can not distinguish two different document from two similar documents the discrimination value is the difference in the occurrence matrix s vector space density versus the same matrix s vector space without the index term s density let math a math be the occurrence matrix math a k math be the occurrence matrix without the index term math k math and math q a math be density of math a math then the discrimination value of the index term math k math is math dv k q a q a k math how to compute given an occurrency matrix math a math and one keyword math k math find the global document centroid math c math this is just the average document vector find the average euclidean distance from every document vector math d i math to math c math find the average euclidean distance from every document vector math d i math to math c math ignoring math k math the difference between the two values in the above step is the discrimination value for keyword math k math a higher value is better because including the keyword will result in better information retrieval qualitative observations keywords that are sparse matrix sparse should be poor discriminators because they have poor precision and recall recall whereas keywords that are frequent should be poor discriminators because they have poor precision and recall precision references gerard salton g salton a wong and c s yang 1975 http www cs uiuc edu class fa05 cs511 spring05 other papers p613 salton pdf a vector space model for automatic indexing communications of the acm vol 18 nr 11 pages 613 620 the article in which the vector space model was first presented can f ozkarahan e a 1987 computation of term document discrimination values by use of the cover coefficient concept journal of the american society for information science vol 38 nr 3 pages 171 183 category information retrieval techniques'
b'hatnote not to be confused with markup language or html element tags file web 2 0 map svg thumb right 250px a tag cloud with terms related to web 2 0 in information system s a tag is a non hierarchical index term keyword or term assigned to a piece of information such as an bookmark world wide web internet bookmark digital image or computer file this kind of metadata helps describe an item and allows it to be found again by browsing or searching tags are generally chosen informally and personally by the item s creator or by its viewer depending on the system tagging was popularized by websites associated with web 2 0 and is an important feature of many web 2 0 services it is now also part of some desktop software history labeling and tagging are carried out to perform functions such as aiding in classification machine learning classification marking ownership noting boundaries and indicating online identity they may take the form of words images or other identifying marks an analogous example of tags in the physical world is museum object tagging in the organization of information and objects the use of textual keywords as part of identification and classification long predates computers however computer based searching made the use of keywords a rapid way of exploring records file a description of the equator and some otherlands collaborative hypercinema portal upload page jpg thumb a description of the equator and some otherlands collaborative hypercinema portal produced by documenta x 1997 user upload page associating user contributed media with the term tag online and internet databases and early websites deployed them as a way for publishers to help users find content in 1997 the collaborative portal a description of the equator and some other lands produced by documenta x germany coined the folksonomic term tag for its co authors and guest authors on its upload page in the equator the term tag for user input was described as an abstract literal or keyword to aid the user turned out in web 1 0 days all otherlands users defined singular tags and did not share tags at that point in 2003 the social bookmarking website delicious website delicious provided a way for its users to add tags to their bookmarks as a way to help find them later delicious also provided browseable aggregated views of the bookmarks of all users featuring a particular tag ref http flickr com photos joshu 765809051 in set 72157600740166824 screenshot of tags on del icio us in 2004 and http flickr com photos joshu 765817375 in set 72157600740166824 screenshot of a tag page on del icio us also in 2004 both published by joshua schachter on july 9 2007 ref flickr allowed its users to add their own text tags to each of their pictures constructing flexible and easy metadata that made the pictures highly searchable ref http www adaptivepath com ideas essays archives 000519 php an interview with flickr s eric costello by jesse james garrett published on august 4 2005 quote tags were not in the initial version of flickr stewart butterfield liked the way they worked on del icio us the social bookmarking application we added very simple tagging functionality so you could tag your photos and then look at all your photos with a particular tag or any one person s photos with a particular tag ref the success of flickr and the influence of delicious popularized the concept ref an example is http www adammathes com academic computer mediated communication folksonomies html folksonomies cooperative classification and communication through shared metadata by adam mathes december 2004 it focuses on tagging in delicious and flickr ref and other social software websites nbsp such as youtube technorati and last fm nbsp also implemented tagging other traditional and web applications have incorporated the concept such as labels in gmail and the ability to add and edit tags in itunes or winamp tagging has gained wide popularity due to the growth of social networking photography sharing and bookmarking sites these sites allow users to create and manage labels or tags that categorize content using simple keywords the use of keywords as part of an identification and classification system long predates computers in the early days of the web keywords meta tags were used by web page designers to tell search engines what the web page was about today s tagging takes the meta keywords concept and re uses it the users add the tags the tags are clearly visible and are themselves links to other items that share that keyword tag knowledge tags are an extension of index term keyword tags they were first used by jumper 2 0 an open source web 2 0 software platform released by jumper networks on 29 september 2008 ref citation url http www jumpernetworks com news jumper networks releases jumper 2 0 platform pdf title jumper networks press release for jumper 2 0 publisher jumper networks inc date 29 september 2008 ref jumper 2 0 was the first collaborative search engine platform to use a method of expanded tagging for knowledge capture websites that include tags often display collections of tags as tag cloud s a user s tags are useful both to them and to the larger community of the website s users tags may be a bottom up type of classification compared to hierarchy hierarchies which are top down in a traditional hierarchical system taxonomy general taxonomy the designer sets out a limited number of terms to use for classification and there is one correct way to classify each item in a tagging system there are an unlimited number of ways to classify an item and there is no wrong choice instead of belonging to one category an item may have several different tags some researchers and applications have experimented with combining structured hierarchy and flat tagging to aid in information retrieval ref http infolab stanford edu heymann taghierarchy html tag hierarchies research notes by paul heymann ref examples within a blog many blog systems allow authors to add free form tags to a post along with or instead of placing the post into categories for example a post may display that it has been tagged with baseball and tickets each of those tags is usually a web link leading to an index page listing all of the posts associated with that tag the blog may have a sidebar listing all the tags in use on that blog with each tag leading to an index page to reclassify a post an author edits its list of tags all connections between posts are automatically tracked and updated by the blog software there is no need to relocate the page within a complex hierarchy of categories for an event an official tag is a keyword adopted by events and conferences for participants to use in their web publications such as blog entries photos of the event and presentation slides search engines can then index them to make relevant materials related to the event searchable in a uniform way in this case the tag is part of a controlled vocabulary in research a researcher may work with a large collection of items e g press quotes a bibliography images in digital form if he she wishes to associate each with a small number of themes e g to chapters of a book or to sub themes of the overall subject then a group of tags for these themes can be attached to each of the items in the larger collection in this way free form categorization classification allows the author to manage what would otherwise be unwieldy amounts of information commercial as well as some free computer applications are readily available to do this special types triple tags see also microformat a triple tag or machine tag uses a special syntax to define extra semantic information about the tag making it easier or more meaningful for interpretation by a computer program triple tags comprise three parts a namespace a wikt predicate predicate and a value for example nowiki geo long 50 123456 nowiki is a tag for the geographical longitude coordinate whose value is 50 123456 this triple structure is similar to the resource description framework model for information the triple tag format was first devised for geolicious ref cite web url http brainoff com weblog 2004 11 05 124 title geo lici us geotagging hosted services first1 mikel last1 maron date november 5 2004 ref in november 2004 to map delicious website delicious bookmarks and gained wider acceptance after its adoption by http stamen com projects mappr mappr and geobloggers ref http web archive org web 20071011024028 http geobloggers com archives 2006 01 11 advanced tagging and tripletags advanced tagging and tripletags by reverend dan catt geobloggers january 11 2006 ref to map flickr photos in january 2007 aaron straup cope at flickr introduced the term machine tag as an alternative name for the triple tag adding some questions and answers on purpose syntax and use ref https www flickr com groups api discuss 72157594497877875 machine tags a post by aaron straup cope in the flickr api group january 24 2007 ref specialized metadata for geographical identification is known as geotagging machine tags are also used for other purposes such as identifying photos taken at a specific event or naming species using binomial nomenclature ref https www flickr com groups encyclopedia of life rules encyclopedia of life use of machine tag the encyclopedia of life project rules including the required use of a taxonomy machine tag september 19 2009 ref hashtags main hashtag a hashtag is a kind of metadata tag marked by the prefix code code sometimes known as a hash symbol this form of tagging is used on microblogging and social networking service s such as twitter facebook google vk social network vk and instagram knowledge tags a knowledge tag is a type of metadata meta information that describes or defines some aspect of an information resource such as a document digital image database table relational table or web page knowledge tags are more than traditional non hierarchical index term keywords or terms they are a type of metadata that captures knowledge in the form of descriptions categorizations classifications semantics comments notes annotations hyperdata hyperlinks or references that are collected in tag profiles these tag profiles reference an information resource that resides in a distributed and often heterogeneous storage repository knowledge tags are a knowledge management discipline that leverages enterprise 2 0 methodologies for users to capture insights expertise attributes dependencies or relationships associated with a data resource it generally allows greater flexibility than other knowledge management classification systems capturing knowledge in tags takes many different forms there is factual knowledge that found in books and data conceptual knowledge found in perspectives and concepts expectational knowledge needed to make judgments and hypothesis and methodological knowledge derived from reasoning and strategies ref citation last wiig first k m year 1997 title knowledge management an introduction and perspective journal journal of knowledge management volume 1 issue 1 pages 6 14 url http www mendeley com c 67997727 wiig 1997 knowledge management an introduction and perspective doi 10 1108 13673279710800682 ref these forms of knowledge often exist outside the data itself and are derived from personal experience insight or expertise knowledge tags in fact manifest themselves in any number of ways conceptual knowledge tags describe procedures lessons learned and facts that are related to the information resource tacit knowledge tags manifests itself through skills habits or learning by doing and represent experience or organizational intelligence anecdotal knowledge is a memory of a particular case or event that may not surface without context ref citation last getting first brian year 2007 title what are tags and what is tagging publisher practical ecommerce url http www practicalecommerce com articles 589 ref knowledge can best be defined as information possessed in the mind of an individual it is personalized or subjective information related to facts procedures concepts interpretations ideas observations and judgments which may or may not be unique useful accurate or structurable knowledge tags are considered an expansion of the information itself that adds additional value context and meaning to the information knowledge tags are valuable for preserving organizational intelligence that is often lost due to turn over for sharing knowledge stored in the minds of individuals that is typically isolated and unharnessed by the organization and for connecting knowledge that is often lost or disconnected from an information resource ref citation last alavi first maryam last2 leidner year 1999 title knowledge management systems issues challenges and benefits journal communications of the association for information systems volume 1 issue 7 url http www belkcollege uncc edu jpfoley readings artic07 pdf ref advantages and disadvantages procon date november 2012 in a typical tagging system there is no explicit information about the meaning or semantics of each tag and a user can apply new tags to an item as easily as applying older tags hierarchical classification systems can be slow to change and are rooted in the culture and era that created them ref name smith2008 smith gene 2008 tagging people powered metadata for the social web berkeley ca new riders isbn 0 321 52917 0 ref the flexibility of tagging allows users to classify their collections of items in the ways that they find useful but the personalized variety of terms can present challenges when searching and browsing when users can freely choose tags creating a folksonomy as opposed to selecting terms from a controlled vocabulary the resulting metadata can include homonym s the same tags used with different meanings and synonym s multiple tags for the same concept which may lead to inappropriate connections between items and inefficient searches for information about a subject ref golder scott a huberman bernardo a 2005 http arxiv org abs cs dl 0508082 the structure of collaborative tagging systems information dynamics lab hp labs visited november 24 2005 ref for example the tag orange may refer to the orange fruit fruit or the orange colour color and items related to a version of the linux kernel may be tagged linux kernel penguin software or a variety of other terms users can also choose tags that are different inflection s of words such as singular and plural ref http keithdevens com weblog archive 2004 dec 24 svp tags singular vs plural tags in a tag based categorization system by keith devens december 24 2004 ref which can contribute to navigation difficulties if the system does not include stemming of tags when searching or browsing larger scale folksonomies address some of the problems of tagging in that users of tagging systems tend to notice the current use of tag terms within these systems and thus use existing tags in order to easily form connections to related items in this way folksonomies collectively develop a partial set of tagging conventions complex system dynamics despite the apparent lack of control research has shown that a simple form of shared vocabularies emerges in social bookmarking systems collaborative tagging exhibits a form of complex system s dynamics ref name www07 ref harry halpin valentin robu hana shepherd http portal acm org citation cfm id 1242572 1242602 the complex dynamics of collaborative tagging proceedings of the 16th international conference on the world wide web www 07 banff canada pp 211 220 acm press 2007 downloadable on http www2007 org papers paper635 pdf the conference s website ref or self organization self organizing dynamics thus even if no central controlled vocabulary constrains the actions of individual users the distribution of tags that describe different resources e g websites converges over time to stable power law distributions ref name www07 ref once such stable distributions form simple vocabularies can be extracted by examining the correlation s that form between different tags this informal collaborative system of tag creation and management has been called a folksonomy spamming tagging systems open to the public are also open to tag spam in which people apply an excessive number of tags or unrelated tags to an item such as a youtube video in order to attract viewers this abuse can be mitigated using human or statistical identification of spam items ref http heymann stanford edu tagspam html tag spam research notes by paul heymann ref the number of tags allowed may also be limited to reduce spam syntax some tagging systems provide a single text box to enter tags so to be able to tokenize the string a wiktionary separator separator must be used two popular separators are the space punctuation space character and the comma to enable the use of separators in the tags a system may allow for higher level separators such as quotation mark s or escape character s systems can avoid the use of separators by allowing only one tag to be added to each input web widget widget at a time although this makes adding multiple tags more time consuming a syntax for use within html is to use the rel tag microformat which uses the rel attribute rel attribute with value tag i e code rel tag code to indicate that the linked to page acts as a tag for the current context ref http microformats org wiki rel tag rel tag microformat specification microformats wiki january 10 2005 ref see also colbegin 27em collective intelligence concept map enterprise 2 0 enterprise bookmarking explicit knowledge faceted classification folksonomy information ecology knowledge representation knowledge transfer metaknowledge ontology information science organisational memory semantic web scicrunch tag cloud web 2 0 colend others colbegin 27em collective unconscious human computer interaction social network aggregation enterprise social software expert system knowledge knowledge base knowledge worker management information system microformats social network social software sociology of knowledge tacit knowledge colend references reflist 30em general refbegin citation surname1 nonaka given1 ikujiro year 1994 title a dynamic theory of organizational knowledge creation journal organization science volume 5 issue 1 pages 14 37 url http papers ssrn com sol3 papers cfm abstract id 889992 doi 10 1287 orsc 5 1 14 citation surname1 wigg given1 karl m year 1993 title knowledge management foundations thinking about thinking how people and organizations create represent and use knowledge journal arlington schema press pages 153 url http papers ssrn com sol3 papers cfm abstract id 889992 citation surname1 alavi given1 maryam surname2 leidner given2 dorothy e year 1999 title knowledge management systems issues challenges and benefits journal communications of the ais volume 1 issue 2 url http portal acm org citation cfm id 374117 citation surname1 kemsley given1 sandy year 2009 title models social tagging and knowledge management bpm2009 bpms2 09 journal bpm enterprise 2 0 and technology trends in business url http www column2 com 2009 09 models social tagging and knowledge management bpm2009 bpms209 refend external links http www inc com tech blog twitter hashtag techniques for businesses html hashtag techniques for businesses curt finch inc magazine may 26 2011 http www tbray org tmp tag urn html a uniform resource name urn namespace for tag metadata tim bray internet draft expired august 5 2007 web syndication defaultsort tag metadata category collective intelligence category computer jargon category information retrieval techniques category knowledge representation category metadata category reference category web 2 0'
b'a search suggest drop down list is a query language query feature used in computing to show the searcher computer shortcut shortcut s while the query is typed into a text box before the query is complete a drop down list with the suggested completions appears to provide options to select the suggested queries then enable the searcher to complete the required search quickly as a form of autocomplete autocompletion the suggestion list is distinct from web browsing history search history in that it attempts to be predictive even when the user is searching for the first time data may come from popular searches sponsors geographic location or other sources ref cite web url http www thingsontop com googles new search suggestions may kill your website 158 html title google s new search suggestions may kill your website first vegard last sandvoid publisher things on top date 2008 12 14 accessdate 2016 08 03 ref ref cite web url https diegobasch com search for obama on facebook and you get romney title search for obama on facebook and you get romney first diego last basch date 2012 09 19 accessdate 2016 08 03 ref ref name se land cite web url http searchengineland com how google instant autocomplete suggestions work 62592 title how google instant s autocomplete suggestions work first danny last sullivan publisher search engine land date 2011 04 06 accessdate 2016 08 03 ref these lists are used by operating system s web browsers and various website s particularly search engine s search suggestions are common with a 2014 survey finding that over 80 of e commerce websites included them ref cite web url https www smashingmagazine com 2014 08 the current state of e commerce search title the current state of e commerce search first christian last holt publisher smash magazine date 2014 08 18 accessdate 2016 08 03 ref the computer science computing science of syntax and algorithm s are used to form search results from a database content management system s and frequent searches can assist software engineering software engineers in optimization computer science optimizing more refined queries with methods of parameters and subroutines suggestions can be results for the current query or related queries by words time and dates categories and tag metadata tags the suggestion list may be reordered by other options as enumeration enumerative hierarchical organization hierarchical or faceted classification faceted although not the first deployment of search suggestions google suggest is one of the most prominent four years before it was considered stable the feature was developed in 2004 by google engineer kevin gibbs and the name was chosen by marissa mayer ref cite web url http allthingsd com 20130823 nearly a decade later the autocomplete origin story kevin gibbs and google suggest title nearly a decade later the autocomplete origin story kevin gibbs and google suggest first liz last gannes publisher all things d date 2013 08 23 accessdate 2016 08 03 ref google and other large search companies maintain a blacklist that prevents the display of queries that could be interpreted as violating their social responsibility despite this the company regularly receives complaints that several popular suggestions or suggestions whose positions have been inflated by internet bot bots should be added to this list ref name se land ref cite web url https utopiaordystopia com 2015 02 22 truth and prediction in the dataclysm title truth and prediction in the dataclysm first rick last searle publisher utopia or dystopia date 2015 02 22 accessdate 2016 08 03 ref the electronic frontier foundation s jillian york has criticized apple computers apple s blacklist for including words that are merely provocative ref cite web url http www thedailybeast com articles 2013 07 16 the apple kill list what your iphone doesn t want you to type html title the apple kill list what your iphone doesn t want you to type first michael last keller publisher the daily beast date 2013 07 16 accessdate 2016 08 03 ref one example of a project using suggested queries to expose societal attitudes was a 2013 ad series called the autocomplete truth by un women the campaign showed several gender stereotypes being displayed as popular searches by google suggest ref cite web url http www adweek com adfreak after viral success inequality ads creators say they will expand campaign 153363 title after viral succes of inequality ads creators say they will expand campaign first david last griner publisher ad week date 2013 10 24 accessdate 2016 08 03 ref another was a story by bad astronomy that revealed a distrustful perspective on scientists in the suggestion box ref cite web url http www slate com blogs bad astronomy 2013 12 04 search engine bias scientists are html title scientists are first phil last plait publisher slate date 2013 12 04 accessdate 2016 08 03 ref additionally cases related to libel laws have posited that suggestions may inspire people to associate specific names with specific alleged crimes when they would not have otherwise ref name japan cite web url http www tamingthebeast net blog online world google autocomplete angst htm title some folks really hate autocomplete first michael last bloch publisher taming the beast date 2012 03 27 accessdate 2016 08 03 ref ref cite journal url http ijlit oxfordjournals org content 23 3 261 full title search engine liability for autocomplete suggestions personality privacy and the power of the algorithm first1 stavroula last1 karapapa first2 maurizio last2 borghi journal international journal of law and information technology volume 23 pages 261 289 year 2015 accessdate 2016 08 03 ref some users have criticized the fact that suggestion enabled text boxes unlike the web forms of static html send data about each keystroke to a central server ref cite web url http thekeesh com 2011 08 who does facebook think you are searching for title who does facebook think you are searching for first jeremy last keeshin publisher the keesh date 2011 08 18 accessdate 2016 08 03 ref such data has the potential to keystroke dynamics identify specific people this has caused at least one mozilla firefox developer to opine that users mostly dislike search suggestions ref cite web url https bugzilla mozilla org show bug cgi id 1189719 title recall and display search history within main browser ui first richard last newman publisher mozilla date 2015 08 25 accessdate 2016 08 03 ref apart from the privacy debate some users have expressed negative reception over the usefulness of search autocompletion ref name japan ref cite web url http arnoldit com wordpress 2012 09 10 google autocomplete is smart help a hindrance title google autocomplete is smart help a hindrance first stephen last arnold publisher beyond search date 2012 09 09 accessdate 2016 08 03 ref ref cite web url https www quora com how do very strange stupid auto complete statements appear while searching on google do people actually do these kind of searches or are they pun intended title how do very strange stupid auto complete statements appear while searching on google do people actually do these kind of searches or are they pun intended first seshal last jain publisher quora date 2015 05 02 accessdate 2016 08 03 ref specifically the sudden appearance of a suggestion box in some programs has been compared to the behaviour of a pop up ad ref cite web url http martesmartes blogspot com 2008 07 disabling openoffices stupid html title disabling open office s stupid autocomplete first jeff last martens publisher martes martes date 2008 07 09 accessdate 2016 08 03 ref ref cite web url https mikesmithers wordpress com 2012 01 28 turning off code completion in sqldeveloper a grumpy old man fights back title turning off code completion in sqldeveloper mdash a grumpy old man fights back first mike last smithers publisher the anti kyte date 2012 01 28 accessdate 2016 08 03 ref see also autocomplete search engine computing search box search algorithm censorship by google search suggestions censorship by google \xc2\xa7 search suggestions references reflist defaultsort search suggest drop down list category information retrieval techniques'
b'unreferenced date october 2007 the use of search engine technology is the main integration component in an information system in a traditional business environment the architectural layer usually occupied by a relational database management system rdbms is supplemented or replaced with a search engine or the indexing technology used to build search engines queries for information which would usually be performed using structured query language sql are replaced by keyword or fielded or field enabled searches for structured semi structured model semi structured or unstructured data in a typical multitier architecture multi tier or multitier architecture n tier architecture information is maintained in a data tier where it can be stored and retrieved from a database or file system the data tier is queried by the logic or business tier when information is needed using a data retrieval language like sql in a search oriented architecture the data tier may be replaced or placed behind another tier which contains a search engine and search engine index which is queried instead of the database management system queries from the business tier are made in the search engine query language instead of sql the search engine itself crawls the relational database management system in addition to other traditional data sources such as web pages or traditional file systems and consolidates the results when queried the benefit of adding a search layer to the architecture stack is rapid response time large dynamic datasets made possible by search indexing technology such as an inverted index contrast with service oriented architecture soa service oriented modeling see also hibernate search category software architecture category information retrieval techniques'
b'the extended boolean model was described in a communications of the acm article appearing in 1983 by gerard salton edward a fox and harry wu the goal of the extended boolean model is to overcome the drawbacks of the boolean model that has been used in information retrieval the boolean model doesn t consider term weights in queries and the result set of a boolean query is often either too small or too big the idea of the extended model is to make use of partial matching and term weights as in the vector space model it combines the characteristics of the vector space model with the properties of boolean algebra logic boolean algebra and ranks the similarity between queries and documents this way a document may be somewhat relevant if it matches some of the queried terms and will be returned as a result whereas in the standard boolean model it wasn t ref citation url http portal acm org citation cfm id 358466 last1 salton first1 gerard first2 edward a last2 fox first3 harry last3 wu title extended boolean information retrieval publisher communications of the acm volume 26 issue 11 year 1983 ref thus the extended boolean model can be considered as a generalization of both the boolean and vector space models those two are special cases if suitable settings and definitions are employed further research has shown effectiveness improves relative to that for boolean query processing other research has shown that relevance feedback and query expansion can be integrated with extended boolean query processing definitions in the extended boolean model a document is represented as a vector similarly to in the vector model each i dimension vector space dimension corresponds to a separate term associated with the document the weight of term math k sub x sub associated with document math d sub j sub is measured by its normalized term frequency and can be defined as math w x j f x j frac idf x max i idf i math where math idf sub x sub is inverse document frequency the weight vector associated with document math d sub j sub can be represented as math mathbf v d j w 1 j w 2 j ldots w i j math the 2 dimensions example multiple image width 150 image1 2d extended boolean model or example png alt1 figure 1 caption1 figure 1 the similarities of math q k sub x sub or k sub y sub with documents math d sub j sub and math d sub j 1 sub image2 2d extended boolean model and example png alt2 figure 2 caption2 figure 2 the similarities of math q k sub x sub and k sub y sub with documents math d sub j sub and math d sub j 1 sub considering the space composed of two terms math k sub x sub and math k sub y sub only the corresponding term weights are math w sub 1 sub and math w sub 2 sub ref http www cs cityu edu hk cs5286 lectures lwang ppt lusheng wang ref thus for query math q sub or sub k sub x sub or k sub y sub we can calculate the similarity with the following formula math sim q or d sqrt frac w 1 2 w 2 2 2 math for query math q sub and sub k sub x sub and k sub y sub we can use math sim q and d 1 sqrt frac 1 w 1 2 1 w 2 2 2 math generalizing the idea and p norms we can generalize the previous 2d extended boolean model example to higher t dimensional space using euclidean distances this can be done using p norm s which extends the notion of distance to include p distances where math 1 le p le infin is a new parameter ref citation last garcia first dr e url http www miislita com term vector term vector 6 boolean model html title the extended boolean model weighted queries term weights p norm queries and multiconcept types boolean or extended and that is the query ref a generalized conjunctive query is given by math q or k 1 lor p k 2 lor p lor p k t math the similarity of math q or math and math d j math can be defined as math sim q or d j sqrt p frac w 1 p w 2 p w t p t math a generalized disjunctive query is given by math q and k 1 land p k 2 land p land p k t math the similarity of math q and math and math d j math can be defined as math sim q and d j 1 sqrt p frac 1 w 1 p 1 w 2 p 1 w t p t math examples consider the query math q k sub 1 sub and k sub 2 sub or k sub 3 sub the similarity between query math q and document math d can be computed using the formula math sim q d sqrt p frac 1 sqrt p frac 1 w 1 p 1 w 2 p 2 p w 3 p 2 math improvements over the standard boolean model lee and fox ref citation last1 lee first1 w c first2 e a last2 fox year 1988 title experimental comparison of schemes for interpreting boolean queries url http eprints cs vt edu archive 00000112 01 tr 88 27 pdf ref compared the standard and extended boolean models with three test collections cisi cacm and inspec using p norms they obtained an average precision improvement of 79 106 and 210 over the standard model for the cisi cacm and inspec collections respectively br the p norm model is computationally expensive because of the number of exponentiation operations that it requires but it achieves much better results than the standard model and even fuzzy retrieval techniques the standard boolean model is still the most efficient further reading http citeseerx ist psu edu viewdoc summary doi 10 1 1 58 1997 adaptive feedback methods in an extended boolean model by dr jongpill choi http www sciencedirect com science ob articleurl udi b6vc8 454t5ms 2 user 513551 rdoc 1 fmt orig search sort d docanchor view c searchstrid 1117914301 rerunorigin google acct c000025338 version 1 urlversion 0 userid 513551 md5 4eab0da46bfe361afa883e48f2060feb interpolation of the extended boolean retrieval model citation title information retrieval algorithms and data structures extended boolean model last1 fox first1 e first2 s last2 betrabet first3 m last3 koushik first4 w last4 lee year 1992 publisher prentice hall inc url http www scribd com doc 13742235 information retrieval data structures algorithms william b frakes citation title experiments with automatic query formulation in the extended boolean model url http www springerlink com content tk1t141253257613 first1 lucie last1 skorkovsk\xc3\xa1 first2 pavel last2 ircing year 2009 publisher springer berlin heidelberg see also information retrieval references reflist defaultsort extended boolean model category information retrieval techniques'
b'latent semantic mapping lsm is a data driven framework to model globally meaningful relationships implicit in large volumes of often textual data it is a generalization of latent semantic analysis in information retrieval lsa enables retrieval on the basis of conceptual content instead of merely matching words between queries and documents lsm was derived from earlier work on latent semantic analysis there are 3 main characteristics of latent semantic analysis discrete entities usually in the form of words and documents are mapped onto continuous vectors the mapping involves a form of global correlation pattern and dimensionality reduction is an important aspect of the analysis process these constitute generic properties and have been identified as potentially useful in a variety of different contexts this usefulness has encouraged great interest in lsm the intended product of latent semantic mapping is a data driven framework for modeling relationships in large volumes of data mac os x v10 5 and later includes a software framework framework implementing latent semantic mapping ref http developer apple com documentation textfonts reference latentsemanticmapping index html api reference latent semantic mapping framework reference bot generated title ref see also latent semantic analysis notes reflist references cite journal url http ieeexplore ieee org iel5 79 32367 01511825 pdf title latent semantic mapping information retrieval author bellegarda j r date 2005 cite conference url https www securecms com icassp2006 tutorial 06 asp title latent semantic mapping principles and applications author j bellegarda booktitle icassp 2006 date 2006 category information retrieval techniques category natural language processing semantics stub compu stub'
b'machine learning bar learning to rank ref name liu citation author tie yan liu title learning to rank for information retrieval series foundations and trends in information retrieval year 2009 isbn 978 1 60198 244 5 doi 10 1561 1500000016 pages 225 331 journal foundations and trends in information retrieval volume 3 issue 3 slides from tie yan liu s talk at world wide web conference www 2009 conference are http www2009 org pdf t7a learning 20to 20rank 20tutorial pdf available online ref or machine learned ranking mlr is the application of machine learning typically supervised learning supervised semi supervised learning semi supervised or reinforcement learning in the construction of ranking function ranking models for information retrieval systems ref mehryar mohri afshin rostamizadeh ameet talwalkar 2012 foundations of machine learning the mit press isbn 9780262018258 ref training data consists of lists of items with some partial order specified between items in each list this order is typically induced by giving a numerical or ordinal score or a binary judgment e g relevant or not relevant for each item the ranking model s purpose is to rank i e produce a permutation of items in new unseen lists in a way which is similar to rankings in the training data in some sense applications in information retrieval file mlr search engine example png 250px thumb a possible architecture of a machine learned search engine ranking is a central part of many information retrieval problems such as document retrieval collaborative filtering sentiment analysis and online advertising a possible architecture of a machine learned search engine is shown in the figure to the right training data consists of queries and documents matching them together with relevance degree of each match it may be prepared manually by human assessors or raters as google calls them assessor is the more standard term used e g by trec conference who check results for some queries and determine relevance information retrieval relevance of each result it is not feasible to check relevance of all documents and so typically a technique called pooling information retrieval pooling is used only the top few documents retrieved by some existing ranking models are checked todo write something about selection bias caused by pooling alternatively training data may be derived automatically by analyzing clickthrough logs i e search results which got clicks from users ref name joachims2002 citation author joachims t journal proceedings of the acm conference on sigkdd knowledge discovery and data mining url http www cs cornell edu people tj publications joachims 02c pdf title optimizing search engines using clickthrough data year 2002 ref query chains ref citation author1 joachims t author2 radlinski f title query chains learning to rank from implicit feedback url http radlinski org papers radlinski05querychains pdf year 2005 journal proceedings of the acm conference on sigkdd knowledge discovery and data mining ref or such search engines features as google s google searchwiki searchwiki training data is used by a learning algorithm to produce a ranking model which computes relevance of documents for actual queries typically users expect a search query to complete in a short time such as a few hundred milliseconds for web search which makes it impossible to evaluate a complex ranking model on each document in the corpus and so a two phase scheme is used ref citation author1 b cambazoglu author2 h zaragoza author3 o chapelle author4 j chen author5 c liao author6 z zheng author7 j degenhardt title early exit optimizations for additive machine learned ranking systems journal wsdm 10 proceedings of the third acm international conference on web search and data mining 2010 url http olivier chapelle cc pub wsdm2010 pdf ref first a small number of potentially relevant documents are identified using simpler retrieval models which permit fast query evaluation such as the vector space model standard boolean model boolean model weighted and ref citation author1 broder a author2 carmel d author3 herscovici m author4 soffer a author5 zien j title efficient query evaluation using a two level retrieval process journal proceedings of the twelfth international conference on information and knowledge management year 2003 pages 426 434 isbn 1 58113 723 0 url http cis poly edu westlab papers cntdstrb p426 broder pdf ref and okapi bm25 bm25 this phase is called top math k math document retrieval and many heuristics were proposed in the literature to accelerate it such as using a document s static quality score and tiered indexes ref name manning q eval citation author1 manning c author2 raghavan p author3 sch\xc3\xbctze h title introduction to information retrieval publisher cambridge university press year 2008 section http nlp stanford edu ir book html htmledition efficient scoring and ranking 1 html 7 1 ref in the second phase a more accurate but computationally expensive machine learned model is used to re rank these documents in other areas learning to rank algorithms have been applied in areas other than information retrieval in machine translation for ranking a set of hypothesized translations ref name duh09 citation author kevin k duh title learning to rank with sic hide y partially labeled data year 2009 url http ssli ee washington edu people duh thesis uwthesis pdf ref in computational biology for ranking candidate 3 d structures in protein structure prediction problem ref name duh09 in recommender system s for identifying a ranked list of related news articles to recommend to a user after he or she has read a current news article ref yuanhua lv taesup moon pranam kolari zhaohui zheng xuanhui wang and yi chang http sifaka cs uiuc edu ylv2 pub www11 relatedness pdf learning to model relatedness for news recommendation in international conference on world wide web www 2011 ref feature vectors for convenience of mlr algorithms query document pairs are usually represented by numerical vectors which are called feature vector s such an approach is sometimes called bag of features and is analogous to the bag of words model and vector space model used in information retrieval for representation of documents components of such vectors are called feature machine learning feature s factors or ranking signals they may be divided into three groups features from document retrieval are shown as examples query independent or static features those features which depend only on the document but not on the query for example pagerank or document s length such features can be precomputed in off line mode during indexing they may be used to compute document s static quality score or static rank which is often used to speed up search query evaluation ref name manning q eval ref cite conference first m last richardson author2 prakash a author3 brill e title beyond pagerank machine learning for static ranking booktitle proceedings of the 15th international world wide web conference pages 707 715 publisher year 2006 url http research microsoft com en us um people mattri papers www2006 staticrank pdf accessdate ref query dependent or dynamic features those features which depend both on the contents of the document and the query such as tf idf score or other non machine learned ranking functions query level features or query features which depend only on the query for example the number of words in a query further information query level feature some examples of features which were used in the well known letor dataset ref name letor3 http research microsoft com en us people taoqin letor3 pdf letor 3 0 a benchmark collection for learning to rank for information retrieval ref tf tf idf okapi bm25 bm25 and language modeling scores of document s zone information retrieval zone s title body anchors text url for a given query lengths and inverse document frequency idf sums of document s zones document s pagerank hits algorithm hits ranks and their variants selecting and designing good features is an important area in machine learning which is called feature engineering evaluation measures there are several measures metrics which are commonly used to judge how well an algorithm is doing on training data and to compare performance of different mlr algorithms often a learning to rank problem is reformulated as an optimization problem with respect to one of these metrics examples of ranking quality measures information retrieval mean average precision mean average precision map discounted cumulative gain dcg and normalized discounted cumulative gain ndcg precision information retrieval precision n ndcg n where n denotes that the metrics are evaluated only on top n documents mean reciprocal rank kendall s tau spearman s rank correlation coefficient spearman s rho dcg and its normalized variant ndcg are usually preferred in academic research when multiple levels of relevance are used ref http www stanford edu class cs276 handouts lecture15 learning ranking ppt ref other metrics such as map mrr and precision are defined only for binary judgements recently there have been proposed several new evaluation metrics which claim to model user s satisfaction with search results better than the dcg metric expected reciprocal rank err ref citation author1 olivier chapelle author2 donald metzler author3 ya zhang author4 pierre grinspan title expected reciprocal rank for graded relevance url https web archive org web 20120224053008 http research yahoo com files err pdf journal cikm year 2009 pages ref yandex s pfound ref citation author1 gulin a author2 karpovich p author3 raskovalov d author4 segalovich i title yandex at romip 2009 optimization of ranking algorithms by machine learning methods url http romip ru romip2009 15 yandex pdf journal proceedings of romip 2009 year 2009 pages 163 168 in russian ref both of these metrics are based on the assumption that the user is more likely to stop looking at search results after examining a more relevant document than after a less relevant document approaches expand section date december 2009 tie yan liu of microsoft research asia has analyzed existing algorithms for learning to rank problems in his paper learning to rank for information retrieval ref name liu he categorized them into three groups by their input representation and loss function pointwise approach in this case it is assumed that each query document pair in the training data has a numerical or ordinal score then learning to rank problem can be approximated by a regression problem given a single query document pair predict its score a number of existing supervised learning supervised machine learning algorithms can be readily used for this purpose ordinal regression and classification machine learning classification algorithms can also be used in pointwise approach when they are used to predict score of a single query document pair and it takes a small finite number of values pairwise approach in this case learning to rank problem is approximated by a classification problem learning a binary classifier that can tell which document is better in a given pair of documents the goal is to minimize average number of permutation inversions inversions in ranking listwise approach these algorithms try to directly optimize the value of one of the above evaluation measures averaged over all queries in the training data this is difficult because most evaluation measures are not continuous functions with respect to ranking model s parameters and so continuous approximations or bounds on evaluation measures have to be used list of methods a partial list of published learning to rank algorithms is shown below with years of first publication of each method class wikitable sortable year name type notes 1989 oprf ref name fuhr1989 citation last fuhr first norbert journal acm transactions on information systems title optimum polynomial retrieval functions based on the probability ranking principle volume 7 number 3 pages 183 204 year 1989 doi 10 1145 65943 65944 ref span style display none 2 span pointwise polynomial regression instead of machine learning this work refers to pattern recognition but the idea is the same 1992 slr ref name cooperetal1992 citation author1 cooper william s author2 gey frederic c author3 dabney daniel p journal sigir 92 proceedings of the 15th annual international acm sigir conference on research and development in information retrieval title probabilistic retrieval based on staged logistic regression pages 198 210 year 1992 doi 10 1145 133160 133199 ref span style display none 2 span pointwise staged logistic regression 2000 http research microsoft com apps pubs default aspx id 65610 ranking svm ranksvm span style display none 2 span pairwise a more recent exposition is in ref name joachims2002 which describes an application to ranking using clickthrough logs 2002 pranking ref cite journal citeseerx 10 1 1 20 378 title pranking ref span style display none 1 span pointwise ordinal regression 2003 or 1998 http jmlr csail mit edu papers volume4 freund03a freund03a pdf rankboost span style display none 2 span pairwise 2005 http research microsoft com en us um people cburges papers icml ranking pdf ranknet span style display none 2 span pairwise 2006 http research microsoft com en us people tyliu cao et al sigir2006 pdf ir svm span style display none 2 span pairwise ranking svm with query level normalization in the loss function 2006 http research microsoft com en us um people cburges papers lambdarank pdf lambdarank pairwise listwise ranknet in which pairwise loss function is multiplied by the change in the ir metric caused by a swap 2007 http research microsoft com en us people junxu sigir2007 adarank pdf adarank span style display none 3 span listwise 2007 http research microsoft com apps pubs default aspx id 70364 frank span style display none 2 span pairwise based on ranknet uses a different loss function fidelity loss 2007 http www cc gatech edu zha papers fp086 zheng pdf gbrank span style display none 2 span pairwise 2007 http research microsoft com apps pubs default aspx id 70428 listnet span style display none 3 span listwise 2007 http research microsoft com apps pubs default aspx id 68128 mcrank span style display none 1 span pointwise 2007 http www stat rutgers edu tzhang papers nips07 ranking pdf qbrank span style display none 2 span pairwise 2007 http research microsoft com en us people hangli qin ipm 2008 pdf rankcosine span style display none 3 span listwise 2007 rankgp ref cite journal citeseerx 10 1 1 90 220 title rankgp ref span style display none 3 span listwise 2007 http staff cs utu fi aatapa publications inppatsaibosa07a pdf rankrls span style display none 2 span pairwise regularized least squares based ranking the work is extended in ref name pahikkala2009efficient citation last pahikkala first tapio author2 tsivtsivadze evgeni author3 airola antti author4 j\xc3\xa4rvinen jouni author5 boberg jorma title an efficient algorithm for learning to rank from preference graphs journal machine learning year 2009 volume 75 issue 1 pages 129 165 doi 10 1007 s10994 008 5097 z postscript ref to learning to rank from general preference graphs 2007 http www cs cornell edu people tj publications yue etal 07a pdf svm sup map sup span style display none 3 span listwise 2008 http research microsoft com pubs 69536 tr 2008 109 pdf lambdamart pairwise listwise winning entry in the recent yahoo learning to rank competition used an ensemble of lambdamart models ref c burges 2010 http research microsoft com en us um people cburges tech reports msr tr 2010 82 pdf from ranknet to lambdarank to lambdamart an overview ref 2008 http research microsoft com en us people tyliu icml listmle pdf listmle span style display none 3 span listwise based on listnet 2008 http research microsoft com en us people junxu sigir2008 directoptimize pdf permurank span style display none 3 span listwise 2008 http research microsoft com apps pubs id 63585 softrank span style display none 3 span listwise 2008 http www cs pitt edu valizadegan publications ranking refinement pdf ranking refinement ref rong jin hamed valizadegan hang li http www cs pitt edu valizadegan publications ranking refinement pdf ranking refinement and its application for information retrieval in international conference on world wide web www 2008 ref span style display none 2 span pairwise a semi supervised approach to learning to rank that uses boosting 2008 http www connex lip6 fr amini ssrankboost ssrankboost ref massih reza amini vinh truong cyril goutte http www connex lip6 fr amini publis semisupranking sigir08 pdf a boosting algorithm for learning bipartite ranking functions with partially labeled data international acm sigir conference 2008 the http www connex lip6 fr amini ssrankboost code is available for research purposes ref span style display none 2 span pairwise an extension of rankboost to learn with partially labeled data semi supervised learning to rank 2008 http phd dii unisi it posterday 2009 tiziano papini pdf sortnet ref leonardo rigutini tiziano papini marco maggini franco scarselli http research microsoft com en us um beijing events lr4ir 2008 proceedings lr4ir 202008 pdf sortnet learning to rank by a neural based sorting algorithm sigir 2008 workshop learning to rank for information retrieval 2008 ref span style display none 2 span pairwise sortnet an adaptive ranking algorithm which orders objects using a neural network as a comparator 2009 http itcs tsinghua edu cn papers 2009 2009031 pdf mpboost span style display none 2 span pairwise magnitude preserving variant of rankboost the idea is that the more unequal are labels of a pair of documents the harder should the algorithm try to rank them 2009 http www machinelearning org archive icml2009 papers 498 pdf boltzrank span style display none 3 span listwise unlike earlier methods boltzrank produces a ranking model that looks during query time not just at a single document but also at pairs of documents 2009 http www iis sinica edu tw papers whm 8820 f pdf bayesrank span style display none 3 span listwise a method combines plackett luce model and neural network to minimize the expected bayes risk related to ndcg from the decision making aspect 2010 https people cs pitt edu valizadegan publications ndcg boost pdf ndcg boost ref hamed valizadegan rong jin ruofei zhang jianchang mao http www cs pitt edu valizadegan publications ndcg boost pdf learning to rank by optimizing ndcg measure in proceeding of neural information processing systems nips 2010 ref span style display none 3 span listwise a boosting approach to optimize ndcg 2010 http arxiv org abs 1001 4597 gblend span style display none 2 span pairwise extends gbrank to the learning to blend problem of jointly solving multiple learning to rank problems with some shared features 2010 http wume cse lehigh edu ovd209 wsdm proceedings docs p151 pdf intervalrank span style display none 2 span pairwise listwise 2010 http www eecs tufts edu dsculley papers combined ranking and regression pdf crr span style display none 2 span pointwise pairwise combined regression and ranking uses stochastic gradient descent to optimize a linear combination of a pointwise quadratic loss and a pairwise hinge loss from ranking svm note as most supervised learning algorithms can be applied to pointwise case only those methods which are specifically designed with ranking in mind are shown above history norbert fuhr introduced the general idea of mlr in 1992 describing learning approaches in information retrieval as a generalization of parameter estimation ref name fuhr1992 citation last fuhr first norbert journal computer journal title probabilistic models in information retrieval volume 35 number 3 pages 243 255 year 1992 doi 10 1093 comjnl 35 3 243 ref a specific variant of this approach using polynomial regression had been published by him three years earlier ref name fuhr1989 bill cooper proposed logistic regression for the same purpose in 1992 ref name cooperetal1992 and used it with his university of california at berkeley berkeley research group to train a successful ranking function for text retrieval conference trec manning et al ref citation author1 manning c author2 raghavan p author3 sch\xc3\xbctze h title introduction to information retrieval publisher cambridge university press year 2008 sections http nlp stanford edu ir book html htmledition references and further reading 7 html 7 4 and http nlp stanford edu ir book html htmledition references and further reading 15 html 15 5 ref suggest that these early works achieved limited results in their time due to little available training data and poor machine learning techniques several conferences such as neural information processing systems nips special interest group on information retrieval sigir and international conference on machine learning icml had workshops devoted to the learning to rank problem since mid 2000s decade practical usage by search engines commercial web search engine s began using machine learned ranking systems since the 2000s decade one of the first search engines to start using it was altavista later its technology was acquired by overture services inc overture and then yahoo which launched a gradient boosting trained ranking function in april 2003 ref jan o pedersen http jopedersen com presentations the mlr story pdf the mlr story ref ref us patent 7197497 ref bing search engine bing s search is said to be powered by ranknet algorithm ref http www bing com community blogs search archive 2009 06 01 user needs features and the science behind bing aspx pageindex 4 bing search blog user needs features and the science behind bing ref when date february 2014 which was invented at microsoft research in 2005 in november 2009 a russian search engine yandex announced ref name snezhinsk http webmaster ya ru replies xml item no 5707 ncrnd 5118 yandex corporate blog entry about new ranking model snezhinsk in russian ref that it had significantly increased its search quality due to deployment of a new proprietary matrixnet algorithm a variant of gradient boosting method which uses oblivious decision tree s ref the algorithm wasn t disclosed but a few details were made public in http download yandex ru company experience gdd zadnie algoritmy karpovich pdf and http download yandex ru company experience searchconf searchconf algoritm matrixnet gulin pdf ref recently they have also sponsored a machine learned ranking competition internet mathematics 2009 ref http imat2009 yandex ru academic mathematic 2009 en yandex s internet mathematics 2009 competition page ref based on their own search engine s production data yahoo has announced a similar competition in 2010 ref http learningtorankchallenge yahoo com yahoo learning to rank challenge ref as of 2008 google s peter norvig denied that their search engine exclusively relies on machine learned ranking ref cite web url http anand typepad com datawocky 2008 05 are human experts less prone to catastrophic errors than machine learned models html archiveurl http www webcitation org 5sq8irwnm archivedate 2010 09 18 title are machine learned models prone to catastrophic errors date 2008 05 24 last rajaraman first anand authorlink anand rajaraman ref cuil s ceo tom costello businessman tom costello suggests that they prefer hand built models because they can outperform machine learned models when measured against metrics like click through rate or time on landing page which is because machine learned models learn what people say they like not what people actually like ref cite web url http www cuil com info blog 2009 06 26 so how is bing doing archiveurl http www webcitation org 5sq7dx3pj archivedate 2010 09 15 title cuil blog so how is bing doing date 2009 06 26 last costello first tom ref references reflist 2 external links competitions and public datasets http research microsoft com en us um people letor letor a benchmark collection for research on learning to rank for information retrieval http imat2009 yandex ru en yandex s internet mathematics 2009 http learningtorankchallenge yahoo com yahoo learning to rank challenge http research microsoft com en us projects mslr default aspx microsoft learning to rank datasets open source code https mloss org software view 332 parallel c mpi implementation of gradient boosted regression trees for ranking released september 2011 https sites google com site rtranking c implementation of gradient boosted regression trees and random forests for ranking http dlib net ml html svm rank trainer c and python tools for using the svm rank algorithm category information retrieval techniques category machine learning category ranking functions'
b'in research communities for example earth science s astronomy business and government subsetting is the process of retrieving just the parts of large files which are of interest for a specific purpose this occurs usually in a client server setting where the extraction of the parts of interest occurs on the server before the data is sent to the client over a network the main purpose of subsetting is to save bandwidth on the network and storage space on the client computer subsetting may be favorable for the following reasons ref name institute2012 cite book author sas institute title sas ets 12 1 user s guide url https books google com books id oe0ufahit4kc pg pa70 date 1 august 2012 publisher sas institute isbn 978 1 61290 379 8 pages 70 ref restrict or divide the time range select cross sectional data cross section s of data select particular kinds of time series exclude particular observations references reflist external links http www subset org index jsp subset org category information retrieval techniques statistics stub'
b'linguistics statistical semantics is the study of how the statistical patterns of human word usage can be used to figure out what people mean at least to a level sufficient for information access citation needed date july 2012 george furnas furnas 2006 this page has been moved and the new version no longer contains this quotation how can we figure out what words mean simply by looking at patterns of words in huge collections of text what are the limits to this approach to understanding words history the term statistical semantics was first used by warren weaver in his well known paper on machine translation ref harvnb weaver 1955 ref he argued that word sense disambiguation for machine translation should be based on the co occurrence frequency of the context words near a given target word the underlying assumption that a word is characterized by the company it keeps was advocated by j r firth j r firth ref harvnb firth 1957 ref this assumption is known in linguistics as the distributional hypothesis ref harvnb sahlgren 2008 ref emile delavenay defined statistical semantics as the statistical study of meanings of words and their frequency and order of recurrence ref harvnb delavenay 1960 ref george furnas furnas et al 1983 is frequently cited as a foundational contribution to statistical semantics ref harvnb furnas landauer gomez dumais 1983 ref an early success in the field was latent semantic analysis applications research in statistical semantics has resulted in a wide variety of algorithms that use the distributional hypothesis to discover many aspects of semantics by applying statistical techniques to text corpus large corpora measuring the semantic similarity similarity in word meanings ref harvnb lund burgess atchley 1995 ref ref harvnb landauer dumais 1997 ref ref harvnb mcdonald ramscar 2001 ref ref harvnb terra clarke 2003 ref measuring the similarity in word relations ref harvnb turney 2006 ref modeling similarity based generalization ref harvnb yarlett 2008 ref discovering words with a given relation ref harvnb hearst 1992 ref classifying relations between words ref harvnb turney littman 2005 ref extracting keywords from documents ref harvnb frank paynter witten gutwin 1999 ref ref harvnb turney 2000 ref measuring the cohesiveness of text ref harvnb turney 2003 ref discovering the different senses of words ref harvnb pantel lin 2002 ref distinguishing the different senses of words ref harvnb turney 2004 ref subcognitive aspects of words ref harvnb turney 2001 ref distinguishing praise from criticism ref harvnb turney littman 2003 ref related fields statistical semantics focuses on the meanings of common words and the relations between common words unlike text mining which tends to focus on whole documents document collections or named entities names of people places and organizations statistical semantics is a subfield of computational semantics which is in turn a subfield of computational linguistics and natural language processing many of the applications of statistical semantics listed above can also be addressed by lexicon based algorithms instead of the text corpus corpus based algorithms of statistical semantics one advantage of corpus based algorithms is that they are typically not as labour intensive as lexicon based algorithms another advantage is that they are usually easier to adapt to new languages than lexicon based algorithms however the best performance on an application is often achieved by combining the two approaches ref harvnb turney littman bigham shnayder 2003 ref see also portal linguistics div col 3 co occurrence computational linguistics information retrieval latent semantic analysis latent semantic indexing natural language processing semantic analytics semantic similarity text corpus text mining web mining div col end references reflist 2 sources refbegin cite book last delavenay first emile year 1960 title an introduction to machine translation location new york ny publisher thames and hudson oclc 1001646 ref harv cite journal last firth first john r authorlink john rupert firth year 1957 title a synopsis of linguistic theory 1930 1955 journal studies in linguistic analysis pages 1 32 location oxford publisher philological society ref harv reprinted in cite book editor1 first f r editor1 last palmer title selected papers of j r firth 1952 1959 location london publisher longman year 1968 oclc 123573912 cite conference last1 frank first1 eibe last2 paynter first2 gordon w last3 witten first3 ian h last4 gutwin first4 carl last5 nevill manning first5 craig g year 1999 title domain specific keyphrase extraction booktitle proceedings of the sixteenth international joint conference on artificial intelligence conference international joint conference on artificial intelligence ijcai 99 volume 2 pages 668 673 location california publisher morgan kaufmann isbn 1 55860 613 0 citeseerx 10 1 1 148 3598 ref harv cite journal last1 furnas first1 george w authorlink george furnas last2 landauer first2 t k last3 gomez first3 l m last4 dumais first4 s t year 1983 title statistical semantics analysis of the potential performance of keyword information systems url https web archive org web http furnas people si umich edu papers furnasetal1983 bstj p1753 pdf journal bell system technical journal volume 62 issue 6 pages 1753 1806 ref harv doi 10 1002 j 1538 7305 1983 tb03513 x cite conference last hearst first marti a year 1992 title automatic acquisition of hyponyms from large text corpora booktitle proceedings of the fourteenth international conference on computational linguistics conference coling coling 92 pages 539 545 location nantes france url http acl ldc upenn edu c c92 c92 2082 pdf doi 10 3115 992133 992154 citeseerx 10 1 1 36 701 ref harv cite journal last1 landauer first1 thomas k last2 dumais first2 susan t year 1997 title a solution to plato s problem the latent semantic analysis theory of the acquisition induction and representation of knowledge journal psychological review volume 104 issue 2 pages 211 240 url http lsa colorado edu papers plato plato annote html citeseerx 10 1 1 184 4759 ref harv doi 10 1037 0033 295x 104 2 211 cite conference last1 lund first1 kevin last2 burgess first2 curt last3 atchley first3 ruth ann year 1995 title semantic and associative priming in high dimensional semantic space booktitle proceedings of the 17th annual conference of the cognitive science society publisher cognitive science society pages 660 665 url http locutus ucr edu reprintpdfs lba95csp pdf ref harv cite conference last1 mcdonald first1 scott last2 ramscar first2 michael year 2001 title testing the distributional hypothesis the influence of context on judgements of semantic similarity booktitle proceedings of the 23rd annual conference of the cognitive science society pages 611 616 url http homepages inf ed ac uk smcdonal cogsci2001 pdf citeseerx 10 1 1 104 7535 ref harv cite conference last1 pantel first1 patrick last2 lin first2 dekang year 2002 title discovering word senses from text booktitle proceedings of acm sigkdd conference on knowledge discovery and data mining isbn 1 58113 567 x conference kdd conference kdd 02 pages 613 619 citeseerx 10 1 1 12 6771 doi 10 1145 775047 775138 ref harv cite journal last1 sahlgren first1 magnus year 2008 title the distributional hypothesis url http soda swedish ict se 3941 1 sahlgren distr hypo pdf journal rivista di linguistica volume 20 issue 1 pages 33 53 ref harv cite conference last1 terra first1 egidio l last2 clarke first2 charles l a year 2003 title frequency estimates for statistical word similarity measures booktitle proceedings of the human language technology and north american chapter of association of computational linguistics conference 2003 conference hlt naacl 2003 pages 244 251 url http acl ldc upenn edu n n03 n03 1032 pdf citeseerx 10 1 1 12 9041 doi 10 3115 1073445 1073477 ref harv cite journal last turney first peter d date may 2000 title learning algorithms for keyphrase extraction journal information retrieval journal information retrieval volume 2 issue 4 pages 303 336 arxiv cs 0212020 citeseerx 10 1 1 11 1829 doi 10 1023 a 1009976227802 ref harv cite journal last turney first peter d year 2001 title answering subcognitive turing test questions a reply to french journal journal of experimental and theoretical artificial intelligence volume 13 issue 4 pages 409 419 arxiv cs 0212015 citeseerx 10 1 1 12 8734 ref harv doi 10 1080 09528130110100270 cite conference last turney first peter d year 2003 title coherent keyphrase extraction via web mining booktitle proceedings of the eighteenth international joint conference on artificial intelligence conference ijcai 03 location acapulco mexico pages 434 439 arxiv cs 0308033 citeseerx 10 1 1 100 3751 ref harv cite conference last turney first peter d year 2004 title word sense disambiguation by web mining for word co occurrence probabilities booktitle proceedings of the third international workshop on the evaluation of systems for the semantic analysis of text conference senseval 3 location barcelona spain pages 239 242 arxiv cs 0407065 url http cogprints org 3732 ref harv cite journal last turney first peter d year 2006 title similarity of semantic relations journal computational linguistics journal computational linguistics volume 32 issue 3 pages 379 416 arxiv cs 0608100 url http cogprints org 5098 doi 10 1162 coli 2006 32 3 379 citeseerx 10 1 1 75 8007 ref harv cite journal last1 turney first1 peter d last2 littman first2 michael l date october 2003 title measuring praise and criticism inference of semantic orientation from association journal acm transactions on information systems volume 21 issue 4 pages 315 346 arxiv cs 0309034 url http cogprints org 3164 citeseerx 10 1 1 9 6425 doi 10 1145 944012 944013 ref harv cite journal last1 turney first1 peter d last2 littman first2 michael l year 2005 title corpus based learning of analogies and semantic relations journal machine learning journal machine learning volume 60 issue 1 3 pages 251 278 arxiv cs 0508103 citeseerx 10 1 1 90 9819 doi 10 1007 s10994 005 0913 1 url http cogprints org 4518 ref harv cite conference last1 turney first1 peter d last2 littman first2 michael l last3 bigham first3 jeffrey last4 shnayder first4 victor year 2003 title combining independent modules to solve multiple choice synonym and analogy problems booktitle proceedings of the international conference on recent advances in natural language processing conference ranlp 03 location borovets bulgaria pages 482 489 arxiv cs 0309035 citeseerx 10 1 1 5 2939 url http cogprints org 3163 ref harv cite book last weaver first warren authorlink warren weaver year 1955 chapter translation chapter url http www mt archive info weaver 1949 pdf editor1 first w n editor1 last locke editor2 first d a editor2 last booth title machine translation of languages location cambridge massachusetts publisher mit press isbn 0 8371 8434 7 pages 15 23 ref harv cite thesis last yarlett first daniel g year 2008 title language learning through similarity based generalization url http psych stanford edu michael papers draft yarlett similarity pdf degree phd publisher stanford university ref harv refend defaultsort statistical semantics category artificial intelligence applications category computational linguistics category information retrieval techniques category semantics category statistical natural language processing category applied statistics'
b'no footnotes date march 2013 file semanticnetexample jpg thumb simplistic example of the sort of semantic net used in semantic web technology in software semantic technology encodes meanings separately from data and content files and separately from application code this enables machines as well as people to understand share and reason with them at execution time with semantic technologies adding changing and implementing new relationships or interconnecting programs in a different way can be just as simple as changing the external model that these programs share with traditional information technology on the other hand meanings and relationships must be predefined and hard wired into data formats and the application program code at design time this means that when something changes previously unexchanged information needs to be exchanged or two programs need to interoperate in a new way the humans must get involved off line the parties must define and communicate between them the knowledge needed to make the change and then recode the data structures and program logic to accommodate it and then apply these changes to the database and the application then and only then can they implement the changes semantic technologies are meaning centered they include tools for autorecognition of topics and concepts information and meaning extraction and categorization given a question semantic technologies can directly search topics concepts associations that span a vast number of sources semantic technologies provide an abstraction layer above existing it technologies that enables bridging and interconnection of data content and processes second from the portal perspective semantic technologies can be thought of as a new level of depth that provides far more intelligent capable relevant and responsive interaction than with information technologies alone see also business intelligence 2 0 bi 2 0 metadata ontology computer science semantic web references j t pollock r hodgson adaptive information improving business through semantic interoperability grid computing and enterprise integration j wiley and sons october 2004 r guha r mccool and e miller semantic search in www2003 proc of the 12th international conference on world wide web pp 700 709 acm press 2003 i polikoff and d allemang https lists oasis open org archives regrep semantic 200402 pdf00000 pdf semantic technology topquadrant technology briefing v1 1 september 2003 tim berners lee t berners lee j hendler and o lassila the semantic web a new form of web content that is meaningful to computers will unleash a revolution of new possibilities scientific american may 2001 a p sheth c ramakrishnan http corescholar libraries wright edu knoesis 970technology 20in 20action 20ontology 20driven 20information 20systems 20for 20search 20integration 20and 20analysis semantic web technology in action ontology driven information systems for search integration and analysis ieee data engineering bulletin 2003 steffen staab rudi studer ed handbook on ontologies springer mills davis the business value of semantic technologies presentation and report semantic technologies for e government september 2004 p hitzler m kr\xc3\xb6tzsch s rudolph foundations of semantic web technologies chapman hall crc 2009 isbn 978 1 4200 9050 5 external links http semtech2010 semanticuniverse com semantic technology conference category information retrieval techniques category semantics'
b'in natural language processing semantic compression is a process of compacting a lexicon used to build a textual document or a set of documents by reducing language heterogeneity while maintaining text semantics as a result the same ideas can be represented using a smaller set of words semantic compression is a lossy compression that is some data is being discarded and an original document cannot be reconstructed in a reverse process semantic compression by generalization semantic compression is basically achieved in two steps using frequency list frequency dictionaries and semantic network determining cumulated term frequencies to identify target lexicon replacing less frequent terms with their hypernyms generalization from target lexicon ref http dx doi org 10 1007 978 3 642 12090 9 10 d ceglarek k haniewicz w rutkowski semantic compression for specialised information retrieval systems advances in intelligent information and database systems vol 283 p 111 121 2010 ref step 1 requires assembling word frequencies and information on semantic relationships specifically hyponymy moving upwards in word hierarchy a cumulative concept frequency is calculating by adding a sum of hyponyms frequencies to frequency of their hypernym math cum f k i f k i sum j cum f k j math where math k i math is a hypernym of math k j math then a desired number of words with top cumulated frequencies are chosen to build a targed lexicon in the second step compression mapping rules are defined for the remaining words in order to handle every occurrence of a less frequent hyponym as its hypernym in output text example the below fragment of text has been processed by the semantic compression words in bold have been replaced by their hypernyms blockquote they are both nest building social insects but paper wasps and honey bees organize their colonies in very different ways in a new study researchers report that despite their differences these insects rely on the same network of genes to guide their social behavior the study appears in the proceedings of the royal society b biological sciences honey bees and paper wasps are separated by more than 100 million years of evolution and there are striking differences in how they divvy up the work of maintaining a colony blockquote the procedure outputs the following text blockquote they are both facility building insect but insect s and honey insects arrange their biological groups in very different structure in a new study researchers report that despite their difference of opinions these insects act the same network of genes to steer their party demeanor the study appears in the proceeding of the institution bacteria biological sciences honey insects and insect are separated by more than hundred million years of organic processes and there are impinging differences of opinions in how they divvy up the work of affirming a biological group blockquote implicit semantic compression a natural tendency to keep natural language expressions concise can be perceived as a form of implicit semantic compression by omitting unmeaningful words or redundant meaningful words especially to avoid pleonasm s ref http dx doi org 10 3115 990100 990155 n n percova on the types of semantic compression of text coling 82 proceedings of the 9th conference on computational linguistics vol 2 p 229 231 1982 ref applications and advantages in the vector space model compacting a lexicon leads to a reduction of curse of dimensionality dimensionality which results in less computational complexity theory computational complexity and a positive influence on efficiency semantic compression is advantageous in information retrieval tasks improving their effectiveness in terms of both precision and recall ref http dl acm org citation cfm id 1947662 1947683 d ceglarek k haniewicz w rutkowski quality of semantic compression in classification proceedings of the 2nd international conference on computational collective intelligence technologies and applications vol 1 p 162 171 2010 ref this is due to more precise descriptors reduced effect of language diversity limited language redundancy a step towards a controlled dictionary as in the example above it is possible to display the output as natural text re applying inflexion adding stop words see also text simplification lexical substitution information theory quantities of information references references external links http semantic net pl semantic compression php semantic compression on project seneca semantic networks and categorization website category information retrieval techniques category natural language processing category quantitative linguistics category computational linguistics'
b'literature based discovery refers to the use of papers and other academic publishing academic publications the literature to find new relationships between existing knowledge the discovery the technique was pioneered by don r swanson in the 1980s and has since seen widespread use literature based discovery does not generate new knowledge through laboratory experiments as is customary for empirical sciences instead it seeks to connect existing knowledge from empirical results by bringing to light relationships that are implicated and neglected ref cite journal last1 swanson first1 don year 1988 title migraine and magnesium eleven neglected connections url journal perspectives in biology and medicine volume 31 issue 4 pages 526 557 doi 10 1353 pbm 1988 0009 ref it is marked by empiricism and rationalism in concert or consilience swanson linking file swanson linking jpg thumb swanson linking example diagram swanson linking is a term proposed in 2003 ref stegmann j grohmann g hypothesis generation guided by co word clustering scientometrics 2003 56 111 135 as quoted by bekhuis ref that refers to connecting two pieces of knowledge previously thought to be unrelated ref cite journal last bekhuis first tanja title conceptual biology hypothesis discovery and text mining swanson s legacy publisher biomed central ltd year 2006 pmc 1459187 pmid 16584552 doi 10 1186 1742 5581 3 2 volume 3 journal biomed digit libr pages 2 ref for example it may be known that illness a is caused by chemical b and that drug c is known to reduce the amount of chemical b in the body however because the respective articles were published separately from one another called disjoint data the relationship between illness a and drug c may be unknown swanson linking aims to find these relationships and report them see also arrowsmith system implicature latent semantic indexing metaphor references chen ran hongfei lin zhihao yang 2011 passage retrieval based hidden knowledge discovery from biomedical literature expert systems with applications an international journal august 2011 vol 38 no 8 pp nbsp 9958 9964 abstract automatic extraction of the implicit biological relationship from biomedical literature contributes to building the biomedical hypothesis that can be explored further experimentally this paper presents a passage retrieval based method which can explore the hidden connection from medline records experimental results show this method can significantly improve the hidden knowledge discovery performance http portal acm org citation cfm id 1967763 1968003 coll dl dl guide cfid 23143258 cftoken 52033794 acm dl further readings patrick wilson librarian wilson patrick 1977 public knowledge private ignorance toward a library and information policy greenwood publishing group p nbsp 156 isbn 0 8371 9485 7 footnotes reflist category information retrieval techniques category medical research science stub'
b'multiple issues disputed date march 2014 more footnotes date march 2014 document clustering or text clustering is the application of cluster analysis to textual documents it has applications in automatic document organization topic linguistics topic extraction and fast information retrieval or filtering overview document clustering involves the use of descriptors and descriptor extraction descriptors are sets of words that describe the contents within the cluster document clustering is generally considered to be a centralized process examples of document clustering include web document clustering for search users the application of document clustering can be categorized to two types online and offline online applications are usually constrained by efficiency problems when compared to offline applications in general there are two common algorithms the first one is the hierarchical based algorithm which includes single link complete linkage group average and ward s method by aggregating or dividing documents can be clustered into hierarchical structure which is suitable for browsing however such an algorithm usually suffers from efficiency problems the other algorithm is developed using the k means algorithm and its variants generally hierarchical algorithms produce more in depth information for detailed analyses while algorithms based around variants of the k means algorithm are more efficient and provide sufficient information for most purposes ref name manning manning chris and hinrich sch\xc3\xbctze foundations of statistical natural language processing mit press cambridge ma may 1999 ref rp ch 14 these algorithms can further be classified as hard or soft clustering algorithms hard clustering computes a hard assignment each document is a member of exactly one cluster the assignment of soft clustering algorithms is soft a document s assignment is a distribution over all clusters in a soft assignment a document has fractional membership in several clusters ref name manning rp 499 dimensionality reduction methods can be considered a subtype of soft clustering for documents these include latent semantic indexing truncated singular value decomposition on term histograms ref http nlp stanford edu ir book pdf 16flat pdf ref and topic model s other algorithms involve graph based clustering ontology supported clustering and order sensitive clustering given a clustering it can be beneficial to automatically derive human readable labels for the clusters cluster labeling various methods exist for this purpose clustering in search engines a web search engine often returns thousands of pages in response to a broad query making it difficult for users to browse or to identify relevant information clustering methods can be used to automatically group the retrieved documents into a list of meaningful categories as is achieved by e g open source software such as carrot2 procedures in practice document clustering often takes the following steps 1 tokenization lexical analysis tokenization tokenization is the process of parsing text data into smaller units tokens such as words and phrases commonly used tokenization methods include bag of words model and n gram model 2 stemming and lemmatization different tokens might carry out similar information e g tokenization and tokenizing and we can avoid calculating similar information repeatedly by reducing all tokens to its base form using various stemming and lemmatization dictionaries 3 removing stop words and punctuation some tokens are less important than others for instance common words such as the might not be very helpful for revealing the essential characteristics of a text so usually it is a good idea to eliminate stop words and punctuation marks before doing further analysis 4 computing term frequencies or tf idf after pre processing the text data we can then proceed to generate features for document clustering one of the most common ways to generate features for a document is to calculate the term frequencies of all its tokens although not perfect these frequencies can usually provide some clues about the topic of the document and sometimes it is also useful to weight the term frequencies by the inverse document frequencies see tf idf for detailed discussions 5 clustering we can then cluster different documents based on the features we have generated see the algorithm section in cluster analysis for different types of clustering methods 6 evaluation and visualization finally the clustering models can be assessed by various metrics and it is sometimes helpful to visualize the results by plotting the clusters into low two dimensional space see multidimensional scaling as a possible approach clustering v classifying clustering algorithms in computational text analysis groups documents into what are called subsets or clusters where the algorithm s goal is to create internally coherent clusters that are distinct from one another ref cite web url http nlp stanford edu ir book title introduction to information retrieval website nlp stanford edu pages 349 access date 2016 05 03 ref classification on the other hand is a form of supervised learning where the features of the documents are used to predict the type of documents references reflist publications christopher d manning prabhakar raghavan and hinrich sch\xc3\xbctze flat clustering in u introduction to information retrieval u cambridge university press 2008 nicholas o andrews and edward a fox recent developments in document clustering october 16 2007 http eprints cs vt edu archive 00001000 01 docclust pdf claudio carpineto stanislaw osi\xc5\x84ski giovanni romano dawid weiss a survey of web clustering engines acm computing surveys volume 41 issue 3 july 2009 article no 17 issn 0360 0300 see also cluster analysis fuzzy clustering category information retrieval techniques'
b'context date june 2012 the binary independence model bim ref name cyu76 ref name jones77 is a probabilistic information retrieval technique that makes some simple assumptions to make the estimation of document query similarity probability feasible definitions the binary independence assumption is that documents are bit array binary vector s that is only the presence or absence of terms in documents are recorded terms are independence probability theory independently distributed in the set of relevant documents and they are also independently distributed in the set of irrelevant documents the representation is an ordered set of boolean data type boolean variables that is the representation of a document or query is a vector with one boolean element for each term under consideration more specifically a document is represented by a vector d x sub 1 sub x sub m sub where x sub t sub 1 if term t is present in the document d and x sub t sub 0 if it s not many documents can have the same vector representation with this simplification queries are represented in a similar way independence signifies that terms in the document are considered independently from each other and no association between terms is modeled this assumption is very limiting but it has been shown that it gives good enough results for many situations this independence is the naive assumption of a naive bayes classifier where properties that imply each other are nonetheless treated as independent for the sake of simplicity this assumption allows the representation to be treated as an instance of a vector space model by considering each term as a value of 0 or 1 along a dimension orthogonal to the dimensions used for the other terms the probability p r d q that a document is relevant derives from the probability of relevance of the terms vector of that document p r x q by using the bayes rule we get math p r x q frac p x r q p r q p x q math where p x r 1 q and p x r 0 q are the probabilities of retrieving a relevant or nonrelevant document respectively if so then that document s representation is x the exact probabilities can not be known beforehand so use estimates from statistics about the collection of documents must be used p r 1 q and p r 0 q indicate the previous probability of retrieving a relevant or nonrelevant document respectively for a query q if for instance we knew the percentage of relevant documents in the collection then we could use it to estimate these probabilities since a document is either relevant or nonrelevant to a query we have that math p r 1 x q p r 0 x q 1 math query terms weighting given a binary query and the dot product as the similarity function between a document and a query the problem is to assign weights to the terms in the query such that the retrieval effectiveness will be high let math p i math and math q i math be the probability that a relevant document and an irrelevant document has the math i th math term respectively yu and gerard salton salton ref name cyu76 who first introduce bim propose that the weight of the math i th math term is an increasing function of math y i frac p i 1 q i 1 p i q i math thus if math y i math is higher than math y j math the weight of term math i math will be higher than that of term math j math yu and salton ref name cyu76 showed that such a weight assignment to query terms yields better retrieval effectiveness than if query terms are equally weighted stephen robertson computer scientist robertson and karen sp\xc3\xa4rck jones sp\xc3\xa4rck jones ref name jones77 later showed that if the math i th math term is assigned the weight of math log y i math then optimal retrieval effectiveness is obtained under the binary independence assumption the binary independence model was introduced by yu and salton ref name cyu76 the name binary independence model was coined by robertson and sp\xc3\xa4rck jones ref name jones77 see also bag of words model further reading citation url http nlp stanford edu ir book html htmledition irbook html title introduction to information retrieval author christopher d manning author2 prabhakar raghavan author3 hinrich sch\xc3\xbctze publisher cambridge university press year 2008 citation url http www ir uwaterloo ca book title information retrieval implementing and evaluating search engines author stefan b uuml ttcher author2 charles l a clarke author3 gordon v cormack publisher mit press year 2010 references reflist refs ref name cyu76 cite journal doi 10 1145 321921 321930 title precision weighting an effective automatic indexing method journal journal of the acm volume 23 pages 76 year 1976 last1 yu first1 c t last2 salton first2 g authorlink2 gerard salton ref ref name jones77 cite journal doi 10 1002 asi 4630270302 title relevance weighting of search terms journal journal of the american society for information science volume 27 issue 3 pages 129 year 1976 last1 robertson first1 s e authorlink1 stephen robertson computer scientist last2 sp\xc3\xa4rck jones first2 k authorlink2 karen sp\xc3\xa4rck jones ref category information retrieval techniques category probabilistic models'
b'an index term subject term subject heading or descriptor in information retrieval is a term that captures the essence of the topic of a document index terms make up a controlled vocabulary for use in bibliographic record s they are an integral part of bibliographic control which is the function by which libraries collect organize and disseminate documents they are used as keywords to retrieve documents in an information system for instance a catalog or a search engine a popular form of keywords on the web are tag metadata tags which are directly visible and can be assigned by non experts index terms can consist of a word phrase or alphanumerical term they are created by analyzing the document either manually with subject indexing or automatically with index search engine automatic indexing or more sophisticated methods of keyword extraction index terms can either come from a controlled vocabulary or be freely assigned keywords are stored in a index search engine search index common words like article grammar articles a an the and conjunctions and or but are not treated as keywords because it s inefficient almost every english language site on the internet has the article the and so it makes no sense to search for it the most popular search engine google removed stop words such as the and a from its indexes for several years but then re introduced them making certain types of precise search possible again the term descriptor was coined by calvin mooers in 1948 it is in particular used about a preferred term from a thesaurus information retrieval thesaurus the simple knowledge organization system language skos provides a way to express index terms with resource description framework for use in the context of semantic web ref name auto cite book last svenonius first elaine author link elaine svenonius title the intellectual foundation of information organization date 2009 publisher mit press location cambridge mass isbn 9780262512619 edition 1st mit press pbk ref in web search engines most web search engine s are designed to search for words anywhere in a document the title the body and so on this being the case a keyword can be any term that exists within the document however priority is given to words that occur in the title words that recur numerous times and words that are explicitly assigned as keywords within the coding ref cutts matt 2010 march 4 how search works retrieved from https www youtube com watch v bnhr6iqjgzs ref index terms can be further refined using boolean algebra boolean operators such as and or not and is normally unnecessary as most search engines infer it or will search for results with one search term or another or both not eliminates a word or phrase from the search getting rid of any results that include it multiple words can also be enclosed in quotation marks to turn the individual index terms into a specific index phrase these modifiers and methods all help to refine search terms to better maximize the accuracy of search results ref clio keyword search columbia university libraries retrieved from http www columbia edu cu lweb help clio keyword html ref author keywords many journals and databases provides access also to index terms made by authors to the articles being published or represented the relative quality of indexer provided index terms and author provided index terms is of interest to research in information retrieval the quality of both kinds of indexing terms depends of course on the qualifications of provider in general authors have difficulties providing indexing terms that characterizes his document relative to the other documents in the database author keywords are an integral part of literature ref name auto examples canadian subject headings csh library of congress subject headings lcsh medical subject headings mesh polythematic structured subject heading system psh subject headings authority file swd see also dynamic keyword insertion tag cloud keyword density search engine optimization tag metadata subject documents references reflist authority control category information retrieval techniques'
b'orphan date may 2015 contextual search is a form of optimizing web based search results based on context provided by the user and the computer being used to enter the query ref cite journal first susan e last feldman title the answer machine journal synthesis lectures on information concepts retrieval and services doi 10 2200 s00442ed1v01y201208icr023 ref contextual search services differ from current search engines based on traditional information retrieval that return lists of documents based on their relevance information retrieval relevance to the query rather contextual search attempts to increase the precision and recall precision of results based on how valuable they are to individual users ref cite journal last1 pitokow first1 james first2 hinrich last2 sch\xc3\xbctze first3 todd last3 cass first4 rob last4 cooley first5 don last5 turnbull first6 andy last6 edmonds first7 eytan last7 adar first8 thomas last8 breuel date 2002 title personalized search url http www cond org p50 pitkow pdf journal communications of the acm cacm volume 45 issue 9 pages 50 55 ref basic contextual search the basic form of contextual search is the process of scanning the full text of a query in order to understand what the user needs web search engines scan html pages for content and return an index rating based on how relevant the content is to the entered query html pages that have a higher occurrence of query keywords within their content are not rated higher users have limited control over the context of their query based on the words they use to search with ref steve lawrence context in web search ieee data engineering bulletin volume 23 number 3 pp 25 2000 ref for example users looking for the menu portion of a website can add menu to the end of their query to provide the search engine with context of what they need the next step in contextualizing search is for the search service itself to request information that narrows down the results such as google asking for a time range to search within explicitly supplied context certain search services including many meta search engines request individual contextual information from users to increase the precision of returned documents inquirus 2 is a meta search engine that acts as a mediator between the user query and other search engines when searching on inquirus 2 users enter a query and specify constraints such as the information need category maximum number of hits and display formats ref steve lawrence context in web search ieee data engineering bulletin volume 23 number 3 pp 27 2000 ref for example a user looking for research papers can specify documents with references or abstracts to be rated higher if another user is searching for general information on the topic rather than research papers they can specify the genscore attribute to have a heavier weight ref steve lawrence c lee giles inquirus the neci meta search engine http www7 scu edu au 1906 com1906 htm ref explicitly supplied context effectively increases the precision of results however these search services tend to suffer from poor user experience learning the interface of programs like inquirus can prove challenging for general users without knowledge of search metrics aspects of supplied context do appear on major search engines with better user interaction such as google and bing google allows users to filter by type images maps shopping news videos books flights and apps ref https support google com websearch answer 142143 hl en https support google com websearch answer 142143 hl en filter your search results ref google has an extensive https support google com websearch answer 2466433 rd 1 list of search operators that allow users to explicitly limit results to fit their needs such as restricting certain file types or removing certain words ref https support google com websearch answer 2466433 rd 1 https support google com websearch answer 2466433 rd 1 search operators ref bing also uses a similar set of search operators to assist users in explicitly narrowing down the context of their queries bing allows users to search within a time range by file type by location language and more ref http www howtogeek com 106751 how to use bings advanced search operators 8 tips for better searches http www howtogeek com 106751 how to use bings advanced search operators 8 tips for better searches bing tricks ref automatically inferred context there are other systems being developed that are working on automatically inferring the context of user queries based on the content of other documents they view or edit watson computer ibm s watson project aims to create a cognitive technology that dynamically learns as it processes user queries when presented with a query watson creates a hypothesis that is evaluated against its present bank of knowledge based on previous questions as related terms and relevant documents are matched against the query watson s hypothesis is modified to reflect the new information provided through unstructured data based on information it has obtained in previous situations ref http www ibm com smarterplanet us en ibmwatson what is watson html http www ibm com smarterplanet us en ibmwatson what is watson html how watson works ibm ref watson s ability to build off previous knowledge allows queries to be automatically filtered for similar contexts in order to supply precise results major search services such as google bing and yahoo also have a system of automatically inferring the context of particular user queries google tracks user s previous queries and selected results to further personalize results for those individuals for example if a user consistently searches for articles related to animals wild animals or animal care a search for jaguar would rank an article on jaguar cats higher than links to jaguar cars ref cite journal first1 eric j last1 glover first2 steve last2 lawrence first3 michael d last3 gordon first4 william p last4 birmingham first5 c lee last5 giles title web search your way publisher nec research institution citeseerx 10 1 1 41 7499 ref similar to watson search services strive to learn from users based on previous experiences to automatically provide context on current queries bing also provides automatic context for particular queries based on content of the query itself a http www bing com search q pizza go submit qs n form geoma1 pq pizza sc 8 1 sp 1 sk cvid 883269b61529466e810bc096e371ec19 search of pizza returns an interactive list of restaurants and their ratings based on the approximate location of the user s computer the bing server automatically infers that when a user searches for a food item they are interested in documents within the context of purchasing that food item or finding restaurants that sell that particular item contextual mobile search the drive to develop better contextualized search coincides with the increasing popularity of using mobile phones to complete searches bia kelsey research marketing firm projects that by 2015 mobile local search will exceed local search by more than 27 billion queries ref http www biakelsey com company press releases 120418 mobile local search volume will surpass desktop local search in 2015 asp http www biakelsey com company press releases 120418 mobile local search volume will surpass desktop local search in 2015 asp mobile search to surpass desktop ref mobile phones provide the opportunity to provide search services with a broader supply of contextual information particularly for location services but also personalized searches based on the wealth of information stored locally on the phone including contacts information geometric analysis such as speed and elevation and installed apps ref http blog broadcom com ces beyond gps smartphones get smarter with context awareness at ces 2014 http blog broadcom com ces beyond gps smartphones get smarter with context awareness at ces 2014 contextually aware mobile devices ref references reflist internet search defaultsort contextual searching category internet search engines category semantic web category information retrieval techniques category internet terminology'
b'compound term processing refers to a category of techniques used in information retrieval applications to perform matching on the basis of compound term s compound terms are built by combining two or more simple terms for example triple is a single word term but triple heart bypass is a compound term compound term processing is a new approach to an old problem how can one improve the relevance of search results while maintaining ease of use using this technique a search for survival rates following a triple heart bypass in elderly people will locate documents about this topic even if this precise phrase is not contained in any document this can be performed by a concept search which itself uses compound term processing this will extract the key concepts automatically in this case survival rates triple heart bypass and elderly people and use these concepts to select the most relevant documents techniques in august 2003 concept searching limited introduced the idea of using statistical compound term processing ref cite journal url http www conceptsearching com web userfiles file concept 20searching 20lateral 20thinking pdf title lateral thinking in information retrieval journal information management and technology volume 36 part 4 the british library direct catalogue entry can be found here http direct bl uk bld placeorder do uin 138451913 etoc rn ref clamour is a european collaborative project which aims to find a better way to classify when collecting and disseminating industrial information and statistics clamour appears to use a linguistic approach rather than one based on statistical modelling ref http webarchive nationalarchives gov uk 20040117000117 statistics gov uk methods quality clamour default asp national statistics clamour project ref history techniques for probabilistic weighting of single word terms date back to at least 1976 in the landmark publication by stephen robertson computer scientist stephen e robertson and karen sp\xc3\xa4rck jones ref cite journal doi 10 1002 asi 4630270302 title relevance weighting of search terms journal journal of the american society for information science volume 27 issue 3 pages 129 year 1976 last1 robertson first1 s e authorlink1 stephen robertson computer scientist last2 sp\xc3\xa4rck jones first2 k authorlink2 karen sp\xc3\xa4rck jones ref robertson stated that the assumption of word independence is not justified and exists as a matter of mathematical convenience his objection to the term independence is not a new idea dating back to at least 1964 when h h williams stated that t he assumption of independence of words in a document is usually made as a matter of mathematical convenience ref cite journal last williams first j h title results of classifying documents with multiple discriminant functions url http oai dtic mil oai oai verb getrecord metadataprefix html identifier ad0612272 journal statistical association methods for mechanized documentation national bureau of standards location washington pp 217 224 year 1965 ref in 2004 anna lynn patterson filed patents on phrase based searching in an information retrieval system ref patent us 20060031195 ref to which google subsequently acquired the rights ref http www seobythesea com 2012 02 google acquires cuil patent applications google acquires cuil patent applications ref adaptability statistical compound term processing is more adaptable than the process described by patterson her process is targeted at searching the world wide web where an extensive statistical knowledge of common searches can be used to identify candidate phrases statistical compound term processing is more suited to enterprise search applications where such a priori and a posteriori a priori knowledge is not available statistical compound term processing is also more adaptable than the linguistic approach taken by the clamour project which must consider the syntactic properties of the terms i e part of speech gender number etc and their combinations clamour is highly language dependent whereas the statistical approach is language independent applications compound term processing allows information retrieval applications such as search engines to perform their matching on the basis of multi word concepts rather than on single words in isolation which can be highly ambiguous early search engines looked for documents containing the words entered by the user into the search box these are known as keyword search engines boolean search engines add a degree of sophistication by allowing the user to specify additional requirements for example tiger near woods and golf or golfing not volkswagen uses the operators near and or and not to specify that these words must follow certain requirements a phrase search is simpler to use but requires that the exact phrase specified appear in the results see also concept searching limited enterprise search information retrieval references reflist 30em external links natural language processing defaultsort compound term processing category information retrieval techniques'
b'fuzzy retrieval techniques are based on the extended boolean model and the fuzzy set theory there are two classical fuzzy retrieval models mixed min and max mmm and the paice model both models do not provide a way of evaluating query weights however this is considered by the extended boolean model p norms algorithm mixed min and max model mmm in fuzzy set theory an element has a varying degree of membership say d sub a sub to a given set a instead of the traditional membership choice is an element is not an element br in mmm ref citation last1 fox first1 e a author2 s sharat year 1986 title a comparison of two methods for soft boolean interpretation in information retrieval publisher technical report tr 86 1 virginia tech department of computer science ref each index term has a fuzzy set associated with it a document s weight with respect to an index term a is considered to be the degree of membership of the document in the fuzzy set associated with a the degree of membership for union and intersection are defined as follows in fuzzy set theory br math d a cap b min d a d b math math d a cup b max d a d b math according to this documents that should be retrieved for a query of the form a or b should be in the fuzzy set associated with the union of the two sets a and b similarly the documents that should be retrieved for a query of the form a and b should be in the fuzzy set associated with the intersection of the two sets hence it is possible to define the similarity of a document to the or query to be max d sub a sub d sub b sub and the similarity of the document to the and query to be min d sub a sub d sub b sub the mmm model tries to soften the boolean operators by considering the query document similarity to be a linear combination of the min and max document weights given a document d with index term weights d sub a1 sub d sub a2 sub d sub an sub for terms a sub 1 sub a sub 2 sub a sub n sub and the queries q sub or sub a sub 1 sub or a sub 2 sub or or a sub n sub br q sub and sub a sub 1 sub and a sub 2 sub and and a sub n sub the query document similarity in the mmm model is computed as follows slm q sub or sub d c sub or1 sub max d sub a1 sub d sub a2 sub d sub an sub c sub or2 sub min d sub a1 sub d sub a2 sub d sub an sub br slm q sub and sub d c sub and1 sub min d sub a1 sub d sub a2 sub d sub an sub c sub and2 sub max d sub a1 sub d sub a2 sub d sub an sub where c sub or1 sub c sub or2 sub are softness coefficients for the or operator and c sub and1 sub c sub and2 sub are softness coefficients for the and operator since we would like to give the maximum of the document weights more importance while considering an or query and the minimum more importance while considering an and query generally we have c sub or1 sub c sub or2 sub and c sub and1 sub c sub and2 sub for simplicity it is generally assumed that c sub or1 sub 1 c sub or2 sub and c sub and1 sub 1 c sub and2 sub lee and fox ref name leefox citation last1 lee first1 w c author2 e a fox year 1988 title experimental comparison of schemes for interpreting boolean queries ref experiments indicate that the best performance usually occurs with c sub and1 sub in the range 0 5 0 8 and with c sub or1 sub 0 2 in general the computational cost of mmm is low and retrieval effectiveness is much better than with the standard boolean model paice model the paice model ref citation last paice first c p year 1984 title soft evaluation of boolean search queries in information retrieval systems publisher information technology res dev applications 3 1 33 42 ref is a general extension to the mmm model in comparison to the mmm model that considers only the minimum and maximum weights for the index terms the paice model incorporates all of the term weights when calculating the similarity math s d q sum i 1 n frac r i 1 w di sum j 1 n r j 1 math where r is a constant coefficient and w sub di sub is arranged in ascending order for and queries and descending order for or queries when n 2 the paice model shows the same behavior as the mmm model the experiments of lee and fox ref name leefox have shown that setting the r to 1 0 for and queries and 0 7 for or queries gives good retrieval effectiveness the computational cost for this model is higher than that for the mmm model this is because the mmm model only requires the determination of min or max of a set of term weights each time an and or or clause is considered which can be done in o n the paice model requires the term weights to be sorted in ascending or descending order depending on whether an and clause or an or clause is being considered this requires at least an 0 n log n sorting algorithm a good deal of floating point calculation is needed too improvements over the standard boolean model lee and fox ref name leefox compared the standard boolean model with mmm and paice models with three test collections cisi cacm and inspec these are the reported results for average mean precision improvement class wikitable cisi cacm inspec mmm 68 109 195 paice 77 104 206 these are very good improvements over the standard model mmm is very close to paice and p norm results which indicates that it can be a very good technique and is the most efficient of the three recent work recently kang et al ref citation title fuzzy information retrieval indexed by concept identification url http www springerlink com content ac96v4qf4f8adatp last1 kang first1 bo yeong author2 dae won kim author3 hae jung kim publisher springer berlin heidelberg year 2005 ref have devised a fuzzy retrieval system indexed by concept identification if we look at documents on a pure tf idf approach even eliminating stop words there will be words more relevant to the topic of the document than others and they will have the same weight because they have the same term frequency if we take into account the user intent on a query we can better weight the terms of a document each term can be identified as a concept in a certain lexical chain that translates the importance of that concept for that document br they report improvements over paice and p norm on the average precision and recall for the top 5 retrieved documents zadrozny ref citation title fuzzy information retrieval model revisited doi 10 1016 j fss 2009 02 012 first1 s\xc5\x82awomir last1 zadrozny last2 nowacka first2 katarzyna year 2009 publisher elsevier north holland inc ref revisited the fuzzy information retrieval model he further extends the fuzzy extended boolean model by assuming linguistic terms as importance weights of keywords also in documents taking into account the uncertainty concerning the representation of documents and queries interpreting the linguistic terms in the representation of documents and queries as well as their matching in terms of the zadeh s fuzzy logic calculus of linguistic statements addressing some pragmatic aspects of the proposed model notably the techniques of indexing documents and queries the proposed model makes it possible to grasp both imprecision and uncertainty concerning the textual information representation and retrieval see also information retrieval further reading citation title information retrieval algorithms and data structures extended boolean model last1 fox first1 e author2 s betrabet author3 m koushik author4 w lee year 1992 publisher prentice hall inc url http www scribd com doc 13742235 information retrieval data structures algorithms william b frakes references reflist defaultsort fuzzy retrieval category information retrieval techniques'
b'faceted search also called faceted navigation or faceted browsing is a technique for accessing information organized according to a faceted classification system allowing users to explore a collection of information by applying multiple filters a faceted classification system classifies each information element along multiple explicit dimensions called facets enabling the classifications to be accessed and ordered in multiple ways rather than in a single pre determined taxonomy general taxonomic order ref name faceted search http www morganclaypool com doi abs 10 2200 s00190ed1v01y200904icr005 faceted search morgan claypool 2009 ref facets correspond to properties of the information elements they are often derived by analysis of the text of an item using entity extraction techniques or from pre existing fields in a database such as author descriptor language and format thus existing web pages product descriptions or online collections of articles can be augmented with navigational facets within the academic community faceted search has attracted interest primarily among library and information science researchers and to some extent among computer science researchers specializing in information retrieval ref name sigir06 http facetedsearch googlepages com sigir 2006 workshop on faceted search call for participation ref development the association for computing machinery s special interest group on information retrieval provided the following description of the role of faceted search for a 2006 workshop blockquote the web search world since its very beginning has offered two paradigms navigational search uses a hierarchy structure taxonomy to enable users to browse the information space by iteratively narrowing the scope of their quest in a predetermined order as exemplified by yahoo directory open directory project dmoz etc direct search allows users to simply write their queries as a bag of words in a text box this approach has been made enormously popular by web search engine s over the last few years the direct search paradigm has gained dominance and the navigational approach became less and less popular recently a new approach has emerged combining both paradigms namely the faceted search approach faceted search enables users to navigate a multi dimensional information space by combining text search with a progressive narrowing of choices in each dimension it has become the prevailing user interaction mechanism in e commerce sites and is being extended to deal with semi structured data continuous dimensions and folksonomy folksonomies ref name sigir06 http facetedsearch googlepages com sigir 2006 workshop on faceted search call for participation ref blockquote mass market use faceted search has become a popular technique in commercial search applications particularly for online retailers and libraries an increasing number of list of enterprise search vendors enterprise search vendors provide software for implementing faceted search applications online retail catalogs pioneered the earliest applications of faceted search reflecting both the faceted nature of product data most products have a type brand price etc and the ready availability of the data in retailers existing information systems in the early 2000s retailers started using faceted search a 2014 benchmark of 50 of the largest us based online retailers reveals that despite the benefits of faceted search only 40 of the sites have implemented it ref name smashing magazine the current state of e commerce search 2014 http www smashingmagazine com 2014 08 18 the current state of e commerce search smashing magazine the current state of e commerce search retrieved on 2014 08 27 ref examples include the filtering options that appear in the left column on amazon com or google shopping after a keyword search has been performed libraries and information science in 1933 the noted librarian s r ranganathan ranganathan proposed a faceted classification system for library materials known as colon classification in the pre computer era he did not succeed in replacing the pre coordinated dewey decimal classification system ref name major classification systems the dewey centennial https archive org details majorclassificat00alle major classification systems the dewey centennial ref modern online library catalogs also known as opac s have increasingly adopted faceted search interfaces noted examples include the north carolina state university library catalog part of the triangle research libraries network and the online computer library center oclc open worldcat system the citeseerx project ref http citeseerx ist psu edu citeseerx citeseerx ist psu edu retrieved on 2013 07 21 ref at the pennsylvania state university allows faceted search for academic documents and continues to expand into other facets such as table search see also enterprise search exploratory search faceted classification human computer information retrieval information extraction nosql references references defaultsort faceted search category information retrieval techniques'
b'natural language user interfaces lui or nlui are a type of user interface computer human interface where linguistic phenomena such as verbs phrases and clauses act as ui controls for creating selecting and modifying data in software applications in interface design natural language interfaces are sought after for their speed and ease of use but most suffer the challenges to natural language understanding understanding wide varieties of ambiguous input ref hill i 1983 natural language versus computer language in m sime and m coombs eds designing for human computer communication academic press ref natural language interfaces are an active area of study in the field of natural language processing and computational linguistics an intuitive general natural language interface is one of the active goals of the semantic web text interfaces are natural to varying degrees many formal un natural programming languages incorporate idioms of natural human language likewise a traditional keyword search engine could be described as a shallow natural language user interface overview a natural language search engine would in theory find targeted answers to user questions as opposed to keyword search for example when confronted with a question of the form which united states u s state has the highest income tax conventional search engines ignore the question and instead search on the index term keywords state income and tax natural language search on the other hand attempts to use natural language processing to understand the nature of the question and then to search and return a subset of the web that contains the answer to the question if it works results would have a higher relevance than results from a keyword search engine citation needed date october 2015 history prototype nl interfaces had already appeared in the late sixties and early seventies ref name edin natural language interfaces to databases an introduction i androutsopoulos g d ritchie p thanisch department of artificial intelligence university of edinburgh ref shrdlu a natural language interface that manipulates blocks in a virtual blocks world lunar a natural language interface to a database containing chemical analyses of apollo 11 moon rocks by http parsecraft com william a woods chat 80 transformed english questions into prolog expressions which were evaluated against the prolog database the code of chat 80 was circulated widely and formed the basis of several other experimental nl interfaces an online demo is available on the lpa website ref http www lpa co uk pws dem5 htm chat 80 demo ref eliza written at mit by joseph weizenbaum between 1964 and 1966 mimicked a psychotherapist and was operated by processing users responses to scripts using almost no information about human thought or emotion the doctor script sometimes provided a startlingly human like interaction an online demo is available on the lpa website ref http www lpa co uk pws dem4 htm eliza demo ref janus is also one of the few systems to support temporal questions intellect from trinzic formed by the merger of aicorp and aion bbn s parlance built on experience from the development of the rus and irus systems ibm languageaccess q a software q a from symantec datatalker from natural language inc loqui from bim english wizard from linguistic technology corporation iaskweb from anserity inc fully implemented in prolog was providing interactive recommendations in nl to users in tax and investment domains in 1999 2001 ref cite book last galitsky first boris title natural language question answering technique of semantic headers publisher advance knowledge international date 2003 location adelaide australia url http www amazon com natural language question answering system dp 0868039799 isbn 0868039799 ref challenges natural language interfaces have in the past led users to anthropomorphize the computer or at least to attribute more intelligence to machines than is warranted on the part of the user this has led to unrealistic expectations of the capabilities of the system such expectations will make it difficult to learn the restrictions of the system if users attribute too much capability to it and will ultimately lead to disappointment when the system fails to perform as expected as was the case in the ai winter of the 1970s and 80s a http arxiv org abs cmp lg 9503016 1995 paper titled natural language interfaces to databases an introduction describes some challenges ref name edin modifier attachment the request list all employees in the company with a driving licence is ambiguous unless you know that companies can t have driving licences conjunction and disjunction list all applicants who live in california and arizona is ambiguous unless you know that a person can t live in two places at once anaphora resolution resolve what a user means by he she or it in a self referential query other goals to consider more generally are the speed and efficiency of the interface in all algorithms these two points are the main point that will determine if some methods are better than others and therefore have greater success in the market in addition localisation across multiple language sites requires extra consideration this is based on differing sentence structure and language syntax variations between most languages finally regarding the methods used the main problem to be solved is creating a general algorithm that can recognize the entire spectrum of different voices while disregarding nationality gender or age the significant differences between the extracted features even from speakers who says the same word or phrase must be successfully overcome uses and applications the natural language interface gives rise to technology used for many different applications some of the main uses are dictation is the most common use for automated speech recognition asr systems today this includes medical transcriptions legal and business dictation and general word processing in some cases special vocabularies are used to increase the accuracy of the system command and control asr systems that are designed to perform functions and actions on the system are defined as command and control systems utterances like open netscape and start a new xterm will do just that telephony some pbx voice mail systems allow callers to speak commands instead of pressing buttons to send specific tones wearables because inputs are limited for wearable devices speaking is a natural possibility medical disabilities many people have difficulty typing due to physical limitations such as repetitive strain injuries rsi muscular dystrophy and many others for example people with difficulty hearing could use a system connected to their telephone to convert a caller s speech to text embedded applications some new cellular phones include c c speech recognition that allow utterances such as call home this may be a major factor in the future of automatic speech recognition and linux below are named and defined some of the applications that use natural language recognition and so have integrated utilities listed above ubiquity main ubiquity firefox ubiquity an add on mozilla add on for mozilla firefox is a collection of quick and easy natural language derived commands that act as mashup web application hybrid mashups of web services thus allowing users to get information and relate it to current and other webpages wolfram alpha main wolfram alpha wolfram alpha is an online service that answers factual queries directly by computing the answer from structured data rather than providing a list of documents or web pages that might contain the answer as a search engine would ref cite news url https www theguardian com technology 2009 mar 09 search engine google title british search engine could rival google last johnson first bobbie date 2009 03 09 work the guardian accessdate 2009 03 09 ref it was announced in march 2009 by stephen wolfram and was released to the public on may 15 2009 ref name launch date cite web url http blog wolframalpha com 2009 05 08 so much for a quiet launch title so much for a quiet launch publisher wolfram alpha blog date 2009 05 08 accessdate 2009 10 20 ref siri main siri software siri is an intelligent personal assistant application integrated with operating system ios the application uses natural language processing to answer questions and make recommendations siri s marketing claims include that it adapts to a user s individual preferences over time and personalizes results and performs tasks such as making dinner reservations while trying to catch a cab ref https www apple com iphone features siri html siri webpage ref others ask com the original idea behind ask jeeves ask com was traditional keyword searching with an ability to get answers to questions posed in everyday natural language the current ask com still supports this with added support for math dictionary and conversion questions braina ref http www brainasoft com braina braina ref braina is a natural language interface for windows os that allows to type or speak english language sentences to perform a certain action or find information http www cmantik com cmantik cmantik is a semantic information search engine which is trying to answer user s questions by looking up relevant information in wikipedia and some news sources http minock github io c phrase c phrase is a web based natural language front end to relational databases c phrase runs under linux connects with postgresql databases via odbc and supports both select queries and updates currently there is only support for english http devtools korzh com easyquery easyquery is a component library for net framework first of all which allows you to implement natural language query builder in your application works both with relational databases or orm solutions like entity framework https friendlydata io friendlydata is a natural language interface for relational databases file gnome do classic png thumb screenshot of gnome do classic interface http yagadi com enguage this is an open source text understanding interface for web mobile devices using publicly available speech to text and text to speech facilities this is directed at controlling apps rather than as a front end database query or web search the interpretation of utterances is programmed and programmable in natural language utterances thus it is or at least asserts that language is an autopoiesis autopoietic system ref http www academia edu 10177437 an autopoietic repertoire ref it can achieve a deep understanding of text ref http cit srce unizg hr index php cit article view 2278 1658 if we are holding hands whose hand am i holding ref a reference app is available on https play google com store apps details id com yagadi ineed google play gnome do allows for quick finding miscellaneous artifacts of gnome environment applications evolution and pidgin contacts firefox bookmarks rhythmbox artists and albums and so on and execute the basic actions on them launch open email chat play etc ref ubuntu 10 04 add remove applications description for gnome do ref hakia hakia is an internet search engine the company has invented an alternative new infrastructure to indexing that uses semanticrank algorithm a solution mix from the disciplines of ontological semantics fuzzy logic computational linguistics and mathematics lexxe lexxe is an internet search engine that uses natural language processing for queries semantic search searches can be made with keywords phrases and questions such as how old is wikipedia when it comes to facts lexxe is quite effective though needs much improvement in natural language analysis in the area of facts and in other areas http www mnemoo com mnemoo mnemoo is an answer engine that aimed to directly answer questions posed in plain text natural language which is accomplished using a database of facts and an inference engine http www naturaldateandtime com natural date and time natural language date and time zone engine it allows you to ask questions about time daylight saving information and to do time zone conversions via plain english questions such as what is the time in s\xc3\xa3o paulo when it is 6pm on the 2nd of june in detroit http www linguasys com web production server item nlui 20server nlui server an enterprise oriented multilingual application server by linguasys for natural language user interface scripts supporting english spanish portuguese german japanese chinese pashto thai russian vietnamese malay with arabic french and more languages in development pikimal pikimal uses natural language tied to user preference to make search recommendations by template powerset company powerset on may 11 2008 the company unveiled a tool for searching a fixed subset of wikipedia using conversational phrases rather than keywords ref cite news url http bits blogs nytimes com 2008 05 12 powerset debuts with search of wikipedia title powerset debuts with search of wikipedia publisher the new york times first miguel last helft date may 12 2008 ref on july 1 2008 it was purchased by microsoft ref cite web url http www powerset com blog articles 2008 07 01 microsoft to acquire powerset archiveurl https web archive org web 20090225064356 http www powerset com blog articles 2008 07 01 microsoft to acquire powerset archivedate february 25 2009 title microsoft to acquire powerset publisher powerset blog first mark last johnson date july 1 2008 ref q go the q go technology provides relevant answers to users in response to queries on a company s internet website or corporate intranet formulated in natural sentences or keyword input alike q go was acquired by rightnow technologies in 2011 start mit project http start csail mit edu start web based question answering system unlike information retrieval systems such as search engines start aims to supply users with just the right information instead of merely providing a list of hits currently the system can answer millions of english questions about places movies people and dictionary definitions https www statmuse com statmuse natural language analytics platform currently in private beta with nba data ask natural questions and get rich visualizations and raw data http swingly com swingly swingly is an answer engine designed to find exact answers to factual questions just ask a question in plain english and swingly will find you the answer or answers you re looking for according to their site yebol yebol is a vertical decision search engine that had developed a knowledge based semantic search platform yebol s artificial intelligence human intelligence infused algorithms automatically cluster and categorize search results web sites pages and content that it presents in a visually indexed format that is more aligned with initial human intent yebol uses association ranking and clustering algorithms to analyze related keywords or web pages yebol integrates natural language processing metasynthetic engineered open complex systems and machine algorithms with human knowledge for each query to establish a web directory that actually learns using correlation clustering and classification algorithms to automatically generate the knowledge query which is retained and regenerated forward ref humphries matthew http www geek com articles news yebolcom steps into the search market 20090731 yebol com steps into the search market geek com 31 july 2009 ref see also attempto controlled english natural user interface natural language programming xtalk a family of english like programming languages chatterbot a computer program that simulates human conversations noisy text question answering selection based search semantic search semantic query semantic web references reflist internet search computable knowledge defaultsort natural language user interface category user interfaces category artificial intelligence applications category natural language processing category computational linguistics category information retrieval techniques'
b'multiple issues unreferenced date march 2009 orphan date february 2009 confusing date march 2009 negative search is the elimination of information which is not relevant from a mass of content in order to present to a user a range of relevant content negative search is different from both positive search and discovery search positive search uses the selection of relevant content as its primary mechanism discovery calculates relatedness between user intent and content to present users with relevant alternatives of which they may not have been aware negative search applies to those forms of searches where the user has the intention of finding a specific actionable piece information but lacks the knowledge of what that specific information is or might be negative search can also apply to searches where the user has a clear understanding of negative intent what they don t want rather than what they do examples of negative intent are job searching someone knows they want a new job but they have no idea what it might be they just know what they don t want online dating someone is looking for a dating partner but cannot identify what criteria they are looking for they just know what they don t want an investigator is looking for a car but has no other information on that car on which to base a search negative search classifiers if there are two forms of search positive and negative it follows that there are two forms of classifier models inclusive classifiers and exclusive classifiers list of countries countries of the world are a good example of a mece list a positive search for the country kenya would identify content referencing kenya and present it a negative search for the country kenya would exclude all content relating to other countries in the world leaving the user with content of some relevance to kenya irrelevancy as a desirable construct positive search tends to view irrelevancy as undesirable having a system actively identify and pursue irrelevant content for the purpose of elimination from a user experience may prove a highly powerful mechanism it follows that positive and negative search are not mutually exclusive and that a more powerful search may result from the combination of selection and elimination as tools to empower user experience in negative searches degrees of passivity positive search involves an active search by a user with no degree of passivity or openness for example i am only interested in the hilton hotel in vientiane on new year s eve new years eve discovery involves a simultaneous secondary more passive search by the user while they are involved in a positive search for example i am interested in the hilton hotel in vientiane on new years eve but if there s a better hotel let me know negative search also involves an active search but with a much higher degree of passivity or openness to discovery for example i need a holiday and really don t care where as long as its good searchers can be active in one dimension positive search while simultaneously being passive to alternatives or what they don t know they re looking for in many dimensions in discovery they are passive in a small number of dimensions but in negative search they are passive in many or all dimensions references reflist category information retrieval techniques'
b'multiple issues cleanup reorganize date june 2008 refimprove date september 2015 tone date september 2015 personalization sometimes known as customization consists of tailoring a service or a product to accommodate specific individuals sometimes tied to groups or segments of individuals a wide variety of organizations use personalization to improve customer satisfaction digital sales conversion marketing results branding and improved website metrics as well as for advertising personalization is a key element in social media and recommender system s web pages web page s can be personalized based on the characteristics interests social category context etc actions click on button open a link etc intent make a purchase check status of an entity or any other parameter that can be identified and associated with an individual therefore providing them with a tailored user experience note that the experience is rarely simply accommodation of the user but a relationship between the user and the desires of the site designers in driving specific actions to achieve objectives e g increase sales conversion on a page the term customization is often used when the site only uses explicit data such as product ratings or user preferences technically web personalization can be achieved by associating a visitor segment with a predefined action customizing the user experience based on behavioural contextual and technical data is proven to have a positive impact on conversion rate optimization efforts associated actions can range from changing the content of a webpage presenting a modal display presenting interstitials triggering a personalized email or even automating a phone call to the user according to a 2014 study from research firm econsultancy less than 30 of e commerce websites have invested in the field of web personalization however many companies now offer services for web personalization as well as web and email recommendation systems that are based on personalization or anonymously collected user behaviours ref name behaviours http online wsj com article sb10001424052748703294904575385532109190198 html wall street journal on the web s cutting edge anonymity in name only august 4 2010 ref according to a study done by compass e commerce websites that use personalization can see an increase in revenue of as much as 29 ref name 29 http blog compass co improving ecommerce retention revenue personalization compass blog improving ecommerce retention and revenue with personalization august 11 2016 ref there are many categories of web personalization including behavioral contextual technical historic data collaboratively filtered there are several camps in defining and executing web personalization a few broad methods for web personalization may include implicit explicit hybrid with implicit personalization the web personalization is performed based on the different categories mentioned above it can also be learned from direct interactions with the user based on implicit data such as items purchased or pages viewed ref cite web last1 flynn first1 lawrence title 5 things to know about siri and google now s growing intelligence url http www forbes com sites parmyolson 2014 07 08 5 things to know about siri and google nows growing intelligence website forbes ref with explicit personalization the web page or information system is changed by the user using the features provided by the system hybrid personalization combines the above two approaches to leverage the best of both worlds web personalization is can be linked to the notion of adaptive hypermedia ah the main difference is that the former would usually work on what is considered an open corpus hypermedia whilst the latter would traditionally work on closed corpus hypermedia however recent research directions in the ah domain take both closed and open corpus into account thus the two fields are closely inter related personalization is also being considered for use in less overtly commercial applications to improve the user experience online ref jonathan bowen bowen j p and filippini fantoni s http www archimuse com mw2004 papers bowen bowen html personalization and the web from a museum perspective in david bearman and jennifer trant eds museums and the web 2004 selected papers from an international conference arlington virginia usa 31 march 3 april 2004 archives museum informatics pages 63 78 2004 ref internet activist eli pariser has documented that search engines like google and yahoo news give different results to different people even when logged out he also points out social media site facebook changes user s friend feeds based on what it thinks they want to see pariser warns that these algorithms can create a filter bubble that prevents people from encountering a diversity of viewpoints beyond their own or which only presents facts which confirm their existing views on an intranet or b2e web portal enterprise web portals enterprise web portals personalization is often based on user attributes such as department functional area or role the term customization in this context refers to the ability of users to modify the page layout or specify what content should be displayed digital media another aspect of personalization is the increasing prevalence of open data on the web many companies make their data available on the web via api s web services and open data standards one such example is ordnance survey open data ref cite news url https www theguardian com news datablog 2010 apr 02 ordnance survey open data location london work the guardian first1 chris last1 thorpe first2 simon last2 rogers title ordnance survey opendata maps what does it actually include date 2 april 2010 ref data made available in this way is structured to allow it to be inter connected and re used by third parties ref cite web url http www cio com article 372363 google opens up data center for third party web applications title google opens up data centre for third party web applications publisher cio com date 2008 05 28 accessdate 2013 01 16 ref data available from a user s personal social graph can be accessed by third party application software to be suited to fit the personalized web page or information appliance current open data standards on the web include attention profiling mark up language apml dataportability openid opensocial mobile phones over time mobile phones have seen an increased emphasis placed on user personalization far from the black and white screens and monophonic ringtones of the past phones now offer interactive wallpapers and mp3 trutones in the uk and asia weemees have become popular weemees are three dimensional characters that are used as wallpaper and respond to the tendencies of the user video graphics array vga picture quality allows people to change their background with ease without sacrificing quality all of these services are downloaded through the provider with the goal to make the user feel connected to the phone ref may harvey and greg hearn the mobile phone as media international journal of cultural studies 8 2 2005 195 211 print ref print media main mail merge in print media ranging from magazine s to admail promotional publication s personalization uses databases of individual recipients information not only does the written document address itself by name to the reader but the advertising is targeted to the recipient s demographics or interests using fields within the database such as first name last name company etc the term personalization should not be confused with variable data which is a much more granular method of marketing that leverages both images and text with the medium not just fields within a database although personalized children s books are created by companies who are using and leveraging all the strengths of variable data printing variable data printing vdp this allows for full image and text variability within a printed book with the advent of online 3d printing services such as shapeways and ponoko we are seeing personalization enter into the realms of product design promotional merchandise promotional items mug s t shirt s keychain s ball s etc are regularly personalized personalized children s storybooks wherein the child becomes the protagonist with the name and image of the child personalized are also popular personalized cds for children also exist with the advent of digital printing personalized calendars that start in any month birthday cards cards e cards posters and photo books can also be obtained 3d printing 3d printing is a production method that allows to create unique and personalized items on a global scale personalized apparel and accessories such as jewellery are increasing in popularity ref cite web url http www jewellermagazine com article aspx id 2167 h new jewellery website targets title new jewellery website targets customisers last weinman first aaron date 21 february 2012 publisher jeweller magazine language accessdate 6 january 2015 ref this kind of customization is also relevant in other areas like consumer electronics ref cite web url http www 3ders org articles 20160121 philips launches worlds first personalized 3d printed face shaver for limited edition run html title philips launches the world s first personalized 3d printed face shaver for limited edition run website 3ders org language en us access date 2016 03 02 ref and retail ref cite web url http twikblog twikit com belgian 3d company twikit brings 3d customization french retail title twikit brings 3d customization to french retail website twikit blog 3d customization 3d printing language en us access date 2016 03 02 ref by combining 3d printing with complex software a product can easily be customized by an end user mass personalization tone section date january 2011 mass personalization is defined as custom tailoring by a company in accordance with its end users tastes and preferences ref cite web url http www answers com personalization r 67 title personalize definition synonyms from publisher answers com date accessdate 2013 01 16 ref from collaborative engineering perspective mass customization can be viewed as collaborative efforts between customers and manufacturers who have different sets of priorities and need to jointly search for solutions that best match customers individual specific needs with manufacturers customization capabilities ref chen s y wang and m m tseng 2009 mass customization as a collaborative engineering effort international journal of collaborative engineering 1 2 152 167 ref the main difference between mass customization and mass personalization is that customization is the ability for a company to give its customers an opportunity to create and choose product to certain specifications but does have limits ref haag et al management information systems for the information age 3rd edition 2006 page 331 ref a website knowing a user s location and buying habits will present offers and suggestions tailored to the user s demographics this is an example of mass personalization the personalization is not individual but rather the user is first classified and then the personalization is based on the group they belong to ref cite news url http www telegraph co uk foodanddrink 9808015 how supermarkets prop up our class system html location london work the daily telegraph first harry last wallop title how supermarkets prop up our class system date 2013 01 18 ref behavioral targeting represents a concept that is similar to mass personalization predictive personalization predictive personalization is defined as the ability to predict customer behavior needs or wants and tailor offers and communications very precisely ref cite web url http www slideshare net jwtintelligence jwt 10 trends for 2013 executive summary title 10 trends for 2013 executive summary definition projected trends publisher jwtintelligence com date accessdate 2012 12 04 ref social data is one source of providing this predictive analysis particularly social data that is structured predictive personalization is a much more recent means of personalization and can be used well to augment current personalization offerings map personalization expand section date september 2015 digital web mapping web maps are also being personalized google maps change the content of the map based on previous searches and other profile information ref cite web title the next frontier for google maps is personalization url http social techcrunch com 2013 02 01 the next frontier for google maps is personalization website techcrunch accessdate 2015 09 13 first frederic last lardinois ref technology writer evgeny morozov has criticized map personalization as a threat to public space ref cite news title my map or yours url http www slate com articles technology future tense 2013 05 google maps personalization will hurt public space and engagement html newspaper slate date 2013 05 28 access date 2015 09 13 issn 1091 2339 language en first evgeny last morozov ref see also adaptation computer science mass customization adaptive hypermedia behavioral targeting bespoke collaborative filtering configurator personalized learning preorder economy real time marketing recommendation system user modeling references reflist 2 external links http www iimcp org international institute on mass customization personalization which organizes mcp a biannual conference on customization and personalization http www umuai org user modeling and user adapted interaction umuai the journal of personalization research category human computer interaction category world wide web category user interface techniques category usability personas category types of marketing category information retrieval techniques'
b'preference learning is a subfield in machine learning in which the goal is to learn a predictive preference economics preference model from observed preference information ref mehryar mohri afshin rostamizadeh ameet talwalkar 2012 foundations of machine learning the mit press isbn 9780262018258 ref in the view of supervised learning preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items while the concept of preference learning has been emerged for some time in many fields such as economics ref name shog00 it s a relatively new topic in artificial intelligence research several workshops have been discussing preference learning and related topics in the past decade ref name web workshop tasks the main task in preference learning concerns problems in learning to rank according to different types of preference information observed the tasks are categorized as three main problems in the book preference learning ref name furn11 label ranking in label ranking the model has an instance space math x x i math and a finite set of labels math y y i i 1 2 cdots k math the preference information is given in the form math y i succ x y j math indicating instance math x math shows preference in math y i math rather than math y j math a set of preference information is used as training data in the model the task of this model is to find a preference ranking among the labels for any instance it was observed some conventional classification in machine learning classification problems can be generalized in the framework of label ranking problem ref name harp03 if a training instance math x math is labeled as class math y i math it implies that math forall j neq i y i succ x y j math in the multi label classification multi label case math x math is associated with a set of labels math l subseteq y math and thus the model can extract a set of preference information math y i succ x y j y i in l y j in y backslash l math training a preference model on this preference information and the classification result of an instance is just the corresponding top ranking label instance ranking instance ranking also has the instance space math x math and label set math y math in this task labels are defined to have a fixed order math y 1 succ y 2 succ cdots succ y k math and each instance math x l math is associated with a label math y l math giving a set of instances as training data the goal of this task is to find the ranking order for a new set of instances object ranking object ranking is similar to instance ranking except that no labels are associated with instances given a set of pairwise preference information in the form math x i succ x j math and the model should find out a ranking order among instances techniques there are two practical representations of the preference information math a succ b math one is assigning math a math and math b math with two real numbers math a math and math b math respectively such that math a b math another one is assigning a binary value math v a b in 0 1 math for all pairs math a b math denoting whether math a succ b math or math b succ a math corresponding to these two different representations there are two different techniques applied to the learning process utility function if we can find a mapping from data to real numbers ranking the data can be solved by ranking the real numbers this mapping is called utility function for label ranking the mapping is a function math f x times y rightarrow mathbb r math such that math y i succ x y j rightarrow f x y i f x y j math for instance ranking and object ranking the mapping is a function math f x rightarrow mathbb r math finding the utility function is a regression analysis regression learning problem which is well developed in machine learning preference relations the binary representation of preference information is called preference relation for each pair of alternatives instances or labels a binary predicate can be learned by conventional supervising learning approach f\xc3\xbcrnkranz johannes and h\xc3\xbcllermeier proposed this approach in label ranking problem ref name furn03 for object ranking there is an early approach by cohen et al ref name cohe98 using preference relations to predict the ranking will not be so intuitive since preference relation is not transitive it implies that the solution of ranking satisfying those relations would sometimes be unreachable or there could be more than one solution a more common approach is to find a ranking solution which is maximally consistent with the preference relations this approach is a natural extension of pairwise classification ref name furn03 uses preference learning can be used in ranking search results according to feedback of user preference given a query and a set of documents a learning model is used to find the ranking of documents corresponding to the relevance with this query more discussions on research in this field can be found in tie yan liu s survey paper ref name liu09 another application of preference learning is recommender systems ref name gemm09 online store may analyze customer s purchase record to learn a preference model and then recommend similar products to customers internet content providers can make use of user s ratings to provide more user preferred contents see also learning to rank references reflist refs ref name shog00 cite journal last shogren first jason f author2 list john a author3 hayes dermot j year 2000 title preference learning in consecutive experimental auctions url http econpapers repec org article oupajagec v 3a82 3ay 3a2000 3ai 3a4 3ap 3a1016 1021 htm journal american journal of agricultural economics volume 82 pages 1016 1021 doi 10 1111 0002 9092 00099 ref ref name web workshop cite web title preference learning workshops url http www preference learning org workshops ref ref name furn11 cite book last f uuml rnkranz first johannes coauthors h uuml llermeier eyke year 2011 title preference learning url https books google com books id nc3xch9xsgyc chapter preference learning an introduction chapterurl https books google com books id nc3xch9xsgyc pg pa4 publisher springer verlag new york inc pages 3 8 isbn 978 3 642 14124 9 ref ref name harp03 cite journal last har peled first sariel author2 roth dan author3 zimak dav year 2003 title constraint classification for multiclass classification and ranking journal in proceedings of the 16th annual conference on neural information processing systems nips 02 pages 785 792 ref ref name furn03 cite journal last f uuml rnkranz first johannes coauthors h uuml llermeier eyke year 2003 title pairwise preference learning and ranking journal proceedings of the 14th european conference on machine learning pages 145 156 ref ref name cohe98 cite journal last cohen first william w author2 schapire robert e author3 singer yoram year 1998 title learning to order things url http dl acm org citation cfm id 302528 302736 journal in proceedings of the 1997 conference on advances in neural information processing systems pages 451 457 ref ref name liu09 cite journal last liu first tie yan year 2009 title learning to rank for information retrieval url http dl acm org citation cfm id 1618303 1618304 journal foundations and trends in information retrieval volume 3 issue 3 pages 225 331 doi 10 1561 1500000016 ref ref name gemm09 cite journal last gemmis first marco de author2 iaquinta leo author3 lops pasquale author4 musto cataldo author5 narducci fedelucio author6 semeraro giovanni year 2009 title preference learning in recommender systems url http www ecmlpkdd2009 net wp content uploads 2008 09 preference learning pdf page 45 journal preference learning volume 41 pages 387 407 doi 10 1007 978 3 642 14125 6 18 ref external links http www preference learning org preference learning site category information retrieval techniques category machine learning'
b'in natural language processing text processing a proximity search looks for documents where two or more separately matching term occurrences are within a specified string distance distance where distance is the number of intermediate words or characters in addition to proximity some implementations may also impose a constraint on the word order in that the order in the searched text must be identical to the order of the search query proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search for example a search could be used to find red brick house and match phrases such as red house of brick or house made of red brick by limiting the proximity these phrases can be matched while avoiding documents where the words are scattered or spread across a page or in unrelated articles in an anthology rationale the basic linguistic assumption of proximity searching is that the proximity of the words in a document implies a semantic relation relationship between the words given that authors of documents try to formulate sentences which contain a single idea or cluster of related ideas within neighboring sentences or organized into paragraphs there is an inherent relatively high probability within the document structure that words used together are related on the other hand when two words are on the opposite ends of a book the probability of a relationship between the words is relatively weak by limiting search results to only include matches where the words are within the specified maximum proximity or distance the search results are assumed to be of higher relevance than the matches where the words are scattered commercial internet search engines tend to produce too many matches known as recall for the average search query proximity searching is one method of reducing the number of pages matches and to improve the relevance of the matched pages by using word proximity to assist in ranking as an added benefit proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words which would otherwise rank highly if the search engine was heavily biased toward word frequency boolean syntax and operators note that a proximity search can designate that only some keywords must be within a specified distance proximity searching can be used with other search syntax and or controls to allow more articulate search queries sometimes query operators like near not near followed by not followed by sentence or far are used to indicate a proximity search limit between specified keywords for example brick near house usage in commercial search engines in regards to implicit automatic versus explicit proximity search as of november 2008 most internet search engine s only implement an implicit proximity search functionality that is they automatically rank those search results higher where the user keywords have a good overall proximity score in such results if only two keywords are in the search query this has no difference from an explicit proximity search which puts a near operator between the two keywords however if three or more than three keywords are present it is often important for the user to specify which subsets of these keywords expect a proximity in search results this is useful if the user wants to do a prior art search e g finding an existing approach to complete a specific task finding a document that discloses a system that exhibits a procedural behavior collaboratively conducted by several components and links between these components web search engine s which support proximity search via an explicit proximity operator in their query language include walhello exalead yandex yahoo altavista and bing search engine bing when using the walhello search engine the proximity can be defined by the number of characters between the keywords ref http www walhello com aboutgl html about walhello visited 23 december 2009 ref the search engine exalead allows the user to specify the required proximity as the maximum number of words between keywords the syntax is tt keyword1 near n keyword2 tt where n is the number of words ref http www exalead com search web search syntax proximity search web search syntax visited 23 december 2009 ref yandex uses the syntax tt keyword1 n keyword2 tt to search for two keywords separated by at most math n 1 math words and supports a few other variations of this syntax ref http help yandex ru search id 481939 yandex help page on query language in russian ref yahoo and altavista both support an undocumented near operator ref http search yahoo com search p site 3awww rfc editor org inurl 3arfc2606 guidance near additional successful yahoo proximity query 22 feb 2010 ref ref http search yahoo com search p site 3awww rfc editor org inurl 3arfc2606 guidance near unused unsuccessful yahoo proximity query 22 feb 2010 ref the syntax is tt keyword1 near keyword2 tt google search supports around ref http www guidingtech com 16116 google search little known around operator guidingtech meet google search s little known around operator ref ref http www netforlawyers com content google offers proximity search around connector 0015 google offers proximity search 8 feb 2011 ref bing search engine bing supports near ref http www howtogeek com 106751 how to use bings advanced search operators 8 tips for better searches how to use bing s advanced search operators ref the syntax is tt keyword1 near n keyword2 tt where n the number of maximum separating words ordered search within the google and yahoo search engines is possible using the asterisk full word wildcard character wildcard s in google this matches one or more words ref http www google com support websearch bin answer py answer 136861 more google search help visited 23 december 2009 ref and an in yahoo search this matches exactly one word ref http www searchengineshowdown com features yahoo review html review of yahoo search by search engine showdown visited 23 december 2009 ref this is easily verified by searching for the following phrase in both google and yahoo addictive of biblioscopy to emulate unordered search of the near operator can be done using a combination of ordered searches for example to specify a close co occurrence of house and dog the following search expression could be specified house dog or dog house or house dog or dog house or house dog or dog house see also compound term processing edit distance information retrieval search engine search engine indexing how texts are indexed to support proximity search semantic proximity notes reflist category information retrieval techniques category internet search algorithms'
b'cosine similarity is a measure of similarity between two non zero vectors of an inner product space that measures the cosine of the angle between them the cosine of 0\xc2\xb0 is 1 and it is less than 1 for any other angle it is thus a judgment of orientation and not magnitude two vectors with the same orientation have a cosine similarity of 1 two vectors at 90\xc2\xb0 have a similarity of 0 and two vectors diametrically opposed have a similarity of 1 independent of their magnitude cosine similarity is particularly used in positive space where the outcome is neatly bounded in 0 1 the name derives from the term direction cosine in this case note that unit vectors are maximally similar if they re parallel and maximally dissimilar if they re orthogonal perpendicular it should not escape the alert reader s attention that this is analogous to cosine which is unity maximum value when the segments subtend a zero angle and zero uncorrelated when the segments are perpendicular note that these bounds apply for any number of dimensions and cosine similarity is most commonly used in high dimensional positive spaces for example in information retrieval and text mining each term is notionally assigned a different dimension and a document is characterised by a vector where the value of each dimension corresponds to the number of times that term appears in the document cosine similarity then gives a useful measure of how similar two documents are likely to be in terms of their subject matter ref singhal amit 2001 modern information retrieval a brief overview bulletin of the ieee computer society technical committee on data engineering 24 4 35 43 ref the technique is also used to measure cohesion within clusters in the field of data mining ref p n tan m steinbach v kumar introduction to data mining addison wesley 2005 isbn 0 321 32136 7 chapter 8 page 500 ref cosine distance is a term often used for the complement in positive space that is math d c a b 1 s c a b math it is important to note however that this is not a proper distance metric as it does not have the triangle inequality property or more formally the schwarz inequality and it violates the coincidence axiom to repair the triangle inequality property while maintaining the same ordering it is necessary to convert to angular distance see below one of the reasons for the popularity of cosine similarity is that it is very efficient to evaluate especially for sparse vectors as only the non zero dimensions need to be considered definition the cosine of two non zero vectors can be derived by using the euclidean vector dot product euclidean dot product formula math mathbf a cdot mathbf b left mathbf a right left mathbf b right cos theta math given two vector geometric vectors of attributes a and b the cosine similarity cos \xce\xb8 is represented using a dot product and magnitude mathematics euclidean vector space magnitude as math text similarity cos theta mathbf a cdot mathbf b over mathbf a mathbf b frac sum limits i 1 n a i b i sqrt sum limits i 1 n a i 2 sqrt sum limits i 1 n b i 2 math where math a i math and math b i math are euclidean vector decomposition components of vector math a math and math b math respectively the resulting similarity ranges from minus 1 meaning exactly opposite to 1 meaning exactly the same with 0 indicating orthogonality decorrelation and in between values indicating intermediate similarity or dissimilarity for text matching the attribute vectors a and b are usually the tf idf term frequency vectors of the documents the cosine similarity can be seen as a method of normalizing document length during comparison in the case of information retrieval the cosine similarity of two documents will range from 0 to 1 since the term frequencies tf idf weights cannot be negative the angle between two term frequency vectors cannot be greater than nbsp 90\xc2\xb0 if the attribute vectors are normalized by subtracting the vector means e g math a bar a math the measure is called centered cosine similarity and is equivalent to the pearson product moment correlation coefficient for a sample pearson correlation coefficient angular distance and similarity the term cosine similarity is sometimes used to refer to different definition of similarity provided below however the most common use of cosine similarity is as defined above and the similarity and distance metrics defined below are referred to as angular similarity and angular distance respectively the normalized angle between the vectors is a formal distance metric and can be calculated from the similarity score defined above this angular distance metric can then be used to compute a similarity function bounded between 0 and 1 inclusive when the vector elements may be positive or negative math text distance frac cos 1 text similarity pi math math text similarity 1 text distance math or if the vector elements are always positive math text distance frac 2 cdot cos 1 text similarity pi math math text similarity 1 text distance math although the term cosine similarity has been used for this angular distance the term is oddly used as the cosine of the angle is used only as a convenient mechanism for calculating the angle itself and is no part of the meaning the advantage of the angular similarity coefficient is that when used as a difference coefficient by subtracting it from 1 the resulting function is a proper distance metric which is not the case for the first meaning however for most uses this is not an important property for any use where only the relative ordering of similarity or distance within a set of vectors is important then which function is used is immaterial as the resulting order will be unaffected by the choice confusion with tanimoto coefficient the cosine similarity may be easily confused with the tanimoto metric a specialised form of a similarity coefficient with a similar algebraic form math t a b a cdot b over a 2 b 2 a cdot b math in fact this algebraic form jaccard index tanimoto similarity and distance was first defined by tanimoto as a mechanism for calculating the jaccard coefficient in the case where the sets being compared are represented as bit vector s while the formula extends to vectors in general it has quite different properties from cosine similarity and bears little relation other than its superficial appearance ochiai coefficient this coefficient is also known in biology as ochiai coefficient or ochiai barkman coefficient or otsuka ochiai coefficient ref ochiai a zoogeographical studies on the soleoid fishes found japan and its neighboring regions ii bull jap soc sci fish 1957 v 22 \xe2\x84\x96 9 p 526 530 ref ref barkman j j phytosociology and ecology of cryptogamic epiphytes including a taxonomic survey and description of their vegetation units in europe assen van gorcum 1958 628 p ref math k frac n a cap b sqrt n a times n b math here math a math and math b math are sets and math n a math is the number of elements in math a math if sets are represented as bit vector s the ochiai coefficient can be seen to be the same as the cosine similarity properties cosine similarity is related to euclidean distance as follows denote euclidean distance by the usual math a b math and observe that math a b 2 a b top a b a 2 b 2 2 a top b math by polynomial expansion expansion when mvar a and mvar b are normalized to unit length math a 2 b 2 1 math so the previous is equal to math 2 1 cos a b math null distribution for data which can be negative as well as positive the null distribution for cosine similarity is the distribution of the dot product of two independent random unit vectors this distribution has a mean of zero and a variance of math 1 n math where math n math is the number of dimensions and although the distribution is bounded between 1 and 1 as math n math grows large the distribution is increasingly well approximated by the normal distribution ref cite journal author spruill marcus c year 2007 title asymptotic distribution of coordinates on high dimensional spheres journal electronic communications in probability volume 12 pages 234 247 doi 10 1214 ecp v12 1294 ref ref http stats stackexchange com questions 85916 distribution of dot products between two random unit vectors in mathbbrd crossvalidated distribution of dot products between two random unit vectors in rd ref for other types of data such as bitstreams taking values of 0 or 1 only the null distribution will take a different form and may have a nonzero mean ref cite journal author graham l giller year 2012 title the statistical properties of random bitstreams and the sampling distribution of cosine similarity journal giller investments research notes number 20121024 1 doi 10 2139 ssrn 2167044 ref soft cosine measure soft cosine measure is a measure of soft similarity between two vectors i e the measure that considers similarity of pairs of features ref cite journal last1 sidorov first1 grigori last2 gelbukh first2 alexander last3 g\xc3\xb3mez adorno first3 helena last4 pinto first4 david title soft similarity and soft cosine measure similarity of features in vector space model journal computaci\xc3\xb3n y sistemas volume 18 issue 3 pages 491 504 doi 10 13053 cys 18 3 2043 url http cys cic ipn mx ojs index php cys article view 2043 accessdate 7 october 2014 ref the traditional cosine similarity considers the vector space model vsm features as independent or completely different while the soft cosine measure proposes considering the similarity of features in vsm which allows generalization of the concepts of cosine measure and also the idea of similarity soft similarity for example in the field of natural language processing nlp the similarity among features is quite intuitive features such as words n grams or syntactic n grams ref cite book last1 sidorov first1 grigori last2 velasquez first2 francisco last3 stamatatos first3 efstathios last4 gelbukh first4 alexander last5 chanona hern\xc3\xa1ndez first5 liliana title syntactic dependency based n grams as classification features publisher lnai 7630 isbn 978 3 642 37798 3 pages 1 11 url http link springer com chapter 10 1007 2f978 3 642 37798 3 1 accessdate 7 october 2014 ref can be quite similar though formally they are considered as different features in the vsm for example words play and game are different words and thus are mapped to different dimensions in vsm yet it is obvious that they are related semantically in case of n grams or syntactic n grams levenshtein distance can be applied in fact levenshtein distance can be applied to words as well for calculation of the soft cosine measure the matrix math s of similarity between features is introduced it can be calculated using levenshtein distance or other similarity measures e g various wordnet similarity measures then we just multiply by this matrix given two math n dimension vectors a and b the soft cosine similarity is calculated as follows math begin align operatorname soft cosine 1 a b frac sum nolimits i j n s ij a ib j sqrt sum nolimits i j n s ij a ia j sqrt sum nolimits i j n s ij b ib j end align math where math s sub ij sub similarity feature sub i sub feature sub j sub if there is no similarity between features math s sub ii sub 1 math s sub ij sub 0 for math i \xe2\x89\xa0 j the given equation is equivalent to the conventional cosine similarity formula the complexity of this measure is quadratic which makes it perfectly applicable to real world tasks the complexity can be transformed to subquadratic citation needed date december 2015 see also s\xc3\xb8rensen similarity index s\xc3\xb8rensen s quotient of similarity hamming distance correlation dice s coefficient jaccard index simrank information retrieval references reflist external links http mathforum org kb message jspa messageid 5658016 tstart 0 weighted cosine measure http blog christianperone com p 2497 a tutorial on cosine similarity using python http www rxnlp com api reference text similarity api reference web api to compute cosine jaccard and dice for text in any language defaultsort cosine similarity category information retrieval techniques'
b'use dmy dates date february 2013 the anchor text link label link text or link title is the visible clickable text in a hyperlink the words contained in the anchor text can determine the ranking that the page will receive by search engines since 1998 some web browser s have added the ability to show a tooltip for a hyperlink before it is selected not all links have anchor texts because it may be obvious where the link will lead due to the context in which it is used anchor texts normally remain below 60 character computing characters different browsers will display anchor texts differently usually web search engines analyze anchor text from hyperlinks on web pages other services apply the basic principles of anchor text analysis as well for instance list of academic databases and search engines academic search engines may use citation context to classify academic publishing academic articles ref cite web author1 bader aljaber author2 nicola stokes author3 james bailey author4 jian pei url http www springerlink com content p278617582u5x3x1 title document clustering of scientific texts using citation contexts date 1 april 2010 publisher springer ref and anchor text from documents linked in mind maps may be used too ref needs new reference link ref file anchor text png thumb visual implementation of anchor text overview anchor text usually gives the user relevant descriptive or contextual information about the content of the link s destination the anchor text may or may not be related to the actual text of the uniform resource locator url of the link for example a hyperlink to the english wikipedia english language wikipedia s homepage might take this form code nowiki a href http en wikipedia org wiki main page wikipedia a nowiki code the anchor text in this example is wikipedia the longer but vital url code nowiki http en wikipedia org wiki main page nowiki code needed to locate the target page displays on the web page as srlink main page wikipedia contributing to clean easy to read text common misunderstanding of the concept this proper method of linking is beneficial to users and webmaster s as anchor text holds significant weight in search engine rankings the limit of the concept is building sentence linguistics sentence s only composed with linked word s citation needed date september 2011 search engine algorithms anchor text is weighted ranked highly in search engine algorithm s because the linked text is usually relevant to the landing page the objective of search engines is to provide highly relevant search results this is where anchor text helps as the tendency was more often than not to hyperlink words relevant to the landing page anchor text can also serve the purpose of directing the user to internal pages on the site which can also help to rank the website higher in the search rankings ref name search engine watch 1 cite web publisher search engine watch url http searchenginewatch com article 2169750 how the web uses anchor text in internal linking study title how the web uses anchor text in internal linking study accessdate 6 july 2012 ref webmaster s may use anchor text to procure high results in search engine results page s google s google webmaster tools webmaster tools facilitate this optimization by letting website owners view the most common words in anchor text linking to their site ref cite web last fox first vanessa url http googlewebmastercentral blogspot com 2007 03 get more complete picture about how html title get a more complete picture about how other sites link to you date 15 march 2007 publisher official google webmaster central blog accessdate 2007 03 27 archiveurl https web archive org web 20070331195216 http googlewebmastercentral blogspot com 2007 03 get more complete picture about how html archivedate 31 march 2007 dashbot deadurl no ref in the past google bomb ing was possible through anchor text manipulation however in january 2007 google announced it had updated its algorithm to minimize the impact of google bombs which refers to a prank where people attempt to cause someone else s site to rank for an obscure or meaningless query ref cite web last cutts first matt url http googlewebmastercentral blogspot com 2007 01 quick word about googlebombs html title a quick word about googlebombs date 25 january 2007 publisher official google webmaster central blog accessdate 2007 03 27 archiveurl https web archive org web 20070324043013 http googlewebmastercentral blogspot com 2007 01 quick word about googlebombs html archivedate 24 march 2007 dashbot deadurl no ref in april 2012 google announced in its march google penguin penguin update that it would be changing the way it handled anchor text implying that anchor text would no longer be as important an element for their ranking metrics ref cite web url http insidesearch blogspot co uk 2012 04 search quality highlights 50 changes html title google s march update publisher google ref moving forward google would be paying more attention to a diversified link profile which has a mix of anchor text and other types of links ref name search engine watch 2 cite web publisher search engine watch url http searchenginewatch com article 2172839 google penguin update impact of anchor text diversity link relevancy title google penguin update impact of anchor text diversity link relevancy accessdate 6 july 2012 ref however a 2016 study of anchor text influence across 16 000 keywords found that presence of exact and partial match anchor links continues to have a strong correlation with google rankings ref cite web publisher ahrefs url https ahrefs com blog anchor text title everything you ever wanted to know about anchor text accessdate 27 july 2016 ref august 2016 study conducted by moz found that exact and partial match domains can be affected by over optimization penalty since google considers domain brand and naked url links as exact match ref cite news url https moz com ugc case study the interconnectedness of local seo and exact match domains title case study the interconnectedness of local seo and exact match domains newspaper moz access date 2016 12 12 ref terminology there are different classifications of anchor text that are used within the search engine optimization community such as the following exact match an anchor that is used with a keyword that mirrors the page that is being linked to example search engine optimization is an exact match anchor because it s linking to a page about search engine optimization branded a brand that is used as the anchor wikipedia is a branded anchor text naked link a url that is used as an anchor www wikipedia com is a naked link anchor generic a generic word or phrase that is used as the anchor click here is a generic anchor other variations may include go here visit this website etc images whenever an image is linked google will use the alt tag as the anchor text references reflist colwidth 30em category information retrieval techniques category internet search engines category internet terminology category search engine optimization category hypertext'
b'in natural language processing and information retrieval cluster labeling is the problem of picking descriptive human readable labels for the clusters produced by a document clustering algorithm standard clustering algorithms do not typically produce any such labels cluster labeling algorithms examine the contents of the documents per cluster to find a labeling that summarize the topic of each cluster and distinguish the clusters from each other differential cluster labeling differential cluster labeling labels a cluster by comparing term probability distribution distributions across clusters using techniques also used for feature selection in document classification such as mutual information and pearson s chi squared test chi squared feature selection terms having very low frequency are not the best in representing the whole cluster and can be omitted in labeling a cluster by omitting those rare terms and using a differential test one can achieve the best results with differential cluster labeling ref manning christopher d prabhakar raghavan and hinrich schutze introduction to information retrieval cambridge cambridge up 2008 cluster labeling stanford natural language processing group web 25 nov 2009 http nlp stanford edu ir book html htmledition cluster labeling 1 html ref pointwise mutual information main article pointwise mutual information in the fields of probability theory and information theory mutual information measures the degree of dependence of two random variables the mutual information of two variables mvar x and mvar y is defined as math i x y sum x in x sum y in y p x y log 2 left frac p x y p 1 x p 2 y right math where p x y is the joint probability joint probability distribution of the two variables p sub 1 sub x is the probability distribution of x and p sub 2 sub y is the probability distribution of y in the case of cluster labeling the variable x is associated with membership in a cluster and the variable y is associated with the presence of a term ref manning christopher d prabhakar raghavan and hinrich schutze introduction to information retrieval cambridge cambridge up 2008 mutual information stanford natural language processing group web 25 nov 2009 http nlp stanford edu ir book html htmledition mutual information 1 html ref both variables can have values of 0 or 1 so the equation can be rewritten as follows math i c t sum c in 0 1 sum t in 0 1 p c c t t log 2 left frac p c c t t p c c p t t right math in this case p c 1 represents the probability that a randomly selected document is a member of a particular cluster and p c 0 represents the probability that it isn t similarly p t 1 represents the probability that a randomly selected document contains a given term and p t 0 represents the probability that it doesn t the joint probability joint probability distribution function p c t represents the probability that two events occur simultaneously for example p 0 0 is the probability that a document isn t a member of cluster c and doesn t contain term t p 0 1 is the probability that a document isn t a member of cluster c and does contain term t and so on chi squared selection main article pearson s chi squared test the pearson s chi squared test can be used to calculate the probability that the occurrence of an event matches the initial expectations in particular it can be used to determine whether two events a and b are statistically independent the value of the chi squared statistic is math x 2 sum a in a sum b in b frac o a b e a b 2 e a b math where o sub a b sub is the observed frequency of a and b co occurring and e sub a b sub is the expected frequency of co occurrence in the case of cluster labeling the variable a is associated with membership in a cluster and the variable b is associated with the presence of a term both variables can have values of 0 or 1 so the equation can be rewritten as follows math x 2 sum a in 0 1 sum b in 0 1 frac o a b e a b 2 e a b math for example o sub 1 0 sub is the observed number of documents that are in a particular cluster but don t contain a certain term and e sub 1 0 sub is the expected number of documents that are in a particular cluster but don t contain a certain term our initial assumption is that the two events are independent so the expected probabilities of co occurrence can be calculated by multiplying individual probabilities ref manning christopher d prabhakar raghavan and hinrich schutze introduction to information retrieval cambridge cambridge up 2008 chi2 feature selection stanford natural language processing group web 25 nov 2009 http nlp stanford edu ir book html htmledition feature selectionchi2 feature selection 1 html ref e sub 1 0 sub n p c 1 p t 0 where n is the total number of documents in the collection cluster internal labeling cluster internal labeling selects labels that only depend on the contents of the cluster of interest no comparison is made with the other clusters cluster internal labeling can use a variety of methods such as finding terms that occur frequently in the centroid or finding the document that lies closest to the centroid centroid labels main article vector space model a frequently used model in the field of information retrieval is the vector space model which represents documents as vectors the entries in the vector correspond to terms in the vocabulary binary vectors have a value of 1 if the term is present within a particular document and 0 if it is absent many vectors make use of weights that reflect the importance of a term in a document and or the importance of the term in a document collection for a particular cluster of documents we can calculate the centroid by finding the arithmetic mean of all the document vectors if an entry in the centroid vector has a high value then the corresponding term occurs frequently within the cluster these terms can be used as a label for the cluster one downside to using centroid labeling is that it can pick up words like place and word that have a high frequency in written text but have little relevance to the contents of the particular cluster contextualized centroid labels a simple cost effective way of overcoming the above limitation is to embed the centroid terms with the highest weight in a graph structure that provides a context for their interpretation and selection ref francois role moahmed nadif http dl acm org citation cfm id 2574675 beyond cluster labeling semantic interpretation of clusters contents using a graph representation knowledge based systems volume 56 january 2014 141 155 ref in this approach a term term co occurrence matrix referred as math t k math is first built for each cluster math s k math each cell represents the number of times term math i math co occurs with term math j math within a certain window of text a sentence a paragraph etc in a second stage a similarity matrix math t k sim math is obtained by multiplying math t k math with its transpose we have math t k sim t k t k t sim ij math being the dot product of two normalized vectors math tilde t i math and math tilde t j math math t sim ij math denotes the cosine similarity between terms math i math and math j math the so obtained math t k sim math can then be used as the weighted adjacency matrix of a term similarity graph the centroid terms are part of this graph and they thus can be interpreted and scored by inspecting the terms that surround them in the graph title labels an alternative to centroid labeling is title labeling here we find the document within the cluster that has the smallest euclidean distance to the centroid and use its title as a label for the cluster one advantage to using document titles is that they provide additional information that would not be present in a list of terms however they also have the potential to mislead the user since one document might not be representative of the entire cluster external knowledge labels cluster labeling can be done indirectly using external knowledge such as pre categorized knowledge such as the one of wikipedia ref david carmel haggai roitman naama zwerdling http portal acm org citation cfm doid 1571941 1571967 enhancing cluster labeling using wikipedia sigir 2009 139 146 ref in such methods a set of important cluster text features are first extracted from the cluster documents these features then can be used to retrieve the weighted k nearest categorized documents from which candidates for cluster labels can be extracted the final step involves the ranking of such candidates suitable methods are such that are based on a voting or a fusion process which is determined using the set of categorized documents and the original cluster features combining several cluster labelers the cluster labels of several different cluster labelers can be further combined to obtain better labels for example linear regression can be used to learn an optimal combination of labeler scores ref david carmel haggai roitman naama zwerdling http portal acm org citation cfm doid 1571941 1571967 enhancing cluster labeling using wikipedia sigir 2009 139 146 ref a more sophisticated technique is based on a wikt fusion fusion approach and analysis of the cluster labels decision stability of various labelers ref haggai roitman shay hummel michal shmueli scheuer http dl acm org citation cfm id 2609465 a fusion approach to cluster labeling sigir 2014 883 886 ref external links http nlp stanford edu ir book html htmledition hierarchical clustering 1 html hierarchical clustering http www cs cmu edu callan papers dgo06 puck pdf automatically labeling hierarchical clusters references references defaultsort cluster labeling category information retrieval techniques'
b'external links date november 2013 use dmy dates date june 2013 recommender systems file collaborative filtering gif 300px thumb this image shows an example of predicting of the user s rating using collaborative software collaborative filtering at first people rate different items like videos images games after that the system is making prediction s about user s rating for an item which the user hasn t rated yet these predictions are built upon the existing ratings of other users who have similar ratings with the active user for instance in our case the system has made a prediction that the active user won t like the video collaborative filtering cf is a technique used by recommender system s ref name handbook francesco ricci and lior rokach and bracha shapira http www inf unibz it ricci papers intro rec sys handbook pdf introduction to recommender systems handbook recommender systems handbook springer 2011 pp 1 35 ref collaborative filtering has two senses a narrow one and a more general one ref name recommender cite web title beyond recommender systems helping people help each other url http www grouplens org papers pdf rec sys overview pdf publisher addison wesley accessdate 16 january 2012 page 6 year 2001 last1 terveen first1 loren last2 hill first2 will authorlink1 loren terveen ref in the newer narrower sense collaborative filtering is a method of making automatic prediction s filtering about the interests of a user by collecting preferences or taste sociology taste information from crowdsourcing many users collaborating the underlying assumption of the collaborative filtering approach is that if a person a has the same opinion as a person b on an issue a is more likely to have b s opinion on a different issue x than to have the opinion on x of a person chosen randomly for example a collaborative filtering recommendation system for television tastes could make predictions about which television show a user should like given a partial list of that user s tastes likes or dislikes ref http www redbeemedia com insights integrated approach tv vod recommendations an integrated approach to tv vod recommendations webarchive url https web archive org web 20120606225352 http www redbeemedia com insights integrated approach tv vod recommendations date 6 june 2012 ref note that these predictions are specific to the user but use information gleaned from many users this differs from the simpler approach of giving an average non specific score for each item of interest for example based on its number of vote s in the more general sense collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration among multiple agents viewpoints data sources etc ref name recommender applications of collaborative filtering typically involve very large data sets collaborative filtering methods have been applied to many different kinds of data including sensing and monitoring data such as in mineral exploration environmental sensing over large areas or multiple sensors financial data such as financial service institutions that integrate many financial sources or in electronic commerce and web applications where the focus is on user data etc the remainder of this discussion focuses on collaborative filtering for user data although some of the methods and approaches may apply to the other major applications as well introduction the internet growth growth of the internet has made it much more difficult to effectively information extraction extract useful information from all the available online information the overwhelming amount of data necessitates mechanisms for efficient information filtering collaborative filtering is one of the techniques used for dealing with this problem the motivation for collaborative filtering comes from the idea that people often get the best recommendations from someone with tastes similar to themselves collaborative filtering encompasses techniques for matching people with similar interests and making recommender system recommendations on this basis collaborative filtering algorithms often require 1 users active participation 2 an easy way to represent users interests and 3 algorithms that are able to match people with similar interests typically the workflow of a collaborative filtering system is a user expresses his or her preferences by rating items e g books movies or cds of the system these ratings can be viewed as an approximate representation of the user s interest in the corresponding domain the system matches this user s ratings against other users and finds the people with most similar tastes with similar users the system recommends items that the similar users have rated highly but not yet being rated by this user presumably the absence of rating is often considered as the unfamiliarity of an item a key problem of collaborative filtering is how to combine and weight the preferences of user neighbors sometimes users can immediately rate the recommended items as a result the system gains an increasingly accurate representation of user preferences over time methodology file collaborative filtering in recommender systems jpg thumb collaborative filtering in recommender systems collaborative filtering systems have many forms but many common systems can be reduced to two steps look for users who share the same rating patterns with the active user the user whom the prediction is for use the ratings from those like minded users found in step 1 to calculate a prediction for the active user this falls under the category of user based collaborative filtering a specific application of this is the user based k nearest neighbor algorithm nearest neighbor algorithm alternatively item item collaborative filtering item based collaborative filtering users who bought x also bought y proceeds in an item centric manner build an item item matrix determining relationships between pairs of items infer the tastes of the current user by examining the matrix and matching that user s data see for example the slope one item based collaborative filtering family another form of collaborative filtering can be based on implicit observations of normal user behavior as opposed to the artificial behavior imposed by a rating task these systems observe what a user has done together with what all users have done what music they have listened to what items they have bought and use that data to predict the user s behavior in the future or to predict how a user might like to behave given the chance these predictions then have to be filtered through business logic to determine how they might affect the actions of a business system for example it is not useful to offer to sell somebody a particular album of music if they already have demonstrated that they own that music relying on a scoring or rating system which is averaged across all users ignores specific demands of a user and is particularly poor in tasks where there is large variation in interest as in the recommendation of music however there are other methods to combat information explosion such as www web search and data clustering types memory based this approach uses user rating data to compute the similarity between users or items this is used for making recommendations this was an early approach used in many commercial systems it s effective and easy to implement typical examples of this approach are neighbourhood based cf and item based user based top n recommendations for example in user based approaches the value of ratings user u gives to item i is calculated as an aggregation of some similar users rating of the item math r u i operatorname aggr u prime in u r u prime i math where u denotes the set of top n users that are most similar to user u who rated item i some examples of the aggregation function includes math r u i frac 1 n sum limits u prime in u r u prime i math math r u i k sum limits u prime in u operatorname simil u u prime r u prime i math math r u i bar r u k sum limits u prime in u operatorname simil u u prime r u prime i bar r u prime math where k is a normalizing factor defined as math k 1 sum u prime in u operatorname simil u u prime math and math bar r u math is the average rating of user u for all the items rated by u the neighborhood based algorithm calculates the similarity between two users or items produces a prediction for the user by taking the weighted average of all the ratings similarity computation between items or users is an important part of this approach multiple measures such as pearson product moment correlation coefficient pearson correlation and cosine similarity vector cosine based similarity are used for this the pearson correlation similarity of two users x y is defined as math operatorname simil x y frac sum limits i in i xy r x i bar r x r y i bar r y sqrt sum limits i in i xy r x i bar r x 2 sum limits i in i xy r y i bar r y 2 math where i sub xy sub is the set of items rated by both user x and user y the cosine based approach defines the cosine similarity between two users x and y as ref name breese1999 john s breese david heckerman and carl kadie http uai sis pitt edu displayarticledetails jsp mmnu 1 smnu 2 article id 231 proceeding id 14 empirical analysis of predictive algorithms for collaborative filtering 1998 webarchive url https web archive org web 20131019134152 http uai sis pitt edu displayarticledetails jsp mmnu 1 smnu 2 article id 231 proceeding id 14 date 19 october 2013 ref math operatorname simil x y cos vec x vec y frac vec x cdot vec y vec x times vec y frac sum limits i in i xy r x i r y i sqrt sum limits i in i x r x i 2 sqrt sum limits i in i y r y i 2 math the user based top n recommendation algorithm uses a similarity based vector model to identify the k most similar users to an active user after the k most similar users are found their corresponding user item matrices are aggregated to identify the set of items to be recommended a popular method to find the similar users is the locality sensitive hashing which implements the nearest neighbor search nearest neighbor mechanism in linear time the advantages with this approach include the explainability of the results which is an important aspect of recommendation systems easy creation and use easy facilitation of new data content independence of the items being recommended good scaling with co rated items there are also several disadvantages with this approach its performance decreases when sparsity data gets sparse which occurs frequently with web related items this hinders the scalability of this approach and creates problems with large datasets although it can efficiently handle new users because it relies on a data structure adding new items becomes more complicated since that representation usually relies on a specific vector space adding new items requires inclusion of the new item and the re insertion of all the elements in the structure model based models are developed using data mining machine learning algorithms to find patterns based on training data these are used to make predictions for real data there are many model based cf algorithms these include bayesian networks cluster analysis clustering models latent semantic indexing latent semantic models such as singular value decomposition probabilistic latent semantic analysis multiple multiplicative factor latent dirichlet allocation and markov decision process based models ref name suetal2009 xiaoyuan su taghi m khoshgoftaar http www hindawi com journals aai 2009 421425 a survey of collaborative filtering techniques advances in artificial intelligence archive 2009 ref this approach has a more holistic goal to uncover latent factors that explain observed ratings ref http research yahoo com pub 2435 factor in the neighbors scalable and accurate collaborative filtering webarchive url https web archive org web 20101023032716 http research yahoo com pub 2435 date 23 october 2010 ref most of the models are based on creating a classification or clustering technique to identify the user based on the training set the number of the parameters can be reduced based on types of principal component analysis principal component analysis there are several advantages with this paradigm it handles the sparsity better than memory based ones this helps with scalability with large data sets it improves the prediction performance it gives an intuitive rationale for the recommendations the disadvantages with this approach are in the expensive model building one needs to have a tradeoff between prediction performance and scalability one can lose useful information due to reduction models a number of models have difficulty explaining the predictions hybrid a number of applications combine the memory based and the model based cf algorithms these overcome the limitations of native cf approaches and improve prediction performance importantly they overcome the cf problems such as sparsity and loss of information however they have increased complexity and are expensive to implement ref cite journal url http www sciencedirect com science article pii s0020025512002587 doi 10 1016 j ins 2012 04 012 volume 208 title kernel mapping recommender system algorithms journal information sciences pages 81 104 ref usually most commercial recommender systems are hybrid for example the google news recommender system ref cite web url http dl acm org citation cfm id 1242610 title google news personalization publisher ref application on social web unlike the traditional model of mainstream media in which there are few editors who set guidelines collaboratively filtered social media can have a very large number of editors and content improves as the number of participants increases services like reddit youtube and last fm are typical example of collaborative filtering based media ref http www readwriteweb com archives collaborative filtering social web php collaborative filtering lifeblood of the social web ref one scenario of collaborative filtering application is to recommend interesting or popular information as judged by the community as a typical example stories appear in the front page of reddit as they are voted up rated positively by the community as the community becomes larger and more diverse the promoted stories can better reflect the average interest of the community members another aspect of collaborative filtering systems is the ability to generate more personalized recommendations by analyzing information from the past activity of a specific user or the history of other users deemed to be of similar taste to a given user these resources are used as user profiling and helps the site recommend content on a user by user basis the more a given user makes use of the system the better the recommendations become as the system gains data to improve its model of that user problems a collaborative filtering system does not necessarily succeed in automatically matching content to one s preferences unless the platform achieves unusually good diversity and independence of opinions one point of view will always dominate another in a particular community as in the personalized recommendation scenario the introduction of new users or new items can cause the cold start problem as there will be insufficient data on these new entries for the collaborative filtering to work accurately in order to make appropriate recommendations for a new user the system must first learn the user s preferences by analysing past voting or rating activities the collaborative filtering system requires a substantial number of users to rate a new item before that item can be recommended challenges data sparsity in practice many commercial recommender systems are based on large datasets as a result the user item matrix used for collaborative filtering could be extremely large and sparse which brings about the challenges in the performances of the recommendation one typical problem caused by the data sparsity is the cold start problem as collaborative filtering methods recommend items based on users past preferences new users will need to rate sufficient number of items to enable the system to capture their preferences accurately and thus provides reliable recommendations similarly new items also have the same problem when new items are added to system they need to be rated by substantial number of users before they could be recommended to users who have similar tastes with the ones rated them the new item problem does not limit the content based filtering content based recommendation because the recommendation of an item is based on its discrete set of descriptive qualities rather than its ratings scalability as the numbers of users and items grow traditional cf algorithms will suffer serious scalability problems citation needed date april 2013 for example with tens of millions of customers math o m math and millions of items math o n math a cf algorithm with the complexity of math n math is already too large as well many systems need to react immediately to online requirements and make recommendations for all users regardless of their purchases and ratings history which demands a higher scalability of a cf system large web companies such as twitter use clusters of machines to scale recommendations for their millions of users with most computations happening in very large memory machines ref name twitterwtf pankaj gupta ashish goel jimmy lin aneesh sharma dong wang and reza bosagh zadeh http dl acm org citation cfm id 2488433 wtf the who to follow system at twitter proceedings of the 22nd international conference on world wide web ref synonyms synonyms refers to the tendency of a number of the same or very similar items to have different names or entries most recommender systems are unable to discover this latent association and thus treat these products differently for example the seemingly different items children movie and children film are actually referring to the same item indeed the degree of variability in descriptive term usage is greater than commonly suspected citation needed date september 2013 the prevalence of synonyms decreases the recommendation performance of cf systems topic modeling like the latent dirichlet allocation technique could solve this by grouping different words belonging to the same topic citation needed date september 2013 gray sheep gray sheep refers to the users whose opinions do not consistently agree or disagree with any group of people and thus do not benefit from collaborative filtering black sheep are the opposite group whose idiosyncratic tastes make recommendations nearly impossible although this is a failure of the recommender system non electronic recommenders also have great problems in these cases so black sheep is an acceptable failure shilling attacks in a recommendation system where everyone can give the ratings people may give lots of positive ratings for their own items and negative ratings for their competitors it is often necessary for the collaborative filtering systems to introduce precautions to discourage such kind of manipulations diversity and the long tail collaborative filters are expected to increase diversity because they help us discover new products some algorithms however may unintentionally do the opposite because collaborative filters recommend products based on past sales or ratings they cannot usually recommend products with limited historical data this can create a rich get richer effect for popular products akin to positive feedback this bias toward popularity can prevent what are otherwise better consumer product matches a wharton school of the university of pennsylvania wharton study details this phenomenon along with several ideas that may promote diversity and the long tail ref cite journal last1 fleder first1 daniel first2 kartik last2 hosanagar title blockbuster culture s next rise or fall the impact of recommender systems on sales diversity journal management science date may 2009 url http papers ssrn com sol3 papers cfm abstract id 955984 doi 10 1287 mnsc 1080 0974 ref several collaborative filtering algorithms have been developed to promote diversity and the long tail by recommending novel unexpected ref cite journal last1 adamopoulos first1 panagiotis first2 alexander last2 tuzhilin title on unexpectedness in recommender systems or how to better expect the unexpected journal acm transactions on intelligent systems and technology date january 2015 url http dl acm org citation cfm id 2559952 doi 10 1145 2559952 ref and serendipitous items ref cite journal last1 adamopoulos first1 panagiotis title beyond rating prediction accuracy on new perspectives in recommender systems journal proceedings of the 7th acm conference on recommender systems date october 2013 url http dl acm org citation cfm id 2508073 doi 10 1145 2507157 2508073 ref innovations prose date may 2012 new algorithms have been developed for cf as a result of the netflix prize cross system collaborative filtering where user profiles across multiple recommender systems are combined in a privacy preserving manner robust collaborative filtering where recommendation is stable towards efforts of manipulation this research area is still active and not completely solved ref cite web url http dl acm org citation cfm id 1297240 title robust collaborative filtering doi 10 1145 1297231 1297240 publisher portal acm org date 19 october 2007 accessdate 2012 05 15 ref see also div col 3 attention profiling mark up language attention profiling mark up language apml cold start collaborative model collaborative search engine collective intelligence customer engagement delegative democracy the same principle applied to voting rather than filtering enterprise bookmarking firefly website a defunct website which was based on collaborative filtering filter bubble preference elicitation recommendation system relevance information retrieval reputation system robust collaborative filtering similarity search slope one social translucence div col end references reflist 30em external links http www grouplens org papers pdf rec sys overview pdf beyond recommender systems helping people help each other page 12 2001 http www prem melville com publications recommender systems eml2010 pdf recommender systems prem melville and vikas sindhwani in encyclopedia of machine learning claude sammut and geoffrey webb eds springer 2010 http arxiv org abs 1203 4487 recommender systems in industrial contexts phd thesis 2012 including a comprehensive overview of many collaborative recommender systems http ieeexplore ieee org xpls abs all jsp arnumber 1423975 toward the next generation of recommender systems a survey of the state of the art and possible extensions dead link date june 2016 bot medic cbignore bot medic adomavicius g and tuzhilin a ieee transactions on knowledge and data engineering 06 2005 https web archive org web 20060527214435 http ectrl itc it home laboratory meeting download p5 l herlocker pdf evaluating collaborative filtering recommender systems http www doi org doi http dx doi org 10 1145 963770 963772 10 1145 963770 963772 http www grouplens org publications html grouplens research papers http www cs utexas edu users ml papers cbcf aaai 02 pdf content boosted collaborative filtering for improved recommendations prem melville raymond j mooney and ramadass nagarajan proceedings of the eighteenth national conference on artificial intelligence aaai 2002 pp nbsp 187 192 edmonton canada july 2002 http agents media mit edu projects html a collection of past and present information filtering projects including collaborative filtering at mit media lab http www ieor berkeley edu goldberg pubs eigentaste pdf eigentaste a constant time collaborative filtering algorithm ken goldberg theresa roeder dhruv gupta and chris perkins information retrieval 4 2 133 151 july 2001 http downloads hindawi com journals aai 2009 421425 pdf a survey of collaborative filtering techniques su xiaoyuan and khoshgortaar taghi m http dl acm org citation cfm id 1242610 google news personalization scalable online collaborative filtering abhinandan das mayur datar ashutosh garg and shyam rajaram international world wide web conference proceedings of the 16th international conference on world wide web https web archive org web 20101023032716 http research yahoo com pub 2435 factor in the neighbors scalable and accurate collaborative filtering yehuda koren transactions on knowledge discovery from data tkdd 2009 http webpages uncc edu asaric ismis09 pdf rating prediction using collaborative filtering http www cis upenn edu ungar cf recommender systems http www2 sims berkeley edu resources collab berkeley collaborative filtering authority control defaultsort collaborative filtering category collaboration category collaborative software category collective intelligence category information retrieval techniques category recommender systems category social information processing'
b'orphan date february 2009 a communication engine is a tool that sends user requests to several other communication protocols and or database s and aggregates the results into a single list or displays them according to their source communication engines enable users to enter communication account authorization once and access several communication avenues simultaneously communication engines operate on the premise that the world wide web is too large for any one engine to index it all and that more productive results can be obtained by combining the results from several engines dynamically this may save the user from having to use multiple engines separately category information retrieval techniques category computing terminology web stub'
b'refimprove date march 2009 globalize date june 2015 a policy framework is a logical structure that is established to organize policy documentation into groupings and categories that make it easier for employees to find and understand the contents of various policy documents policy frameworks can also be used to help in the planning and development of the policies for an organization principles state services commission of new zealand outlines eleven principles of policy framework as below ref http www ssc govt nz documents policy framework for government htm ref availability government departments should make information available easily widely and equitably to the people of new zealand except where reasons preclude such availability as specified in legislation coverage government departments should make the following information increasingly available on an electronic basis all published material or material already in the public domain all policies that could be released publicly all information created or collected on a statutory basis subject to commercial sensitivity and privacy considerations all documents that the public may be required to complete corporate documentation in which the public would be interested pricing a free dissemination of government held information is appropriate where dissemination to a target audience is desirable for a public policy purpose or a charge to recover the cost of dissemination is not feasible or cost effective b pricing to recover the cost of dissemination is appropriate where there is no particular public policy reason to disseminate the information and a charge to recover the cost of dissemination is both feasible and cost effective c pricing to recover the cost of transformation is appropriate where pricing to recover the cost of dissemination is appropriate and there is an avoidable cost involved in transforming the information from the form in which it is held into a form preferred by the recipient where it is feasible and cost effective to recover in addition to the cost of dissemination d pricing to recover the full costs of information production and dissemination is appropriate where the information is created for the commercial purpose of sale at a profit and to do so would not breach the other pricing principles ownership government held information created or collected by any person employed or engaged by the crown is a strategic resource owned by the government as a steward on behalf of the public stewardship government departments are stewards of government held information and it is their responsibility to implement good information management collection government departments should only collect information for specified public policy operational business or legislative purposes copyright information created by departments is subject to crown copyright but where wide dissemination is desirable the crown should permit use of its copyrights subject to acknowledgement of source preservation government held information should be preserved only where a public business need legislative or policy requirement or a historical or archival reason exists quality the key qualities underpinning government held information include accuracy relevancy timeliness consistency and collection without bias so that the information supports the purposes for which it is collected integrity the integrity of government held information will be achieved when all guarantees and conditions surrounding the information are met the principles are clear and communicated any situation relating to government held information is handled openly and consistently those affected by changes to government held information are consulted on those changes those charged as independent guardians of the public interest e g the ombudsman have confidence in the ability of departments to manage the information well there are minimum exceptions to the principles privacy the principles of the privacy act 1993 apply references reflist defaultsort policy framework category information retrieval techniques category government of new zealand'
b'for webometrics ranking of world universities webometrics ranking of world universities refimprove date may 2014 the science of webometrics also cybermetrics tries to measure the world wide web to get knowledge about the number and types of hyperlink s structure of the world wide web and usage patterns according to bj\xc3\xb6rneborn and ingwersen 2004 the definition of webometrics is the study of the quantitative aspects of the construction and use of information resources structures and technologies on the web drawing on bibliometrics bibliometric and informetrics informetric approaches the term webometrics was first coined by almind and ingwersen 1997 a second definition of webometrics has also been introduced the study of web based content with primarily quantitative methods for social science research goals using techniques that are not specific to one field of study thelwall 2009 which emphasizes the development of applied methods for use in the wider social sciences the purpose of this alternative definition was to help publicize appropriate methods outside of the information science discipline rather than to replace the original definition within information science similar scientific fields are bibliometrics informetrics scientometrics virtual ethnography and web mining file site based graph relationship jpg thumb site based graph relationship the idea was taken from paper web communicator creation costs sharing problem as a cooperative game sfn mazalov pechnikov chirkov chuyko 2010 p 189 one relatively straightforward measure is the web impact factor wif introduced by ingwersen 1998 the wif measure may be defined as the number of web pages in a web site receiving links from other web sites divided by the number of web pages published in the site that are accessible to the crawler however the use of wif has been disregarded due to the mathematical artifacts derived from power law distributions of these variables other similar indicators using size of the institution instead of number of webpages have been proved more useful see also altmetrics impact factor pagerank network mapping search engine webometrics ranking of world universities references references bibliography cite journal author1 tomas c almind author2 peter ingwersen lastauthoramp yes year 1997 title informetric analyses on the world wide web methodological approaches to webometrics journal journal of documentation volume 53 issue 4 pages 404 426 doi 10 1108 eum0000000007205 cite journal author1 lennart bj\xc3\xb6rneborn author2 peter ingwersen lastauthoramp yes year 2004 title toward a basic framework for webometrics journal journal of the american society for information science and technology volume 55 issue 14 pages 1216 1227 url http www3 interscience wiley com cgi bin abstract 109594194 abstract doi 10 1002 asi 20077 cite journal author peter ingwersen year 1998 title the calculation of web impact factors journal journal of documentation volume 54 issue 2 pages 236 243 doi 10 1108 eum0000000007167 cite journal author1 mike thelwall author2 liwen vaughan author3 lennart bj\xc3\xb6rneborn year 2005 title webometrics journal annual review of information science and technology volume 39 pages 81 135 doi 10 1002 aris 1440390110 cite book author mike thelwall title introduction to webometrics quantitative web research for the social sciences publisher morgan claypool year 2009 isbn 978 1 59829 993 9 url http www morganclaypool com doi abs 10 2200 s00176ed1v01y200903icr004 cite conference url http www mtas ru upload library ubs30112 pdf title web communicator creation costs sharing problem as a cooperative game in russian last1 mazalov first1 vladimir last2 pechnikov first2 andrey last3 chirkov first3 alexandr last4 chuyko first4 julia year 2010 booktitle \xd1\x83\xd0\xbf\xd1\x80\xd0\xb0\xd0\xb2\xd0\xbb\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd0\xb1\xd0\xbe\xd0\xbb\xd1\x8c\xd1\x88\xd0\xb8\xd0\xbc\xd0\xb8 \xd1\x81\xd0\xb8\xd1\x81\xd1\x82\xd0\xb5\xd0\xbc\xd0\xb0\xd0\xbc\xd0\xb8 \xd1\x81\xd0\xb1\xd0\xbe\xd1\x80\xd0\xbd\xd0\xb8\xd0\xba \xd1\x82\xd1\x80\xd1\x83\xd0\xb4\xd0\xbe\xd0\xb2 pages location ref harv cite web url http eprints rclis org 7554 title webometrics ten years of expansion last ingwersen first peter year 2006 accessdate 2013 ref harv category world wide web category information science category information retrieval techniques web stub pt webometria'
b'use mdy dates date may 2016 use american english date may 2016 file global summit to end sexual violence in conflict 14203190979 jpg thumb a sign suggesting the use of a timetoact hashtag at a 2014 conference a hashtag is a type of label or tag metadata metadata tag used on social networking service social network and microblogging services which makes it easier for users to find messages with a specific theme or content users create and use hashtags by placing the number sign hash character code code also known as the number sign or pound sign in front of a word or unspaced phrase either in the main text of a message or at the end searching for that hashtag will yield each message that has been tagged with it a hashtag archive is consequently collected into a single stream under the same hashtag ref cite journal last chang first hsia ching last2 iyer first2 hemalata title trends in twitter hashtag applications design features for value added dimensions to future library catalogues url http muse jhu edu article 485537 journal library trends volume 61 issue 1 pages 248 258 doi 10 1353 lib 2012 0024 issn 1559 0682 ref for example on the photo sharing photo sharing service instagram the hashtag bluesky allows users to find all the posts that have been tagged using that hashtag because of its widespread use hashtag was added to the oxford english dictionary in june 2014 ref cite web title hashtag added to the oed but isn t a hash pound nor number sign url http www theregister co uk 2014 06 13 hashtag added to the oed work the register date june 13 2014 ref ref cite web title new words notes june 2014 url http public oed com the oed today recent updates to the oed june 2014 update new words notes june 2014 work oxford english dictionary date june 2014 ref the term hashtag can also refer to the hash symbol itself when used in the context of a hashtag ref cite web title oxford english dictionary hash url http www oed com view entry 389023 eid301493073 work oxford english dictionary date june 2014 ref origin and use the number sign pound sign or number sign hash symbol was often used in information technology to highlight a special meaning it should be noted that the words pound sign in the uk refer specifically to currency \xc2\xa3 extended ascii character 156 and not weight in 1970 for example the number sign was used to denote immediate address mode in the assembly language of the pdp 11 ref cite web url https programmer209 wordpress com 2011 08 03 the pdp 11 assembly language title pdp 11 assembly language publisher programmer209 wordpress com date august 3 2011 accessdate august 25 2014 ref when placed next to a symbol or a number in 1978 brian kernighan and dennis ritchie used in the c programming language c programming language for special keywords that had to be processed first by the c preprocessor ref cite book title the c programming language authors b w kernighan d ritchie publisher prentice hall year 1978 pages 86 and 207 isbn 0 13 110163 3 ref since before the invention of the hashtag the pound sign has been called the hash symbol in some countries outside of north america ref cite book last1 bourke first1 jane title communication technology resource book date 2004 publisher ready ed publications pages 19 url https books google com books id gpnbtmxzpiic lpg pa19 dq hash 20key 20telephone pg pa19 v onepage q hash f false accessdate november 7 2014 isbn 978 1 86397 585 8 ref ref cite book last1 hargraves first1 orin title mighty fine words and smashing expressions making sense of transatlantic english date 2003 publisher oxford univ press location oxford u a isbn 978 0 19 515704 8 pages 33 260 url https books google com books id dutdk93cq9uc lpg pa260 dq hash 20telephone pg pa260 v onepage q hash 20mark f false ref the pound sign appeared and was used by people within internet relay chat irc networks to label groups and topics ref channel scope section 2 2 rfc 2811 ref channels or topics that are available across an entire irc network are prefixed with a hash symbol as opposed to those local to a server which use an ampersand ref cite ietf title internet relay chat protocol rfc 1459 sectionname channels section 1 3 page last1 oikarinen first1 jarkko authorlink1 jarkko oikarinen last2 reed first2 darren authorlink2 year 1993 month may publisher internet engineering task force ietf accessdate june 3 2014 ref the use of the pound sign in irc inspired ref cite web url http www cmu edu homepage computing 2014 summer originstory shtml title originstory publisher carnegie mellon university date august 29 2014 ref chris messina open source advocate chris messina to propose a similar system to be used on twitter to tag topics of interest on the microblogging network ref cite news url http www nytimes com 2011 06 12 fashion hashtags a new way for tweets cultural studies html r 1 pagewanted all title twitter s secret handshake work the new york times date june 10 2011 accessdate july 26 2011 author parker ashley ref he posted the first hashtag on twitter quote 1 how do you feel about using pound for groups as in barcamp msg author chris messina source factoryjoe august 23 2007 ref cite web url https twitter com factoryjoe statuses 223115412 title twitter post author chris messina factoryjoe date august 23 2007 3 25 pm ref width 50 align center messina s suggestion to use the hashtag was not adopted by twitter but the practice took off after hashtags were widely used in tweets relating to the 2007 san diego forest fires in southern california ref http mashable com 2013 10 08 what is hashtag what is hashtag mashable 8 october 2013 ref ref https factoryjoe com 2007 10 22 twitter hashtags for emergency coordination and disaster relief ref according to messina he suggested use of the hashtag to make it easy for lay users to search for content and find specific relevant updates they are for people who do not have the technological knowledge to navigate the site therefore the hashtag was created organically by twitter users as a way to categorize messages ref cite journal last scott first kate date 2015 05 01 title the pragmatics of hashtags inference and conversational style on twitter url http www sciencedirect com science article pii s037821661500096x journal journal of pragmatics volume 81 pages 8 20 doi 10 1016 j pragma 2015 03 015 ref internationally the hashtag became a practice of writing style for twitter posts during the 2009 2010 iranian election protests twitter users inside and outside iran used both english and persian language persian language hashtags in communications during the events ref cite news title the story of the hashtag began with iranians url http www dw de \xd8\xad\xda\xa9\xd8\xa7\xdb\x8c\xd8\xaa \xd9\x87\xd8\xb4\xd8\xaa\xda\xaf\xdb\x8c \xda\xa9\xd9\x87 \xd8\xa7\xdb\x8c\xd8\xb1\xd8\xa7\xd9\x86\xdb\x8c\xd8\xa7\xd9\x86 \xd8\xa2\xd8\xba\xd8\xa7\xd8\xb2 \xda\xa9\xd8\xb1\xd8\xaf\xd9\x86\xd8\xaf g 18012627 accessdate march 12 2015 publisher deutsche welle persian date 2009 ref the first published use of the term hash tag was in a blog post by stowe boyd hash tags twitter groupings ref cite web url http stoweboyd com post 39877198249 hash tags twitter groupings title stowe boyd hash tags twitter groupings publisher stoweboyd com date accessdate september 19 2013 ref on august 26 2007 according to lexicographer ben zimmer chair of the american dialect society s new words committee beginning july 2 2009 ref cite web title twitter makes hashtags more useful url http techcrunch com 2009 07 02 twitter makes hashtags more useful accessdate december 27 2015 ref twitter began to hyperlink all hashtags in tweets to twitter search results for the hashtagged word and for the standard spelling of commonly misspelled words in 2010 twitter introduced twitter trending topics trending topics on the twitter front page displaying hashtags that are rapidly becoming popular twitter has an algorithm to tackle attempts to spamming spam the trending list and ensure that hashtags trend naturally ref cite web url http www allisayis com the secret of twitters trending hashtags with insight and tips title the secret of twitter s trending hashtags with insight and tips publisher allisayis com date accessdate december 3 2014 ref although the hashtag started out most popularly on twitter as the main social media platform for this use the use has extended to other social media sites including instagram facebook flickr tumblr and google ref cite web url http www cnn com 2013 06 12 tech social media facebook hashtags index html title facebook finally gets hashtags cnn com last mashable first by christina warren website cnn access date 2016 05 16 ref in china microblogs sina weibo and tencent weibo use a double hashtag hashname format since the lack of spacing between chinese characters necessitates a closing tag in contrast when using chinese characters and orthographies with similar spacing conventions on twitter users must insert spacing before and after the hashtagged element e g \xe6\x88\x91 \xe7\x88\xb1 \xe4\xbd\xa0 instead of \xe6\x88\x91 \xe7\x88\xb1\xe4\xbd\xa0 ref cite news last1 martin first1 rick title twitter rolls out hashtag support for japanese korean chinese and russian url https www techinasia com twitter hashtag languages accessdate march 5 2015 publisher tech in asia date july 13 2011 ref or insert a zero width non joiner character before and after the hashtagged element to retain a linguistically natural appearance such as \xe6\x88\x91 \xe7\x88\xb1\xe4\xbd\xa0 ref cite news last1 international services team title right to left languages on twitter url https blog twitter com 2012 right to left languages on twitter accessdate march 5 2015 publisher twitter date april 5 2012 ref style on microblogging or social networking sites hashtags can be inserted anywhere within a sentence either preceding it following it as a postscript or being included as a word within the sentence e g it is sunny today the quantity of hashtags used in a post or tweet is just as important as the types of hashtags used it is currently considered acceptable to tag a post once when contributing to a specific conversation two hashtags are considered acceptable when adding a location to the conversation three hashtags are seen by some as the absolute maximum and any contribution exceeding this risks raising the ire of the community ref cite web title what is a hashtag url http www hashtags org how to history what is a hashtag publisher hashtags org accessdate february 22 2014 ref as well as frustrating other users the misuse of hashtags can lead to account suspensions twitter warns that adding hashtags to unrelated tweets or repeated use of the same hashtag without adding to a conversation could cause an account to be filtered from search or even suspended ref cite web title the twitter rules url https support twitter com groups 56 policies violations topics 236 twitter rules policies articles 18311 the twitter rules publisher twitter inc accessdate february 22 2014 ref failed verification date august 2014 jimmy fallon and justin timberlake performed a sketch parodying the often misused and misunderstood usage of hashtags on late night with jimmy fallon in september 2013 ref cite web author the tonight show starring jimmy fallon url https www youtube com watch v 57dzamaouxa title hashtag with jimmy fallon justin timberlake late night with jimmy fallon publisher youtube date september 24 2013 accessdate august 25 2014 ref function file seguir hashtags png upright 1 3 right thumb search bar in the header of a social networking site searching for most recent posts containing the hashtag science hashtags are mostly used in unmoderated ad hoc discussion forums any combination of characters led by a hash symbol is a hashtag and any hashtag if promoted by enough individuals can trend and attract more individual users to discussion on twitter when a hashtag becomes extremely popular it will appear in the trending topics area of a user s homepage the trending topics can be organized by geographic area or by all of twitter hashtags are neither registered nor controlled by any one user or group of users they cannot be retired from public usage meaning that any given hashtag can theoretically be used in perpetuity they do not contain any set definitions meaning that a single hashtag can be used for any number of purposes as chosen by those who make use of them hashtags intended for discussion of a particular event tend to use an obscure wording to avoid being caught up with generic conversations on similar subjects such as a cake festival using cakefestival rather than simply cake however this can also make it difficult for topics to become trending topics because people often use different spelling or words to refer to the same topic in order for topics to trend there has to be a consensus whether silent or stated that the hashtag refers to that specific topic hashtags also function as beacons in order for users to find and follow subscribe or list organize into public contact lists other users of similar interest in recent years broadcasters such as channel 4 have employed the hashtag during the airing of programmes such as first dates and the undateables research has shown that audience numbers go up when individuals can be interactive by tweeting while viewing a programme on tv hashtags can be used on the social network instagram by posting a picture and hashtagging it with its subject as an example a photo of oneself and a friend posted to the social network can be hashtagged bffl or friends instagram has banned certain hashtags some because they are too generic such as photography iphone iphoneography and therefore do not fulfill a purpose they have also blocked hashtags that can be linked to illegal activities such as drug use ref cite web url http www bbc co uk news technology 24842750 title instagram banned hashtags date november 7 2013 publisher bbc co uk accessdate november 25 2013 ref the ban against certain hashtags has a consequential role in the way that particular subaltern communities are built and maintained on instagram despite instagram s content policies users are finding creative ways of maintaining their practices and ultimately circumventing censorship ref olszanowski m 2014 feminist self imaging and instagram tactics of circumventing sensorship sic hide y visual communication quarterly 21 1 83 95 retrieved february 8 2015 from http www tandfonline com doi abs 10 1080 15551393 2014 928154 vnggt7df 7ff 7f ref hashtags are also used informally to express context around a given message with no intent to categorize the message for later searching sharing or other reasons one of the functions of the hashtag is to serve as a reflexive meta commentary which contributes to the idea of how written communication in new media can be paralleled to how pragmatic methodology is applied to speech ref cite web url http www linguistics fi julkaisut sky2014 wikstrom pdf title srynotfunny communicative functions of hashtags on twitter last wilkstr\xc3\xb6m first peter date 2014 work sky journal of linguistics publisher access date may 15 2016 ref this can help express contextual cues or offer more depth to the information or message that appears with the hashtag my arms are getting darker by the minute toomuchfaketan another function of the hashtag can be used to express personal feelings and emotions for example with it s monday excited sarcasm in which the adjectives are directly indicating the emotions of the speaker it can also be used as a disclaimer of the information that the hashtag accompanies as in breaking us gdp growth is back kidding in this case the hashtag provides an essential piece of information in which the meaning of the utterance is changed entirely by the disclaimer hashtag this may also be conveyed with sarcasm as in the previous example self mockery is another informal function of the hashtag used by writers as in this tweet feeling great about myself till i met an old friend who now races at the master s level yup there s today s lessoninhumility where the informality of the hashtag provides commentary on the tweet itself ref name 0 cite web url http www skase sk volumes jtl28 pdf doc 05 pdf title the hashtag a new word or a new rule last caleffi first paola maria date website skase journal of theoretical linguistics publisher access date ref other uses the feature has been added to other non short message oriented services such as the user comment systems on youtube and gawker media in the case of the latter hashtags for blog comments and directly submitted comments are used to maintain a more constant rate of user activity even when paid employees are not logged into the website ref cite web url http gawker com 5382267 anarchy in the machine welcome to gawkers open forums title anarchy in the machine welcome to gawker s open forums author gabriel snyder publisher gawker date october 15 2009 3 25 pm ref ref cite web url http www niemanlab org 2009 10 got a tip gawker media opens tag pages to masses expecting chaos title got a tip gawker media opens tag pages to masses expecting chaos author zachary m seward publisher nieman journalism lab date october 15 2009 8 a m ref real time search aggregators such as the former google real time search also support hashtags in syndicated posts meaning that hashtags inserted into twitter posts can be hyperlinked to incoming posts falling under that same hashtag this has further enabled a view of the river of twitter posts that can result from search terms or hashtags citation needed date september 2014 uses broadcast media the use of hashtags has extended to television nsmdns a concept that began rising in prominence in the early 2010s broadcasters may display a hashtag as an on screen digital on screen graphic bug encouraging viewers to participate in a backchannel of discussion via social media prior to during or after the program television commercial s have sometimes contained hashtags for similar purposes ref cite web url http www tvguide com news new tv screen 1032111 aspx title new to your tv screen twitter hashtags date april 21 2011 3 25 pm author michael schneider publisher tv guide ref hashtag bugs appear on either corner of the screen or they may appear at the end of an advertisement ref cite web url http mashable com 2012 12 03 mcdonalds tv ad twitter hashtag title mcdonald s releases first tv ad with twitter hashtag date dec 3 2012 author todd wasserman publisher mashable ref while personalities associated with broadcasts such as hosts and correspondents also promote their corporate or personal twitter usernames in order to receive mentions and replies to posts usage of related or branded hashtags alongside twitter usernames e g the ed show edshow as well as ed schultz edshow is increasingly encouraged as a microblogging style in order to trend the hashtag and hence the discussion topic in twitter and other search engines broadcasters also make use of such a style in order to index select posts for live broadcast chloe sladden twitter s director of media partnerships identified two types of television formatted usage of hashtags hashtags which identify a series being broadcast i e it s always sunny in philadelphia sunnyfx and instantaneous temporary hashtags issued by television personalities to gauge topical responses from viewers during broadcasts ref cite web url http www fastcompany com 1747437 twitter tv hashtag tips twitters own expert title twitter tv hashtag tips from twitter s own expert author gregory ferenstein date april 15 2011 publisher fast company ref some have speculated that hashtags might take the place of or co exist with the nielsen ratings nielsen television ratings system ref cite web url http www ibtimes com twitter chatter correlates tv ratings good or bad news nielsen 1144311 title twitter chatter correlates with tv ratings but is that good or bad news for nielsen work international business times date march 22 2013 accessdate september 19 2013 ref an example of trending temporary hashtags garnering viewers during broadcasts is observed on the tonight show with jimmy fallon a variety talk show on nbc every wednesday fallon hosts a segment on his show called tonight show hashtags which engages viewers by inviting them via twitter to post humorous stories based on a specific hashtag topic such as whydidisaythat worstfirstdate to onetimeinclass reflecting on funny experiences in daily life by using hashtags fallon creates a sense of community and solidarity among his viewers and draws a wider range of viewers through an online platform while they watch a classic non interactive television program because of its popularity the tonight show hashtags are usually the most tweeted hashtag on twitter which promotes the show by engaging viewers with a lighthearted subject and simple hashtags fallon can gauge topical responses from viewers during broadcasts and also use the hashtags to brand his show citation needed date april 2016 the increased usage of hashtags as brand promotion devices has been compared to the promotion of branded index term keywords by aol in the late 1990s and early 2000s as such keywords were also promoted at the end of television commercials and series episodes ref cite web url http techcrunch com 2012 06 10 twitter hashtag pages aol keywords title twitter s hashtag pages could be the new aol keywords but better author ryan lawler date june 10 2012 publisher techcrunch ref the late night television comedy game show midnight with chris hardwick on comedy central features a daily game entitled hashtag wars in which three comedians compete against one another to come up with phrases based on a given hashtag theme some hashtags have become famous worldwide for instance the slogan je suis charlie which was first used on twitter as the hashtag jesuischarlie and iamcharlie to indicate solidarity with charlie hebdo offices attacked in paris spread to the internet at large purchasing since february 2013 twitter and american express have collaborated to enable users to pay for discounted goods online by tweeting a special hashtag ref cite news first kelly last heather title twitter and amex let you pay with a hashtag date february 12 2013 url http edition cnn com 2013 02 11 tech social media twitter hashtag purchases work cnn accessdate november 25 2013 ref american express members can sync their card with twitter and pay for offers by tweeting american express tweets a response to the member that confirms the purchase ref cite web url https sync americanexpress com twitter index title sync with twitter publisher amex sync accessdate november 25 2013 ref event promotion file occupy for rights jpg thumb stencil graffiti promoting the hashtag occupyforrights organized real world events have used hashtags and ad hoc lists for discussion and promotion among participants hashtags are used as beacons by event participants in order to find each other both on twitter and in many cases during actual physical events companies and advocacy organizations have taken advantage of hashtag based discussions for promotion of their products services or campaigns political protests and campaigns in the early 2010s such as occupy wall street occupywallstreet and 2011 libyan civil war libyafeb17 have been organized around hashtags or have made extensive usage of hashtags for the promotion of discussion consumer complaints hashtags are often used by consumers on social media platforms in order to complain about the customer service experience with large companies the term bashtag has been created to describe situations in which a user refers to a corporate social media hashtag in order to criticise the company or to tell others about poor customer service for example in january 2012 mcdonald s created the mcdstories hashtag so that customers could share positive experiences about the restaurant chain but the marketing effort was cancelled after two hours when mcdonald s received numerous complaint tweets rather than the positive stories they were anticipating ref cite news first alexis last akwagyiram title are twitter and facebook changing the way we complain date may 17 2012 url http www bbc co uk news uk 18081651 work bbc news accessdate june 12 2012 ref sentiment analysis the use of hashtags also reveals what feelings or sentiment an author attaches to a statement this can range from the obvious where a hashtag directly describes the state of mind to the less obvious for example words in hashtags are the strongest predictor of whether or not a statement is sarcasm sarcastic ref cite journal last maynard title who cares about sarcastic tweets investigating the impact of sarcasm on sentiment analysis journal proceedings of the conference on language resources and evaluation year 2014 ref a difficult artificial intelligence ai problem ref http www huffingtonpost com entry power yourself with viral marketing become a hashtag us 57bf13e6e4b06384eb3e7f1d dxrywr9zcw30rizfr ref sports the youtuber spencer fc used the hashtag for the name and crest of his youtube based association football team hashtag united in popular culture during the 2011 canadian leaders debates april 2011 canadian party leader debate jack layton then leader of the new democratic party of canada new democratic party referred to conservative party of canada conservative prime minister stephen harper s crime policies as a hashtag fail presumably fail ref cite news url http www theglobeandmail com news politics jack laytons debatable hashtag fail article576224 title jack layton s debatable hashtag fail author anna mehler paperny publisher the globe and mail date april 13 2011 6 00 am edt ref ref cite news url http www cbc ca news politics canadavotes2011 story 2011 04 13 cv debate twitter html title canadians atwitter throughout debate date april 13 2011 3 25 pm publisher cbc news ref the term hashtag hip hop music rap coined by kanye west ref cite web url http blogs villagevoice com music 2010 11 the ten best qu php title the ten best quotes from kanye west s epic hot 97 interview with funkmaster flex author zach baron publisher the village voice date november 3 2010 ref was developed in the 2010s to describe a style of rapping which according to rizoh of the houston press uses three main ingredients a metaphor a pause and a one word punch line often placed at the end of a rhyme ref cite web url http blogs houstonpress com rocks 2011 07 a brief history of hashtag rap php title a brief history of hashtag rap author rizoh publisher houston press date july 7 2011 at 9 00 am ref rappers nicki minaj big sean drake rapper drake and lil wayne are credited with the popularization of hashtag rap while the style has been criticized by ludacris the lonely island ref cite web url http www tucsonweekly com therange archives 2013 05 22 the lonely island puts hashtag rap in its place looking at you drake title the lonely island puts hashtag rap in its place looking at you drake author david mendez date may 22 2013 at 11 43 am publisher tucson weekly ref and various music writers ref cite web url http www joplinglobe com enjoy x1666506743 jeremiah tucker hashtag rap is 2010s lamest trend title jeremiah tucker hashtag rap is 2010 s lamest trend author jeremiah tucker date december 17 2010 publisher joplin globe ref on september 13 2013 a hashtag twitteripo appeared in the headline of a the new york times new york times front page article regarding twitter s initial public offering ref cite web title twitter nickbilton my first byline on a1 of the \xe2\x80\xa6 url https twitter com nickbilton status 378534272962793472 photo 1 accessdate september 14 2013 ref bird s eye foods released in 2014 a shaped mashed potato food that included forms of symbols and hashtags called mashtags ref cite web title birds eye launches mashtags social media potato shapes url http www thegrocer co uk fmcg birds eye launches mashtags potato shapes 354514 article work the grocer ref in may 2014 twitter users began using the hashtag yesallwomen yesallwomen to raise awareness about personal experiences of sexism and violence against women ref name nytimes cite news last medina first jennifer title campus killings set off anguished conversation about the treatment of women work the new york times accessdate september 23 2014 date may 27 2014 url http www nytimes com 2014 05 27 us campus killings set off anguished conversation about the treatment of women html ref us r 0 ref in september 2014 in response to the blame the victim public reactions to videotaped footage of nfl player ray rice assaulting his then fianc\xc3\xa9e janay palmer in the elevator of an atlantic city casino beverly gooden shared on twitter her own story of domestic abuse using the hashtag whyistayed and encouraged others to share theirs ref cite news work today title whyistayed woman behind ray rice inspired hashtag writes to past self other abuse victims author gooden beverly date september 10 2014 url http www today com news whyistayed woman behind ray rice inspired hashtag writes past self 1d80139011 ref ref cite news work the leonard lopate show authors lopate leonard gooden beverly title whyistayed date september 10 2014 ref hashtags have been used verbally to make a humorous point in informal conversations ref http www macmillandictionary com dictionary british hashtag ref such as i m hashtag confused ref name 0 in august 2012 british journalist tom meltzer reported in the guardian about a new hand gesture that mimicked the hashtag sometimes called the finger hashtag in which both hands form a peace sign the v sign peace sign and then the fingers are crossed to form the symbol of a hashtag ref cite web url https www theguardian com technology shortcuts 2012 aug 01 how to say hashtag fingers title how to say hashtag with your fingers work the guardian author tom meltzer date august 1 2012 accessdate march 20 2014 ref the emerging gesture was reported about in wired magazine wired by nimrod kamer ref cite web url http www wired co uk news archive 2013 03 06 hashtags title finger hashtags work wired magazine wired author nimrod kamer date march 2013 accessdate march 20 2014 ref and during 2013 it was seen on tv as used by jimmy fallon and on the colbert report among other programs ref cite web url http www dailydot com lol finger hashtag jimmy fallon twitter title i invented finger hashtags and i regret nothing work the daily dot author nimrod kamer date february 26 2014 accessdate march 20 2014 ref writing in 2015 paola maria caleff considered this usage a fad but noted that people talking the way that they write was a consequence of computer mediated communication ref name 0 adaptations hashflags in 2010 twitter introduced hashflags during the 2010 world cup in south africa ref cite web author url http www ryanseacrest com 2010 06 11 twitter supports world cup fever with hashflags title twitter supports world cup fever with hashflags publisher ryanseacrest com date june 11 2010 accessdate august 5 2015 archiveurl https web archive org web 20101129201517 http ryanseacrest com 2010 06 11 twitter supports world cup fever with hashflags archivedate november 29 2010 ref they reintroduced the feature on june 10 2014 in time for the 2014 world cup in brazil ref cite web url http howto digidefen se twitter what are hashflags php title what are hashflags publisher howto digidefen se date june 10 2014 accessdate august 25 2014 ref ref cite web author ben woods url http thenextweb com twitter 2014 06 10 twitter brings back hashflags just time world cup 2014 kick title twitter brings back hashflags just in time for world cup 2014 kick off publisher thenextweb com date june 10 2014 accessdate august 25 2014 ref and then again on april 10 2015 with uk political party logos for the 2015 uk general election ref cite web title twitter just launched election hashflags url http www bbc co uk newsbeat article 32249518 twitter just launched election hashflags website bbc news accessdate april 15 2015 ref when a user tweets a hashtag consisting of the three letter country code of any of the 32 countries represented in the tournament twitter automatically embeds a flag emoticon for that country cashtags in 2009 stocktwits used ticker symbol s preceded by the dollar sign to create cashtags ref name wong2012 cite journal author wong matthew title vcs and start ups pin their hopes on pinterest date 2012 08 17 work the wall street journal url http blogs wsj com venturecapital 2012 08 17 vcs and start ups pin their hopes on pinterest accessdate 2013 05 28 ref ref name taylor2012 cite journal author taylor colleen title howard lindzon on why he sold his twitter stock and the hijack of stocktwits cashtags tctv date 2012 07 01 publisher techcrunch url http techcrunch com 2012 08 01 howard lindzon on why he sold his twitter stock and the hijack of stocktwits cashtags tctv accessdate 2013 05 09 ref in july 2012 twitter adapted the hashtag style to make company ticker symbols preceded by the dollar sign clickable as in apple inc aapl a method that twitter dubbed the cashtag ref cite web last kim first erin url http money cnn com 2012 07 31 technology twitter cashtag title twitter unveils cashtags to track stock symbols jul 31 2012 publisher money cnn com date july 31 2012 accessdate november 12 2013 ref ref cite web author url http www theverge com 2012 7 30 3205284 twitter stock ticker cashtag links official title twitter makes stock symbol cashtag links official following and publisher the verge date july 30 2012 accessdate november 12 2013 ref this is intended to allow users to search posts discussing companies and their stocks this is also used for discussion of currency fluctuations on twitter eg using usdgbp or usdgbp when mentioning the us dollar s level expressed in pounds sterling references reflist 30em external links commons category hashtags tools wmflabs org hashtags search artandfeminism wikipedia internal hashtag search engine for hashtags used in edit summaries microblogging online social networking web syndication authority control category hashtags category 2010s slang category collective intelligence category computer jargon category information retrieval techniques category knowledge representation category metadata category reference category social media category web 2 0 category twitter'
b'subject indexing is the act of describing or document classification classifying a document by index term s or other symbols in order to indicate what the document is aboutness about to summarize its content media and publishing content or to increase its findability in other words it is about identifying and describing the subject documents subject of documents indexes are constructed separately on three distinct levels terms in a document such as a book objects in a collection such as a library and documents such as books and articles within a field of knowledge subject indexing is used in information retrieval especially to create bibliographic index es to retrieve documents on a particular subject examples of academic indexing services are zentralblatt math chemical abstracts and pubmed the index terms were mostly assigned by experts but author keywords are also common the process of indexing begins with any analysis of the subject of the document the indexer must then identify terms which appropriately identify the subject either by extracting words directly from the document or assigning words from a controlled vocabulary ref name lancaster2003a f w lancaster 2003 indexing and abstracting in theory and practise third edition london facet isbn 1 85604 482 3 page 6 ref the terms in the index are then presented in a systematic order indexers must decide how many terms to include and how specific the terms should be together this gives a depth of indexing subject analysis the first step in indexing is to decide on the subject matter of the document in manual indexing the indexer would consider the subject matter in terms of answer to a set of questions such as does the document deal with a specific product condition or phenomenon ref name chowdhury2004 g g chowdhury 2004 introduction to modern information retrieval third edition london facet isbn 1 85604 480 7 page 71 ref as the analysis is influenced by the knowledge and experience of the indexer it follows that two indexers may analyze the content differently and so come up with different index terms this will impact on the success of retrieval automatic vs manual subject analysis automatic indexing follows set processes of analyzing frequencies of word patterns and comparing results to other documents in order to assign to subject categories this requires no understanding of the material being indexed this therefore leads to more uniform indexing but this is at the expense of the true meaning being interpreted a computer program will not understand the meaning of statements and may therefore fail to assign some relevant terms or assign incorrectly human indexers focus their attention on certain parts of the document such as the title abstract summary and conclusions as analyzing the full text in depth is costly and time consuming ref name lancaster2003b f w lancaster 2003 indexing and abstracting in theory and practice third edition london facet isbn 1 85604 482 3 page 24 ref an automated system takes away the time limit and allows the entire document to be analyzed but also has the option to be directed to particular parts of the document term selection the second stage of indexing involves the translation of the subject analysis into a set of keyword search index terms this can involve extracting from the document or assigning from a controlled vocabulary with the ability to conduct a full text search widely available many people have come to rely on their own expertise in conducting information searches and full text search has become very popular subject indexing and its experts professional indexers catalogers and librarians remains crucial to information organization and retrieval these experts understand controlled vocabularies and are able to find information that cannot be located by full text search the cost of expert analysis to create subject indexing is not easily compared to the cost of hardware software and labor to manufacture a comparable set of full text fully searchable materials with new web applications that allow every user to annotate documents social tagging has gained popularity especially in the web ref name voss2007 cite conference last1 voss first1 jakob title tagging folksonomy co renaissance of manual indexing booktitle proceedings of the international symposium of information science pages 234 254 year 2007 arxiv cs 0701072 ref one application of indexing the index publishing book index remains relatively unchanged despite the information revolution extraction derived indexing extraction indexing involves taking words directly from the document it uses natural language and lends itself well to automated techniques where word frequencies are calculated and those with a frequency over a pre determined threshold are used as index terms a stop list containing common words such as the and would be referred to and such stop words would be excluded as index terms automated extraction indexing may lead to loss of meaning of terms by indexing single words as opposed to phrases although it is possible to extract commonly occurring phrases it becomes more difficult if key concepts are inconsistently worded in phrases automated extraction indexing also has the problem that even with use of a stop list to remove common words some frequent words may not be useful for allowing discrimination between documents for example the term glucose is likely to occur frequently in any document related to diabetes therefore use of this term would likely return most or all the documents in the database post co ordinated indexing where terms are combined at the time of searching would reduce this effect but the onus would be on the searcher to link appropriate terms as opposed to the information professional in addition terms that occur infrequently may be highly significant for example a new drug may be mentioned infrequently but the novelty of the subject makes any reference significant one method for allowing rarer terms to be included and common words to be excluded by automated techniques would be a relative frequency approach where frequency of a word in a document is compared to frequency in the database as a whole therefore a term that occurs more often in a document than might be expected based on the rest of the database could then be used as an index term and terms that occur equally frequently throughout will be excluded another problem with automated extraction is that it does not recognise when a concept is discussed but is not identified in the text by an indexable keyword ref name lamb2008 j lamb 2008 http www indexers org uk index php id 463 human or computer produced indexes online sheffield society of indexers accessed 15 january 2009 ref assignment indexing an alternative is assignment indexing where index terms are taken from a controlled vocabulary this has the advantage of controlling for synonym s as the preferred term is indexed and synonyms or related terms direct the user to the preferred term this means the user can find articles regardless of the specific term used by the author and saves the user from having to know and check all possible synonyms ref name tenopir c tenopir 1999 human or automated indexing is important library journal 124 18 pages 34 38 ref it also removes any confusion caused by homograph s by inclusion of a qualifying term a third advantage is that it allows the linking of related terms whether they are linked by hierarchy or association e g an index entry for an oral medication may list other oral medications as related terms on the same level of the hierarchy but would also link to broader terms such as treatment assignment indexing is used in manual indexing to improve inter indexer consistency as different indexers will have a controlled set of terms to choose from controlled vocabularies do not completely remove inconsistencies as two indexers may still interpret the subject differently ref name chowdhury2004 index presentation the final phase of indexing is to present the entries in a systematic order this may involve linking entries in a pre coordinated index the indexer determines the order in which terms are linked in an entry by considering how a user may formulate their search in a post coordinated index the entries are presented singly and the user can link the entries through searches most commonly carried out by computer software post coordination results in a loss of precision in comparison to pre coordination ref name bodoff1998 d bodoff and a kambil 1998 partial coordination i the best of pre coordination and post coordination journal of the american society for information science 49 14 1254 1269 ref depth of indexing indexers must make decisions about what entries should be included and how many entries an index should incorporate the depth of indexing describes the thoroughness of the indexing process with reference to exhaustivity and specificity ref name cleveland2001 d b cleveland and a d cleveland 2001 introduction to indexing and abstracting 3rd ed englewood libraries unlimited inc isbn 1 56308 641 7 page 105 ref exhaustivity an exhaustive index is one which lists all possible index terms greater exhaustivity gives a higher recall information retrieval recall or more likelihood of all the relevant articles being retrieved however this occurs at the expense of precision information retrieval precision this means that the user may retrieve a larger number of irrelevant documents or documents which only deal with the subject in little depth in a manual system a greater level of exhaustivity brings with it a greater cost as more man hours are required the additional time taken in an automated system would be much less significant at the other end of the scale in a selective index only the most important aspects are covered ref name weinberg1999 b h weinberg 1990 exhaustivity of indexes books journals and electronic full texts summary of a workshop presented at the 1999 asi annual conference key words 7 5 pages 1 ref recall is reduced in a selective index as if an indexer does not include enough terms a highly relevant article may be overlooked therefore indexers should strive for a balance and consider what the document may be used they may also have to consider the implications of time and expense specificity the specificity describes how closely the index terms match the topics they represent ref name anderson1997 j d anderson 1997 http www niso org publications tr guidelines for indexes and related information retrieval devices online bethesda maryland niso press 10 december 2008 ref an index is said to be specific if the indexer uses parallel descriptors to the concept of the document and reflects the concepts precisely ref name cleveland2001b d b cleveland and a d cleveland 2001 introduction to indexing and abstracting 3rd ed englewood libraries unlimited inc isbn 1 56308 641 7 page 106 ref specificity tends to increase with exhaustivity as the more terms you include the narrower those terms will be indexing theory birger hj\xc3\xb8rland hj\xc3\xb8rland 2011 ref hj\xc3\xb8rland birger 2011 the importance of theories of knowledge indexing and information retrieval as an example journal of the american society for information science and technology 62 1 72 77 ref found that theories of indexing is at the deepest level connected to different theories of knowledge rationalist theories of indexing such as ranganathan s theory suggest that subjects are constructed logically from a fundamental set of categories the basic method of subject analysis is then analytic synthetic to isolate a set of basic categories analysis and then to construct the subject of any given document by combining those categories according to some rules synthesis empiricist theories of indexing are based on selecting similar documents based on their properties in particular by applying numerical statistical techniques historicist and hermeneutical theories of indexing suggest that the subject of a given document is relative to a given discourse or domain why the indexing should reflect the need of a particular discourse or domain according to hermeneutics is a document always written and interpreted from particular horizon the same is the case with systems of knowledge organization and with all users searching such systems any question put to such a system is put from a particular horizon all those horizons may be more or less in consensus or in conflict to index a document is to try to contribute to the retrieval of relevant documents by knowing about those different horizons pragmatic and critical theories of indexing such as hj\xc3\xb8rland 1997 ref hj\xc3\xb8rland b 1997 information seeking and subject representation an activity theoretical approach to information science westport london greenwood press ref is in agreement with the historicist point of view that subjects are relative to specific discourses but emphasizes that subject analysis should support given goals and values and should consider the consequences of indexing one way or another these theories believe that indexing cannot be neutral and that it is a wrong goal to try to index in a neutral way indexing is an act and computer based indexing is acting according to the programmers intentions acts serve human goals libraries and information services also serve human goals why their indexing should be done in a way that supports these goals as much as possible at a first glance this looks strange because the goals of libraries and information services is to identify any document or piece of information nonetheless is any specific way of indexing always supporting some kind of uses at the expense of other the documents to be indexed intend to serve some specific purposes in a community basically the indexing should intend serving the same purposes primary and secondary documents and information services are parts of the same overall social system in such a system different theories epistemologies worldviews etc may be at play and users need to be able to orient themselves and to navigate among those different views this calls for a mapping of the different epistemologies in the field and classification of the single document into such a map excellent examples of such different paradigms and their consequences for indexing and classification systems are provided in the domain of art by \xc3\xb8rom 2003 ref \xc3\xb8rom anders 2003 knowledge organization in the domain of art studies history transition and conceptual changes knowledge organization 30 3 4 128 143 ref and in music by abrahamsen 2003 ref abrahamsen knut t 2003 indexing of musical genres an epistemological perspective knowledge organization 30 3 4 144 169 ref the core of indexing is as stated by rowley farrow ref name rowley2000 rowley j e farrow j 2000 organizing knowledge an introduction to managing access to information 3rd alderstot gower publishing company ref to evaluate a papers contribution to knowledge and index it accordingly or with the words of hj\xc3\xb8rland 1992 ref hj\xc3\xb8rland birger 1992 the concept of subject in information science journal of documentation 48 2 172 200 http iva dk bh core 20concepts 20in 20lis 1992jdoc 5fsubject pdf ref 1997 to index its informative potentials in order to achieve good consistent indexing the indexer must have a thorough appreciation of the structure of the subject and the nature of the contribution that the document is making to the advancement of knowledge rowley farrow 2000 ref name rowley2000 p nbsp 99 see also commons category subject indexing indexing and abstracting service document classification metadata overcategorization thomas of ireland a medieval pioneer in subject indexing references reflist cite book author fugman robert year 1993 title subject analysis and indexing theoretical foundation and practical advice place frankfurt main publisher index verlag cite journal author frohmann b year 1990 title rules of indexing a critique of mentalism in information retrieval theory journal journal of documentation volume 46 issue 2 pages 81 101 doi 10 1108 eb026855 category index publishing category information science category information retrieval techniques'
b'image musicalignment beethovenfifth png thumb 300px right first theme of symphony no 5 by ludwig van beethoven in a sheet music audio and piano roll representation the red bidirectional arrows indicate the aligned time positions of corresponding note events in the different representations music can be described and represented in many different ways including sheet music symbolic representations and audio recordings for each of these representations there may exist different versions that correspond to the same musical work the general goal of music alignment sometimes also referred to as music synchronization is to automatically link the various data streams thus interrelating the multiple information sets related to a given musical work more precisely music alignment is taken to mean a procedure which for a given position in one representation of a piece of music determines the corresponding position within another representation ref name mueller15 chapter3fmp springer cite book last m\xc3\xbcller first meinard title music synchronization in fundamentals of music processing chapter 3 pages 115 166 url http www music processing de publisher springer year 2015 doi 10 1007 978 3 319 21945 5 isbn 978 3 319 21944 8 ref in the figure on the right such an alignment is visualized by the red bidirectional arrows such synchronization results form the basis for novel interfaces that allow users to access search and browse musical content in a convenient way ref name dammftckm12 dml ijdl cite journal last1 damm first1 david last2 fremerey first2 christian last3 thomas first3 verena last4 clausen first4 michael last5 kurth first5 frank last6 m\xc3\xbcller first6 meinard title a digital library framework for heterogeneous music collections from document acquisition to cross modal interaction url http link springer com article 10 1007 2fs00799 012 0087 y journal international journal on digital libraries special issue on music digital libraries volume 12 issue 2 3 year 2012 pages 53 71 doi 10 1007 s00799 012 0087 y ref ref name muellerckef10 sync isr cite journal last1 m\xc3\xbcller first1 meinard last2 clausen first2 michael last3 konz first3 verena last4 ewert first4 sebastian last5 fremerey first5 christian title a multimodal way of experiencing and exploring music url https www audiolabs erlangen de content 05 fau professor 00 mueller 03 publications 2010 muellerclausenkonzewertfremerey musicsynchronization isr pdf journal interdisciplinary science reviews isr volume 35 issue 2 year 2010 pages 138 153 doi 10 1179 030801810x12723585301110 ref basic procedure file musicalignment procedure png thumb 300px right overview of the processing pipeline of a typical music alignment procedure given two different music representations typical music alignment approaches proceed in two steps ref name mueller15 chapter3fmp springer in the first step the two representations are transformed into sequences of suitable features in general such feature representations need to find a compromise between two conflicting goals on the one hand features should show a large degree of robustness to variations that are to be left unconsidered for the task at hand on the other hand features should capture enough characteristic information to accomplish the given task for music alignment one often uses chroma feature chroma based features also called chromagram s or harmonic pitch class profiles pitch class profiles which capture harmonic and melodic characteristics of music while being robust to changes in timbre and instrumentation are being used in the second step the derived feature sequences have to be brought into temporal correspondence to this end techniques related to dynamic time warping dynamic time warping dtw or hidden markov model hidden markov models hmms are used to compute an optimal alignment between two given feature sequences related tasks music alignment and related synchronization tasks have been studied extensively within the field of music information retrieval in the following we give some pointers to related tasks depending upon the respective types of music representations one can distinguish between various synchronization scenarios for example audio alignment refers to the task of temporally aligning two different audio recordings of a piece of music similarly the goal of score audio alignment is to coordinate note events given in the score representation with audio data in the offline scenario the two data streams to be aligned are known prior to the actual alignment in this case one can use global optimization procedures such as dynamic time warping dynamic time warping dtw to find an optimal alignment in general it is harder to deal with scenarios where the data streams are to be processed online one prominent online scenario is known as score following where a musician is performing a piece according to a given musical score the goal is then to identify the currently played musical events depicted in the score with high accuracy and low latency ref cite journal last1 cont first1 arshia title a coupled duration focused architecture for real time music to score alignment journal ieee transactions on pattern analysis and machine intelligence volume 32 issue 6 year 2010 pages 974 987 issn 0162 8828 doi 10 1109 tpami 2009 106 ref ref cite journal last1 orio first1 nicola last2 lemouton first2 serge last3 schwarz first3 diemo title score following state of the art and new developments url http recherche ircam fr equipes temps reel suivi resources orio 2002 nime pdf journal proceedings of the international conference on new interfaces for musical expression nime date 2003 pages 36 41 ref in this scenario the score is known as a whole in advance but the performance is known only up to the current point in time in this context alignment techniques such as hidden markov models or particle filters have been employed where the current score position and tempo are modeled in a statistical sense ref cite journal last1 duan first1 zhiyao last2 pardo first2 bryan journal proceedings of the ieee international conference on acoustics speech and signal processing icassp title a state space model for online polyphonic audio score alignment url http www ece rochester edu zduan resource duanpardo scorefollowing icassp11 pdf year 2011 pages 197 200 doi 10 1109 icassp 2011 5946374 ref ref cite journal last1 montecchio first1 nicola last2 cont first2 arshia title a unified approach to real time audio to score and audio to audio alignment using sequential montecarlo inference techniques url http articles ircam fr textes montecchio11a index pdf year 2011 pages 193 196 doi 10 1109 icassp 2011 5946373 ref as opposed to classical dtw such an online synchronization procedure inherently has a running time that is linear in the duration of the performed version however as a main disadvantage an online strategy is very sensitive to local tempo variations and deviations from the score once the procedure is out of sync it is very hard to recover and return to the right track a further online synchronization problem is known as pop music automation automatic accompaniment automatic accompaniment having a solo part played by a musician the task of the computer is to accompany the musician according to a given score by adjusting the tempo and other parameters in real time such systems were already proposed some decades ago ref cite journal last1 dannenberg first1 roger b title an on line algorithm for real time accompaniment journal proceedings of the international computer music conference icmc url http www cs cmu edu rbd papers icmc84accomp pdf date 1984 pages 193 198 ref ref cite journal last1 raphael first1 christopher title a probabilistic expert system for automatic musical accompaniment journal journal of computational and graphical statistics url http citeseerx ist psu edu viewdoc download doi 10 1 1 20 6559 rep rep1 type pdf year 2001 pages 487 512 ref ref cite journal last2 raphael first2 christopher year 2006 title music score alignment and computer accompaniment url http www cs cmu edu rbd papers accompaniment cacm 06 pdf journal communications of the acm volume 49 issue 8 pages 38 43 doi 10 1145 1145287 1145311 issn 0001 0782 last1 dannenberg first1 roger b ref references reflist category music information retrieval category music technology category musicology category information retrieval techniques'
b'the probabilistic relevance model ref citation author s e robertson and k s jones title relevance weighting of search terms publisher journal of the american society for information science pages 129 146 date may june 1976 url http portal acm org citation cfm id 106783 ref ref name robertson2009 cite journal author stephen robertson and hugo zaragoza title the probabilistic relevance framework bm25 and beyond date 2009 url http dl acm org citation cfm id 1704810 publisher found trends inf retr volume 3 issue 4 pages 333 389 doi 10 1561 1500000019 ref was devised by robertson and jones as a framework for statistical model probabilistic models to come it is a formalism of information retrieval useful to derive ranking function s used by search engine s and web search engine s in order to rank matching documents according to their relevance information retrieval relevance to a given search query it makes an estimation of the probability of finding if a document d sub j sub is relevant to a query q this model assumes that this probability of relevance depends on the query and document representations furthermore it assumes that there is a portion of all documents that is preferred by the user as the answer set for query q such an ideal answer set is called r and should maximize the overall probability of relevance to that user the prediction is that documents in this set r are relevant to the query while documents not present in the set are non relevant math sim d j q frac p r vec d j p bar r vec d j math related models there are some limitations to this framework that need to be addressed by further development there is no accurate estimate for the first run probabilities index terms are not weighted terms are assumed mutually independent to address these and other concerns there are some developed models from the probabilistic relevance framework the binary independence model for one as it is from the same author the most known derivative of this framework is the probabilistic relevance model bm25 okapi bm25 weighting scheme and its bm25f brother references reflist category information retrieval techniques category probabilistic models'
b'semantics latent semantic analysis lsa is a technique in natural language processing in particular distributional semantics of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms lsa assumes that words that are close in meaning will occur in similar pieces of text a matrix containing word counts per paragraph rows represent unique words and columns represent each paragraph is constructed from a large piece of text and a mathematical technique called singular value decomposition svd is used to reduce the number of rows while preserving the similarity structure among columns words are then compared by taking the cosine of the angle between the two vectors or the dot product between the unit vector normalizations of the two vectors formed by any two rows values close to 1 represent very similar words while values close to 0 represent very dissimilar words ref cite journal title latent semantic analysis author susan t dumais year 2005 doi 10 1002 aris 1440380105 journal annual review of information science and technology volume 38 pages 188 230 ref an information retrieval technique using latent semantic structure was patented in 1988 http patft uspto gov netacgi nph parser patentnumber 4839853 us patent 4 839 853 now expired by scott deerwester susan dumais george furnas richard harshman thomas landauer karen lochbaum and lynn streeter in the context of its application to information retrieval it is sometimes called latent semantic indexing latent semantic indexing lsi ref cite web url http lsa colorado edu title the latent semantic indexing home page ref overview occurrence matrix lsa can use a term document matrix which describes the occurrences of terms in documents it is a sparse matrix whose rows correspond to terminology terms and whose columns correspond to documents a typical example of the weighting of the elements of the matrix is tf idf term frequency inverse document frequency the weight of an element of the matrix is proportional to the number of times the terms appear in each document where rare terms are upweighted to reflect their relative importance this matrix is also common to standard semantic models though it is not necessarily explicitly expressed as a matrix since the mathematical properties of matrices are not always used rank lowering after the construction of the occurrence matrix lsa finds a low rank approximation ref markovsky i 2012 low rank approximation algorithms implementation applications springer 2012 isbn 978 1 4471 2226 5 page needed date january 2012 ref to the term document matrix there could be various reasons for these approximations the original term document matrix is presumed too large for the computing resources in this case the approximated low rank matrix is interpreted as an approximation a least and necessary evil the original term document matrix is presumed noisy for example anecdotal instances of terms are to be eliminated from this point of view the approximated matrix is interpreted as a de noisified matrix a better matrix than the original the original term document matrix is presumed overly sparse matrix sparse relative to the true term document matrix that is the original matrix lists only the words actually in each document whereas we might be interested in all words related to each document generally a much larger set due to synonymy the consequence of the rank lowering is that some dimensions are combined and depend on more than one term car truck flower 1 3452 car 0 2828 truck flower this mitigates the problem of identifying synonymy as the rank lowering is expected to merge the dimensions associated with terms that have similar meanings it also mitigates the problem with polysemy since components of polysemous words that point in the right direction are added to the components of words that share a similar meaning conversely components that point in other directions tend to either simply cancel out or at worst to be smaller than components in the directions corresponding to the intended sense derivation let math x math be a matrix where element math i j math describes the occurrence of term math i math in document math j math this can be for example the frequency math x math will look like this math begin matrix textbf d j downarrow textbf t i t rightarrow begin bmatrix x 1 1 dots x 1 n vdots ddots vdots x m 1 dots x m n end bmatrix end matrix math now a row in this matrix will be a vector corresponding to a term giving its relation to each document math textbf t i t begin bmatrix x i 1 dots x i n end bmatrix math likewise a column in this matrix will be a vector corresponding to a document giving its relation to each term math textbf d j begin bmatrix x 1 j vdots x m j end bmatrix math now the dot product math textbf t i t textbf t p math between two term vectors gives the correlation between the terms over the set of documents the matrix product math x x t math contains all these dot products element math i p math which is equal to element math p i math contains the dot product math textbf t i t textbf t p math math textbf t p t textbf t i math likewise the matrix math x t x math contains the dot products between all the document vectors giving their correlation over the terms math textbf d j t textbf d q textbf d q t textbf d j math now from the theory of linear algebra there exists a decomposition of math x math such that math u math and math v math are orthogonal matrix orthogonal matrices and math sigma math is a diagonal matrix this is called a singular value decomposition svd math begin matrix x u sigma v t end matrix math the matrix products giving us the term and document correlations then become math begin matrix x x t u sigma v t u sigma v t t u sigma v t v t t sigma t u t u sigma v t v sigma t u t u sigma sigma t u t u sigma 2 u t x t x u sigma v t t u sigma v t v t t sigma t u t u sigma v t v sigma t u t u sigma v t v sigma t sigma v t v sigma 2 v t end matrix math since math sigma sigma t math and math sigma t sigma math are diagonal we see that math u math must contain the eigenvector s of math x x t math while math v math must be the eigenvectors of math x t x math both products have the same non zero eigenvalues given by the non zero entries of math sigma sigma t math or equally by the non zero entries of math sigma t sigma math now the decomposition looks like this math begin matrix x u sigma v t textbf d j hat textbf d j downarrow downarrow textbf t i t rightarrow begin bmatrix x 1 1 dots x 1 n vdots ddots vdots x m 1 dots x m n end bmatrix hat textbf t i t rightarrow begin bmatrix begin bmatrix textbf u 1 end bmatrix dots begin bmatrix textbf u l end bmatrix end bmatrix cdot begin bmatrix sigma 1 dots 0 vdots ddots vdots 0 dots sigma l end bmatrix cdot begin bmatrix begin bmatrix textbf v 1 end bmatrix vdots begin bmatrix textbf v l end bmatrix end bmatrix end matrix math the values math sigma 1 dots sigma l math are called the singular values and math u 1 dots u l math and math v 1 dots v l math the left and right singular vectors notice the only part of math u math that contributes to math textbf t i math is the math i textrm th math row let this row vector be called math hat textrm t t i math likewise the only part of math v t math that contributes to math textbf d j math is the math j textrm th math column math hat textrm d j math these are not the eigenvectors but depend on all the eigenvectors it turns out that when you select the math k math largest singular values and their corresponding singular vectors from math u math and math v math you get the rank math k math approximation to math x math with the smallest error frobenius norm this approximation has a minimal error but more importantly we can now treat the term and document vectors as a semantic space the row term vector math hat textbf t t i math then has math k math entries mapping it to a lower dimensional space dimensions these new dimensions do not relate to any comprehensible concepts they are a lower dimensional approximation of the higher dimensional space likewise the document vector math hat textbf d j math is an approximation in this lower dimensional space we write this approximation as math x k u k sigma k v k t math you can now do the following see how related documents math j math and math q math are in the low dimensional space by comparing the vectors math sigma k hat textbf d j math and math sigma k hat textbf d q math typically by vector space model cosine similarity comparing terms math i math and math p math by comparing the vectors math sigma k hat textbf t i math and math sigma k hat textbf t p math note that math hat textbf t math is now a column vector documents and term vector representations can be clustered using traditional clustering algorithms like k means using similarity measures like cosine given a query view this as a mini document and compare it to your documents in the low dimensional space to do the latter you must first translate your query into the low dimensional space it is then intuitive that you must use the same transformation that you use on your documents math hat textbf d j sigma k 1 u k t textbf d j math note here that the inverse of the diagonal matrix math sigma k math may be found by inverting each nonzero value within the matrix this means that if you have a query vector math q math you must do the translation math hat textbf q sigma k 1 u k t textbf q math before you compare it with the document vectors in the low dimensional space you can do the same for pseudo term vectors math textbf t i t hat textbf t i t sigma k v k t math math hat textbf t i t textbf t i t v k t sigma k 1 textbf t i t v k sigma k 1 math math hat textbf t i sigma k 1 v k t textbf t i math applications the new low dimensional space typically can be used to compare the documents in the low dimensional space data clustering document classification find similar documents across languages after analyzing a base set of translated documents cross language retrieval find relations between terms synonymy and polysemy given a query of terms translate it into the low dimensional space and find matching documents information retrieval find the best similarity between small groups of terms in a semantic way i e in a context of a knowledge corpus as for example in multi choice questions multiple choice question mcq answering model ref name alain2009 cite journal url http hal archives ouvertes fr docs 00 38 41 43 pdf elsa1 brm20 pdf format pdf title effect of tuned parameters on an lsa multiple choice questions answering model author1 alain lifchitz author2 sandra jhean larose author3 guy denhi\xc3\xa8re journal behavior research methods volume 41 issue 4 pages 1201 1209 year 2009 doi 10 3758 brm 41 4 1201 pmid 19897829 ref expand the feature space of machine learning text mining systems ref name galvez2017 cite journal url http www sciencedirect com science article pii s1877750317300091 title assessing the usefulness of online message board mining in automatic stock prediction systems author1 ramiro h g\xc3\xa1lvez author2 agust\xc3\xadn gravano journal journal of computational science volume 19 pages 1877 7503 year 2017 doi 10 1016 j jocs 2017 01 001 ref synonymy and polysemy are fundamental problems in natural language processing synonymy is the phenomenon where different words describe the same idea thus a query in a search engine may fail to retrieve a relevant document that does not contain the words which appeared in the query for example a search for doctors may not return a document containing the word physicians even though the words have the same meaning polysemy is the phenomenon where the same word has multiple meanings so a search may retrieve irrelevant documents containing the desired words in the wrong meaning for example a botanist and a computer scientist looking for the word tree probably desire different sets of documents commercial applications lsa has been used to assist in performing prior art searches for patents ref name gerry2007 cite journal author gerry j elman title automated patent examination support a proposal journal biotechnology law report date october 2007 doi 10 1089 blr 2007 9896 volume 26 issue 5 pages 435 436 postscript bot inserted parameter either remove it or change its value to for the cite to end in a as necessary inconsistent citations ref applications in human memory the use of latent semantic analysis has been prevalent in the study of human memory especially in areas of free recall and memory search there is a positive correlation between the semantic similarity of two words as measured by lsa and the probability that the words would be recalled one after another in free recall tasks using study lists of random common nouns they also noted that in these situations the inter response time between the similar words was much quicker than between dissimilar words these findings are referred to as the semantic proximity effect ref cite journal url http psycnet apa org journals xlm 25 4 923 pdf format pdf title contextual variability and serial position effects in free recall author1 marc w howard author2 michael j kahana year 1999 ref when participants made mistakes in recalling studied items these mistakes tended to be items that were more semantically related to the desired item and found in a previously studied list these prior list intrusions as they have come to be called seem to compete with items on the current list for recall ref cite journal url https memory psych upenn edu files pubs zaroetal06 pdf format pdf title temporal associations and prior list intrusions in free recall author franklin m zaromb booktitle interspeech 2005 year 2006 display authors etal ref another model termed word association spaces was is also used in memory studies by collecting free association data from a series of experiments and which includes measures of word relatedness for over 72 000 distinct word pairs ref cite web last nelson first douglas title the university of south florida word association rhyme and word fragment norms url http w3 usf edu freeassociation intro html accessdate may 8 2011 ref implementation the singular value decomposition svd is typically computed using large matrix methods for example lanczos method s but may also be computed incrementally and with greatly reduced resources via a neural network like approach which does not require the large full rank matrix to be held in memory ref name genevi2005 cite conference url http www dcs shef ac uk genevieve gorrell webb pdf format pdf title generalized hebbian algorithm for latent semantic analysis author1 genevi\xc3\xa8ve gorrell author2 brandyn webb booktitle interspeech 2005 year 2005 ref a fast incremental low memory large matrix svd algorithm has recently been developed ref name brand2006 cite journal url http www merl com reports docs tr2006 059 pdf format pdf title fast low rank modifications of the thin singular value decomposition author matthew brand journal linear algebra and its applications volume 415 pages 20 30 year 2006 doi 10 1016 j laa 2005 07 021 ref http web mit edu wingated www resources html matlab and http radimrehurek com gensim python implementations of these fast algorithms are available unlike gorrell and webb s 2005 stochastic approximation brand s algorithm 2003 provides an exact solution in recent years progress has been made to reduce the computational complexity of svd for instance by using a parallel arpack algorithm to perform parallel eigenvalue decomposition it is possible to speed up the svd computation cost while providing comparable prediction quality ref cite journal doi 10 1109 iccsnt 2011 6182070 title a parallel implementation of singular value decomposition based on map reduce and parpack journal proceedings of 2011 international conference on computer science and network technology ref limitations some of lsa s drawbacks include the resulting dimensions might be difficult to interpret for instance in car truck flower \xe2\x86\xa6 1 3452 car 0 2828 truck flower the 1 3452 car 0 2828 truck component could be interpreted as vehicle however it is very likely that cases close to car bottle flower \xe2\x86\xa6 1 3452 car 0 2828 bottle flower will occur this leads to results which can be justified on the mathematical level but have no interpretable meaning in natural language lsa cannot capture polysemy i e multiple meanings of a word because each occurrence of a word is treated as having the same meaning due to the word being represented as a single point in space for example the occurrence of chair in a document containing the chair of the board and in a separate document containing the chair maker are considered the same the behavior results in the vector representation being an average of all the word s different meanings in the corpus which can make it difficult for comparison however the effect is often lessened due to words having a word sense disambiguation predominant sense throughout a corpus i e not all meanings are equally likely limitations of bag of words model bow where a text is represented as an unordered collection of words to address some of the limitation of bag of words model bow n gram multi gram dictionary can be used to find direct and indirect association as well as higher order statistics higher order co occurrence s among terms ref cite journal url http www translational medicine com content 12 1 324 title empirical study using network of semantically related associations in bridging the knowledge gap first1 vida last1 abedi first2 mohammed last2 yeasin first3 ramin last3 zand date 27 november 2014 publisher volume 12 issue 1 doi 10 1186 s12967 014 0324 9 pmid 25428570 pmc 4252998 journal journal of translational medicine ref the probabilistic model of lsa does not match observed data lsa assumes that words and documents form a joint normal distribution gaussian model ergodic hypothesis while a poisson distribution has been observed thus a newer alternative is probabilistic latent semantic analysis based on a multinomial distribution multinomial model which is reported to give better results than standard lsa ref name thomas1999 cite conference url http www cs brown edu people th papers hofmann uai99 pdf format pdf title probabilistic latent semantic analysis author thomas hofmann booktitle uncertainty in artificial intelligence year 1999 ref alternative methods semantic hashing in semantic hashing ref salakhutdinov ruslan and geoffrey hinton semantic hashing rbm 500 3 2007 500 ref documents are mapped to memory addresses by means of a neural network in such a way that semantically similar documents are located at nearby addresses deep learning deep neural network essentially builds a graphical model of the word count vectors obtained from a large set of documents documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document this way of extending the efficiency of hash coding to approximate matching is much faster than locality sensitive hashing which is the fastest current method latent semantic indexing latent semantic indexing lsi is an indexing and retrieval method that uses a mathematical technique called singular value decomposition svd to identify patterns in the relationships between the terminology term s and concept s contained in an unstructured collection of text lsi is based on the principle that words that are used in the same contexts tend to have similar meanings a key feature of lsi is its ability to extract the conceptual content of a text corpus body of text by establishing associations between those terms that occur in similar context language use context s ref name deerwester1988 deerwester s et al improving information retrieval with latent semantic indexing proceedings of the 51st annual meeting of the american society for information science 25 1988 pp 36 40 ref lsi is also an application of correspondence analysis a multivariate statistical technique developed by jean paul benz\xc3\xa9cri ref cite book author benz\xc3\xa9cri j p publisher dunod location paris france year 1973 title l analyse des donn\xc3\xa9es volume ii l analyse des correspondences ref in the early 1970s to a contingency table built from word counts in documents called latent semantic indexing because of its ability to correlate semantically related terms that are latent in a collection of text it was first applied to text at bellcore in the late 1980s the method also called latent semantic analysis lsa uncovers the underlying latent semantic structure in the usage of words in a body of text and how it can be used to extract the meaning of the text in response to user queries commonly referred to as concept searches queries or concept searches against a set of documents that have undergone lsi will return results that are conceptually similar in meaning to the search criteria even if the results don t share a specific word or words with the search criteria benefits of lsi lsi overcomes two of the most problematic constraints of boolean keyword search keyword queries multiple words that have similar meanings synonymy and words that have more than one meaning polysemy synonymy is often the cause of mismatches in the vocabulary used by the authors of documents and the users of information retrieval systems ref cite journal last1 furnas first1 g w last2 landauer first2 t k last3 gomez first3 l m last4 dumais first4 s t title the vocabulary problem in human system communication doi 10 1145 32206 32212 journal communications of the acm volume 30 issue 11 pages 964 971 year 1987 pmid pmc ref as a result boolean or keyword queries often return irrelevant results and miss information that is relevant lsi is also used to perform automated document categorization in fact several experiments have demonstrated that there are a number of correlations between the way lsi and humans process and categorize text ref name landauer2008 landauer t et al learning human like knowledge by singular value decomposition a progress report m i jordan m j kearns s a solla eds advances in neural information processing systems 10 cambridge mit press 1998 pp 45 51 ref document categorization is the assignment of documents to one or more predefined categories based on their similarity to the conceptual content of the categories ref cite book last1 dumais first1 s last2 platt first2 j last3 heckerman first3 d last4 sahami first4 m chapter inductive learning algorithms and representations for text categorization doi 10 1145 288627 288651 title proceedings of the seventh international conference on information and knowledge management cikm 98 pages 148 year 1998 isbn 1581130619 url http research microsoft com en us um people jplatt cikm98 pdf pmid pmc ref lsi uses example documents to establish the conceptual basis for each category during categorization processing the concepts contained in the documents being categorized are compared to the concepts contained in the example items and a category or categories is assigned to the documents based on the similarities between the concepts they contain and the concepts that are contained in the example documents dynamic clustering based on the conceptual content of documents can also be accomplished using lsi clustering is a way to group documents based on their conceptual similarity to each other without using example documents to establish the conceptual basis for each cluster this is very useful when dealing with an unknown collection of unstructured text because it uses a strictly mathematical approach lsi is inherently independent of language this enables lsi to elicit the semantic content of information written in any language without requiring the use of auxiliary structures such as dictionaries and thesauri lsi can also perform cross linguistic concept searching and example based categorization for example queries can be made in one language such as english and conceptually similar results will be returned even if they are composed of an entirely different language or of multiple languages citation needed date july 2015 lsi is not restricted to working only with words it can also process arbitrary character strings any object that can be expressed as text can be represented in an lsi vector space ref zukas anthony price robert j document categorization using latent semantic indexing white paper content analyst company llc ref for example tests with medline abstracts have shown that lsi is able to effectively classify genes based on conceptual modeling of the biological information contained in the titles and abstracts of the medline citations ref cite journal last1 homayouni first1 r last2 heinrich first2 k last3 wei first3 l last4 berry first4 m w title gene clustering by latent semantic indexing of medline abstracts doi 10 1093 bioinformatics bth464 journal bioinformatics volume 21 issue 1 pages 104 115 year 2004 pmid 15308538 pmc ref lsi automatically adapts to new and changing terminology and has been shown to be very tolerant of noise i e misspelled words typographical errors unreadable characters etc ref cite book last1 price first1 r j last2 zukas first2 a e chapter application of latent semantic indexing to processing of noisy text doi 10 1007 11427995 68 title intelligence and security informatics series lecture notes in computer science volume 3495 pages 602 year 2005 isbn 978 3 540 25999 2 pmid pmc ref this is especially important for applications using text derived from optical character recognition ocr and speech to text conversion lsi also deals effectively with sparse ambiguous and contradictory data text does not need to be in sentence form for lsi to be effective it can work with lists free form notes email web based content etc as long as a collection of text contains multiple terms lsi can be used to identify patterns in the relationships between the important terms and concepts contained in the text lsi has proven to be a useful solution to a number of conceptual matching problems ref ding c a similarity based probability model for latent semantic indexing proceedings of the 22nd international acm sigir conference on research and development in information retrieval 1999 pp 59 65 ref ref bartell b cottrell g and belew r latent semantic indexing is an optimal special case of multidimensional scaling proceedings acm sigir conference on research and development in information retrieval 1992 pp 161 167 ref the technique has been shown to capture key relationship information including causal goal oriented and taxonomic information ref cite journal url http citeseerx ist psu edu viewdoc download doi 10 1 1 23 5444 rep rep1 type pdf author1 graesser a author2 karnavat a title latent semantic analysis captures causal goal oriented and taxonomic structures journal proceedings of cogsci 2000 pages 184 189 ref lsi timeline mid 1960s factor analysis technique first described and tested h borko and m bernick 1988 seminal paper on lsi technique published ref name deerwester1988 1989 original patent granted ref name deerwester1988 1992 first use of lsi to assign articles to reviewers ref cite journal last1 dumais first1 s last2 nielsen first2 j title automating the assignment of submitted manuscripts to reviewers journal proceedings of the fifteenth annual international conference on research and development in information retrieval year 1992 pages 233 244 doi 10 1145 133160 133205 isbn 0897915232 ref 1994 patent granted for the cross lingual application of lsi landauer et al 1995 first use of lsi for grading essays foltz et al landauer et al 1999 first implementation of lsi technology for intelligence community for analyzing unstructured text science applications international corporation saic 2002 lsi based product offering to intelligence based government agencies saic 2005 first vertical specific application publishing edb ebsco content analyst company mathematics of lsi lsi uses common linear algebra techniques to learn the conceptual correlations in a collection of text in general the process involves constructing a weighted term document matrix performing a singular value decomposition singular value decomposition on the matrix and using the matrix to identify the concepts contained in the text term document matrix lsi begins by constructing a term document matrix math a math to identify the occurrences of the math m math unique terms within a collection of math n math documents in a term document matrix each term is represented by a row and each document is represented by a column with each matrix cell math a ij math initially representing the number of times the associated term appears in the indicated document math mathrm tf ij math this matrix is usually very large and very sparse once a term document matrix is constructed local and global weighting functions can be applied to it to condition the data the weighting functions transform each cell math a ij math of math a math to be the product of a local term weight math l ij math which describes the relative frequency of a term in a document and a global weight math g i math which describes the relative frequency of the term within the entire collection of documents some common local weighting functions ref berry m w and browne m understanding search engines mathematical modeling and text retrieval society for industrial and applied mathematics philadelphia 2005 ref are defined in the following table style width 60 cellpadding 25 cellspacing 5 align center style width 22 binary math l ij 1 math if the term exists in the document or else math 0 math style width 22 termfrequency math l ij mathrm tf ij math the number of occurrences of term math i math in document math j math style width 22 log math l ij log mathrm tf ij 1 math style width 22 augnorm math l ij frac big frac mathrm tf ij max i mathrm tf ij big 1 2 math some common global weighting functions are defined in the following table style width 60 cellpadding 25 cellspacing 5 align center style width 22 binary math g i 1 math style width 22 normal math g i frac 1 sqrt sum j mathrm tf ij 2 math style width 22 gfidf math g i mathrm gf i mathrm df i math where math mathrm gf i math is the total number of times term math i math occurs in the whole collection and math mathrm df i math is the number of documents in which term math i math occurs style width 22 tf idf inverse document frequency 2 idf inverse document frequency math g i log 2 frac n 1 mathrm df i math style width 22 entropy math g i 1 sum j frac p ij log p ij log n math where math p ij frac mathrm tf ij mathrm gf i math empirical studies with lsi report that the log and entropy weighting functions work well in practice with many data sets ref landauer t et al handbook of latent semantic analysis lawrence erlbaum associates 2007 ref in other words each entry math a ij math of math a math is computed as math g i 1 sum j frac p ij log p ij log n math math a ij g i log mathrm tf ij 1 math rank reduced singular value decomposition a rank reduced singular value decomposition is performed on the matrix to determine patterns in the relationships between the terms and concepts contained in the text the svd forms the foundation for lsi ref berry michael w dumais susan t o brien gavin w using linear algebra for intelligent information retrieval december 1994 siam review 37 4 1995 pp 573 595 ref it computes the term and document vector spaces by approximating the single term frequency matrix math a math into three other matrices an m by r term concept vector matrix math t math an r by r singular values matrix math s math and a n by r concept document vector matrix math d math which satisfy the following relations math a approx tsd t math math t t t i r quad d t d i r math math s 1 1 geq s 2 2 geq ldots geq s r r 0 quad s i j 0 text where i neq j math in the formula a is the supplied m by n weighted matrix of term frequencies in a collection of text where m is the number of unique terms and n is the number of documents t is a computed m by r matrix of term vectors where r is the rank of a a measure of its unique dimensions \xe2\x89\xa4 min m n s is a computed r by r diagonal matrix of decreasing singular values and d is a computed n by r matrix of document vectors the svd is then singular value decomposition truncated svd truncated to reduce the rank by keeping only the largest k \xc2\xab r diagonal entries in the singular value matrix s where k is typically on the order 100 to 300 dimensions this effectively reduces the term and document vector matrix sizes to m by k and n by k respectively the svd operation along with this reduction has the effect of preserving the most important semantic information in the text while reducing noise and other undesirable artifacts of the original space of a this reduced set of matrices is often denoted with a modified formula such as a \xe2\x89\x88 a sub k sub t sub k sub s sub k sub d sub k sub sup t sup efficient lsi algorithms only compute the first k singular values and term and document vectors as opposed to computing a full svd and then truncating it note that this rank reduction is essentially the same as doing principal component analysis pca on the matrix a except that pca subtracts off the means pca loses the sparseness of the a matrix which can make it infeasible for large lexicons querying and augmenting lsi vector spaces the computed t sub k sub and d sub k sub matrices define the term and document vector spaces which with the computed singular values s sub k sub embody the conceptual information derived from the document collection the similarity of terms or documents within these spaces is a factor of how close they are to each other in these spaces typically computed as a function of the angle between the corresponding vectors the same steps are used to locate the vectors representing the text of queries and new documents within the document space of an existing lsi index by a simple transformation of the a t s d sup t sup equation into the equivalent d a sup t sup t s sup \xe2\x88\x921 sup equation a new vector d for a query or for a new document can be created by computing a new column in a and then multiplying the new column by t s sup \xe2\x88\x921 sup the new column in a is computed using the originally derived global term weights and applying the same local weighting function to the terms in the query or in the new document a drawback to computing vectors in this way when adding new searchable documents is that terms that were not known during the svd phase for the original index are ignored these terms will have no impact on the global weights and learned correlations derived from the original collection of text however the computed vectors for the new text are still very relevant for similarity comparisons with all other document vectors the process of augmenting the document vector spaces for an lsi index with new documents in this manner is called folding in although the folding in process does not account for the new semantic content of the new text adding a substantial number of documents in this way will still provide good results for queries as long as the terms and concepts they contain are well represented within the lsi index to which they are being added when the terms and concepts of a new set of documents need to be included in an lsi index either the term document matrix and the svd must be recomputed or an incremental update method such as the one described in ref name brand2006 be used additional uses of lsi it is generally acknowledged that the ability to work with text on a semantic basis is essential to modern information retrieval systems as a result the use of lsi has significantly expanded in recent years as earlier challenges in scalability and performance have been overcome lsi is being used in a variety of information retrieval and text processing applications although its primary application has been for concept searching and automated document categorization ref dumais s latent semantic analysis arist review of information science and technology vol 38 2004 chapter 4 ref below are some other ways in which lsi is being used information discovery ref best practices commentary on the use of search and information retrieval methods in e discovery the sedona conference 2007 pp 189 223 ref electronic discovery ediscovery government intelligence community publishing automated document classification ediscovery government intelligence community publishing ref foltz p w and dumais s t personalized information delivery an analysis of information filtering methods communications of the acm 1992 34 12 51 60 ref text summarization ref gong y and liu x creating generic text summaries proceedings sixth international conference on document analysis and recognition 2001 pp 903 907 ref ediscovery publishing relationship discovery ref bradford r efficient discovery of new information in large text databases proceedings ieee international conference on intelligence and security informatics atlanta georgia lncs vol 3495 springer 2005 pp 374 380 ref government intelligence community social networking automatic generation of link charts of individuals and organizations ref bradford r application of latent semantic indexing in generating graphs of terrorist networks in proceedings ieee international conference on intelligence and security informatics isi 2006 san diego ca usa may 23 24 2006 springer lncs vol 3975 pp 674 675 ref government intelligence community matching technical papers and grants with reviewers ref yarowsky d and florian r taking the load off the conference chairs towards a digital paper routing assistant proceedings of the 1999 joint sigdat conference on empirical methods in nlp and very large corpora 1999 pp 220 230 ref government online customer support ref caron j applying lsa to online customer support a trial study unpublished master s thesis may 2000 ref customer management determining document authorship ref soboroff i et al visualizing document authorship using n grams and latent semantic indexing workshop on new paradigms in information visualization and manipulation 1997 pp 43 48 ref education automatic keyword annotation of images ref monay f and gatica perez d on image auto annotation with latent space models proceedings of the 11th acm international conference on multimedia berkeley ca 2003 pp 275 278 ref understanding software source code ref cite journal author1 maletic j author2 marcus a title using latent semantic analysis to identify similarities in source code to support program understanding journal proceedings of 12th ieee international conference on tools with artificial intelligence location vancouver british columbia date november 13 15 2000 pages 46 53 doi 10 1109 tai 2000 889845 isbn 0 7695 0909 6 ref software engineering filtering spam electronic spam ref gee k using latent semantic indexing to filter spam in proceedings 2003 acm symposium on applied computing melbourne florida pp 460 464 ref system administration information visualization ref name landauer2004 landauer t laham d and derr m from paragraph to graph latent semantic analysis for information visualization proceedings of the national academy of sciences 101 2004 pp 5214 5219 ref automated essay scoring essay scoring ref foltz peter w laham darrell and landauer thomas k automated essay scoring applications to educational technology proceedings of edmedia 1999 ref education literature based discovery ref gordon m and dumais s using latent semantic indexing for literature based discovery journal of the american society for information science 49 8 1998 pp 674 685 ref stock resturns prediction ref name galvez2017 cite journal url http www sciencedirect com science article pii s1877750317300091 title assessing the usefulness of online message board mining in automatic stock prediction systems author1 ramiro h g\xc3\xa1lvez author2 agust\xc3\xadn gravano journal journal of computational science volume 19 pages 1877 7503 year 2017 doi 10 1016 j jocs 2017 01 001 ref lsi is increasingly being used for electronic document discovery ediscovery to help enterprises prepare for litigation in ediscovery the ability to cluster categorize and search large collections of unstructured text on a conceptual basis is essential concept based searching using lsi has been applied to the ediscovery process by leading providers as early as 2003 ref there has to be a better way to search 2008 white paper fios inc ref challenges to lsi early challenges to lsi focused on scalability and performance lsi requires relatively high computational performance and memory in comparison to other information retrieval techniques ref karypis g han e fast supervised dimensionality reduction algorithm with applications to document categorization and retrieval proceedings of cikm 00 9th acm conference on information and knowledge management ref however with the implementation of modern high speed processors and the availability of inexpensive memory these considerations have been largely overcome real world applications involving more than 30 million documents that were fully processed through the matrix and svd computations are common in some lsi applications a fully scalable unlimited number of documents online training implementation of lsi is contained in the open source gensim software package ref name rehurek2011 cite journal url http dx doi org 10 1007 978 3 642 20161 5 29 format pdf title subspace tracking for latent semantic analysis author radim \xc5\x99eh\xc5\xaf\xc5\x99ek journal advances in information retrieval 33rd european conference on ir research ecir 2011 volume 6611 pages 289 300 year 2011 doi 10 1007 978 3 642 20161 5 29 series lecture notes in computer science isbn 978 3 642 20160 8 ref another challenge to lsi has been the alleged difficulty in determining the optimal number of dimensions to use for performing the svd as a general rule fewer dimensions allow for broader comparisons of the concepts contained in a collection of text while a higher number of dimensions enable more specific or more relevant comparisons of concepts the actual number of dimensions that can be used is limited by the number of documents in the collection research has demonstrated that around 300 dimensions will usually provide the best results with moderate sized document collections hundreds of thousands of documents and perhaps 400 dimensions for larger document collections millions of documents ref bradford r an empirical study of required dimensionality for large scale latent semantic indexing applications proceedings of the 17th acm conference on information and knowledge management napa valley california usa 2008 pp 153 162 ref however recent studies indicate that 50 1000 dimensions are suitable depending on the size and nature of the document collection ref name landauer2008 landauer thomas k and dumais susan t latent semantic analysis scholarpedia 3 11 4356 2008 ref checking the amount of variance in the data after computing the svd can be used to determine the optimal number of dimensions to retain the variance contained in the data can be viewed by plotting the singular values s in a scree plot some lsi practitioners select the dimensionality associated with the knee of the curve as the cut off point for the number of dimensions to retain others argue that some quantity of the variance must be retained and the amount of variance in the data should dictate the proper dimensionality to retain seventy percent is often mentioned as the amount of variance in the data that should be used to select the optimal dimensionality for recomputing the svd ref cangelosi r goriely a component retention in principal component analysis with application to cdna microarray data bmc biology direct 2 2 2007 ref ref jolliffe l t principal component analysis springer verlag new york 1986 ref ref hu x z cai et al lsa first dimension and dimensional weighting 25th annual meeting of the cognitive science society boston ma ref see also compound term processing explicit semantic analysis latent semantic mapping latent semantic structure indexing principal components analysis probabilistic latent semantic analysis spamdexing topic model latent dirichlet allocation distributional semantics coh metrix references reflist 30em further reading cite journal url http lsa colorado edu papers dp1 lsaintro pdf format pdf title introduction to latent semantic analysis author link1 thomas landauer first1 thomas last1 landauer first2 peter w last2 foltz first3 darrell last3 laham journal discourse processes volume 25 pages 259 284 year 1998 doi 10 1080 01638539809545028 issue 2 3 cite journal url http lsi research telcordia com lsi papers jasis90 pdf format pdf title indexing by latent semantic analysis first1 scott last1 deerwester first2 susan t last2 dumais first3 george w last3 furnas first4 thomas k last4 landauer first5 richard last5 harshman author link1 scott deerwester author link2 susan dumais author link3 george furnas author link4 thomas landauer author link5 richard harshman journal journal of the american society for information science volume 41 issue 6 pages 391 407 year 1990 doi 10 1002 sici 1097 4571 199009 41 6 391 aid asi1 3 0 co 2 9 original article where the model was first exposed cite journal url http citeseer ist psu edu berry95using html title using linear algebra for intelligent information retrieval first1 michael last1 berry first2 susan t last2 dumais first3 gavin w last3 o brien author link1 susan dumais year 1995 http lsirwww epfl ch courses dis 2003ws papers ut cs 94 270 pdf pdf illustration of the application of lsa to document retrieval cite web url http iv slis indiana edu sw lsa html title latent semantic analysis publisher infovis cite web url http cran at r project org web packages lsa index html title an open source lsa package for r publisher cran author fridolin wild date november 23 2005 accessdate november 20 2006 cite web url http www welchco com 02 14 01 60 96 02 2901 htm title a solution to plato s problem the latent semantic analysis theory of acquisition induction and representation of knowledge author thomas landauer susan dumais susan t dumais accessdate 2007 07 02 external links articles on lsa http www scholarpedia org article latent semantic analysis latent semantic analysis a scholarpedia article on lsa written by tom landauer one of the creators of lsa talks and demonstrations http videolectures net slsfs05 hofmann lsvm lsa overview talk by prof http www cs brown edu th thomas hofmann describing lsa its applications in information retrieval and its connections to probabilistic latent semantic analysis http www semanticquery com archive semanticsearchart researchlsa html complete lsa sample code in c for windows the demo code includes enumeration of text files filtering stop words stemming making a document term matrix and svd implementations due to its cross domain applications in information retrieval natural language processing nlp cognitive science and computational linguistics lsa has been implemented to support many different kinds of applications http www d umn edu tpederse senseclusters html sense clusters an information retrieval oriented perl implementation of lsa http code google com p airhead research s space package a computational linguistics and cognitive science oriented java implementation of lsa http code google com p semanticvectors semantic vectors applies random projection lsa and reflective random indexing to lucene term document matrices http infomap nlp sourceforge net infomap project an nlp oriented c implementation of lsa superseded by semanticvectors project http scgroup20 ceid upatras gr 8000 tmg index php main page text to matrix generator a matlab toolbox for generating term document matrices from text collections with support for lsa gensim contains a python implementation of lsa for matrices larger than ram category information retrieval techniques category natural language processing category latent variable models'
b'multiple issues essay like date january 2015 original research date january 2015 personalized search refers to web search experiences that are tailored specifically to an individual s interests by incorporating information about the individual beyond specific query provided pitkow et al describe two general approaches to personalizing search results one involving modifying the user s query and the other re ranking search results ref cite journal last pitokow first james author2 hinrich sch\xc3\xbctze author3 todd cass author4 rob cooley author5 don turnbull author6 andy edmonds author7 eytan adar author8 thomas breuel title personalized search journal communications of the acm year 2002 volume 45 issue 9 pages 50 55 url http portal acm org citation cfm doid 567498 567526 ref history google introduced personalized search in 2004 and it was implemented in 2005 to google search google has personalized search implemented for all users not only those with a google account there is not very much information on how exactly google personalizes their searches however it is believed that they use user language location and web history ref cite conference url http personalization ccs neu edu paper pdf title measuring personalization of web search year 2013 archiveurl https web archive org web 20130425195202 http personalization ccs neu edu paper pdf archivedate april 25 2013 deadurl y author1 aniko hannak author2 piotr sapiezynski author3 arash molavi kakhki author4 balachander krishnamurthy author5 david lazer author6 alan mislove author7 christo wilson ref early search engine s like google and altavista found results based only on key words personalized search as pioneered by google has become far more complex with the goal to understand exactly what you mean and give you exactly what you want ref name remerowski cite av media last remerowski first ted title national geographic inside google year 2013 ref using mathematical algorithms search engines are now able to return results based on the number of links to and from sites the more links a site has the higher it is placed on the page ref name remerowski search engines have two degrees of expertise the shallow expert and the deep expert an expert from the shallowest degree serves as a witness who knows some specific information on a given event a deep expert on the other hand has comprehensible knowledge that gives it the capacity to deliver unique information that is relevant to each individual inquirer ref name simpson cite journal last simpson first thomas title evaluating google as an epistemic tool journal metaphilosophy year 2012 volume 43 issue 4 pages 969 982 ref if a person knows what he or she wants than the search engine will act as a shallow expert and simply locate that information but search engines are also capable of deep expertise in that they rank results indicating that those near the top are more relevant to a user s wants than those below ref name simpson while many search engines take advantage of information about people in general or about specific groups of people personalized search depends on a user profile that is unique to the individual research systems that personalize search results model their users in different ways some rely on users explicitly specifying their interests or on demographic cognitive characteristics ref cite journal last ma first z author2 pant g author3 sheng o title interest based personalized search journal acm tois year 2007 volume 25 issue 5 ref ref cite journal last frias martinez first e author2 chen s y author3 liu x title automatic cognitive style identification of digital library users for personalization journal jasist year 2007 volume 58 issue 2 pages 237 251 doi 10 1002 asi 20477 ref however user supplied information can be difficult to collect and keep up to date others have built implicit user models based on content the user has read or their history of interaction with web pages ref cite journal last chirita first p author2 firan c author3 nejdl w title summarizing local context to personalize global web search journal sigir year 2006 pages 287 296 ref ref cite journal last dou first z author2 song r author3 wen j r title a large scale evaluation and analysis of personalized search strategies journal www year 2007 pages 581 590 ref ref cite journal last shen first x author2 tan b author3 zhai c x title implicit user modeling for personalized search journal cikm year 2005 pages 824 831 ref ref cite journal last sugiyama first k author2 hatano k author3 yoshikawa m title adaptive web search based on user profile constructed without any effort from the user journal www year 2004 pages 675 684 ref ref cite journal last teevan first j author2 dumais s t author3 horvitz e title personalizing search via automated analysis of interests and activities journal sigir year 2005 pages 415 422 url http people csail mit edu teevan work publications papers tochi10 pdf ref there are several publicly available systems for personalizing web search results e g google personalized search and bing search engine bing s search result personalization ref cite web last crook first aidan and sanaz ahari title making search yours url http www bing com community site blogs b search archive 2011 02 10 making search yours aspx publisher bing accessdate 14 march 2011 ref however the technical details and evaluations of these commercial systems are proprietary one technique google uses to personalize searches for its users is to track log in time and if the user has enabled web history in his browser if a user accesses the same site through a search result from google many times it believes that they like that page so when users carry out certain searches google s personalized search algorithm gives the page a boost moving it up through the ranks even if a user is signed out google may personalize their results because it keeps a 180 day record of what a particular web browser has searched for linked to a cookie in that browser ref cite web last sullivan first danny title of magic keywords and flavors of personalized search at google url http searchengineland com flavors of google personalized search 139286 accessdate 21 april 2014 ref in order to better understand how personalized search results are being presented to the users a group of researchers at northeastern university compared an aggregate set of searches from logged in users against a control group the research team found that 11 7 of results show differences due to personalization however this varies widely by web search query search query and result ranking position ref name briggs cite web last briggs first justin title a better understanding of personalized search url http justinbriggs org better understanding personalized search date 24 june 2013 accessdate 21 april 2014 ref of various factors tested the two that had measurable impact were being logged in with a google account and the ip address of the searching users it should also be noted that results with high degrees of personalization include companies and politics one of the factors driving personalization is localization of results with company queries showing store locations relevant to the location of the user so for example if a user searched for used car sales google may produce results of local car dealerships in their area on the other hand queries with the least amount of personalization include factual queries what is and health ref name briggs when measuring personalization it is important to eliminate background noise in this context one type of background noise is the carry over effect the carry over effect can be defined as follows when a user performs a search and follow it with a subsequent search the results of the second search is influenced by the first search a noteworthy point is that the top ranked url s are less likely to change based off personalization with most personalization occurring at the lower ranks this is a style of personalization based on recent search history but it is not a consistent element of personalization because the phenomenon times out after 10 minutes according to the researchers ref name briggs the filter bubble main article filter bubble several concerns have been brought up regarding personalized search it decreases the likelihood of finding new information by bias ing search results towards what the user has already found it introduces potential privacy problems in which a user may not be aware that their search results are personalized for them and wonder why the things that they are interested in have become so relevant such a problem has been coined as the filter bubble by author eli pariser he argues that people are letting major websites drive their destiny and make decisions based on the vast amount of data they ve collected on individuals this can isolate users in their own worlds or filter bubbles where they only see information that they want to such a consequence of the friendly world syndrome as a result people are much less informed of problems in the developing world which can further widen the gap between the north developed countries and the south developing countries ref name pariser cite book url http www sp uconn edu jbl00001 pariser the 20filter 20bubble introduction pdf title the filter bubble archiveurl https web archive org web 20131228150122 http www sp uconn edu jbl00001 pariser the 20filter 20bubble introduction pdf archivedate december 28 2013 author e pariser year 2011 ref the methods of personalization and how useful it is to promote certain results which have been showing up regularly in searches by like minded individuals in the same community the personalization method makes it very easy to understand how the filter bubble is created as certain results are bumped up and viewed more by individuals other results not favored by them are relegated to obscurity as this happens on a community wide level it results in the community consciously or not sharing a skewed perspective of events ref cite journal last smyth first b title adaptive information access personalization and privacy journal international journal of pattern recognition artificial intelligence year 2007 pages 183 205 ref an area of particular concern to some parts of the world is the use of personalized search as a form of control over the people utilizing the search by only giving them particular information selective exposure this can be used to give particular influence over highly talked about topics such as gun control or even gear people to side with a particular political regime in different countries ref name pariser while total control by a particular government just from personalized search is a stretch control of the information readily available from searches can easily be controlled by the richest corporations the biggest example of a corporation controlling the information is google google is not only feeding you the information they want but they are at times using your personalized search to gear you towards their own companies or affiliates this has led to a complete control of various parts of the web and a pushing out of their competitors such as how google maps took a major control over the online map and direction industry with mapquest and others forced to take a backseat ref name consumer watchdog cite web title traffic report how google is squeezing out competitors and muscling into new markets url http www consumerwatchdog org resources trafficstudy google pdf date 2 june 2010 accessdate 27 april 2014 work consumer watchdog ref many search engines use concept based user profiling strategies that derive only topics that users are highly interested in but for best results according to researchers wai tin and dik lun both positive and negative preferences should be considered such profiles applying negative and positive preferences result in highest quality and most relevant results by separating alike queries from unalike queries for example typing in apple could refer to either the fruit or the macintosh computer and providing both preferences aids search engines ability to learn which apple the user is really looking for based on the links clicked one concept strategy the researchers came up with to improve personalized search and yield both positive and negative preferences is the click based method this method captures a user s interests based on which links they click on in a results list while downgrading unclicked links ref cite journal last wai tin first kenneth author2 dik lun l title deriving concept based user profiles from search engine logs journal ieee transactions on knowledge and data engineering year 2010 volume 22 issue 7 pages 969 982 doi 10 1109 tkde 2009 144 ref the feature also has profound effects on the search engine optimization industry due to the fact that search results will no longer be ranked the same way for every user ref http www networkworld com news 2009 120709 google personalized results could be html google personalized results could be bad for search network world retrieved july 12 2010 ref an example of this is found in eli pariser s the filter bubble where he had two friends type in bp into google s search bar one friend found information on the bp oil spill in the gulf of mexico while the other retrieved investment information ref name pariser some have noted that personalized search results not only serve to customize a user s search results but also advertising advertisements this has been criticized as an expectation of privacy invasion on privacy ref cite web url http www seooptimizers com search engines and customized results based on your internet history html title search engines and customized results based on your internet history publisher seo optimizers accessdate 27 february 2013 ref the case of google main article google personalized search an important example of search personalization is google there are a host of google applications all of which can be personalized and integrated with the help of a google account personalizing search does not require an account however one is almost deprived of a choice since so many useful google products are only accessible if one has a google account the google dashboard introduced in 2009 covers more than 20 products and services including gmail calendar docs youtube etc ref cite journal last mattison first d title time space and google toward a real time synchronous personalized collaborative web journal searcher year 2010 pages 20 31 ref that keeps track of all the information directly under one s name the free google custom search is available for individuals and big companies alike providing the search facility for individual websites and powering corporate sites such as that of the new york times the high level of personalization that was available with google played a significant part in helping remain the world s most favorite search engine one example of google s ability to personalize searches is in its use of google news google has geared its news to show everyone a few similar articles that can be deemed interesting but as soon as the user scrolls down it can be seen that the news articles begin to differ google takes into account past searches as well as the location of the user to make sure that local news gets to them first this can lead to a much easier search and less time going through all of the news to find the information one want the concern however is that the very important information can be held back because it does not match the criteria that the program sets for the particular user this can create the filter bubble as described earlier ref name pariser an interesting point about personalization that often gets overlooked is the privacy vs personalization battle while the two do not have to be mutually exclusive it is often the case that as one becomes more prominent it compromises the other google provides a host of services to people and many of these services do not require information to be collected about a person to be customizable since there is no threat of privacy invasion with these services the balance has been tipped to favor personalization over privacy even when it comes to search as people reap the rewards of convenience from customizing their other google services they desire better search results even if it comes at the expense of private information where to draw the line between the information versus search results tradeoff is new territory and google gets to make that decision until people get the power to control the information that is being collected about them google is not truly protecting privacy google s popularity as a search engine and internet browser has allowed it to gain a lot of power their popularity has created millions of usernames which have been used to collect vast amounts of information about individuals google can use multiple methods of personalization such as traditional social geographic ip address browser cookies time of day year behavioral query history bookmarks and more although having google personalize search results based on what users searched previously may have its benefits there are negatives that come with it ref cite web last jackson first mark title the future of google s search personalization url http searchenginewatch com article 2067001 the future of googles search personalization accessdate 29 april 2014 ref ref cite web last harry first david title search personalization and the user experience url http searchenginewatch com article 2118126 search personalization the user experience accessdate 29 april 2014 ref with the power from this information google has chosen to enter other sectors it owned such as videos document sharing shopping maps and many more google has done this by steering searchers to their own services offered as opposed to others such as mapquest using search personalization google has doubled its video market share to about eighty percent the legal definition of a monopoly is when a firm gains control of seventy to eighty percent of the market google has reinforced this monopoly by creating significant barriers of entry such as manipulating search results to show their own services this can be clearly seen with google maps being the first thing displayed in most searches the analytical firm experian hitwise stated that since 2007 mapquest has had its traffic cut in half because of this other statistics from around the same time include photobucket going from twenty percent of market share to only three percent myspace going from twelve percent market share to less than one percent and espn from eight percent to four percent market share in terms of images photobucket went from 31 in 2007 to 10 in 2010 and yahoo images has gone from 12 to 7 it becomes apparent that the decline of these companies has come because of google s increase in market share from 43 in 2007 to about 55 in 2009 it can be said that google is more dominant because they provide better services however experian hitwise has also created graphs to show the market share of about fifteen different companies at once this has been done for every category for the market share of pictures videos product search and more the graph for product search is evidence enough for google s influence because their numbers went from 1 3 million unique visitors to 11 9 unique visitors in one month that kind of growth can only come with the change of a process in the end there are two common themes with all of these graphs the first is that google s market share has a directly inverse relationship to the market share of the leading competitors the second is that this directly inverse relationship began around 2007 which is around the time that google began to use its universal search method ref cite web title traffic report how google is squeezing out competitors and muscling into new markets url https courses lis illinois edu pluginfile php 226148 mod resource content 1 trafficstudy google pdf publisher consumerwatchdog org accessdate 29 april 2014 ref benefits one of the most critical benefits personalized search has is to improve the quality of decisions consumers make the internet has made the transaction cost of obtaining information significantly lower than ever however human ability to process information has not expanded much ref name diehl cite journal author diehl k year 2003 title personalization and decision support tools effects on search and consumer decision making journal advances in consumer research volume 30 issue 1 pages 166 169 ref when facing overwhelming amount of information consumers need a sophisticated tool to help them make high quality decisions two studies examined the effects of personalized screening and ordering tools and the results show a positive correlation between personalized search and the quality of consumers decisions the first study was conducted by kristin diehl from the university of south carolina her research discovered that reducing search cost led to lower quality choices the reason behind this discovery was that consumers make worse choices because lower search costs cause them to consider inferior options it also showed that if consumers have a specific goal in mind they would further their search resulting in an even worse decision ref name diehl the study by gerald haubl from the university of alberta and benedict g c dellaert from maastricht university mainly focused on recommendation systems both studies concluded that a personalized search and recommendation system significantly improved consumers decision quality and reduced the number of products inspected ref name diehl models personalized search gains popularity because of the demand for more relevant information research has indicated low success rates among major search engines in providing relevant results in 52 of 20 000 queries searchers did not find any relevant results within the documents that google returned ref cite book author1 coyle m author2 smyth b lastauthoramp y year 2007 chapter information recovery and discovery in collaborative web search title advances in information retrieval pp 356 367 doi 10 1007 978 3 540 71496 5 33 isbn 978 3 540 71494 1 series lecture notes in computer science ref personalized search can improve search quality significantly and there are mainly two ways to achieve this goal the first model available is based on the users historical searches and search locations people are probably familiar with this model since they often find the results reflecting their current location and previous searches there is another way to personalize search results in bracha shapira and boaz zabar s personalized search integrating collaboration and social networks shapira and zabar focused on a model that utilizes a recommendation system ref cite journal author1 shapira b author2 zabar b lastauthoramp y year 2011 title personalized search integrating collaboration and social networks journal journal of the american society for information science technology volume 62 issue 1 pages 146 160 doi 10 1002 asi 21446 ref this model shows results of other users who have searched for similar keywords the authors examined keyword search the recommendation system and the recommendation system with social network working separately and compares the results in terms of search quality the results show that a personalized search engine with the recommendation system produces better quality results than the standard search engine and that the recommendation system with social network even improves more recent paper https arxiv org abs 1612 03597 search personalization with embeddings shows that a new embedding model for search personalization where users are embedded on a topical interest space produces better search results than strong learning to rank models disadvantages while there are documented benefits of the implementation of search personalization there are also arguments against its use the foundation of this argument against its use is because it confines internet users search engine results to material that aligns with the users interests and history it limits the users ability to become exposed to material that would be relevant to the user s search query but due to the fact that some of this material differs from the user s interests and history the material is not displayed to the user search personalization takes the objectivity out of the search engine and undermines the engine objectivity matters little when you know what you are looking for but its lack is problematic when you do not ref cite journal last simpson first thomas w title evaluating google as an epistemic tool journal metaphilosophy date 2012 volume 43 4 pages 426 445 doi 10 1111 j 1467 9973 2012 01759 x ref another criticism of search personalization is that it limits a core function of the web the collection and sharing of information search personalization prevents users from easily accessing all the possible information that is available for a specific search query search personalization adds a bias to user s search queries if a user has a particular set of interests or internet history and uses the web to research a controversial issue the user s search results will reflect that the user may not be shown both sides of the issue and miss potentially important information if the user s interests lean to one side or another a study done on search personalization and its effects on search results in google news resulted in different orders of news stories being generated by different users even though each user entered the same search query according to bates only 12 of the searchers had the same three stories in the same order this to me is prima facie evidence that there is filtering going on ref cite journal last bates first mary ellen title is google hiding my news year 2011 journal online volume 35 issue 6 pages 64 ref if search personalization was not active all the results in theory should have been the same stories in an identical order another disadvantage of search personalization is that internet companies such as google are gathering and potentially selling their users internet interests and histories to other companies this raises a privacy issue concerning whether people are comfortable with companies gathering and selling their internet information without their consent or knowledge many web users are unaware of the use of search personalization and even fewer have knowledge that user data is a valuable commodity for internet companies sites that use it e pariser author of the filter bubble explains how there are differences that search personalization has on both facebook and google facebook implements personalization when it comes to the amount of things people share and what pages they like an individual s social interaction s whose profile they visit the most who they message or chat with are all indicators that are used when facebook uses personalization rather than what people share being an indicator of what is filtered out google takes into consideration what we click to filter out what comes up in our searches in addition facebook searches are not necessarily as private as the google ones facebook draws on the more public self and users share what other people want to see even while tag metadata tag ging photographs facebook uses personalization and face recognition that will automatically assign a name to face in terms of google users are provided similar websites and resources based on what they initially click on there are even other websites that use the filter tactic to better adhere to user preferences for example netflix also judges from the users search history to suggest movies that they may be interested in for the future there are sites like amazon com amazon and personal shopping site s also use other peoples history in order to serve their interests better twitter also uses personalization by suggesting other people to follow in addition based on who one follows tweets and retweets at twitter filters out suggestions most relevant to the user mark zuckerberg founder of facebook believed that people only have one identity e pariser argues that is completely false and search personalization is just another way to prove that isn t true although personalized search may seem helpful it is not a very accurate representation of any person there are instances where people also search things and share things in order to make themselves look better for example someone may look up and share political articles and other intellectual articles there are many sites being used for different purposes and that do not make up one person s personal identity identity at all but provide false representations instead ref name pariser online shopping main article online shopping search engines such as google and yahoo utilize personalized search to attract possible customers to products that fit their presumed desires based on a large amount of collected data aggregated from an individual s web clicks search engines can use personalized search to put advertisements that may pique the interest of an individual utilizing personalized search can help consumers find what they want faster as well as help match up products and services to individuals within more specialized and or niche markets many of these products or services that are sold via personalized online results would struggle to sell in brick and mortar stores these types of products and services are called long tail items ref cite journal author badke william title personalization and information literacy journal online volume 36 issue 1 page 47 date february 2012 ref using personalized search allows faster product and service discoveries for consumers and reduces the amount of necessary advertisement money spent to reach those consumers in addition utilizing personalized search can help companies determine which individuals should be offered online coupon codes to their products and or services by tracking if an individual has perused their website considered purchasing an item or has previously made a purchase a company can post advertisements on other websites to reach that particular consumer in an attempt to have them make a purchase aside from aiding consumers and businesses in finding one another the search engines that provide personalized search benefit greatly the more data collected on an individual the more personalized results will be in turn this allows search engines to sell more advertisements because companies understand that they will have a better opportunity to sell to high percentage matched individuals then medium and low percentage matched individuals this aspect of personalized search angers many scholars such as william badke and eli pariser because they believe personalized search is driven by the desire to increase advertisement revenues in addition they believe that personalized search results are frequently utilized to sway individuals into using products and services that are offered by the particular search engine company or any other company in partnered with them for example google searching any company with at least one brick and mortar location will offer a map portraying the closest company location using the google maps service as the first result to the query ref consumer watchdog in order to use other mapping services such as mapquest a user would have to dig deeper into the results another example pertains to more vague queries searching the word shoes using the google search engine will offer several advertisements to shoe companies that pay google to link their website as a first result to consumer s queries references reflist 30em defaultsort personalized search category information retrieval techniques category internet search engines personalized search category internet terminology category personalized search'
b'voice search also called voice enabled search allows the user to use a voice command to search the internet or a portable device currently voice search is commonly used in in a narrow sense directory assistance or local search examples include google 411 tellme directory assistance and yellowpages com s 1 800 yellowpages in a broader definition voice search include open domain keyword query on any information on the internet for example in google voice search cortana software cortana siri and amazon echo given that voice based systems are interactive such systems are also called open domain question answering systems voice search is often interactive involving several rounds of interaction that allows a system to ask for clarification voice search is a type of dialog systems dialog system references no footnotes date april 2009 ye yi wang dong yu yun cheng ju alex acero an introduction to voice search ieee signal processing magazine special issue on spoken language technology institute of electrical and electronics engineers inc may 2008 j sherwani dong yu tim paek mary czerwinski yun cheng ju and alex acero voicepedia towards speech based access to unstructured information proceedings of the 8th annual conference of the international communication association interspeech 2007 antwerp belgium august 2007 internet search category information retrieval genres'
b'multiple issues expert subject computer science date january 2015 coi date february 2009 xml retrieval or xml information retrieval is the content based retrieval of documents structured with xml extensible markup language as such it is used for computing relevance information retrieval relevance of xml documents ref cite web url ftp ftp tm informatik uni frankfurt de pub papers ir an 20architecture 20for 20xml 20information 20retrieval 20in 20a 20peer to peer 20environment 2007 pdf title an architecture for xml information retrieval in a peer to peer environment last winter first judith author2 drobnik oswald date november 9 2007 publisher acm accessdate 2009 02 10 ref queries most xml retrieval approaches do so based on techniques from the information retrieval ir area e g by computing the similarity between a query consisting of keywords query terms and the document however in xml retrieval the query can also contain data structure structural hint sql hints so called content and structure cas queries enable users to specify what structure the requested content can or must have exploiting xml structure taking advantage of the self documenting self describing structure of xml documents can improve the search for xml documents significantly this includes the use of cas queries the weighting of different xml elements differently and the focused retrieval of subdocuments ranking ranking in xml retrieval can incorporate both content relevance and structural similarity which is the resemblance between the structure given in the query and the structure of the document also the retrieval units resulting from an xml query may not always be entire documents but can be any deeply nested xml elements i e dynamic documents the aim is to find the smallest retrieval unit that is highly relevant relevance can be defined according to the notion of specificity which is the extent to which a retrieval unit focuses on the topic of request ref name inex2006 cite web url http www cs otago ac nz homepages andrew 2006 10 pdf title overview of inex 2006 last malik first saadia author2 trotman andrew author3 lalmas mounia author4 fuhr norbert year 2007 work proceedings of the fifth workshop of the initiative for the evaluation of xml retrieval accessdate 2009 02 10 deadurl yes archiveurl https web archive org web 20081016101202 http www cs otago ac nz homepages andrew 2006 10 pdf archivedate october 16 2008 ref existing xml search engines an overview of two potential approaches is available ref cite web url http www sigmod org record issues 0612 p16 article yahia pdf title xml search languages inex and scoring last amer yahia first sihem author2 lalmas mounia year 2006 publisher sigmod rec vol 35 no 4 accessdate 2009 02 10 dead link date october 2010 bot h3llbot ref ref cite paper citeseerx 10 1 1 109 5986 title xml retrieval a survey last pal first sukomal date june 30 2006 publisher technical report cvpr ref the initiative for the evaluation of xml retrieval inex was founded in 2002 and provides a platform for evaluating such algorithm s ref name inex2006 three different areas influence xml retrieval ref name inex2002 cite web url http www is informatik uni duisburg de bib pdf ir fuhr etal 02a pdf title inex initiative for the evaluation of xml retrieval last fuhr first norbert author2 g\xc3\xb6vert n author3 kazai gabriella author4 lalmas mounia year 2003 work proceedings of the first inex workshop dagstuhl germany 2002 publisher ercim workshop proceedings france accessdate 2009 02 10 deadurl yes archiveurl https web archive org web 20081121135758 http www is informatik uni duisburg de bib pdf ir fuhr etal 02a pdf archivedate november 21 2008 ref traditional xml query languages query language s such as the w3c standard xquery ref cite web url http www w3 org tr 2007 rec xquery 20070123 title xquery 1 0 an xml query language last boag first scott author2 chamberlin don author3 fern\xc3\xa1ndez mary f author4 florescu daniela author5 robie jonathan author6 sim\xc3\xa9on j\xc3\xa9r\xc3\xb4me date 23 january 2007 work w3c recommendation publisher world wide web consortium accessdate 2009 02 10 ref supply complex queries but only look for exact matches therefore they need to be extended to allow for vague search with relevance computing most xml centered approaches imply a quite exact knowledge of the documents database schema schemas ref name schlieder2002 cite journal url http www cis uni muenchen de people meuss pub jasis02 ps gz title querying and ranking xml documents last schlieder first torsten author2 meuss holger year 2002 work journal of the american society for information science and technology vol 53 no 6 accessdate 2009 02 10 deadurl yes archiveurl https web archive org web 20070610002349 http www cis uni muenchen de people meuss pub jasis02 ps gz archivedate june 10 2007 ref databases classic database systems have adopted the possibility to store semi structured model semi structured data ref name inex2002 and resulted in the development of xml database s often they are very formal concentrate more on searching than on ranking and are used by experienced users able to formulate complex queries information retrieval classic information retrieval models such as the vector space model provide relevance ranking but do not include document structure only flat queries are supported also they apply a static document concept so retrieval units usually are entire documents ref name schlieder2002 they can be extended to consider structural information and dynamic document retrieval examples for approaches extending the vector space models are available they use document subtree s index terms plus structure as dimensions of the vector space ref cite web url http www cobase cs ucla edu tech docs sliu sigir04 pdf title configurable indexing and ranking for xml information retrieval last liu first shaorong author2 zou qinghua author3 chu wesley w year 2004 work sigir 04 publisher acm accessdate 2009 02 10 ref see also document retrieval information retrieval applications references reflist defaultsort xml retrieval category xml category information retrieval genres'
b'adversarial information retrieval adversarial ir is a topic in information retrieval related to strategies for working with a data source where some portion of it has been manipulated maliciously tasks can include gathering indexing filtering retrieving and ranking information from such a data source adversarial ir includes the study of methods to detect isolate and defeat such manipulation on the web the predominant form of such manipulation is spamdexing search engine spamming also known as spamdexing which involves employing various techniques to disrupt the activity of web search engines usually for financial gain examples of spamdexing are google bomb link bombing comment spam disambiguation comment or referrer spam spam blog s splogs malicious tagging reverse engineering of ranking function ranking algorithms ad filtering advertisement blocking click fraud ref jansen b j 2007 https faculty ist psu edu jjansen academic jansen click fraud pdf click fraud ieee computer 40 7 85 86 ref and web content filtering may also be considered forms of adversarial data manipulation ref b davison m najork and t converse 2006 http wayback archive org web 20090320173324 http www acm org sigs sigir forum 2006d 2006d sigirforum davison pdf sigir worksheet report adversarial information retrieval on the web airweb 2006 ref activities intended to poison the supply of useful data make search engines less useful for users if search engines are more exclusionary they risk becoming more like directories and less dynamic topics topics related to web spam spamdexing link spam keyword spamming cloaking malicious tagging spam related to blogs including spam in blogs comment spam spam blog splogs and sping ping spam other topics click fraud detection reverse engineering of search engine s ranking algorithm web content filtering ad filtering advertisement blocking stealth web crawling crawling troll internet malicious tagging or voting in social networks astroturfing sockpuppetry history the term adversarial information retrieval was first coined in 2000 by andrei broder then chief scientist at alta vista during the web plenary session at the text retrieval conference trec 9 conference ref d hawking and n craswell 2004 http es csiro au pubs trecbook for website pdf very large scale retrieval and web search preprint version ref see also spamdexing information retrieval references reflist external links http airweb cse lehigh edu airweb series of workshops on adversarial information retrieval on the web http webspam lip6 fr web spam challenge competition for researchers on web spam detection http wayback archive org web 20100217125910 http barcelona research yahoo net webspam web spam datasets datasets for research on web spam detection defaultsort adversarial information retrieval category information retrieval genres category internet fraud'
b'multiple issues technical date october 2014 manual date october 2016 file adunaautofocus5 png thumb osl desktop search engines software aduna autofocus 5 desktop search tools search within a user s own computer files as opposed to searching the internet these tools are designed to find information on the user s pc including web browser history e mail archives text documents sound files images and video one of the main advantages of desktop search programs is that search results are displayed quickly due to the use of proper indexes a variety of desktop search programs are now available see list of search engines desktop search engines this list for examples most desktop search programs are standalone applications whereas a few also provide search capabilities in an integrated writing environment iwe desktop search emerged as a concern for large firms for two main reasons untapped productivity and security on the one hand users need to be able to quickly find relevant files but on the other hand they shouldn t have access to restricted files according to analyst firm gartner up to 80 of some companies data is locked up inside unstructured data the information stored on an end user s pc the directories folders and files they ve created on a computer network network documents stored in repositories such as corporate intranet s and a multitude of other locations ref citation url http www computerweekly com articles 2006 04 25 215622 security special report who sees your data htm title security special report who sees your data newspaper computer weekly date 2006 04 25 ref moreover many companies have structured or unstructured information stored in older file formats to which they don t have ready access companies doing business in the united states are frequently required under regulatory mandates like sarbanes oxley health insurance portability and accountability act hipaa and ferpa to make sure that access to sensitive information is 100 controlled this creates a challenge for it organizations which may not have a desktop search standard or lack strict central control over end users downloading tools from the internet some consumer oriented desktop search tools make it possible to generate indexes outside the corporate firewall computing firewall and share those indexes with unauthorized users in some cases end users are able to index but not preview items they should not even know exist citation needed date november 2009 historically full desktop search comes from the work of apple inc apple computer s apple advanced technology group advanced technology group resulting in the underlying applesearch technology in the early 1990s it was used to build the sherlock software sherlock search engine and then developed into spotlight software spotlight which brought automated non timer based full indexing into the operating system technologies most desktop search engines build and maintain an index search engine index database to achieve reasonable performance when searching several gigabyte s of data indexing usually takes place when the computer is idle and most search applications can be set to suspend indexing if a portable computer is running on batteries in order to save power there are notable exceptions however voidtools everything search engine ref cite web title everything search engine url http www voidtools com publisher voidtools accessdate 27 december 2013 ref which performs searches over only filenames mdash not the files contents mdash for ntfs volumes only is able to build its index from scratch in just a few seconds another exception is vegnos desktop search engine ref cite web title vegnos url http www vegnos com publisher vegnos accessdate 27 december 2013 ref which performs searches over filenames and files contents without building any indices the benefits to not having indices is that in addition to not requiring persistent storage more powerful queries e g regular expressions can be issued whereas indexed search engines are limited to keyword based queries an index may also not be up to date when a query is performed in this case results returned will not be accurate that is a hit may be shown when it is no longer there and a file may not be shown when in fact it is a hit some products have sought to remedy this disadvantage by building a real time indexing function into the software there are disadvantages to not indexing namely the time to complete a query can be significant and the issued query can also be resource intensive desktop search tools typically collect three types of information about files file and folder names metadata such as titles authors comments in file types such as mp3 portable document format pdf and jpeg file content for supported types of documents only to search effectively within documents the tools need to be able to parse many different types of documents this is achieved by using filters that interpret selected file formats for example a microsoft office filter might be used to search inside microsoft office documents long term goals for desktop search include the ability to search the contents of image files sound files and video by context ref cite web url http www niallkennedy com blog archives 2006 10 video search html title the current state of video search author niall kennedy date 17 october 2006 work niall kennedy accessdate 24 june 2015 ref ref cite web url http www niallkennedy com blog archives 2006 10 audio search html title the current state of audio search author niall kennedy date 15 october 2006 work niall kennedy accessdate 24 june 2015 ref the sector attracted considerable attention from the struggle between microsoft and google ref cite web url http news bbc co uk 1 hi technology 3952285 stm title bbc news technology search wars hit desktop computers work bbc co uk accessdate 24 june 2015 ref according to market analysts both companies were attempting to leverage their monopolies of web browser s and search engine s respectively to strengthen their dominance due to google s complaint that users of windows vista cannot choose any competitor s desktop search program over the built in one an agreement was reached between us justice department and microsoft that windows vista service pack 1 would enable users to choose between the built in and other desktop search programs and select which one is to be the default ref cite web url http goebelgroup com searchtoolblog 2007 06 20 microsoft agrees to change vista desktop search tool title searchmax work goebelgroup com accessdate 24 june 2015 ref as of september 2011 google ended life for google desktop a program designed to make it easy for users to search their own pcs for emails files music photos web pages and more ref http googledesktop blogspot com 2011 09 google desktop update html google desktop update sept 2011 ref desktop search products are software alternatives to windows desktop and outlook search helping business professional sift through desktop files emails attachments sharepoint data and more ref http www brianmadden com blogs brianmadden archive 2015 03 11 what do you do for desktop search in vdi and rdsh aspx \xe2\x80\x9ewhat do you do for desktop search in vdi and rdsh blogpost by brian madden on brainmadden com retrieved on march 25 2015 ref ref cite web url http venturebeat com 2008 06 02 lookeen offers a new way way for outlook users to search title lookeen offers a new way for outlook users to search author anthony ha date 2 june 2008 work venturebeat accessdate 8 march 2016 ref ref cite web url http www computerworld com article 2475293 desktop apps x1 rises again with desktop search 8 virtual edition html title x1 rises again with desktop search 8 virtual edition author robert l mitchell date 8 may 2013 work computerworld accessdate 24 june 2015 ref platforms their histories there are three main platforms that desktop search falls into microsoft windows windows mac os mac os linux this article will focus on the history of these search platforms the features they had and how those features evolved windows today s windows search replaced wds windows desktop search wds in turn replaced indexing service a a base service that extracts content from files and constructs an indexed catalog to facilitate efficient and rapid searching ref cite web url https msdn microsoft com en us library ee805985 28v vs 85 29 aspx title indexing service publisher microsoft work microsoft com accessdate 24 june 2015 ref indexing service was originally released in august 1996 it was built in order to speed up manually searching for files on personal desktops and corporate computer network indexing service helped by using microsoft web servers to index files on the desired hard drives indexing was done by file format by using terms that users provided a search was conducted that matched terms to the data within the file formats the largest issue that indexing service faced was the fact that every time a file was added it had to be indexed this coupled with the fact that the indexing cached the entire index in ram made the hardware a huge limitation ref cite web url https msdn microsoft com en us library dd582937 28v office 11 29 aspx title indexing with microsoft index server publisher microsoft work microsoft com accessdate 24 june 2015 ref this made indexing large amounts of files require extremely powerful hardware and very long wait times in 2003 windows desktop search wds replaced microsoft indexing service instead of only matching terms to the details of the file format and file names wds brings in content indexing to all microsoft files and text based formats such as e mail and text files this means that wds looked into the files and indexed the content thus when a user searched a term wds no longer matched just information such as file format types and file names but terms and values stored within those files wds also brought instant searching meaning the user could type a character and the query would instantly start searching and updating the query as the user typed in more characters ref cite web url http www microsoft com windows products winfamily desktopsearch technicalresources techfaq mspx archiveurl https web archive org web 20110924212903 http www microsoft com windows products winfamily desktopsearch technicalresources techfaq mspx title windows search technical faq archivedate 24 september 2011 publisher microsoft work microsoft com accessdate 24 june 2015 ref windows search apparently used up a lot of processing power as windows desktop search would only run if it was directly queried or while the pc was idle even only running while directly queried or while the computer was idled indexing the entire hard drive still took hours the index would be around 10 of the size of all the files that it indexed for example if the indexed files amounted to around 100gb of space the index would itself be 10gb large with the release of windows vista came windows search 3 1 unlike its predecessors wds and windows search 3 0 3 1 could search through both indexed and non indexed locations seamlessly also the ram and cpu requirements were greatly reduced cutting back indexing times immensely windows search 4 0 is currently running on all pcs with windows 7 and up mac os mac os was the first to implement desktop search with its applesearch search engine allowing users to fully search all documents within their macintosh computer including file format types meta data on those files and content within the files applesearch was a client server model client server application and as such required a server separate from the main device in order to function the biggest issue with applesearch were its large resource requirements applesearch requires at least a 68040 processor and 5mb of ram ref cite web url http infomotions com musings tricks manuscript 1600 0001 html title applesearch work infomotions com accessdate 24 june 2015 ref at the time a macintosh computer with these specifications was priced at approximately 1400 equivalent to 2050 in 2015 ref cite web url http stats areppim com calc calc usdlrxdeflator php title converter of current to real us dollars using the gdp deflator author eduardo casais work areppim com accessdate 24 june 2015 ref on top of this the software itself cost an additional 1400 for a single license in 1997 sherlock software sherlock was released alongside mac os 8 5 sherlock named after the famous fictional detective sherlock holmes was integrated into mac os s file browser nbsp finder software finder sherlock extended the desktop search function to the world wide web allowing users to search both locally and externally adding additional functions such as internet access to sherlock was relatively simple as this was done through plugins written as plain text files sherlock was included in every release of mac os from mac os 8 before being deprecated and replaced by spotlight software spotlight and dashboard mac os dashboard in mac os x tiger mac os x 10 4 tiger it was officially removed in mac os x leopard mac os x 10 5 leopard spotlight software spotlight was released in 2005 as part of mac os x tiger mac os x 10 4 tiger it is a selection based search tool which means the user invokes a query using only the mouse spotlight allows the user to search the internet for more information about any keyword or phrase contained within a document or webpage and uses a built in calculator and oxford american dictionary to offer quick access to small calculations and word definitions ref cite web url http www apple com pr library 2005 04 12apple to ship mac os x tiger on april 29 html title apple press info apple to ship mac os x tiger on april 29 work apple com accessdate 24 june 2015 ref while spotlight initially has a long startup time this decreases as the hard disk is indexed as files are added by the user the index is constantly updated in the background using minimal cpu ram resources linux there are a wide range of desktop search options for linux users depending upon the skill level of the user their preference to use desktop tools which tightly integrate into their desktop environment command shell functionality often with advanced scripting options or browser based users interfaces to locally running software in addition many users create their own indexing from a variety of indexing packages e g one which does extraction and indexing of pdf doc docx opendocument odt documents well another search engine which works w vcard ldap and other directory contact databases as well as the conventional tt find tt and tt locate tt commands ubuntu the ubuntu distribution is a popular version of linux strangely enough ubuntu didn t have desktop search until feisty fawn 7 04 using tracker search software tracker ref cite web url http arstechnica com information technology 2007 07 afirst look at tracker 0 6 0 title a first look at tracker 0 6 0 work ars technica accessdate 24 june 2015 ref desktop search the desktop search feature was very similar to mac os s applesearch and sherlock considering the fact that both are unix based systems tracker released in late 2007 was built to have a relatively low impact on system resources but unfortunately occasionally had sporadic control over what resources it was using it not only featured the basic features of file format sorting and meta data matching but support for searching through emails and instant messages was added years later in 2014 recoll ref cite web url http www lesbonscomptes com recoll usermanual index html rcl indexing title recoll user manual work lesbonscomptes com accessdate 24 june 2015 ref was added to linux distributions it works with other search programs such as tracker and beagle software beagle to provide efficient full text search this greatly increased the types of queries that linux desktop searches could handle as well as file types a major advantage of recoll is that it allows for greater customization of what is indexed for example recoll will index the entire hard disk by default but will and can index just a few select directories instead of wasting time indexing directories you know you will never need to look at it also allows for more search options you may actually narrow down what kind of query you want to ask for example you could search for just file types or by content ref cite web url http archive09 linux com feature 114283 title linux com work linux com accessdate 24 june 2015 ref opensuse ref http www opensuse org ref todo prior desktop search before kde 3 5 starting with kde4 the nepomuk software nepomuk was introduced it provided the ability to index a wide range of desktop content email and use semantic web technologies e g resource description framework rdf to annotate the database the introduction faced a few glitches much of which seemed to be based on the triplestore performance improved at least for queries by switching the backend to a stripped own version of the virtuoso open source edition however indexing remained a common user complaint based on user feedback the nepomuk indexing and search has been replaced with the baloo framework ref https community kde org baloo ref based on xapian see also list of search engines desktop search engines list of desktop search engines references reflist 2 navigationbox desktopsearch defaultsort desktop search category desktop search engines category information retrieval genres'
b'original research date november 2015 enterprise search is the practice of making content from multiple enterprise type sources such as database s and intranet s searchable to a defined audience enterprise search is used to describe the software of search information within an enterprise though the search function and its results may still be public ref cite web url http www aiim org what is enterprise search title what is enterprise search publisher ref enterprise search can be contrasted with web search which applies search technology to documents on the open web and desktop search which applies search technology to the content on a single computer enterprise search systems index data and documents from a variety of sources such as file systems intranets document management system s e mail and databases many enterprise search systems integrate structured and unstructured data in their collections ref http www arma org bookstore files delgado pdf the new face of enterprise search bridging structured and unstructured information ref enterprise search systems also use access controls to enforce a security policy on their users ref cite web url http www ideaeng com tabid 98 itemid 118 mapping security requirements to enterprise search aspx title security requirements to enterprise search part 1 new idea engineering publisher ref enterprise search can be seen as a type of vertical search of an enterprise components of an enterprise search system in an enterprise search system content goes through various phases from source repository to search results content awareness content awareness or content collection is usually either a push or pull model in the push model a source system is integrated with the search engine in such a way that it connects to it and pushes new content directly to its api s this model is used when realtime indexing is important in the pull model the software gathers content from sources using a connector such as a web crawler or a database connector the connector typically polls the source with certain intervals to look for new updated or deleted content ref cite web url http www information management com issues 20 7 content management data integration indexing metadata 10019105 1 html title understanding content collection and indexing publisher ref content processing and analysis content from different sources may have many different formats or document types such as xml html office document formats or plain text the content processing phase processes the incoming documents to plain text using document filters it is also often necessary to normalize content in various ways to improve recall information retrieval recall or precision information retrieval precision these may include stemming lemmatization synonym expansion entity extraction part of speech tagging as part of processing and analysis tokenization lexical analysis tokenization is applied to split the content into lexical analysis token tokens which is the basic matching unit it is also common to normalize tokens to lower case to provide case insensitive search as well as to normalize accents to provide better recall indexing the resulting text is stored in an index search engine index which is optimized for quick lookups without storing the full text of the document the index may contain the dictionary of all unique words in the corpus as well as information about ranking and term frequency query processing using a web page the user issues a web search query query to the system the query consists of any terms the user enters as well as navigational actions such as faceted search faceting and paging information matching the processed query is then compared to the stored index and the search system returns results or hits referencing source documents that match some systems are able to present the document as it was indexed differences from web search unreferenced section date november 2015 beyond the difference in the kinds of materials being indexed enterprise search systems also typically include functionality that is not associated with the mainstream web search engine s these include adapters to index content from a variety of repositories such as databases and content management systems federated search which consists of transforming a query and broadcasting it to a group of disparate databases or external content sources with the appropriate syntax merging the results collected from the databases presenting them in a succinct and unified format with minimal duplication and providing a means performed either automatically or by the portal user to sort the merged result set enterprise bookmarking collaborative tag metadata tagging systems for capturing knowledge about structured and semi structured enterprise data entity extraction that seeks to locate and classify elements in text into predefined categories such as the names of persons organizations locations expressions of times quantities monetary values percentages etc faceted search a technique for accessing a collection of information represented using a faceted classification allowing users to explore by filtering available information access control usually in the form of an access control list acl is often required to restrict access to documents based on individual user identities there are many types of access control mechanisms for different content sources making this a complex task to address comprehensively in an enterprise search environment see below text clustering which groups the top several hundred search results into topics that are computed on the fly from the search results descriptions typically titles excerpts snippets and meta data this technique lets users navigate the content by topic rather than by the meta data that is used in faceting clustering compensates for the problem of incompatible meta data across multiple enterprise repositories which hinders the usefulness of faceting user interfaces which in web search are deliberately kept simple in order not to distract the user from clicking on ads which generates the revenue although the business model for enterprise search could include showing ads in practice this is not done to enhance end user productivity enterprise vendors continually experiment with rich ui functionality which occupies significant screen space which would be problematic for web search relevance factors for enterprise search unreferenced section date november 2015 the factors that determine the relevance of search results within the context of an enterprise overlap with but are different from those that apply to web search in general enterprise search engines cannot take advantage of the rich hyperlink link structure as is found on the web s hypertext content however a new breed of enterprise search engines based on a bottom up web 2 0 technology are providing both a contributory approach and hyperlink ing within the enterprise algorithms like pagerank exploit hyperlink structure to assign authority to documents and then use that authority as a query independent relevance factor in contrast enterprises typically have to use other query independent factors such as a document s recency or popularity along with query dependent factors traditionally associated with information retrieval algorithms also the rich functionality of enterprise search uis such as clustering and faceting diminish reliance on ranking as the means to direct the user s attention access control early binding vs late binding security and restricted access to documents is an important matter in enterprise search there are two main approaches to apply restricted access early binding vs late binding ref http enterprisesearch co enterprise search document access control enterprise search document access control ref late binding permissions are analyzed and assigned to documents at query stage query engine generates a document set and before returning it to a user this set is filtered based on user access rights it is costly process but accurate based on user permissions at the moment of query early binding permissions are analyzed and assigned to documents at indexing stage it is much more effective than late binding but could be inaccurate user might be granted or revoked permissions between in the period between indexing and querying search relevance testing options search application relevance can be determined by following relevance testing options like ref http searchhub org 2009 09 02 debugging search application relevance issues debugging search application relevance issues ref focus groups reference evaluation protocol based on relevance judgements of results from agreed upon queries performed against common document corpuses empirical testing a b testing log analysis on a beta production site online ratings see also collaborative search engine comparison of enterprise search software data defined storage enterprise bookmarking enterprise information access faceted search information extraction knowledge management list of enterprise search vendors list of search engines text mining vertical search references reflist defaultsort enterprise search category information retrieval genres'
b'temporal information retrieval t ir is an emerging area of research related to the field of information retrieval ir and a considerable number of sub areas positioning itself as an important dimension in the context of the user information needs according to information theory science metzger 2007 ref name metzger2007 cite journal last metzger first miriam title making sense of credibility on the web models for evaluating online information and recommendations for future research journal journal of the american society for information science and technology volume 58 issue 13 pages 2078 2091 year 2007 url http dl acm org citation cfm id 1315940 doi 10 1002 asi 20672 ref timeliness or currency is one of the key five aspects that determine a document s credibility besides relevance accuracy objectivity and coverage one can provide many examples when the returned search results are of little value due to temporal problems such as obsolete data on weather outdated information about a given company s earnings or information on already happened or invalid predictions t ir in general aims at satisfying these temporal needs and at combining traditional notions of document relevance with the so called temporal relevance this will enable the return of temporally relevant documents thus providing a temporal overview of the results in the form of timeliness or similar structures it also shows to be very useful for query understanding query disambiguation query classification result diversification and so on this page contains a list of the most important research in temporal information retrieval t ir and its related sub areas as several of the referred works are related with different research areas a single article can be found in more than one different table for ease of reading the articles are categorized in a number of different sub areas referring to its main scope in detail temporal dynamics t dynamics class wikitable sortable reference year conference journal main scope comments baeza y 2002 http www dcs bbk ac uk webdyn2 proceedings baeza yates web strucutre pdf web structure dynamics and page quality in a laendar a oliveira eds in lecture notes in computer science spire2002 9th international symposium on string processing and information retrieval vol 2476 2002 pp nbsp 117 130 lisbon portugal september 11 13 springer berlin heidelberg 2002 spire t dynamics cho j garcia molina h 2003 http dl acm org citation cfm id 857170 estimating frequency of change in http toit acm org toit acm transactions on internet technology 3 3 256 290 2003 toit t dynamics fetterly d manasse m najork m wiener j 2003 http dl acm org citation cfm id 775246 a large scale study of the evolution of web pages in http www2003 org www2003 proceedings of the 12th international world wide web conference pp nbsp 669 678 budapest hungary may 20 24 acm press 2003 www t dynamics ntoulas a cho j olston c 2004 http dl acm org citation cfm id 988674 what s new on the web the evolution of the web from a search engine perspective in http www2004 org www2004 proceedings of the 13th international world wide web conference pp nbsp 1 12 new york ny united states may 17 22 acm press 2004 www t dynamics vlachos m meek c vagena z gunopulos d 2004 http portal acm org citation cfm id 1007586 identifying similarities periodicities and bursts for online search queries in http www09 sigmod org sigmod04 eproceedings sigmod2004 proceedings of the international conference on management of data pp nbsp 131 142 paris france june 13 18 acm press 2004 sigmod t dynamics beitzel s m jensen e c chowdhury a frieder o grossman d 2007 http dl acm org citation cfm id 1190282 temporal analysis of a very large topically categorized web query log in http www asis org jasist html jasist journal of the american society for information science and technology 58 2 166 178 2007 jasist t dynamics jones r diaz f 2007 http dl acm org citation cfm id 1247720 temporal profiles of queries in http tois acm org tois acm transactions on information systems 25 3 article no 14 2007 tois tq understanding bordino i boldi p donato d santini m vigna s 2008 http ieeexplore ieee org xpl login jsp tp arnumber 4734022 url http 3a 2f 2fieeexplore ieee org 2fiel5 2f4733896 2f4733897 2f04734022 pdf 3farnumber 3d4734022 temporal evolution of the uk web in http compbio cs uic edu adn icdm08 adn2008 proceedings of the 1st international workshop on analysis of dynamic networks associated to http icdm08 isti cnr it icdm2008 ieee international conference on data mining pp nbsp 909 918 pisa italy december 19 ieee computer society press 2008 icdm adn t dynamics adar e teevan j dumais s t elsas j l 2009 http portal acm org citation cfm id 1498837 the web changes everything understanding the dynamics of web content in http wsdm2009 org wsdm2009 proceedings of the 2nd acm international conference on web search and data mining pp nbsp 282 291 barcelona spain february 9 12 acm press 2009 wsdm t dynamics metzler d jones r peng f zhang r 2009 http dl acm org citation cfm id 1572085 improving search relevance for implicitly temporal queries in http www sigir2009 org sigir 2009 proceedings of the 32nd annual international acm sigir conference on research and development in information retrieval pp nbsp 700 701 boston ma united states july 19 23 acm press 2009 sigir tq understanding elsas j l dumais s t 2010 http dl acm org citation cfm id 1718489 leveraging temporal dynamics of document content in relevance ranking in http www wsdm conference org 2010 wsdm10 third acm international conference on web search and data mining pp nbsp 1 10 new york united states february 3 06 acm press 2010 wsdm t dynamics jatowt a kawai h kanazawa k tanaka k kunieda k 2010 http dl acm org citation cfm id 1772835 analyzing collective view of future time referenced events on the web in http www2010 org www index html www2010 proceedings of the 19th international world wide web conference pp nbsp 1123 1124 raleigh united states april 26 30 acm press 2010 www f iretrieval aji a agichtein e 2010 http dl acm org citation cfm id 2175298 2175332 deconstructing interaction dynamics in knowledge sharing communities in http sbp asu edu sbp2010 sbp10 html third international conference on social computing behavioral cultural modeling prediction pp nbsp 273 281 washington dc united states march 30 31 springer verlag 2010 sbp t dynamics kulkarni a teevan j svore k m dumais s t 2011 http portal acm org citation cfm id 1935862 understanding temporal query dynamics in http www wsdm2011 org wsdm2011 in proceedings of the 4th acm international conference on web search and data mining pp nbsp 167 176 hong kong china february 9 12 acm press 2011 wsdm t dynamics campos r dias g jorge a m 2011 http ceur ws org vol 707 twaw2011 pdf what is the temporal value of web snippets in http temporalweb net page3 page3 html twaw 2011 proceedings of the 1st international temporal web analytics workshop associated to http www www2011india com www2011 20th international world wide web conference hyderabad india march 28 ceur workshop proceedings 2011 www twaw t dynamics campos r jorge a dias g 2011 http ciir cs umass edu sigir2011 qru campos al pdf using web snippets and query logs to measure implicit temporal intents in queries in http ciir cs umass edu sigir2011 qru qru 2011 proceedings of the query representation and understanding workshop associated to http www sigir2011 org sigir2011 34th annual international acm sigir 2011 conference on research and development in information retrieval pp nbsp 13 16 beijing china july 28 2011 sigir qru t dynamics shokouhi m 2011 http dl acm org citation cfm id 2010104 detecting seasonal queries by time series analysis in http www sigir2011 org sigir2011 in proceedings of the 34th international acm sigir conference on research and development in information pp nbsp 1171 1172 beijing china july 24 28 acm press 2011 sigir t dynamics dias g campos r jorge a 2011 http select cs cmu edu meetings enir2011 papers dias campos jorge pdf future retrieval what does the future talk about in http select cs cmu edu meetings enir2011 enir 2011 proceedings of the enriching information retrieval workshop associated to http www sigir2011 org sigir2011 34th annual international acm sigir conference on research and development in information retrieval beijing china july 28 2011 sigir enir f iretrieval campos r dias g jorge a m 2011 http dl acm org citation cfm id 2051169 an exploratory study on the impact of temporal features on the classification and clustering of future related web documents in l antunes h s pinto eds lecture notes in artificial intelligence progress in artificial intelligence http epia2011 appia pt epia2011 15th portuguese conference on artificial intelligence associated to appia portuguese association for artificial intelligence vol 7026 2011 pp nbsp 581 596 lisboa portugal october 10 13 springer berlin heidelberg 2011 epia f iretrieval jatowt a yeung c m 2011 http dl acm org citation cfm id 2063759 extracting collective expectations about the future from large text collections in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1259 1264 glasgow scotland uk october 24 28 acm press 2011 cikm f iretrieval yeung c m a jatowt a 2011 http dl acm org citation cfm id 2063755 studying how the past is remembered towards computational history through large scale text mining in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1231 1240 glasgow scotland uk october 24 28 acm press 2011 cikm c memory costa m silva m j couto f m 2014 http dl acm org citation cfm id 2609619 learning temporal dependent ranking models in proceedings of the http sigir org sigir2014 sigir2014 37th annual acm sigir conference pp nbsp 757 766 gold coast australia july 6 11 acm press 2014 sigir t rmodels temporal markup languages t mlanguages class wikitable sortable reference year conference journal main scope comments setzer a gaizauskas r 2000 ftp ftp dcs shef ac uk home robertg papers lrec00 tempann pdf annotating events and temporal information in newswire texts in http www xanthi ilsp gr lrec lrec2000 proceedings of the 2nd international conference on language resources and evaluation athens greece may 31 june 2 elda 2000 lrec t mlanguages setzer a 2001 http www andrea setzer org uk papers thesis pdf temporal information in newswire articles an annotation scheme and corpus study sheffield uk university of sheffield 2001 phd thesis t mlanguages ferro l mani i sundheim b wilson g 2001 http www timeml org site terqas readings mtrannotationguide v1 02 pdf tides temporal annotation guidelines version 1 0 2 technical report mitre corporation mclean virginia united states 2001 technical report t mlanguages pustejovsky j casta\xc3\xb1o j ingria r sauri r gaizauskas r setzer a et al 2003 timeml robust specification of event and temporal expression in text in http iwcs uvt nl iwcs5 index htm iwcs2003 proceedings of the 5th international workshop on computational semantics pp nbsp 28 34 tilburg netherlands january 15 17 2003 iwcs t mlanguages ferro l gerber l mani i sundheim b wilson g 2005 http projects ldc upenn edu ace docs english timex2 guidelines v0 1 pdf tides 2005 standard for the annotation of temporal expressions technical report mitre corporation mclean virginia united states 2005 technical report t mlanguages temporal taggers t taggers class wikitable sortable reference year conference journal main scope comments http www timeml org site tarsqi toolkit manual tempex module http www timeml org site tarsqi toolkit index html tarsqi toolkit mani i wilson g 2000 dl acm org citation cfm id 1075228 robust temporal processing of news in http www cse ust hk acl2000 acl2000 proceedings of the 38th annual meeting of the association for computational linguistics pp nbsp 69 76 hong kong china october 1 8 association for computational linguistics 2000 acl t taggers http www aktors org technologies annie annie http gate ac uk download index html gate distribution cunningham h maynard d bontcheva k tablan v 2002 http eprints aktors org 90 01 acl main pdf gate a framework and graphical development environment for robust nlp tools and applications in http www aclweb org mirror acl2002 acl2002 proceedings of the 40th annual meeting of the association for computational linguistics pp nbsp 168 175 philadelphia pa united states july 6 12 association for computational linguistics 2002 acl t taggers http www timeml org site tarsqi modules gutime download html gutime http www timeml org site tarsqi toolkit index html tarsqi toolkit 2002 t taggers http dbs ifi uni heidelberg de index php id form downloads heideltime str\xc3\xb6tgen j gertz m 2010 http delivery acm org 10 1145 1860000 1859735 p321 strotgen pdf ip 188 80 124 88 acc open cfid 82473711 cftoken 13661527 acm 1337002719 1b05141ffc83e798f400c972756d43ad heideltime high quality rule based extraction and normalization of temporal expressions in http semeval2 fbk eu semeval2 php semeval2010 proceedings of the 5th international workshop on semantic evaluation associated to http acl2010 org acl2010 41st annual meeting of the association for computational linguistics pp nbsp 321 324 uppsala sweden july 11 16 2010 acl semeval t taggers http www timen org timen llorens h derczynski l gaizauskas r saquete e 2012 http www lrec conf org proceedings lrec2012 pdf 128 paper pdf timen an open temporal expression normalisation resource in http www lrec conf org lrec2012 lrec2012 proceedings of the 8th international conference on language resources and evaluation istanbul turkey may 23 25 2012 lrec t taggers chang a manning c 2012 http www lrec conf org proceedings lrec2012 pdf 284 paper pdf sutime a library for recognizing and normalizing time expressions in http www lrec conf org lrec2012 lrec2012 proceedings of the 8th international conference on language resources and evaluation istanbul turkey may 23 25 2012 lrec t taggers http dbs ifi uni heidelberg de index php id form downloads heideltime str\xc3\xb6tgen j gertz m 2012 http www springerlink com content 64767752451075k8 multilingual and cross domain temporal tagging in http www springerlink com content 1574 020x lre language resources and evaluation 1 30 2012 lre t taggers http www cs man ac uk filannim projects tempeval 3 mantime filannino m brown g nenadic g 2013 http www aclweb org anthology s s13 s13 2 pdf page 89 mantime temporal expression identification and normalization in the tempeval 3 challenge in second joint conference on lexical and computational semantics sem volume 2 seventh international workshop on semantic evaluation semeval 2013 53 57 atlanta georgia june 14 15 2013 2013 acl semeval t taggers http www cs man ac uk filannim projects tempeval 3 online demo temporal indexing t indexing class wikitable sortable reference year conference journal main scope comments alonso o gertz m 2006 http dl acm org citation cfm id 1148170 1148273 coll dl dl guide cfid 102654836 cftoken 48651941 clustering of search results using temporal attributes in http www sigir org sigir2006 sigir 2006 proceedings of the 29th annual international acm sigir conference on research and development in information retrieval pp nbsp 597 598 seattle washington united states august 6 11 acm press 2006 sigir t clustering berberich k bedathur s neumann t weikum g 2007 http dl acm org citation cfm id 1277831 a time machine for text search in http www sigir org sigir2007 sigir 2007 proceedings of the 30th annual international acm sigir conference on research and development in information retrieval pp nbsp 519 526 amsterdam netherlands july 23 27 acm press 2007 sigir w archives jin p lian j zhao x wan s 2008 http ieeexplore ieee org xpl articledetails jsp arnumber 4739991 tise a temporal search engine for web contents in iita2008 proceedings of the 2nd international symposium on intelligent information technology application pp nbsp 220 224 shanghai china december 21 22 ieee computer society press 2008 iita t sengine song s jaja j 2008 http www umiacs umd edu joseph temporal web archiving final umiacs tr 2008 08 pdf archiving temporal web information organization of web contents for fast access and compact storage technical report umiacs tr 2008 08 university of maryland institute for advanced computer studies maryland md united states 2008 technical report w archives pasca m 2008 http dl acm org citation cfm id 1363946 towards temporal web search in http www acm org conferences sac sac2008 sac2008 proceedings of the 23rd acm symposium on applied computing pp nbsp 1117 1121 fortaleza ceara brazil march 16 20 acm press 2008 sac t qanswering alonso o gertz m baeza yates r 2009 http dl acm org citation cfm id 1645953 1645968 clustering and exploring search results using timeline constructions in http www comp polyu edu hk conference cikm2009 cikm 2009 proceedings of the 18th international acm conference on information and knowledge management hong kong china november 2 6 acm press 2009 cikm t clustering arikan i bedathur s berberich k 2009 http www wsdm2009 org arikan 2009 temporal expressions pdf time will tell leveraging temporal expressions in ir in http wsdm2009 org wsdm 2009 proceedings of the 2nd acm international conference on web search and data mining barcelona spain february 9 12 acm press 2009 wsdm t rmodels matthews m tolchinsky p blanco r atserias j mika p zaragoza h 2010 http research yahoo com pub 3341 searching through time in the new york times in http www iiix2010 org hcir workshop hcir2010 proceedings of the 4th workshop on human computer interaction and information retrieval pp nbsp 41 44 new brunswick united states august 22 2010 hcir t sengine anand a bedathur s berberich k schenkel r 2010 http dl acm org citation cfm id 1871437 1871528 efficient temporal keyword search over versioned text in http www yorku ca cikm10 cikm2010 proceedings of the 19th acm international conference on information and knowledge management pp nbsp 699 708 toronto canada october 26 30 acm press 2010 cikm w archives anand a bedathur s berberich k schenkel r 2011 http dl acm org citation cfm id 2009991 temporal index sharding for space time efficiency in archive search in http www sigir org sigir2011 sigir2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 545 554 beijing china july 24 28 acm press 2011 sigir t indexing anand a bedathur s berberich k schenkel r 2012 http dl acm org citation cfm id 2348318 index maintenance for time travel text search in http www sigir org sigir2012 sigir2012 proceedings of the 35th annual international acm sigir conference on research and development in information retrieval pp nbsp 235 243 portland united states august 12 16 acm press 2012 sigir w archives temporal query understanding tq understanding class wikitable sortable reference year conference journal main scope comments vlachos m meek c vagena z gunopulos d 2004 http portal acm org citation cfm id 1007586 identifying similarities periodicities and bursts for online search queries in http www09 sigmod org sigmod04 eproceedings sigmod2004 proceedings of the international conference on management of data pp nbsp 131 142 paris france june 13 18 acm press 2004 sigmod t dynamics beitzel s m jensen e c chowdhury a frieder o grossman d 2007 http dl acm org citation cfm id 1190282 temporal analysis of a very large topically categorized web query log in http www asis org jasist html jasist journal of the american society for information science and technology 58 2 166 178 2007 jasist t dynamics jones r diaz f 2007 http dl acm org citation cfm id 1247720 temporal profiles of queries in http tois acm org tois acm transactions on information systems 25 3 article no 14 2007 tois tq understanding dakka w gravano l ipeirotis p g 2008 http dl acm org citation cfm id 1458320 answering general time sensitive queries in http www cikm2008 org cikm 2008 proceedings of the 17th international acm conference on information and knowledge management pp nbsp 1437 1438 napa valley california united states october 26 30 acm press 2008 cikm tq understanding diaz f 2009 http dl acm org citation cfm id 1498825 integration of news content into web results in http wsdm2009 org wsdm2009 proceedings of the 2nd acm international conference on web search and data mining pp nbsp 182 191 barcelona spain february 9 12 acm press 2009 wsdm tq understanding metzler d jones r peng f zhang r 2009 http dl acm org citation cfm id 1572085 improving search relevance for implicitly temporal queries in http www sigir2009 org sigir2009 proceedings of the 32nd annual international acm sigir conference on research and development in information retrieval pp nbsp 700 701 boston ma united states july 19 23 acm press 2009 sigir tq understanding k\xc3\xb6nig a 2009 http dl acm org citation cfm id 1572002 click through prediction for news queries in http www sigir2009 org sigir2009 proceedings of the 32nd annual international acm sigir conference on research and development in information retrieval pp nbsp 347 354 boston ma united states july 19 23 acm press 2009 sigir tq understanding kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine dong a chang y zheng z mishne g bai j zhang r et al 2010 http dl acm org citation cfm id 1718490 towards recency ranking in web search in http www wsdm conference org 2010 wsdm2010 in proceedings of the 3rd acm international conference on web search and data mining pp nbsp 11 20 new york united states february 3 6 acm press 2010 wsdm t rmodels kanhabua n n\xc3\xb8rv\xc3\xa5g k 2010 http dl acm org citation cfm id 1887796 determining time of queries for re ranking search results in http www ecdl2010 org ecdl2010 proceedings of the european conference on research and advanced technology for digital libraries glasgow scotland september 6 10 springer berlin heidelberg 2010 ecdl tq understanding zhang r konda y dong a kolari p chang y zheng z 2010 http dl acm org citation cfm id 1870768 learning recurrent event queries for web search in http www lsi upc edu events emnlp2010 emnlp2010 proceedings of the conference on empiral methods in natural language processing pp nbsp 1129 1139 massachusetts united states october 9 11 association for computational linguistics 2010 emnlp tq understanding kulkarni a teevan j svore k m dumais s t 2011 http portal acm org citation cfm id 1935862 understanding temporal query dynamics in http www wsdm2011 org wsdm2011 in proceedings of the 4th acm international conference on web search and data mining pp nbsp 167 176 hong kong china february 9 12 acm press 2011 wsdm t dynamics campos r 2011 http dl acm org citation cfm id 2010182 using k top retrieved web snippets to date temporal implicit queries based on web content analysis in http www sigir2011 org 20 sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval p nbsp 1325 beijing china july 24 28 acm press 2011 sigir tq understanding campos r jorge a dias g 2011 http ciir cs umass edu sigir2011 qru campos al pdf using web snippets and query logs to measure implicit temporal intents in queries in http ciir cs umass edu sigir2011 qru qru 2011 proceedings of the query representation and understanding workshop associated to http www sigir2011 org sigir2011 34th annual international acm sigir 2005 conference on research and development in information retrieval pp nbsp 13 16 beijing china july 28 2011 sigir qru t dynamics shokouhi m 2011 http dl acm org citation cfm id 2010104 detecting seasonal queries by time series analysis in http www sigir2011 org sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 1171 1172 beijing china july 24 28 acm press 2011 sigir tq understanding campos r dias g jorge a nunes c 2012 http dl acm org citation cfm id 2169103 cfid 102654836 cftoken 48651941 enriching temporal query understanding through date identification how to tag implicit temporal queries in http www temporalweb net twaw 2012 proceedings of the 2nd international temporal web analytics workshop associated to http www2012 wwwconference org www2012 20th international world wide web conference pp nbsp 41 48 lyon france april 17 acm dl 2012 www twaw tq understanding shokouhi m radinsky k 2012 http dl acm org citation cfm id 2348364 time sensitive query auto completion in http www sigir org sigir2012 sigir 2012 proceedings of the 35th annual international acm sigir conference on research and development in information retrieval pp nbsp 601 610 portland united states august 12 16 acm press 2012 sigir tq understanding campos r dias g jorge a nunes c 2012 http dl acm org citation cfm id 2398567 dl acm coll dl cfid 204979644 cftoken 99312511 gte a distributional second order co occurrence approach to improve the identification of top relevant dates in http www cikm2012 org cikm 2012 proceedings of the 21st acm conference on information and knowledge management pp nbsp 2035 2039 maui hawaii united states october 29 november 02 acm press 2012 cikm tq understanding campos r jorge a dias g nunes c 2012 http dl acm org citation cfm id 2457524 2457656 disambiguating implicit temporal queries by clustering top relevant dates in web snippets in http www fst umac mo wic2012 wi wic 2012 proceedings of the 2012 ieee wic acm international joint conferences on web intelligence and intelligent agent technology vol 1 pp nbsp 1 8 macau china december 04 07 2012 wic t clustering time aware retrieval ranking models t rmodels class wikitable sortable reference year conference journal main scope comments li x croft b w 2003 http dl acm org citation cfm doid 956863 956951 time based language models in cikm 2003 proceedings of the 12th international acm conference on information and knowledge management pp nbsp 469 475 new orleans louisiana united states november 2 8 acm press 2003 cikm t rmodels sato n uehara m sakai y 2003 http ieeexplore ieee org xpl articledetails jsp reload true arnumber 1232026 contenttype conference publications temporal information retrieval in cooperative search engine in http www dexa org previous dexa2003 cfp dexa html dexa2003 proceedings of the 14th international workshop on database and expert systems applications pp nbsp 215 220 prague czech republic september 1 5 ieee 2003 dexa t rmodels berberich k vazirgiannis m weikum g 2005 http projecteuclid org dpubs verb display version 1 0 service ui handle euclid im 1150474885 page record time aware authority ranking in http www tandf co uk journals journal asp issn 1542 7951 linktype 44 im internet mathematics 2 3 301 332 2005 im t rmodels cho j roy s adams r 2005 http dl acm org citation cfm id 1066220 page quality in search of an unbiased web ranking in http cimic rutgers edu sigmod05 sigmod2005 proceedings of the international conference on management of data pp nbsp 551 562 baltimore united states june 13 16 acm press 2005 sigmod t rmodels perki\xc3\xb6 j buntine w tirri h 2005 http dl acm org citation cfm id 1076171 a temporally adaptative content based relevance ranking algorithm in http www dcc ufmg br eventos sigir2005 sigir 2005 proceedings of the 28th annual international acm sigir conference on research and development in information retrieval pp nbsp 647 648 salvador brazil august 15 16 acm press 2005 sigir t rmodels jones r diaz f 2007 http dl acm org citation cfm id 1247720 temporal profiles of queries in http tois acm org tois acm transactions on information systems 25 3 article no 14 2007 tois tq understanding pasca m 2008 http dl acm org citation cfm id 1363946 towards temporal web search in http www acm org conferences sac sac2008 sac2008 proceedings of the 23rd acm symposium on applied computing pp nbsp 1117 1121 fortaleza ceara brazil march 16 20 acm press 2008 sac t qanswering dakka w gravano l ipeirotis p g 2008 http dl acm org citation cfm id 1458320 answering general time sensitive queries in http www cikm2008 org cikm 2008 proceedings of the 17th international acm conference on information and knowledge management pp nbsp 1437 1438 napa valley california united states october 26 30 acm press 2008 cikm tq understanding jin p lian j zhao x wan s 2008 http ieeexplore ieee org xpl articledetails jsp arnumber 4739991 tise a temporal search engine for web contents in iita2008 proceedings of the 2nd international symposium on intelligent information technology application pp nbsp 220 224 shanghai china december 21 22 ieee computer society press 2008 iita t sengine arikan i bedathur s berberich k 2009 http www wsdm2009 org arikan 2009 temporal expressions pdf time will tell leveraging temporal expressions in ir in http wsdm2009 org wsdm 2009 proceedings of the 2nd acm international conference on web search and data mining barcelona spain february 9 12 acm press 2009 wsdm t rmodels zhang r chang y zheng z metzler d nie j y 2009 http dl acm org citation cfm id 1620899 search result re ranking by feedback control adjustment for time sensitive query in http www naaclhlt2009 org naacl2009 proceedings of the north american chapter of the association for computational linguistics human language technologies pp nbsp 165 168 boulder colorado united states may 31 june 5 2009 naacl t rmodels metzler d jones r peng f zhang r 2009 http dl acm org citation cfm id 1572085 improving search relevance for implicitly temporal queries in http www sigir2009 org sigir 2009 proceedings of the 32nd annual international acm sigir conference on research and development in information retrieval pp nbsp 700 701 boston ma united states july 19 23 acm press 2009 sigir tq understanding alonso o gertz m baeza yates r 2009 http dl acm org citation cfm id 1645953 1645968 clustering and exploring search results using timeline constructions in http www comp polyu edu hk conference cikm2009 cikm 2009 proceedings of the 18th international acm conference on information and knowledge management hong kong china november 2 6 acm press 2009 cikm t clustering kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine elsas j l dumais s t 2010 http dl acm org citation cfm id 1718489 leveraging temporal dynamics of document content in relevance ranking in http www wsdm conference org 2010 wsdm10 third acm international conference on web search and data mining pp nbsp 1 10 new york united states february 3 06 acm press 2010 wsdm t dynamics aji a wang y agichtein e gabrilovich e 2010 http dl acm org citation cfm id 1871519 using the past to score the present extending term weighting models through revision history analysis in http www cikm2010 org cikm 2010 proceedings of the 19th acm conference on information and knowledge management pp nbsp 629 638 toronto on canada october 26 october 30 acm press 2010 cikm t rmodels dong a chang y zheng z mishne g bai j zhang r et al 2010 http dl acm org citation cfm id 1718490 towards recency ranking in web search in http www wsdm conference org 2010 wsdm2010 in proceedings of the 3rd acm international conference on web search and data mining pp nbsp 11 20 new york united states february 3 6 acm press 2010 wsdm t rmodels berberich k bedathur s alonso o weikum g 2010 http www springerlink com content b193008160713350 a language modeling approach for temporal information needs in c gurrin y he g kazai u kruschwitz s little t roelleke et al eds in lecture notes in computer science research and advanced technology for digital libraries http kmi open ac uk events ecir2010 ecir 2010 32nd european conference on information retrieval vol 5993 2010 pp nbsp 13 25 milton keynes uk march 28 31 springer berlin heidelberg 2010 ecir t rmodels dong a zhang r kolari p jing b diaz f chang y zheng z zha h 2010 http dl acm org citation cfm id 1772725 dl acm coll dl cfid 204979644 cftoken 99312511 time is of the essence improving recency ranking using twitter data in http www2010 org www index html www2010 proceedings of the 19th international world wide web conference pp nbsp 331 340 raleigh united states april 26 30 acm press 2010 www t rmodels inagaki y sadagopan n dupret g dong a liao c chang y zheng z 2010 http labs yahoo com files aaai10 recencyfeature 2 pdf session based click features for recency ranking in http www aaai org conferences aaai aaai10 php aaai2010 proceedings of the 24th aaai conference on artificial intelligence pp nbsp 331 340 atlanta united states june 11 15 aaai press 2010 aaai t rmodels dai n davison b 2010 http dl acm org citation cfm id 1835471 freshness matters in flowers food and web authority in http www sigir2010 org doku php sigir 2010 proceedings of the 33rd annual international acm sigir conference on research and development in information retrieval pp nbsp 114 121 geneve switzerland july 19 23 acm press 2010 sigir t rmodels matthews m tolchinsky p blanco r atserias j mika p zaragoza h 2010 http research yahoo com pub 3341 searching through time in the new york times in http www iiix2010 org hcir workshop hcir2010 proceedings of the 4th workshop on human computer interaction and information retrieval pp nbsp 41 44 new brunswick united states august 22 2010 hcir t sengine kanhabua n n\xc3\xb8rv\xc3\xa5g k 2010 http dl acm org citation cfm id 1887796 determining time of queries for re ranking search results in http www ecdl2010 org ecdl2010 proceedings of the european conference on research and advanced technology for digital libraries glasgow scotland september 6 10 springer berlin heidelberg 2010 ecdl tq understanding efron m golovchinsky g 2011 http dl acm org citation cfm id 2009916 2009984 estimation methods for ranking recent information in http www sigir2011 org sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 495 504 beijing china july 24 28 acm press 2011 sigir t rmodels dai n shokouhi m davison b d 2011 http dl acm org citation cfm id 2009916 2009933 learning to rank for freshness and relevance in http www sigir2011 org sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 95 104 beijing china july 24 28 acm press 2011 sigir t rmodels kanhabua n blanco r matthews m 2011 http dl acm org citation cfm id 2010018 dl acm coll dl cfid 102654836 cftoken 48651941 ranking related news predictions in http www sigir2011 org sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 755 764 beijing china july 24 28 acm press 2011 sigir f iretrieval chang p t huang y c yang c l lin s d cheng p j 2012 http dl acm org citation cfm id 2348489 learning based time sensitive re ranking for web search in proceedings of the http www sigir org sigir2012 sigir2012 35th annual international acm sigir 2012 conference on research and development in information retrieval pp nbsp 1101 1102 portland united states august 12 16 2012 sigir t rmodels efron m 2012 http research microsoft com en us people milads efrontemporalwsv02 pdf query specific recency ranking survival analysis for improved microblog retrieval in http research microsoft com en us people milads taia2012 aspx taia 2012 proceedings of the time aware information access workshop associated to http www sigir org sigir2012 sigir2012 35th annual international acm sigir 2012 conference on research and development in information retrieval portland united states august 16 2012 sigir taia t rmodels kanhabua n n\xc3\xb8rv\xc3\xa5g k 2012 http dl acm org citation cfm id 2398667 learning to rank search results for time sensitive queries in http www cikm2012 org cikm 2012 proceedings of the 21st acm conference on information and knowledge management pp nbsp 2463 2466 maui hawaii united states october 29 november 02 acm press 2012 cikm t rmodels kim g and xing e p 2013 http dl acm org citation cfm id 2433417 time sensitive web image ranking and retrieval via dynamic multi task regression in http wsdm2013 org wsdm2013 proceedings of the 6th acm international conference on web search and data mining pp nbsp 163 172 rome italy february 4 8 acm press 2013 wsdm t iretrieval costa m silva m j couto f m 2014 http dl acm org citation cfm id 2609619 learning temporal dependent ranking models in proceedings of the http sigir org sigir2014 sigir2014 37th annual acm sigir conference pp nbsp 757 766 gold coast australia july 6 11 acm press 2014 sigir t rmodels temporal clustering t clustering class wikitable sortable reference year conference journal main scope comments shaparenko b caruana r gehrke j joachims t 2005 http www cs cornell edu people tj publications shaparenko etal 05a pdf identifying temporal paterns and key players in document collections in http users cis fiu edu taoli workshop tdm2005 index html tdm2005 proceedings of the workshop on temporal data mining associated to http www cacs louisiana edu icdm05 icdm2005 pp nbsp 165 174 houston united states november 27 30 ieee press 2005 icdm tdm tdt alonso o gertz m 2006 http dl acm org citation cfm id 1148170 1148273 coll dl dl guide cfid 102654836 cftoken 48651941 clustering of search results using temporal attributes in http www sigir org sigir2006 sigir 2006 proceedings of the 29th annual international acm sigir conference on research and development in information retrieval pp nbsp 597 598 seattle washington united states august 6 11 acm press 2006 sigir t clustering mori m miura t shioya i 2006 http dl acm org citation cfm id 1249137 topic detection and tracking for news web pages in http www comp hkbu edu hk wii06 wi wic2006 ieee main conference proceedings of the ieee wic acm international conference on web intelligence pp nbsp 338 342 hong kong china december 18 22 ieee computer society press 2006 wic tdt alonso o baeza yates r gertz m 2007 exploratory search using timelines in eschi proceedings of the workshop on exploratory search and computer human interaction associated to http www chi2007 org chi2007 http research microsoft com en us um people ryenw esi acceptedposters html sigchi conference on human factors in computing systems san jose ca united states april 29 acm press 2007 chi eschi t sengine jatowt a kawai h kanazawa k tanaka k kunieda k 2009 http dl acm org citation cfm id 1555420 supporting analysis of future related information in news archives and the web in http www jcdl2009 org jcdl2009 proceedings of the joint conference on digital libraries pp nbsp 115 124 austin united states june 15 19 acm press 2009 jcdl f iretrieval campos r dias g jorge a 2009 http www ccc ipt pt ricardo ficheiros kdir2009 pdf disambiguating web search results by topic and temporal clustering a proposal in http www kdir ic3k org kdir2009 proceedings of the international conference on knowledge discovery and information retrieval pp nbsp 292 296 funchal madeira portugal october 6 8 2009 kdir t clustering alonso o gertz m baeza yates r 2009 http dl acm org citation cfm id 1645953 1645968 clustering and exploring search results using timeline constructions in http www comp polyu edu hk conference cikm2009 cikm 2009 proceedings of the 18th international acm conference on information and knowledge management hong kong china november 2 6 acm press 2009 cikm t clustering kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine jatowt a yeung c m 2011 http dl acm org citation cfm id 2063759 extracting collective expectations about the future from large text collections in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1259 1264 glasgow scotland uk october acm press 2011 cikm f iretrieval campos r jorge a dias g nunes c 2012 http dl acm org citation cfm id 2457524 2457656 disambiguating implicit temporal queries by clustering top relevant dates in web snippets in http www fst umac mo wic2012 wi wic 2012 proceedings of the 2012 ieee wic acm international joint conferences on web intelligence and intelligent agent technology vol 1 pp nbsp 1 8 macau china december 04 07 2012 wic t clustering temporal text classification t classification class wikitable sortable reference year conference journal main scope comments jong f rode h hiemstra d 2006 http doc utwente nl 66448 temporal language models for the disclosure of historical text in http www dans knaw nl en ahc2005 proceedings of the xvith international conference of the association for history and computing pp nbsp 161 168 amsterdam netherlands september 14 17 2005 ahc t classification toyoda m kitsuregawa m 2006 http dl acm org citation cfm id 1135777 1135815 what s really new on the web identifying new pages from a series of unstable web snapshots in http www2006 org www2006 proceedings of the 15th international world wide web conference pp nbsp 233 241 edinburgh scotland may 23 26 acm press 2006 www t classification nunes s ribeiro c david g 2007 http dl acm org citation cfm id 1316924 using neighbors to date web documents in http workshops inf ed ac uk widm2007 widm2007 proceedings of the 9th acm international workshop on web information and data management associated to www2 fc ul pt cikm2007 cikm2007 16th international conference on knowledge and information management pp nbsp 129 136 lisboa portugal november 9 acm press 2007 cikm widm t classification jatowt a kawai y tanaka k 2007 http dl acm org citation cfm id 1316925 detecting age of page content in http workshops inf ed ac uk widm2007 widm2007 proceedings of the 8th international workshop on web information and data management associated to http www2 fc ul pt cikm2007 cikm2007 16th international conference on knowledge and information management pp nbsp 137 144 lisbon portugal november 9 acm press 2007 cikm widm t classification kanhabua n n\xc3\xb8rv\xc3\xa5g k 2008 http dl acm org citation cfm id 1429902 improving temporal language models for determining time of non timestamped documents in christensen dalsgaard b castelli d jurik b a lippincott j eds in lecture notes in computer science research and advanced technology for digital libraries http www ecdl2008 org ecdl 2008 12th european conference on research and advances technology for digital libraries vol 5173 2008 pp nbsp 358 370 aarhus denmark september 14 19 springer berlin heidelberg 2008 ecdl t classification jatowt a yeung c m 2011 http dl acm org citation cfm id 2063759 extracting collective expectations about the future from large text collections in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1259 1264 glasgow scotland uk october acm press 2011 cikm f iretrieval str\xc3\xb6tgen j alonso o gertz m 2012 http dl acm org citation cfm id 2169095 2169102 coll dl dl guide cfid 102654836 cftoken 48651941 identification of top relevant temporal expressions in documents in http www temporalweb net twaw 2012 proceedings of the 2nd international temporal web analytics workshop associated to http www2012 wwwconference org www2012 20th international world wide web conference pp nbsp 33 40 lyon france april 17 acm dl 2012 www twaw t classification filannino m and nenadic g 2014 http www aclweb org anthology w w14 w14 4502 pdf mining temporal footprints from wikipedia in proceedings of the first aha workshop on information discovery in text dublin ireland august 2014 association for computational linguistics and dublin city university pp 7 13 2014 coling t classification http www cs man ac uk filannim projects temporal footprints online demo temporal visualization t interfaces class wikitable sortable reference year conference journal main scope comments swan r allan j 2000 http dl acm org citation cfm id 345546 automatic generation of overview timelines in http www aueb gr conferences sigir2000 sigir 2000 proceedings of the 23rd annual international acm sigir conference on research and development in information retrieval pp nbsp 49 56 athens greece july 24 28 acm press 2000 sigir tdt swan r jensen d 2000 http www cs cmu edu dunja swan tm pdf timemines constructing timelines with statistical models of word usage in m grobelnik d mladenic n milic frayling ed http www cs cmu edu dunja wshkdd2000 html tm2000 proceedings of the workshop on text mining associated to http www sigkdd org kdd2000 kdd2000 6th acm sigkdd international conference on knowledge discovery and data mining pp nbsp 73 80 boston massachusetts united states august 20 23 acm press 2000 kdd tm tdt https books google com ngrams google ngram viewer t interfaces cousins s kahn m 1991 http www sciencedirect com science article pii 093336579190005v the visual display of temporal information e keravnou ed in aim artificial intelligence in medicine 3 6 341 357 1991 aim t interfaces karam g m 1994 http dl acm org citation cfm id 187157 visualization using timelines in t j ostrand ed issta1994 proceedings of the international symposium on software testing and analysis associated to sigsoft acm special interest group on software engineering pp nbsp 125 137 seattle washington united states august 17 19 acm press 1994 issta t interfaces plaisant c miiash b rose a widoff s shneiderman b 1996 http dl acm org citation cfm id 238493 lifelines visualizing personal histories in http www sigchi org chi96 proceedings index htm chi1996 proceedings of the sigchi conference on human factors in computing systems pp nbsp 221 227 vancouver british columbia canada april 13 18 acm press 1996 chi t interfaces toyoda m kitsuregawa m 2005 http dl acm org citation cfm id 1083387 a system for visualizing and analyzing the evolution of the web with a time series of graphs in http www ht05 org ht2005 proceedings of the 16th acm conference on hypertext and hypermedia pp nbsp 151 160 salzburg austria september 6 9 acm press 2005 ht w archives efendioglu d faschetti c parr t 2006 http dl acm org authorize 815487 chronica a temporal web search engine in d wolber n calder c brooks ed http www icwe2006 org icwe2006 proceedings of the 6th international conference on web engineering pp nbsp 119 120 palo alto california united states july 11 14 acm press 2006 icwe w archives catizone r dalli a wilks y 2006 http www lrec conf org proceedings lrec2006 pdf 702 pdf pdf evaluating automatically generated timelines from the web in http www lrec conf org lrec2006 lrec2006 proceedings of the 5th international conference on language resources and evaluation genoa italy may 24 26 elda 2006 lrec t interfaces mori m miura t shioya i 2006 http dl acm org citation cfm id 1249137 topic detection and tracking for news web pages in http www comp hkbu edu hk wii06 wi wic2006 ieee main conference proceedings of the ieee wic acm international conference on web intelligence pp nbsp 338 342 hong kong china december 18 22 ieee computer society press 2006 wic tdt alonso o baeza yates r gertz m 2007 exploratory search using timelines in eschi proceedings of the workshop on exploratory search and computer human interaction associated to http www chi2007 org chi2007 http research microsoft com en us um people ryenw esi acceptedposters html sigchi conference on human factors in computing systems san jose ca united states april 29 acm press 2007 chi eschi t sengine jatowt a kawai y tanaka k 2008 http dl acm org citation cfm id 1367497 1367736 visualizing historical content of web pages in http www2008 org www2008 proceedings of the 17th international world wide web conference pp nbsp 1221 1222 beijing china april 21 25 acm press 2008 www w archives nunes s ribeiro c david g 2008 http dl acm org citation cfm id 1822292 wikichanges exposing wikipedia revision activity in http www wikisym org ws2008 wikisym2008 proceedings of the 4th international symposium on wikis porto portugal september 8 10 acm press 2008 wikisym t interfaces nunes s ribeiro c david g 2009 http epia2009 web ua pt onlineedition 601 pdf improving web user experience with document activity sparklines in l s lopes n lau p mariano l rocha ed http epia2009 web ua pt epia2009 proceedings of the 14th portuguese conference on artificial intelligence associated to appia portuguese association for artificial intelligence pp nbsp 601 604 aveiro portugal october 12 15 2009 epia t interfaces kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine matthews m tolchinsky p blanco r atserias j mika p zaragoza h 2010 http research yahoo com pub 3341 searching through time in the new york times in http www iiix2010 org hcir workshop hcir2010 proceedings of the 4th workshop on human computer interaction and information retrieval pp nbsp 41 44 new brunswick united states august 22 2010 hcir t sengine khurana u nguyen v cheng h ahn j chen x shneiderman b 2011 http ieeexplore ieee org xpl articledetails jsp tp arnumber 6113166 visual analysis of temporal trends in social networks using edge color coding and metric timelines in http ieeexplore ieee org xpl mostrecentissue jsp punumber 6112285 proceedings of the ieee social computing pp nbsp 549 554 boston united states 2011 socialcom t interfaces temporal search engines t sengine class wikitable sortable reference year conference journal main scope comments alonso o gertz m 2006 http dl acm org citation cfm id 1148170 1148273 coll dl dl guide cfid 102654836 cftoken 48651941 clustering of search results using temporal attributes in http www sigir org sigir2006 sigir 2006 proceedings of the 29th annual international acm sigir conference on research and development in information retrieval pp nbsp 597 598 seattle washington united states august 6 11 acm press 2006 sigir t clustering alonso o baeza yates r gertz m 2007 exploratory search using timelines in eschi proceedings of the workshop on exploratory search and computer human interaction associated to http www chi2007 org chi2007 http research microsoft com en us um people ryenw esi acceptedposters html sigchi conference on human factors in computing systems san jose ca united states april 29 acm press 2007 chi eschi t sengine jin p lian j zhao x wan s 2008 http ieeexplore ieee org xpl articledetails jsp arnumber 4739991 tise a temporal search engine for web contents in iita2008 proceedings of the 2nd international symposium on intelligent information technology application pp nbsp 220 224 shanghai china december 21 22 ieee computer society press 2008 iita t sengine alonso o gertz m baeza yates r 2009 http dl acm org citation cfm id 1645953 1645968 clustering and exploring search results using timeline constructions in http www comp polyu edu hk conference cikm2009 cikm 2009 proceedings of the 18th international acm conference on information and knowledge management hong kong china november 2 6 acm press 2009 cikm t clustering kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine matthews m tolchinsky p blanco r atserias j mika p zaragoza h 2010 http research yahoo com pub 3341 searching through time in the new york times in http www iiix2010 org hcir workshop hcir2010 proceedings of the 4th workshop on human computer interaction and information retrieval pp nbsp 41 44 new brunswick united states august 22 2010 hcir t sengine temporal question answering t qanswering class wikitable sortable reference year conference journal main scope comments pasca m 2008 http dl acm org citation cfm id 1363946 towards temporal web search in http www acm org conferences sac sac2008 sac2008 proceedings of the 23rd acm symposium on applied computing pp nbsp 1117 1121 fortaleza ceara brazil march 16 20 acm press 2008 sac t qanswering temporal snippets t snippets class wikitable sortable reference year conference journal main scope comments alonso o baeza yates r gertz m 2009 http www wssp info 2009 wssp2009alonsobaezayatesgertz pdf effectiveness of temporal snippets in http www wssp info 2009 html wssp2009 proceedings of the workshop on web search result summarization and presentation associated to www2009 org www2009 18th international world wide web conference madrid spain april 20 24 acm press 2009 www wssp t snippets alonso o gertz m baeza yates r 2011 http www springerlink com content u78qu8x10h613471 enhancing document snippets using temporal information in r grossi f sebastiani f silvestri eds lecture notes in computer science http spire2011 isti cnr it spire2011 18th international symposium on string processing and information retrieval vol 7024 pp nbsp 26 31 pisa italy october 17 21 springer berlin heidelberg 2011 spire t snippets svore k m teevan j dumais s t kulkarni a 2012 http dl acm org citation cfm id 2348461 creating temporally dynamic web search snippets in http www sigir org sigir2012 sigir2012 proceedings of the 35th annual international acm sigir conference on research and development in information retrieval pp nbsp 1045 1046 portland united states august 12 16 acm press 2012 sigir t snippets future information retrieval f iretrieval class wikitable sortable reference year conference journal main scope comments baeza yates r 2005 http www dcs vein hu cir cikkek searching the future pdf searching the future in s dominich i ounis j y nie ed mfir2005 proceedings of the mathematical formal methods in information retrieval workshop associated to http www dcc ufmg br eventos sigir2005 sigir 2005 28th annual international acm sigir conference on research and development in information retrieval salvador brazil august 15 19 acm press 2005 sigir mfir f iretrieval jatowt a kawai h kanazawa k tanaka k kunieda k 2009 http dl acm org citation cfm id 1555420 supporting analysis of future related information in news archives and the web in http www jcdl2009 org jcdl2009 proceedings of the joint conference on digital libraries pp nbsp 115 124 austin united states june 15 19 acm press 2009 jcdl f iretrieval kawai h jatowt a tanaka k kunieda k yamada k 2010 http dl acm org citation cfm id 2108647 chronoseeker search engine for future and past events in icuimc 2010 proceedings of the 4th international conference on uniquitous information management and communication pp nbsp 166 175 suwon republic of korea january 14 15 acm press 2010 iciumc t sengine jatowt a kawai h kanazawa k tanaka k kunieda k 2010 http dl acm org citation cfm id 1772835 analyzing collective view of future time referenced events on the web in http www2010 org www index html www2010 proceedings of the 19th international world wide web conference pp nbsp 1123 1124 raleigh united states april 26 30 acm press 2010 www f iretrieval matthews m tolchinsky p blanco r atserias j mika p zaragoza h 2010 http research yahoo com pub 3341 searching through time in the new york times in http www iiix2010 org hcir workshop hcir2010 proceedings of the 4th workshop on human computer interaction and information retrieval pp nbsp 41 44 new brunswick united states august 22 2010 hcir t sengine dias g campos r jorge a 2011 http select cs cmu edu meetings enir2011 papers dias campos jorge pdf future retrieval what does the future talk about in http select cs cmu edu meetings enir2011 enir 2011 proceedings of the enriching information retrieval workshop associated to http www sigir2011 org sigir2011 34th annual international acm sigir conference on research and development in information retrieval beijing china july 28 2011 sigir enir f iretrieval kanhabua n blanco r matthews m 2011 http dl acm org citation cfm id 2010018 dl acm coll dl cfid 82290723 cftoken 53881602 ranking related news predictions in http www sigir2011 org sigir 2011 proceedings of the 34th annual international acm sigir conference on research and development in information retrieval pp nbsp 755 764 beijing china july 24 28 acm press 2011 sigir f iretrieval kanazawa k jatowt a tanaka k 2011 http dl acm org citation cfm id 2052362 improving retrieval of future related information in text collections in http liris cnrs fr wi iat11 wi 2011 wic2011 ieee main conference proceedings of the ieee wic acm international conference on web intelligence pp nbsp 278 283 lyon france august 22 27 ieee computer society press 2011 wic f iretrieval campos r dias g jorge a m 2011 http dl acm org citation cfm id 2051169 an exploratory study on the impact of temporal features on the classification and clustering of future related web documents in l antunes h s pinto eds lecture notes in artificial intelligence progress in artificial intelligence http epia2011 appia pt epia2011 15th portuguese conference on artificial intelligence associated to appia portuguese association for artificial intelligence vol 7026 2011 pp nbsp 581 596 lisboa portugal october 10 13 springer berlin heidelberg 2011 epia f iretrieval jatowt a yeung c m 2011 http dl acm org citation cfm id 2063759 extracting collective expectations about the future from large text collections in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1259 1264 glasgow scotland uk october acm press 2011 cikm f iretrieval weerkamp w rijke m 2012 http research microsoft com en us people milads taia2012 activities pdf activity prediction a twitter based exploration in http research microsoft com en us people milads taia2012 aspx taia 2012 proceedings of the time aware information access workshop associated to http www sigir org sigir2012 sigir2012 35th annual international acm sigir 2012 conference on research and development in information retrieval portland united states august 16 2012 sigir taia f iretrieval radinski k horvitz e 2013 http dl acm org citation cfm id 2433431 mining the web to predict future events in http wsdm2013 org wsdm2013 proceedings of the 6th acm international conference on web search and data mining pp nbsp 255 264 rome italy february 4 8 acm press 2013 wsdm f iretrieval temporal image retrieval t iretrieval class wikitable sortable reference year conference journal main scope comments dias g moreno j g jatowt a campos r 2012 http link springer com content pdf 10 1007 2f978 3 642 34109 0 21 temporal web image retrieval in calder\xc3\xb3n benavides l gonz\xc3\xa1lez caro c ch\xc3\xa1vez e ziviani n eds in lecture notes in computer science http catic unab edu co spire spire2012 19th international symposium on string processing and information retrieval vol 7608 2012 pp nbsp 199 204 cartagena de indias colombia october 21 25 springer berlin heidelberg 2012 spire t iretrieval palermo f hays j efros a 2012 http link springer com content pdf 10 1007 978 3 642 33783 3 36 dating historical color images in fitzgibbon a lazebnik s sato y schmid c eds in lecture notes in computer science http eccv2012 unifi it eccv2012 12th european conference on computer vision vol 7577 2012 pp nbsp 499 512 firenze italy october 07 13 springer berlin heidelberg 2012 eccv t iretrieval kim g xing e p 2013 http dl acm org citation cfm id 2433417 time sensitive web image ranking and retrieval via dynamic multi task regression in http wsdm2013 org wsdm2013 proceedings of the 6th acm international conference on web search and data mining pp nbsp 163 172 rome italy february 4 8 acm press 2013 wsdm t iretrieval martin p doucet a jurie f 2014 http dl acm org citation cfm id 2578790 dating color images with ordinal classification in http www icmr2014 org icmr2014 proceedings of international conference on multimedia retrieval pp 447 glasgow united kingdom april 01 04 acm press 2014 icmr t iretrieval collective memory c memory class wikitable sortable reference year conference journal main scope comments surowiecki j 2004 http www amazon com the wisdom crowds collective economies dp 0385503865 the wisdom of crowds why the many are smarter than the few and how collective wisdom shapes business economies societies and nations usa doubleday 2004 c memory hall d jurafsky d manning c d 2008 http dl acm org citation cfm id 1613715 1613763 studying the history of ideas using topic models in http conferences inf ed ac uk emnlp08 emnlp 2008 proceedings of the conference on empirical methods in natural language processing pp nbsp 363 371 waikiki honolulu hawaii october 25 27 association for computational linguistics 2008 emnlp c memory shahaf d guestrin c 2010 http dl acm org citation cfm id 1835884 connecting the dots between news articles in http www sigkdd org kdd2010 kdd2010 proceedings of the 16th acm sigkdd international conference on knowledge discovery and data mining pp nbsp 623 632 washington united states july 25 28 acm press 2010 kdd c memory takahashi y ohshima h yamamoto m iwasaki h oyama s tanaka k 2011 http dl acm org citation cfm id 1995980 evaluating significance of historical entities based on tempo spatial impacts analysis using wikipedia link structure in http www ht2011 org ht2011 proceedings of the 22nd acm conference on hypertext and hypermedia pp nbsp 83 92 eindhoven netherlands june 6 9 acm press 2011 ht c memory michel j b shen y k aiden a p veres a gray m k team t g et al 2011 http www sciencemag org content 331 6014 176 quantitative analysis of culture using millions of digitized books in http www sciencemag org science 331 6014 176 182 2011 science c memory yeung c m a jatowt a 2011 http dl acm org citation cfm id 2063755 studying how the past is remembered towards computational history through large scale text mining in proceedings of the http www cikm2011 org cikm2011 20th acm conference on information and knowledge management pp nbsp 1231 1240 glasgow scotland uk october 24 28 acm press 2011 cikm c memory web archives w archives class wikitable sortable reference year conference journal main scope comments list of web archiving initiatives list of web archive initiatives 2011 w archives kahle b 1997 03 http www sciamdigital com index cfm fa products viewissuepreview issueid char 00b8e369 1805 4a27 a331 9d727feac21 articleid char 00b10b9e 5f13 40b2 aa51 0a4d5c41549 preserving the internet in https www scientificamerican com sciammag scientific american magazine 276 3 pp nbsp 72 73 1997 sam w archives toyoda m kitsuregawa m 2005 http dl acm org citation cfm id 1083387 a system for visualizing and analyzing the evolution of the web with a time series of graphs in http www ht05 org ht2005 proceedings of the 16th acm conference on hypertext and hypermedia pp nbsp 151 160 salzburg austria september 6 9 acm press 2005 ht w archives efendioglu d faschetti c parr t 2006 http dl acm org authorize 815487 chronica a temporal web search engine in d wolber n calder c brooks ed http www icwe2006 org icwe2006 proceedings of the 6th international conference on web engineering pp nbsp 119 120 palo alto california united states july 11 14 acm press 2006 icwe w archives jatowt a kawai y nakamura s kidawara y tanaka k 2006 http dl acm org citation cfm id 1149969 journey to the past proposal of a framework for past web browser in ht2006 proceedings of the 17th conference on hypertext and hypermedia pp nbsp 135 144 odense denmark august 22 25 acm press 2006 ht w archives adar e dontcheva m fogarty j weld d s 2008 http dl acm org citation cfm id 1449756 zoetrope interacting with the ephemeral web in s b cousins m beaudouin lafon ed http www acm org uist uist2008 uist 2008 proceedings of the 21st annual acm symposium on user interface software and technology pp nbsp 239 248 monterey ca united states october 19 22 acm press 2008 uist w archives song s jaja j 2008 http www umiacs umd edu joseph temporal web archiving final umiacs tr 2008 08 pdf archiving temporal web information organization of web contents for fast access and compact storage technical report umiacs tr 2008 08 university of maryland institute for advanced computer studies maryland md united states 2008 technical report w archives gomes d miranda j costa m 2011 http dl acm org citation cfm id 2042590 a survey on web archiving initiatives in http www tpdl2011 org tpdl2011 proceedings of the 15th international conference on theory and practice of digital libraries research and advanced technology for digital libraries pp nbsp 408 420 berlin germany september 25 29 springer verlag 2011 tpdl w archives anand a bedathur s berberich k schenkel r 2012 http dl acm org citation cfm id 2348318 index maintenance for time travel text search in http www sigir org sigir2012 sigir2012 proceedings of the 35th annual international acm sigir conference on research and development in information retrieval pp nbsp 235 243 portland united states august 12 16 acm press 2012 sigir w archives costa m silva m j 2012 http link springer com chapter 10 1007 2f978 3 642 35063 4 32 evaluating web archive search systems in http www wise2012 cs ucy ac cy wise2012 proceedings of the 13th international conference on web information system engineering pp nbsp 440 454 paphos cyprus november 28 30 springer verlag 2012 wise w archives topic detection and tracking tdt class wikitable sortable reference year conference journal main scope comments allan j carbonell j doddington g yamron j 1998 http www cs pitt edu chang 265 proj10 sisref 1 pdf topic detection and tracking pilot study final report in proceedings of the darpa broadcast news transcription and understanding workshop pp nbsp 194 218 lansdowne virginia united states february 1998 technical report tdt swan r allan j 1999 http dl acm org citation cfm id 319956 extracting significant time varying features from text in http cikmconference org 1999 cikm 1999 proceedings of the 8th international acm conference on information and knowledge management pp nbsp 38 45 kansas city missouri united states november 2 6 acm press 1999 cikm tdt swan r jensen d 2000 http www cs cmu edu dunja swan tm pdf timemines constructing timelines with statistical models of word usage in m grobelnik d mladenic n milic frayling ed http www cs cmu edu dunja wshkdd2000 html tm2000 proceedings of the workshop on text mining associated to http www sigkdd org kdd2000 kdd2000 6th acm sigkdd international conference on knowledge discovery and data mining pp nbsp 73 80 boston massachusetts united states august 20 23 acm press 2000 kdd tm tdt swan r allan j 2000 http dl acm org citation cfm id 345546 automatic generation of overview timelines in http www aueb gr conferences sigir2000 sigir 2000 proceedings of the 23rd annual international acm sigir conference on research and development in information retrieval pp nbsp 49 56 athens greece july 24 28 acm press 2000 sigir tdt makkonen j ahonen myka h 2003 http www springerlink com content a5ev5br7wwh5lvyl utilizing temporal information in topic detection and tracking in t koch i t solvberg eds in lecture notes in computer science research and advanced technology for digital libraries http www ecdl2003 org ecdl 2003 7th european conference on research and advances technology for digital libraries vol 2769 2004 pp nbsp 393 404 trondheim norway august 17 22 springer berlin heidelberg 2003 ecdl tdt shaparenko b caruana r gehrke j joachims t 2005 http www cs cornell edu people tj publications shaparenko etal 05a pdf identifying temporal paterns and key players in document collections in http users cis fiu edu taoli workshop tdm2005 index html tdm2005 proceedings of the workshop on temporal data mining associated to http www cacs louisiana edu icdm05 icdm2005 pp nbsp 165 174 houston united states november 27 30 ieee press 2005 icdm tdm tdt mori m miura t shioya i 2006 http dl acm org citation cfm id 1249137 topic detection and tracking for news web pages in http www comp hkbu edu hk wii06 wi wic2006 ieee main conference proceedings of the ieee wic acm international conference on web intelligence pp nbsp 338 342 hong kong china december 18 22 ieee computer society press 2006 wic tdt kim p myaeng s h 2004 http dl acm org citation cfm id 1039624 usefulness of temporal information automatically extracted from news articles for topic tracking in http talip acm org index htm talip journal of acm transactions on asian language information processing pp nbsp 227 242 new york united states 2004 talip tdt references reflist category information retrieval genres'
b'multimedia search enables information search engine technology search using queries in multiple data types including text and other multimedia formats multimedia search can be implemented through multimodal search interfaces i e interfaces that allow to submit search queries not only as textual requests but also through other media we can distinguish two methodologies in multimedia search metadata search the search is made on the layers of metadata query by example the interaction consists in submitting a piece of information e g a video an image or a piece of audio at the purpose of finding similar multimedia items metadata search search is made using the layers in metadata which contain information of the content of a multimedia file metadata search is easier faster and effective because instead of working with complex material such as an audio a video or an image it searches using text there are three processes which should be done in this method multimedia information retrieval feature extraction methods summarization of media content feature extraction the result of feature extraction is a description multimedia information retrieval feature extraction methods filtering of media descriptions for example elimination of redundancy linguistics redundancy multimedia information retrieval categorization methods categorization of media descriptions into classes query by example in query by example the element used to search is a multimedia content image audio video in other words the query is a media often it s used search engine indexing audiovisual indexing it will be necessary to choose the criteria we are going to use for creating metadata the process of search can be divided in three parts generate descriptors for the media which we are going to use as query and the descriptors for the media in our database compare descriptors of the query and our database s media list the media sorted by maximum coincidence multimedia search engine there are two big search families in function of the content visual search engine audio search engine visual search engine inside this family we can distinguish two topics image search and video search image search although usually it s used simple metadata search increasingly is being used indexing methods for making the results of users queries more accurate using query by example for example qr codes video search videos can be searched for simple metadata or by complex metadata generated by indexing the audio contained in the videos is usually scanned by audio search engines audio search engine there are different methods of audio search engine audio searching voice search engine allows the user to search using speech instead of text it uses algorithms of speech recognition an example of this technology is google voice search music search engine although most of applications which searches music works on simple metadata artist name of track album\xe2\x80\xa6 there are some programs of music recognition for example shazam service shazam or soundhound see also journal of multimedia list of search engines multimedia list of search engines multimedia multimedia information retrieval search engine indexing streaming media video search engine external links category information retrieval genres category multimedia'
b'multimodal search is a type of search engines search that uses different methods to get relevant results they can use any kind of search keyword search search by keyword concept search search by concept query by example search by example etc introduction a multimodal search engine is designed to imitate the flexibility and agility of how the mind human mind works to create process and refuse irrelevant ideas so the more elements you have in the input of the search engine to can compare the more arithmetic precision accurate the results can be multimodal search engines use different inputs of different nature and methods of search at the same time with the possibility of combining the results by merging all of the input elements of the search there are also engines that can use a feedback of the results with the evaluation of the user to perform a more appropriate and relevant search file schema of a simple search jpg thumb schema of a simple search nowadays mobile devices have been developed to a point that they can perform infinite functions from any place at any time thanks to the internet and gps connections touch screens motion sensors and voice recognition are now featured on mobile devices called smartphone s all the features and functions make possible to can execute multimodal searches from any place of the world at any time search elements the use of text is an option as well as multimedia search ing image s video s content media audio voice document s even the location of the user can help the search engine to perform a more effective search adaptable to every situation nowadays different ways to human computer interaction interact with a search engine are being discovered in terms of input elements of the search and in the variety of results obtained personal context many queries from mobiles are location based service location based lbs that use the location of the user to interact with the applications if available the browser uses the device gps or computes an approximate location based on cell tower triangulation with the permission of the user who must be agree to share his her location with the application in the download therefore multimodal searches use not only audiovisual content that the user provides directly but also the context where the user is like his her location language time at the moment web site or document where the user is surfing or other elements that can help to improve of a search in every situation file contextual query jpg example of contextual query classification of the results the multimodal search engine works in parallel whilst at the same time performs a search of more to less relevance of every element introduced directly or indirectly personal context afterwards it provides a combination of all the results merging every element with its associated weight for every descriptor the engine analyzes every element and tags them so a comparison of the tags can be made with existent indexed information in databases a classification of the results proceeds to show them from more to less relevance file framework of multimodal search jpg thumb framework of a multimodal search it s necessary to define the importance of every input element there are search engines that do this automatically however there are also engines where the user can do it manually giving more or less weight to every element of the search it s also important that the user provides the appropriate and essential information for the search too much information can confuse the system and provide unsatisfactory results with multimodal searches users can get better results than with a simple search but multimodal searches must process more input information it can also spend more time to process it and require more memory space an efficient search engine interprets the query of the users realizes his her intention and applies a strategy to use an appropriate search i e the engine adapts to every input query and also to the combination of the elements and methods applications nowadays existing multimodal search engines are not very complex and some of them are in an experimental phase some of the more simple engines are google images http images google es or bing search engine bing http www bing com web interfaces that use text and images as inputs to find images in the output mmretrieval http www aviarampatzis com publications p117 zagoris pdf is a multimodal experimental search engine that uses multilingual and multimedia information through a web interface the engine searches the different inputs in parallel and merges all the results by different chosen methods the engine also provides different multistage retrieval as well as a single text index baseline to be able to compare all the different phases of search there are a lot of applications for mobile devices using the context of the user like based location services and using also text images audios or videos that the user provides at the moment or with saved files or even interacting with the voice references query adaptive fusion for multimodal search lyndon kennedy student member ieee shih fu chang fellow ieee and apostol natsev http www ee columbia edu lyndon pubs pieee2008 queryadaptive pdf context aware querying for multimodal search engines jonas etzold arnaud brousseau paul grimm and thomas steiner http www lsi upc edu tsteiner papers 2012 context aware querying mmm2012 pdf apply multimodal search and relevance feedback in a digital video library thesis of yu zhong http www informedia cs cmu edu documents zhong thesis may00 pdf aplicaci\xc3\xb3 rica d internet per a la consulta amb text i imatge al repositori de v\xc3\xaddeos de la corporaci\xc3\xb3 catalana de mitjans audiovisuals ramon salla universitat polit\xc3\xa8cnica de catalunya http upcommons upc edu pfc bitstream 2099 1 8766 1 pfc pdf external links mmretrieval http www mmretrieval net google images http images google es bing http www bing com categories category information retrieval genres category internet search engines category multimedia'
b'multiple issues original research date february 2012 refimprove date february 2012 a visual search engine is a search engine computing search engine designed to search for information on the world wide web through the input of an image or a search engine with a visual display of the search results information may consist of web page s locations other images and other types of documents this type of search engines is mostly used to search on the mobile internet through an image of an unknown object unknown search query examples are buildings in a foreign city these search engines often use techniques for cbir content based image retrieval a visual search engine searches images patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique classification depending on the nature of the search engine there are two main groups those which aim to find visual information and those with a visual display of results visual information searchers file imatge cercadors 1 jpg thumb screenshot of results shown by the image searcher through example gos image search an image search is a search engine that is designed to find an image the search can be based on keywords a picture or a web hyperlink link to a picture the results depend on the search criterion such as metadata distribution of color shape etc and the search technique which the browser uses file imatge wiki 2 png thumb diagram of a search realized through example based on detectable regions from an image image search techniques two techniques currently used in image search search by metadata image search is based on comparison of metadata associated with the image as keywords text etc and it is obtained a set of images sorted by relevance the metadata associated with each image can reference the title of the image format color etc and can be generated manually or automatically this metadata generation process is called audiovisual indexing search by example in this technique also called content based image retrieval the search results are obtained through the comparison between images using computer vision techniques during the search it is examined the content of the image such as color shape texture or any visual information that can be extracted from the image this system requires a higher computational complexity theory computational complexity but is more efficient and reliable than search by metadata there are image searchers that combine both search techniques as the first search is done by entering a text and then from the images obtained can refine the search using as search parameters the images which appear as a result video search a video search is a search engine computing search engine designed to search video on the net some video searchers process the search directly in the internet while others shelter the videos from which the search is done some searchers also enable to use as search parameters the file format format or the length of the video usually the results come with a miniature capture of the video video search techniques currently almost all video searchers are based on keywords search by metadata to perform searches these keywords can be found in the title of the video text accompanying the video or can be defined by the author an example of this type of search is youtube some searchers generate keywords manually while others use algorithms to analyze the audiovisual content of the video and to generate labels the combination of these two processes improves the reliability of the search 3d models searcher a searcher of 3d models aims to find the file of a 3d modeling object from a database or network at first glance the implementation of this type of searchers may seem unnecessary but due to the continuous documentary inflation of the internet every day it becomes more necessary indexing information 3d models search techniques these have been used with traditional text based searchers keywords tags where the authors of the indexed material or internet users have contributed these tags or keywords because it is not always effective it has recently been investigated in the implementation of search engines that combine the search using text with the search compared to 2d drawings 3d drawings and 3d models princeton university has developed a search engine that combines all these parameters to perform the search thus increasing the efficiency of search ref name funk cite journal last funkhouser first thomas first2 patrick last2 min first3 michael last3 kazhdan first4 joyce last4 chen first5 alex last5 halderman first6 david last6 dobkin first7 david last7 jacobs year 2002 title a search engine for 3d models journal acm transactions on graphics url https www cs princeton edu funk tog03 pdf volume 22 issue 1 pages 83 105 doi 10 1145 588272 588279 ref imaginestics llc created the world s first online shape search engine in the fall of 2005 ref cite web url http www purdue edu uns html3month 2006 060824 imaginestics grant html title purdue research park s imaginestics wins grant for research on search engines work purdue edu ref they currently use vizseek search engine technology in the industrial and manufacturing settings to help discover parts using shape as the matching criteria mobile visual search a mobile image searcher is a type of search engine designed exclusively for mobile phones through which you can find any information on internet through an image made with the own mobile phone or using certain words keyword computer programming keywords introduction mobile phones have evolved into powerful image and video processing devices equipped with high resolution cameras color displays and hardware accelerated graphics they are also increasingly equipped with a global positioning system and connected to broadband wireless networks all this enables a new class of applications that use the camera phone to initiate search queries about objects in visual proximity to the user figure 1 such applications can be used e g for identifying products comparison shopping finding information about movies compact disks cds real estate print media or artworks process typically this type of search engine uses techniques of query by example or content based image retrieval image query by example which use the content shape texture and color of the image to compare them in a database and then deliver the approximate results from the query the process used in these searches in the mobile phone s is as follows first the image is sent to the server application already on the server the image will be analyzed by different analytical teams as each one is specialized in different fields that make up an image then each team will decide if the submitted image contains the fields of their speciality or not once this whole procedure is done a central computer will analyze the data and create a page of the results sorted with the efficiency of each team to eventually be sent to the mobile phone applications google goggles is the most popular application of image search engines citation required date november 2016 developed by google labs google labs available for android operating system android only today camfind is a similar application available for both android operating system android and ios justvisual com formerly known as superfish and its likethat showcase apps are api for developers to create their own visual search mobile app other companies in the image recognition space are the reverse image search engines tineye and google s google images search by image search by image feature of google images visual display searchers another type of visual search is a search engine that shows results with a visual display image this is an alternative to the traditional results of a sequence of links through some kind of image display such as graphs diagrams previews of the websites etc it presents the results visually so that it is easier to find the desired material such search engines like http www kiddle co kiddle and manzia ref cite web title manzia search website http www manzia com accessdate 8 august 2014 ref present a new concept in the presentation of results but the search techniques used are the same as in other search engines references reflist category information retrieval genres category internet search engines category multimedia'
b'a concept search or conceptual search is an automated information retrieval method that is used to search electronically stored unstructured data unstructured text for example digital archive s email scientific literature etc for information that is conceptually similar to the information provided in a search query in other words the ideas expressed in the information retrieved in response to a concept search query are relevant to the ideas contained in the text of the query toc development concept search techniques were developed because of limitations imposed by classical boolean search algorithm keyword search technologies when dealing with large unstructured digital collections of text keyword searches often return results that include many non relevant items false positive s or that exclude too many relevant items false negatives because of the effects of synonymy and polysemy synonymy means that one of two or more words in the same language have the same meaning and polysemy means that many individual words have more than one meaning polysemy is a major obstacle for all computer systems that attempt to deal with human language in english most frequently used terms have several common meanings for example the word fire can mean a combustion activity to terminate employment to launch or to excite as in fire up for the 200 most polysemous terms in english the typical verb has more than twelve common meanings or senses the typical noun from this set has more than eight common senses for the 2000 most polysemous terms in english the typical verb has more than eight common senses and the typical noun has more than five ref bradford r b word sense disambiguation content analyst company llc u s patent 7415462 2008 ref in addition to the problems of polysemous and synonymy keyword searches can exclude inadvertently misspelled words as well as the variations on the stemming stems or roots of words for example strike vs striking keyword searches are also susceptible to errors introduced by optical character recognition ocr scanning processes which can introduce random error s into the text of documents often referred to as noisy text during the scanning process a concept search can overcome these challenges by employing word sense disambiguation wsd ref r navigli http www dsi uniroma1 it navigli pubs acm survey 2009 navigli pdf word sense disambiguation a survey acm computing surveys 41 2 2009 ref and other techniques to help it derive the actual meanings of the words and their underlying concepts rather than by simply matching character strings like keyword search technologies approaches in general information retrieval research and technology can be divided into two broad categories semantic and statistical information retrieval systems that fall into the semantic category will attempt to implement some degree of syntactic and semantic analysis machine learning semantic analysis of the natural language text that a human user would provide also see computational linguistics systems that fall into the statistical category will find results based on statistical measures of how closely they match the query however systems in the semantic category also often rely on statistical methods to help them find and retrieve information ref greengrass e information retrieval a survey 2000 ref efforts to provide information retrieval systems with semantic processing capabilities have basically used three different approaches auxiliary structures local co occurrence statistics transform techniques particularly matrix decomposition s auxiliary structures a variety of techniques based on artificial intelligence ai and natural language processing nlp have been applied to semantic processing and most of them have relied on the use of auxiliary structures such as controlled vocabularies and ontology information science ontologies controlled vocabularies dictionaries and thesauri and ontologies allow broader terms narrower terms and related terms to be incorporated into queries ref dubois c the use of thesauri in online retrieval journal of information science 8 2 1984 march pp 63 66 ref controlled vocabularies are one way to overcome some of the most severe constraints of boolean keyword queries over the years additional auxiliary structures of general interest such as the large synonym sets of wordnet have been constructed ref miller g special issue http www mit edu 6 863 spring2009 readings 5papers pdf wordnet an on line lexical database intl journal of lexicography 3 4 1990 ref it was shown that concept search that is based on auxiliary structures such as wordnet can be efficiently implemented by reusing retrieval models and data structures of classical information retrieval ref fausto giunchiglia uladzimir kharkevich and ilya zaihrayeu http www ulakha com concept search eswc2009 html concept search in proceedings of european semantic web conference 2009 ref later approaches have implemented grammars to expand the range of semantic constructs the creation of data models that represent sets of concepts within a specific domain domain ontologies and which can incorporate the relationships among terms has also been implemented in recent years handcrafted controlled vocabularies contribute to the efficiency and comprehensiveness of information retrieval and related text analysis operations but they work best when topics are narrowly defined and the terminology is standardized controlled vocabularies require extensive human input and oversight to keep up with the rapid evolution of language they also are not well suited to the growing volumes of unstructured text covering an unlimited number of topics and containing thousands of unique terms because new terms and topics need to be constantly introduced controlled vocabularies are also prone to capturing a particular world view at a specific point in time which makes them difficult to modify if concepts in a certain topic area change ref name bradford r b 2008 bradford r b why lsi latent semantic indexing and information retrieval white paper content analyst company llc 2008 ref local co occurrence statistics information retrieval systems incorporating this approach count the number of times that groups of terms appear together co occur within a sliding window of terms or sentences for example \xc2\xb1 5 sentences or \xc2\xb1 50 words within a document it is based on the idea that words that occur together in similar contexts have similar meanings it is local in the sense that the sliding window of terms and sentences used to determine the co occurrence of terms is relatively small this approach is simple but it captures only a small portion of the semantic information contained in a collection of text at the most basic level numerous experiments have shown that approximately only \xc2\xbc of the information contained in text is local in nature ref landauer t and dumais s a solution to plato s problem the latent semantic analysis theory of acquisition induction and representation of knowledge psychological review 1997 104 2 pp 211 240 ref in addition to be most effective this method requires prior knowledge about the content of the text which can be difficult with large unstructured document collections ref name bradford r b 2008 transform techniques some of the most powerful approaches to semantic processing are based on the use of mathematical transform techniques matrix decomposition techniques have been the most successful some widely used matrix decomposition techniques include the following ref skillicorn d understanding complex datasets data mining with matrix decompositions crc publishing 2007 ref independent component analysis semi discrete decomposition non negative matrix factorization singular value decomposition matrix decomposition techniques are data driven which avoids many of the drawbacks associated with auxiliary structures they are also global in nature which means they are capable of much more robust information extraction and representation of semantic information than techniques based on local co occurrence statistics ref name bradford r b 2008 independent component analysis is a technique that creates sparse representations in an automated fashion ref honkela t hyvarinen a and vayrynen j wordica emergence of linguistic representations for words by independent component analysis natural language engineering 16 3 277 308 2010 ref and the semi discrete and non negative matrix approaches sacrifice accuracy of representation in order to reduce computational complexity ref name bradford r b 2008 singular value decomposition svd was first applied to text at bell labs in the late 1980s it was used as the foundation for a technique called latent semantic indexing lsi because of its ability to find the semantic meaning that is latent in a collection of text at first the svd was slow to be adopted because of the resource requirements needed to work with large datasets however the use of lsi has significantly expanded in recent years as earlier challenges in scalability and performance have been overcome lsi is being used in a variety of information retrieval and text processing applications although its primary application has been for concept searching and automated document categorization ref dumais s latent semantic analysis arist review of information science and technology vol 38 chapter 4 2004 ref uses ediscovery concept based search technologies are increasingly being used for electronic document discovery edd or ediscovery to help enterprises prepare for litigation in ediscovery the ability to cluster categorize and search large collections of unstructured text on a conceptual basis is much more efficient than traditional linear review techniques concept based searching is becoming accepted as a reliable and efficient search method that is more likely to produce relevant results than keyword or boolean searches ref magistrate judge john m facciola of the u s district court for the district of washington d c disability rights council v washington metropolitan transit authority 242 frd 139 d d c 2007 citing george l paul jason r baron information inflation can the legal system adapt 13 rich j l tech 10 2007 ref enterprise search and enterprise content management ecm concept search technologies are being widely used in enterprise search as the volume of information within the enterprise grows the ability to cluster categorize and search large collections of unstructured text on a conceptual basis has become essential in 2004 the gartner group estimated that professionals spend 30 percent of their time searching retrieving and managing information ref name laplanche r 2004 laplanche r delgado j turck m concept search technology goes beyond keywords information outlook july 2004 ref the research company idc found that a 2 000 employee corporation can save up to 30 million per year by reducing the time employees spend trying to find information and duplicating existing documents ref name laplanche r 2004 content based image retrieval content based image retrieval cbir content based approaches are being used for the semantic retrieval of digitized images and video from large visual corpora one of the earliest content based image retrieval systems to address the semantic problem was the imagescape search engine in this system the user could make direct queries for multiple visual objects such as sky trees water etc using spatially positioned icons in a www index containing more than ten million images and videos using keyframes the system used information theory to determine the best features for minimizing uncertainty in the classification ref name lew m s 2006 lew m s sebe n djeraba c jain r content based multimedia information retrieval state of the art and challenges acm transactions on multimedia computing communications and applications february 2006 ref the semantic gap is often mentioned in regard to cbir the semantic gap refers to the gap between the information that can be extracted from visual data and the interpretation that the same data have for a user in a given situation ref datta r joshi d li j wang j z http infolab stanford edu wangz project imsearch review jour datta pdf image retrieval ideas influences and trends of the new age acm computing surveys vol 40 no 2 april 2008 ref the http www liacs nl mir acm sigmm workshop on multimedia information retrieval is dedicated to studies of cbir multimedia and publishing concept search is used by the multimedia and publishing industries to provide users with access to news technical information and subject matter expertise coming from a variety of unstructured sources content based methods for multimedia information retrieval mir have become especially important when text annotations are missing or incomplete ref name lew m s 2006 digital libraries and archives images videos music and text items in digital libraries and digital archives are being made accessible to large groups of users especially on the web through the use of concept search techniques for example the executive daily brief edb a business information monitoring and alerting product developed by ebsco publishing uses concept search technology to provide corporate end users with access to a digital library containing a wide array of business content in a similar manner the music genome project spawned pandora which employs concept searching to spontaneously create individual music libraries or virtual radio stations genomic information retrieval gir genomic information retrieval gir uses concept search techniques applied to genomic literature databases to overcome the ambiguities of scientific literature human resources staffing and recruiting many human resources staffing and recruiting organizations have adopted concept search technologies to produce highly relevant resume search results that provide more accurate and relevant candidate resumes than loosely related keyword results effective searching the effectiveness of a concept search can depend on a variety of elements including the dataset being searched and the search engine that is used to process queries and display results however most concept search engines work best for certain kinds of queries effective queries are composed of enough text to adequately convey the intended concepts effective queries may include full sentences paragraphs or even entire documents queries composed of just a few words are not as likely to return the most relevant results effective queries do not include concepts in a query that are not the object of the search including too many unrelated concepts in a query can negatively affect the relevancy of the result items for example searching for information about boating on the mississippi river would be more likely to return relevant results than a search for boating on the mississippi river on a rainy day in the middle of the summer in 1967 effective queries are expressed in a full text natural language style similar in style to the documents being searched for example using queries composed of excerpts from an introductory science textbook would not be as effective for concept searching if the dataset being searched is made up of advanced college level science texts substantial queries that better represent the overall concepts styles and language of the items for which the query is being conducted are generally more effective as with all search strategies experienced searchers generally refine their queries through multiple searches starting with an initial seed query to obtain conceptually relevant results that can then be used to compose and or refine additional queries for increasingly more relevant results depending on the search engine using query concepts found in result documents can be as easy as selecting a document and performing a find similar function changing a query by adding terms and concepts to improve result relevance is called query expansion ref stephen robertson computer scientist robertson s e karen sp\xc3\xa4rck jones sp\xc3\xa4rck jones k simple proven approaches to text retrieval technical report university of cambridge computer laboratory december 1994 ref the use of ontology information science ontologies such as wordnet has been studied to expand queries with conceptually related words ref navigli r velardi p http www dcs shef ac uk fabio atem03 navigli ecml03 atem pdf an analysis of ontology based query expansion strategies proc of workshop on adaptive text extraction and mining atem 2003 in the 14th european conference on machine learning ecml 2003 cavtat dubrovnik croatia september 22 26th 2003 pp nbsp 42 49 ref relevance feedback relevance feedback is a feature that helps users determine if the results returned for their queries meet their information needs in other words relevance is assessed relative to an information need not a query a document is relevant if it addresses the stated information need not because it just happens to contain all the words in the query ref name manning c d 2008 manning c d raghavan p sch\xc3\xbctze h introduction to information retrieval cambridge university press 2008 ref it is a way to involve users in the retrieval process in order to improve the final result set ref name manning c d 2008 users can refine their queries based on their initial results to improve the quality of their final results in general concept search relevance refers to the degree of similarity between the concepts expressed in the query and the concepts contained in the results returned for the query the more similar the concepts in the results are to the concepts contained in the query the more relevant the results are considered to be results are usually ranked and sorted by relevance so that the most relevant results are at the top of the list of results and the least relevant results are at the bottom of the list relevance feedback has been shown to be very effective at improving the relevance of results ref name manning c d 2008 a concept search decreases the risk of missing important result items because all of the items that are related to the concepts in the query will be returned whether or not they contain the same words used in the query ref name laplanche r 2004 ranking will continue to be a part of any modern information retrieval system however the problems of heterogeneous data scale and non traditional discourse types reflected in the text along with the fact that search engines will increasingly be integrated components of complex information management processes not just stand alone systems will require new kinds of system responses to a query for example one of the problems with ranked lists is that they might not reveal relations that exist among some of the result items ref name callan j 2007 callan j allan j clarke c l a dumais s evans d a sanderson m zhai c meeting of the minds an information retrieval research agenda acm sigir forum vol 41 no 2 december 2007 ref guidelines for evaluating a concept search engine result items should be relevant to the information need expressed by the concepts contained in the query statements even if the terminology used by the result items is different from the terminology used in the query result items should be sorted and ranked by relevance relevant result items should be quickly located and displayed even complex queries should return relevant results fairly quickly query length should be non fixed i e a query can be as long as deemed necessary a sentence a paragraph or even an entire document can be submitted as a query a concept query should not require any special or complex syntax the concepts contained in the query can be clearly and prominently expressed without using any special rules combined queries using concepts keywords and metadata should be allowed relevant portions of result items should be usable as query text simply by selecting the item and telling the search engine to find similar items query ready indexes should be created relatively quickly the search engine should be capable of performing federated searches federated searching enables concept queries to be used for simultaneously searching multiple datasources for information which are then merged sorted and displayed in the results a concept search should not be affected by misspelled words typographical errors or ocr scanning errors in either the query text or in the text of the dataset being searched conferences and forums formalized search engine evaluation has been ongoing for many years for example the text retrieval conference text retrieval conference trec was started in 1992 to support research within the information retrieval community by providing the infrastructure necessary for large scale evaluation of text retrieval methodologies most of today s commercial search engines include technology first developed in trec ref croft b metzler d strohman t search engines information retrieval in practice addison wesley 2009 ref in 1997 a japanese counterpart of trec was launched called national institute of informatics test collection for ir systems ntcir ntcir conducts a series of evaluation workshops for research in information retrieval question answering text summarization etc a european series of workshops called the cross language evaluation forum clef was started in 2001 to aid research in multilingual information access in 2002 the initiative for the evaluation of xml retrieval inex was established for the evaluation of content oriented xml retrieval systems precision and recall have been two of the traditional performance measures for evaluating information retrieval systems precision is the fraction of the retrieved result documents that are relevant to the user s information need recall is defined as the fraction of relevant documents in the entire collection that are returned as result documents ref name manning c d 2008 although the workshops and publicly available test collections used for search engine testing and evaluation have provided substantial insights into how information is managed and retrieved the field has only scratched the surface of the challenges people and organizations face in finding managing and using information now that so much information is available ref name callan j 2007 scientific data about how people use the information tools available to them today is still incomplete because experimental research methodologies haven t been able to keep up with the rapid pace of change many challenges such as contextualized search personal information management information integration and task support still need to be addressed ref name callan j 2007 see also div col 3 approximate string matching compound term processing concept mining information extraction latent semantic analysis semantic network semantic search semantic web statistical semantics text mining div col end references reflist 2 external links http trec nist gov text retrieval conference trec http research nii ac jp ntcir national institute of informatics test collection for ir systems ntcir http www clef campaign org cross language evaluation forum clef http inex is informatik uni duisburg de initiative for the evaluation of xml retrieval inex category information retrieval genres'
b'refimprove date september 2014 cross language information retrieval clir is a subfield of information retrieval dealing with retrieving information written in a language different from the language of the user s query for example a user may pose their query in english but retrieve relevant documents written in french to do so most of clir systems use translation techniques ref https www academia edu 2475776 versatile question answering systems seeing in synthesis versatile question answering systems seeing in synthesis mittal et al ijiids 5 2 119 142 2011 ref clir techniques can be classified into different categories based on different translation resources dictionary based clir techniques parallel corpora based clir techniques comparable corpora based clir techniques machine translator based clir techniques the first workshop on clir was held in z\xc3\xbcrich during the sigir 96 conference ref the proceedings of this workshop can be found in the book cross language information retrieval grefenstette ed kluwer 1998 isbn 0 7923 8122 x ref workshops have been held yearly since 2000 at the meetings of the cross language evaluation forum clef the term cross language information retrieval has many synonyms of which the following are perhaps the most frequent cross lingual information retrieval translingual information retrieval multilingual information retrieval the term multilingual information retrieval refers to clir in general but it also has a specific meaning of cross language information retrieval where a document collection is multilingual google search had a cross language search feature that was removed in 2013 ref cite web url http searchengineland com google drops translated foreign pages search option due to lack of use 160157 title google drops translated foreign pages search option due to lack of use date 20 may 2013 publisher ref see also exclaim extensible cross linguistic automatic information machine references references external links http www glue umd edu oard research html a resource page for clir http www 2lingual com a search engine for clir defaultsort cross language information retrieval category information retrieval genres category natural language processing linguistics stub'
b'legal information retrieval is the science of information retrieval applied to legal text including legislation case law and scholarly works ref maxwell k t and schafer b 2009 p 1 ref accurate legal information retrieval is important to provide access to the law to laymen and legal professionals its importance has increased because of the vast and quickly increasing amount of legal documents available through electronic means ref name jackson jackson et al p 60 ref legal information retrieval is a part of the growing field of legal informatics overview in a legal setting it is frequently important to retrieve all information related to a specific query however commonly used boolean search methods exact matches of specified terms on full text legal documents have been shown to have an average recall rate as low as 20 percent ref name blair d c 1985 p 293 blair d c and maron m e 1985 p 293 ref meaning that only 1 in 5 relevant documents are actually retrieved in that case researchers believed that they had retrieved over 75 of relevant documents ref name blair d c 1985 p 293 this may result in failing to retrieve important or precedential cases in some jurisdictions this may be especially problematic as legal professionals are legal ethics ethically obligated to be reasonably informed as to relevant legal documents ref american bar association model rules of professional conduct rule 1 1 http www abanet org cpr mrpc rule 1 1 html ref legal information retrieval attempts to increase the effectiveness of legal searches by increasing the number of relevant documents providing a high recall rate and reducing the number of irrelevant documents a high precision rate this is a difficult task as the legal field is prone to jargon ref peters w et al 2007 p 118 ref polysemes ref peters w et al 2007 p 130 ref words that have different meanings when used in a legal context and constant change techniques used to achieve these goals generally fall into three categories boolean search boolean retrieval manual classification of legal text and natural language processing of legal text problems application of standard information retrieval techniques to legal text can be more difficult than application in other subjects one key problem is that the law rarely has an inherent taxonomy general taxonomy ref name lois1 peters w et al 2007 p 120 ref instead the law is generally filled with open ended terms which may change over time ref name lois1 this can be especially true in common law countries where each decided case can subtly change the meaning of a certain word or phrase ref saravanan m et al 2009 p 101 ref legal information systems must also be programmed to deal with law specific words and phrases though this is less problematic in the context of words which exist solely in law legal texts also frequently use polysemes words may have different meanings when used in a legal or common speech manner potentially both within the same document the legal meanings may be dependent on the area of law in which it is applied for example in the context of european union legislation the term worker has four different meanings ref name peters w et al 2007 p 131 peters w et al 2007 p 131 ref any worker as defined in article 3 a of directive 89 391 eec who habitually uses display screen equipment as a significant part of his normal work any person employed by an employer including trainees and apprentices but excluding domestic servants any person carrying out an occupation on board a vessel including trainees and apprentices but excluding port pilots and shore personnel carrying out work on board a vessel at the quayside any person who in the member state concerned is protected as an employee under national employment law and in accordance with national practice in addition it also has the common meaning ol start 5 li a person who works at a specific occupation ref name peters w et al 2007 p 131 li ol though the terms may be similar correct information retrieval must differentiate between the intended use and irrelevant uses in order to return the correct results even if a system overcomes the language problems inherent in law it must still determine the relevancy of each result in the context of judicial decisions this requires determining the precedential value of the case ref name maxwella maxwell k t and schafer b 2008 p 8 ref case decisions from senior or superior court s may be more relevant than those from lower court s even where the lower court s decision contains more discussion of the relevant facts ref name maxwella the opposite may be true however if the senior court has only a minor discussion of the topic for example if it is a secondary consideration in the case ref name maxwella a information retrieval system must also be aware of the authority of the jurisdiction a case from a binding authority is most likely of more value than one from a non binding authority additionally the intentions of the user may determine which cases they find valuable for instance where a legal professional is attempting to argue a specific interpretation of law he might find a minor court s decision which supports his position more valuable than a senior courts position which does not ref name maxwella he may also value similar positions from different areas of law different jurisdictions or dissenting opinions ref name maxwella overcoming these problems can be made more difficult because of the large number of cases available the number of legal cases available via electronic means is constantly increasing in 2003 us appellate courts handed down approximately 500 new cases per day ref name jackson meaning that an accurate legal information retrieval system must incorporate methods of both sorting past data and managing new data ref name jackson ref maxwell k t and schafer b 2007 p 1 ref techniques boolean searches boolean search es where a user may specify terms such as use of specific words or judgments by a specific court are the most common type of search available via legal information retrieval systems they are widely implemented by services such as westlaw lexisnexis and findlaw however they overcome few of the problems discussed above the recall and precision rates of these searches vary depending on the implementation and searches analyzed one study found a basic boolean search s recall rate to be roughly 20 and its precision rate to be roughly 79 ref name blair d c 1985 p 293 another study implemented a generic search that is not designed for legal uses and found a recall rate of 56 and a precision rate of 72 among legal professionals both numbers increased when searches were run by non legal professionals to a 68 recall rate and 77 precision rate this is likely explained because of the use of complex legal terms by the legal professionals ref saravanan m et al 2009 p 116 ref manual classification in order to overcome the limits of basic boolean searches information systems have attempted to classify case laws and statutes into more computer friendly structures usually this results in the creation of an ontology to classify the texts based on the way a legal professional might think about them ref name maxwell k t 2008 p 2 maxwell k t and schafer b 2008 p 2 ref these attempt to link texts on the basis of their type their value and or their topic areas most major legal search providers now implement some sort of classification search such as westlaw s natural language ref name wl westlaw research http www westlaw com ref or lexisnexis headnote ref name ln lexis research http www lexisnexis com ref searches additionally both of these services allow browsing of their classifications via westlaw s west key numbers ref name wl or lexis headnotes ref name ln though these two search algorithms are proprietary and secret it is known that they employ manual classification of text though this may be computer assisted ref name maxwell k t 2008 p 2 these systems can help overcome the majority of problems inherent in legal information retrieval systems in that manual classification has the greatest chances of identifying landmark cases and understanding the issues that arise in the text ref name maxwell k t 2008 p 3 maxwell k t and schafer b 2008 p 3 ref in one study ontological searching resulted in a precision rate of 82 and a recall rate of 97 among legal professionals ref saravanan m et al 2009 p 116 ref the legal texts included however were carefully controlled to just a few areas of law in a specific jurisdiction ref saravanan m et al 2009 p 103 ref the major drawback to this approach is the requirement of using highly skilled legal professionals and large amounts of time to classify texts ref name maxwell k t 2008 p 3 ref schweighofer e and liebwald d 2008 p 108 ref as the amount of text available continues to increase some have stated their belief that manual classification is unsustainable ref maxwell k t and schafer b 2008 p 4 ref natural language processing in order to reduce the reliance on legal professionals and the amount of time needed efforts have been made to create a system to automatically classify legal text and queries ref name jackson ref name ashleya ashley k d and bruninghaus s 2009 p 125 ref ref name gelbart gelbart d and smith j c 1993 p 142 ref adequate translation of both would allow accurate information retrieval without the high cost of human classification these automatic systems generally employ natural language processing nlp techniques that are adapted to the legal domain and also require the creation of a legal ontology though multiple systems have been postulated ref name jackson ref name ashleya ref name gelbart few have reported results one system smile which attempted to automatically extract classifications from case texts resulted in an f measure which is a calculation of both recall rate and precision of under 0 3 compared to perfect f measure of 1 0 ref name ashleyb ashley k d and bruninghaus s 2009 p 159 ref this is probably much lower than an acceptable rate for general usage ref name ashleyb ref maxwell k t and schafer b 2009 p 3 ref despite the limited results many theorists predict that the evolution of such systems will eventually replace manual classification systems ref maxwell k t and schafer b 2009 p 9 ref ref ashley k d and bruninghaus s 2009 p 126 ref list of retrieval systems free to use law texts and associated oficial metadata lexml brazil http www legislation gov uk legislation gov uk eur lex n lex n lex notes reflist 2 references refbegin cite journal author1 maxwell k t author2 schafer b year 2008 title concept and context in legal information retrieval url http portal acm org citation cfm id 1564016 journal frontiers in artificial intelligence and applications volume 189 pages 63 72 publisher ios press accessdate 2009 11 07 cite journal author jackson p year 1998 title information extraction from case law and retrieval of prior cases by partial parsing and query generation url http portal acm org citation cfm id 288627 288642 journal conference on information and knowledge management pages 60 67 publisher acm accessdate 2009 11 07 display authors etal cite journal author1 blair d c author2 maron m e year 1985 title an evaluation of retrieval effectiveness for a full text document retrieval url http portal acm org citation cfm id 3166 3197 coll guide dl guide cfid 61732097 cftoken 95519997 journal communications of the acm volume 28 issue 3 pages 289 299 publisher acm accessdate 2009 11 07 doi 10 1145 3166 3197 cite journal author peters w year 2007 title the structuring of legal knowledge in lois url http www springerlink com content d04l7h2507700g45 journal artificial intelligence and law volume 15 issue 2 pages 117 135 publisher springer netherlands accessdate 2009 11 07 doi 10 1007 s10506 007 9034 4 display authors etal cite journal author saravanan m year 2007 title improving legal information retrieval using an ontological framework url http www springerlink com content h66412k08h855626 journal artificial intelligence and law volume 17 issue 2 pages 101 124 publisher springer netherlands accessdate 2009 11 07 doi 10 1007 s10506 009 9075 y display authors etal cite journal author1 schweighofer e author2 liebwald d year 2007 title advanced lexical ontologies and hybrid knowledge based systems first steps to a dynamic legal electronic commentary url http www springerlink com content v62v7131x10413v0 journal artificial intelligence and law volume 15 issue 2 pages 103 115 publisher springer netherlands accessdate 2009 11 07 doi 10 1007 s10506 007 9029 1 cite journal author1 gelbart d author2 smith j c year 1993 title flexicon an evaluation of a statistical ranking model adapted to intelligent legal text management url http portal acm org citation cfm id 158994 journal international conference on artificial intelligence and law pages 142 151 publisher acm accessdate 2009 11 07 cite journal author1 ashley k d author2 bruninghaus s year 2009 title automatically classifying case texts and predicting outcomes url http www springerlink com content lhg8837331hgu024 journal artificial intelligence and law volume 17 issue 2 pages 125 165 publisher springer netherlands accessdate 2009 11 07 doi 10 1007 s10506 009 9077 9 refend defaultsort legal information retrieval category information retrieval genres category natural language processing category legal research'
b'other uses question answer multiple issues cleanup date january 2012 reason appearance of plagiarised text now in extensive footnote use of draft rather than published sources extensive appearance of text violating wp verify and or wp or use of jargon to define jargon etc cleanup rewrite date january 2012 more footnotes date february 2014 citation style date january 2016 question answering qa is a computer science discipline within the fields of information retrieval and natural language processing nlp which is concerned with building systems that automatically answer questions posed by humans in a natural language a qa implementation usually a computer program may construct its answers by querying a structured database of knowledge or information usually a knowledge base more commonly qa systems can pull answers from an unstructured collection of natural language documents some examples of natural language document collections used for qa systems include a local collection of reference texts internal organization documents and web pages compiled newswire reports a set of wikipedia pages a subset of world wide web pages with a wide range of question types including fact list definition how why hypothetical semantically constrained and cross lingual questions closed domain question answering deals with questions under a specific domain for example medicine or automotive maintenance and can be seen as an easier task because nlp systems can exploit domain specific knowledge frequently formalized in ontology computer science ontologies alternatively closed domain might refer to a situation where only a limited type of questions are accepted such as questions asking for descriptive knowledge descriptive rather than procedural knowledge procedural information qa systems in the context of machine reading applications have also been constructed in the medical domain for instance related to alzheimers disease ref roser morante martin krallinger alfonso valencia and walter daelemans machine reading of biomedical texts about alzheimer s disease clef 2012 evaluation labs and workshop september 17 2012 ref open domain references open domain question answering deals with questions about nearly anything and can only rely on general ontologies and world knowledge on the other hand these systems usually have much more data available from which to extract the answer history unreferenced section date january 2016 two early qa systems were baseball ref cite journal last1 green jr first1 bert f title baseball an automatic question answerer journal western joint ire aiee acm computer conference date 1961 pages 219 224 display authors etal ref and lunar ref cite journal last1 woods first1 william a last2 kaplan first2 r title lunar rocks in natural english explorations in natural language question answering journal linguistic structures processing 5 date 1977 volume 5 pages 521 569 ref baseball answered questions about the us baseball league over a period of one year lunar in turn answered questions about the geological analysis of rocks returned by the apollo moon missions both qa systems were very effective in their chosen domains in fact lunar was demonstrated at a lunar science convention in 1971 and it was able to answer 90 of the questions in its domain posed by people untrained on the system further restricted domain qa systems were developed in the following years the common feature of all these systems is that they had a core database or knowledge system that was hand written by experts of the chosen domain the language abilities of baseball and lunar used techniques similar to eliza and doctor the first chatterbot programs shrdlu was a highly successful question answering program developed by terry winograd in the late 60s and early 70s it simulated the operation of a robot in a toy world the blocks world and it offered the possibility to ask the robot questions about the state of the world again the strength of this system was the choice of a very specific domain and a very simple world with rules of physics that were easy to encode in a computer program in the 1970s knowledge base s were developed that targeted narrower domains of knowledge the qa systems developed to interface with treport expert system nowiki s produced more repeatable and valid responses to questions within an area of knowledge these expert systems closely resembled modern qa systems except in their internal architecture expert systems rely heavily on expert constructed and organized knowledge base s whereas many modern qa systems rely on statistical processing of a large unstructured natural language text corpus the 1970s and 1980s saw the development of comprehensive theories in computational linguistics which led to the development of ambitious projects in text comprehension and question answering one example of such a system was the unix consultant uc developed by robert wilensky at u c berkeley in the late 1980s the system answered questions pertaining to the unix operating system it had a comprehensive hand crafted knowledge base of its domain and it aimed at phrasing the answer to accommodate various types of users another project was lilog a text understanding system that operated on the domain of tourism information in a german city the systems developed in the uc and lilog projects never went past the stage of simple demonstrations but they helped the development of theories on computational linguistics and reasoning recently specialized natural language qa systems have been developed such as http bitem hesge ch content eagli eagle eye eagli for health and life scientists architecture refimprove section date january 2016 most modern qa systems use natural language text documents as their underlying knowledge source citation needed date january 2016 natural language processing techniques are used to both process the question and index or process the text text corpus corpus from which answers are extracted citation needed date january 2016 an increasing number of qa systems use the world wide web as their corpus of text and knowledge however many of these tools do not produce a human like answer but rather employ shallow methods keyword based techniques templates etc to produce a list of documents or a list of document excerpts containing the probable answer highlighted citation needed date january 2016 in an alternative qa implementation human users assemble knowledge in a structured database called a knowledge base similar to those employed in the expert systems of the 1970s citation needed date january 2016 it is also possible to employ a combination of structured databases and natural language text documents in a hybrid qa system citation needed date january 2016 such a hybrid system may employ data mining algorithms to populate a structured knowledge base that is also populated and edited by human contributors citation needed date january 2016 an example hybrid qa system is the wolfram alpha qa system which employs natural language processing to transform human questions into a form that is processed by a curated knowledge base citation needed date january 2016 as of 2001 qa systems typically included a question classifier module that determines the type of question and the type of answer ref hirschman l gaizauskas r 2001 http journals cambridge org action displayabstract frompage online aid 96167 natural language question answering the view from here natural language engineering 2001 7 4 275 300 cambridge university press ref after the question is analysed the system typically uses several modules that apply increasingly complex nlp techniques on a gradually reduced amount of text thus a document retrieval module uses search engine s to identify the documents or paragraphs in the document set that are likely to contain the answer and a filter preselects small text fragments that contain strings of the same type as the expected answer citation needed date january 2016 for example if the question is who invented penicillin the filter returns text that contain names of people finally an answer extraction module looks for further clues in the text to determine if the answer candidate can indeed answer the question citation needed date january 2016 a multiagent question answering architecture has been proposed where each domain is represented by an agent which tries to answer questions taking into account its specific knowledge a meta agent controls the cooperation between question answering agents and chooses the most relevant answer s ref vcite journal author galitsky b pampapathi r title can many agents answer questions better than one journal first monday volume 10 number 1 date 2005 url http firstmonday org ojs index php fm article view 1204 1124 doi 10 5210 fm v10i1 1204 ref question answering methods qa is very dependent on a good search text corpus corpus for without documents containing the answer there is little any qa system can do it thus makes sense that larger collection sizes generally lend well to better qa performance unless the question domain is orthogonal to the collection the notion of data redundancy in massive collections such as the web means that nuggets of information are likely to be phrased in many different ways in differing contexts and documents ref lin j 2002 the web as a resource for question answering perspectives and challenges in proceedings of the third international conference on language resources and evaluation lrec 2002 ref leading to two benefits by having the right information appear in many forms the burden on the qa system to perform complex nlp techniques to understand the text is lessened correct answers can be filtered from false positive s by relying on the correct answer to appear more times in the documents than instances of incorrect ones question answering heavily relies on reasoning there are a number of question answering systems designed in prolog ref cite book last galitsky first boris title natural language question answering system technique of semantic headers url https books google com books id lknmaaaacaaj series international series on advanced intelligence volume volume 2 year 2003 publisher advanced knowledge international location australia isbn 978 0 86803 979 4 ref a logic programming language associated with artificial intelligence open domain question answering unreferenced section date january 2016 in information retrieval an open domain question answering system aims at returning an answer in response to the user s question the returned answer is in the form of short texts rather than a list of relevant documents the system uses a combination of techniques from computational linguistics information retrieval and knowledge representation for finding answers the system takes a natural language question as an input rather than a set of keywords for example when is the national day of china the sentence is then transformed into a query through its logical form having the input in the form of a natural language question makes the system more user friendly but harder to implement as there are various question types and the system will have to identify the correct one in order to give a sensible answer assigning a question type to the question is a crucial task the entire answer extraction process relies on finding the correct question type and hence the correct answer type keyword data extraction extraction is the first step for identifying the input question type in some cases there are clear words that indicate the question type directly i e who where or how many these words tell the system that the answers should be of type person location number respectively in the example above the word when indicates that the answer should be of type date pos part of speech tagging and syntactic parsing techniques can also be used to determine the answer type in this case the subject is chinese national day the predicate is is and the adverbial modifier is when therefore the answer type is date unfortunately some interrogative words like which what or how do not give clear answer types each of these words can represent more than one type in situations like this other words in the question need to be considered first thing to do is to find the words that can indicate the meaning of the question a lexical dictionary such as wordnet can then be used for understanding the context once the question type has been identified an information retrieval system is used to find a set of documents containing the correct key words a tagger and np verb group chunker can be used to verify whether the correct entities and relations are mentioned in the found documents for questions such as who or where a named entity recogniser is used to find relevant person and location names from the retrieved documents only the relevant paragraphs are selected for ranking a vector space model can be used as a strategy for classifying the candidate answers check if the answer is of the correct type as determined in the question type analysis stage inference technique can also be used to validate the candidate answers a score is then given to each of these candidates according to the number of question words it contains and how close these words are to the candidate the more and the closer the better the answer is then translated into a compact and meaningful representation by parsing in the previous example the expected output answer is 1st oct issues in 2002 a group of researchers presented an unpublished and largely unsourced report as a funding support document in which they describe a 5 year roadmap of research current to the state of the question answering filed at that time ref burger j cardie c chaudhri v gaizauskas r harabagiu s israel d jacquemin c lin c y maiorano s miller g moldovan d ogden b prager j riloff e singhal a shrihari r strzalkowski t voorhees e weishedel r date unknown tasks and program structures to roadmap research in question answering qa at http www nlpir nist gov projects duc papers qa roadmap paper v2 doc issues draft document accessed 1 january 2016 ref ref here is some content taken verbatim from that roadmap see preceding citation 1 question classes different types of questions e g what is the capital of liechtenstein vs why does a rainbow form vs did marilyn monroe and cary grant ever appear in a movie together require the use of different strategies to find the answer question classes are arranged hierarchically in taxonomies example needed date february 2011 2 question processing the same information request can be expressed in various ways some interrogative who is the king of lesotho and some assertive tell me the name of the king of lesotho a semantic model of question understanding and processing would recognize equivalent questions regardless of how they are presented this model would enable the translation of a complex question into a series of simpler questions would identify ambiguities and treat them in context or by interactive clarification 3 context and qa questions are usually asked within a context and answers are provided within that specific context the context can be used to clarify a question resolve ambiguities or keep track of an investigation performed through a series of questions for example the question why did joe biden visit iraq in january 2010 might be asking why vice president biden visited and not president obama why he went to iraq and not afghanistan or some other country why he went in january 2010 and not before or after or what biden was hoping to accomplish with his visit if the question is one of a series of related questions the previous questions and their answers might shed light on the questioner s intent 4 data sources for qa before a question can be answered it must be known what knowledge sources are available and relevant if the answer to a question is not present in the data sources no matter how well the question processing information retrieval and answer extraction is performed a correct result will not be obtained 4 answer extraction answer extraction depends on the complexity of the question on the answer type provided by question processing on the actual data where the answer is searched on the search method and on the question focus and context example needed date february 2011 5 answer formulation the result of a qa system should be presented in a way as natural as possible in some cases simple extraction is sufficient for example when the question classification indicates that the answer type is a name of a person organization shop or disease etc a quantity monetary value length size distance etc or a date e g the answer to the question on what day did christmas fall in 1989 the extraction of a single datum is sufficient for other cases the presentation of the answer may require the use of fusion techniques that combine the partial answers from multiple documents 6 real time question answering there is need for developing q a systems that are capable of extracting answers from large data sets in several seconds regardless of the complexity of the question the size and multitude of the data sources or the ambiguity of the question 7 multilingual or cross lingual question answering the ability to answer a question posed in one language using an answer corpus in another language or even several this allows users to consult information that they cannot use directly see also machine translation 8 interactive qa it is often the case that the information need is not well captured by a qa system as the question processing part may fail to classify properly the question or the information needed for extracting and generating the answer is not easily retrieved in such cases the questioner might want not only to reformulate the question but to have a dialogue with the system in addition system may also use previously answered questions for example the system might ask for a clarification of what sense a word is being used or what type of information is being asked for 9 advanced reasoning for qa more sophisticated questioners expect answers that are outside the scope of written texts or structured databases to upgrade a qa system with such capabilities it would be necessary to integrate reasoning components operating on a variety of knowledge bases encoding world knowledge and common sense reasoning mechanisms as well as knowledge specific to a variety of domains evi software evi is an example of such as system 10 information clustering for qa information clustering for question answering systems is a new trend that originated to increase the accuracy of question answering systems through search space reduction in recent years this was widely researched through development of question answering systems which support information clustering in their basic flow of process 11 user profiling for qa the user profile captures data about the questioner comprising context data domain of interest reasoning schemes frequently used by the questioner common ground established within different dialogues between the system and the user and so forth the profile may be represented as a predefined template where each template slot represents a different profile feature profile templates may be nested one within another example needed date february 2011 12 deep question answering deep qa complement traditional question answering by adding some machine learning capabilities within a standard factoid question answering pipeline the idea is to leverage curated data repositories or knowledge bases which can be general ones such as wikipedia or domain specific e g molecular biology in order to provide more accurate answers to the end users ref ref on the subject of interactive qa see also perera r and nand p 2014 interaction history based answer formulation for question answering at http rivinduperera com publications kesw2014 html draft document accessed 1 january 2015 full citation needed date january 2016 ref full citation needed date january 2016 ref on the subject of information clustering for qa see also perera r 2012 ipedagogy question answering system based on web information clustering at http rivinduperera com publications t4e2012 html draft document accessed 1 january 2015 full citation needed date january 2016 ref full citation needed date january 2016 ref on the subject of deep question answering see the following citation ref ref cite journal pmc 4572360 pmid 26384372 doi 10 1093 database bav081 volume 2015 title deep question answering for protein annotation year 2015 journal database oxford vauthors gobeill j gaudinat a pasche e vishnyakova d gaudet p bairoch a ruch p ref because much of the text in this section was copied and pasted from the roadmap document which itself is a draft and unpublished document the text was moved into a footnote progress qa systems have been extended in recent years to encompass additional domains of knowledge ref maybury m t editor 2004 http www mitpressjournals org doi pdf 10 1162 089120105774321055 new directions in question answering aaai mit press ref for example systems have been developed to automatically answer temporal and geospatial questions questions of definition and terminology biographical questions multilingual questions and questions about the content of audio images and video current qa research topics include interactivity clarification of questions or answers answer reuse or caching knowledge representation and reasoning social media analysis with qa systems sentiment analysis ref webarchive url https web archive org web 20121027153311 http totalgood com bitcrawl date october 27 2012 title bitcrawl by hobson lane ref utilization of thematic roles ref perera r and perera u 2012 http rivinduperera com publications qacd coling2012 html towards a thematic role based target identification model for question answering ref semantic resolution to bridge the gap between syntactically different questions and answer bearing texts ref cite conference author1 bahadorreza ofoghi author2 john yearwood author3 liping ma last author amp yes year 2008 conference the 30th european conference on information retrieval ecir 08 pages 430 437 publisher springer berlin heidelberg url http link springer com chapter 10 1007 978 3 540 78646 7 40 title the impact of semantic class identification and semantic role labeling on natural language answer extraction ref utilization of linguistic resources ref cite journal author1 bahadorreza ofoghi author2 john yearwood author3 liping ma last author amp yes title the impact of frame semantic annotation levels frame\xe2\x80\x90alignment techniques and fusion methods on factoid answer processing journal journal of the american society for information science and technology volume 60 issue 2 pages 247 263 year 2009 url http onlinelibrary wiley com doi 10 1002 asi 20989 abstract jsessionid 099f3d167fd0511a48fb1c19c1060676 f02t02 deniedaccesscustomisedmessage userisauthenticated false doi 10 1002 asi 20989 ref such as wordnet framenet and the similar ibm s question answering system watson computer watson defeated the two greatest jeopardy champions brad rutter and ken jennings by a significant margin ref http www nytimes com 2011 02 17 science 17jeopardy watson html r 0 ref references reflist further reading citation style section date january 2016 dragomir r radev john prager and valerie samn http clair si umich edu radev papers anlp00 pdf ranking suspected answers to natural language questions using predictive annotation in proceedings of the 6th conference on applied natural language processing seattle wa may 2000 john prager eric brown anni coden and dragomir radev http clair si umich edu radev papers sigir00 pdf question answering by predictive annotation in proceedings 23rd annual international acm sigir conference on research and development in information retrieval athens greece july 2000 cite book last hutchins first w john authorlink john hutchins author2 harold l somers year 1992 title an introduction to machine translation url http www hutchinsweb me uk intromt toc htm publisher academic press location london isbn 0 12 362830 x l fortnow steve homer 2002 2003 http people cs uchicago edu fortnow papers history pdf a short history of computational complexity in d van dalen j dawson and a kanamori editors the history of mathematical logic north holland amsterdam external links http aclia lti cs cmu edu ntcir8 question answering evaluation at ntcir http trec nist gov data qamain html question answering evaluation at trec http nlp uned es clef qa question answering evaluation at clef http www gyanibano com quiz question answers computable knowledge natural language processing category artificial intelligence applications category natural language processing category computational linguistics category information retrieval genres'
b'human computer information retrieval hcir is the study and engineering of information retrieval techniques that bring human intelligence into the search engine search process it combines the fields of human computer interaction hci and information retrieval ir and creates systems that improve search by taking into account the human context or through a multi step search process that provides the opportunity for human feedback history this term human computer information retrieval was coined by gary marchionini in a series of lectures delivered between 2004 and 2006 ref name march2006 http www asis org bulletin jun 06 marchionini html marchionini g 2006 toward human computer information retrieval bulletin in june july 2006 bulletin of the american society for information science ref marchionini s main thesis is that hcir aims to empower people to explore large scale information bases but demands that people also take responsibility for this control by expending cognitive and physical energy in 1996 and 1998 a pair of workshops at the university of glasgow on information retrieval and human computer interaction sought to address the overlap between these two fields marchionini notes the impact of the world wide web and the sudden increase in information literacy changes that were only embryonic in the late 1990s a few workshops have focused on the intersection of ir and hci the workshop on exploratory search initiated by the university of maryland human computer interaction lab in 2005 alternates between the association for computing machinery special interest group on information retrieval sigir and chi conference special interest group on computer human interaction chi conferences also in 2005 the european science foundation held an exploratory workshop on information retrieval in context then the first workshop on human computer information retrieval was held in 2007 at the massachusetts institute of technology description hcir includes various aspects of ir and hci these include exploratory search in which users generally combine querying and browsing strategies to foster learning and investigation information retrieval in context i e taking into account aspects of the user or environment that are typically not reflected in a query and interactive information retrieval which peter ingwersen defines as the interactive communication processes that occur during the retrieval of information by involving all the major participants in information retrieval ir i e the user the intermediary and the ir system ref name ingwer1992 http vip db dk pi iri index htm ingwersen p 1992 information retrieval interaction london taylor graham ref a key concern of hcir is that ir systems intended for human users be implemented and evaluated in a way that reflects the needs of those users ref cite web title mira working group 1996 evaluation frameworks for interactive multimedia information retrieval applications url http www dcs gla ac uk mira ref most modern ir systems employ a ranking ranked retrieval model in which the documents are scored based on the probability of the document s relevance to the query ref grossman d and frieder o 2004 information retrieval algorithms and heuristics ref in this model the system only presents the top ranked documents to the user this systems are typically evaluated based on their information retrieval average precision of precision and recall mean average precision over a set of benchmark queries from organizations like the text retrieval conference trec because of its emphasis in using human intelligence in the information retrieval process hcir requires different evaluation models one that combines evaluation of the ir and hci components of the system a key area of research in hcir involves evaluation of these systems early work on interactive information retrieval such as juergen koenemann and nicholas j belkin s 1996 study of different levels of interaction for automatic query reformulation leverage the standard ir measures of information retrieval precision precision and information retrieval recall recall but apply them to the results of multiple iterations of user interaction rather than to a single query response ref name koene1996 http sigchi org chi96 proceedings papers koenemann jk1 txt htm koenemann j and belkin n j 1996 a case for interaction a study of interactive information retrieval behavior and effectiveness in proceedings of the sigchi conference on human factors in computing systems common ground vancouver british columbia canada april 13 18 1996 m j tauber ed chi 96 acm press new york ny 205 212 ref other hcir research such as pia borlund s iir evaluation model applies a methodology more reminiscent of hci focusing on the characteristics of users the details of experimental design etc ref name borlund2003 http informationr net ir 8 3 paper152 html borlund p 2003 the iir evaluation model a framework for evaluation of interactive information retrieval systems information research 8 3 paper 152 ref goals hcir researchers have put forth the following goals towards a system where the user has more control in determining relevant results ref name march2006 ref name ipm2013 https dl acm org citation cfm id 2504017 white r capra r golovchinsky g kules b smith c and tunkelang d 2013 introduction to special issue on human computer information retrieval journal of information processing and management 49 5 1053 1057 ref systems should no longer only deliver the relevant documents but must also provide semantic information along with those documents increase user responsibility as well as control that is information systems require human intellectual effort have flexible architectures so they may evolve and adapt to increasingly more demanding and knowledgeable user bases aim to be part of information ecology of personal and collective memory shared memories and tools rather than discrete standalone services support the entire information life cycle from creation to preservation rather than only the dissemination or use phase support tuning by end users and especially by information professionals who add value to information resources be engaging and fun to use in short information retrieval systems are expected to operate in the way that good libraries do systems should help users to bridge the gap between data or information in the very narrow granular sense of these terms and knowledge processed data or information that provides the context necessary to inform the next iteration of an information seeking process that is good libraries provide both the information a patron needs as well as a partner in the learning process the information professional to navigate that information make sense of it preserve it and turn it into knowledge which in turn creates new more informed information needs techniques the techniques associated with hcir emphasize representations of information that use human intelligence to lead the user to relevant results these techniques also strive to allow users to explore and digest the dataset without penalty i e without expending unnecessary costs of time mouse clicks or context shift many search engines have features that incorporate hcir techniques spelling suggestion s and query expansion automatic query reformulation provide mechanisms for suggesting potential search paths that can lead the user to relevant results these suggestions are presented to the user putting control of selection and interpretation in the user s hands faceted search enables users to navigate information hierarchy hierarchically going from a category to its sub categories but choosing the order in which the categories are presented this contrasts with traditional taxonomy general taxonomies in which the hierarchy of categories is fixed and unchanging faceted classification faceted navigation like taxonomic navigation guides users by showing them available categories or facets but does not require them to browse through a hierarchy that may not precisely suit their needs or way of thinking ref hearst m 1999 user interfaces and visualization chapter 10 of baeza yates r and ribeiro neto b modern information retrieval ref combinatorial search lookahead lookahead provides a general approach to penalty free exploration for example various web applications employ ajax programming ajax to automatically complete query terms and suggest popular searches another common example of lookahead is the way in which search engines annotate results with summary information about those results including both static information e g metadata about the objects and snippets of document text that are most pertinent to the words in the search query relevance feedback allows users to guide an ir system by indicating whether particular results are more or less relevant ref rocchio j 1971 relevance feedback in information retrieval in salton g ed the smart retrieval system ref summarization and analytics help users digest the results that come back from the query summarization here is intended to encompass any means of aggregate data aggregating or data compression compressing the query results into a more human consumable form faceted search described above is one such form of summarization another is cluster analysis clustering which analyzes a set of documents by grouping similar or co occurring documents or terms clustering allows the results to be partitioned into groups of related documents for example a search for java might return clusters for java programming language java java island or java coffee information visualization visual representation of data is also considered a key aspect of hcir the representation of summarization or analytics may be displayed as tables charts or summaries of aggregated data other kinds of information visualization that allow users access to summary views of search results include tag clouds and treemapping related areas exploratory video search references references external links cite web url https sites google com site hcirworkshop title workshops on human computer information retrieval cite web url http www chiir org title acm sigir conference on human information interaction and retrieval chiir defaultsort human computer information retrieval category information retrieval genres category human computer interaction'
b'orphan date september 2012 cognitive models of information retrieval rest on the mix of areas such as cognitive science human computer interaction information retrieval and library science they describe the relationship between a person s cognitive model of the information sought and the organization of this information in an information system these models attempt to understand how a person is searching for information so that the database and the search of this database can be designed in such a way as to best serve the user information retrieval may incorporate multiple tasks and cognitive problems particularly because different people may have different methods for attempting to find this information and expect the information to be in different forms cognitive models of information retrieval may be attempts at something as apparently prosaic as improving search results or may be something more complex such as attempting to create a database which can be queried with natural language search berrypicking one way of understanding how users search for information has been described by marcia bates ref marcia bates 1989 the design of browsing and berrypicking techniques for the online search interface https pages gseis ucla edu faculty bates berrypicking html ref at the university of california at los angeles bates argues that berrypicking better reflects how users search for information than previous models of information retrieval this may be because previous models were strictly linear and did not incorporate cognitive questions for instance one typical model is of a simple linear match between a query and a document however bates points out that there are simple modifications that can be made to this process for instance salton has argued that user feedback may help improve the search results ref gerard salton 1968 automatic information and retrieval computer science dubuque iowa mcgraw hill inc ref bates argues that searches are evolving and occur bit by bit that is to say a person constantly changes his or her search terms in response to the results returned from the information retrieval system thus a simple linear model does not capture the nature of information retrieval because the very act of searching causes feedback which causes the user to modify his or her cognitive model of the information being searched for in addition information retrieval can be bit by bit bates gives a number of examples for instance a user may look through footnotes and follow these sources or a user may scan through recent journal articles on the topic in each case the user s question may change and thus the search evolves exploratory search researchers in the areas of human computer interaction and cognitive science focus on how people explore for information when interacting with the www this kind of search sometimes called exploratory search focuses on how people iteratively refine their search activities and update their internal representations of the search problems ref qu yan furnas george model driven formative evaluation of exploratory search a study under a sensemaking framework ref existing search engines were designed based on traditional library science theories related to retrieval basic facts and simple information through an interface however exploratory information retrieval often involves ill defined search goals and evolving criteria for evaluation of relevance the interactions between humans and the information system will therefore involve more cognitive activity and systems that support exploratory search will therefore need to take into account the cognitive complexities involved during the dynamic information retrieval process natural language searching another way in which cognitive models of information may help in information retrieval is with natural language searching for instance how stuff works imagines a world in which rather than searching for local movies reading the reviews then searching for local mexican restaurants and reading their reviews you will simply type i want to see a funny movie and then eat at a good mexican restaurant what are my options into your browser and you will receive a useful and relevant response ref strickland j n d howstuffworks how web 3 0 will work howstuffworks computer retrieved november 4 2009 from http computer howstuffworks com web 30 htm ref although such a thing is not possible today it represents a holy grail for researchers into cognitive models of information retrieval the goal is to somehow program information retrieval programs to respond to natural language searches this would require a fuller understanding of how people structure queries notes reflist category information retrieval genres category cognitive modeling'
b'exploratory search is a specialization of information exploration which represents the activities carried out by searchers who are ref ryen w white and resa a roth 2009 exploratory search beyond the query response paradigm san rafael ca morgan and claypool ref unfamiliar with the domain of their goal i e need to learn about the topic in order to understand how to achieve their goal or unsure about the ways to achieve their goals either the technology or the process or unsure about their goals in the first place consequently exploratory search covers a broader class of activities than typical information retrieval such as investigating evaluating comparing and synthesizing where new information is sought in a defined conceptual area exploratory data analysis is another example of an information exploration activity typically therefore such users generally combine querying and browsing strategies to foster learning and investigation history exploratory search is a topic that has grown from the fields of information retrieval and information seeking but has become more concerned with alternatives to the kind of search that has received the majority of focus returning the most relevant documents to a google like keyword search the research is motivated by questions like what if the user doesn t know which keywords to use or what if the user isn t looking for a single answer consequently research has begun to focus on defining the broader set of information behaviors in order to learn about the situations when a user is or feels limited by only having the ability to perform a keyword search in the last few years when date april 2016 a series of workshops has been held at various related and key events in 2005 the exploratory search interfaces workshop focused on beginning to define some of the key challenges in the field ref cite web url http research microsoft com ryenw xsi index html title hcil soh 2005 workshop on exploratory search interfaces publisher microsoft accessdate 8 april 2016 ref since then a series of other workshops has been held at related conferences evaluating exploratory search ref cite web url http research microsoft com ryenw eess index html title sigir 2006 workshop evaluating exploratory search systems publisher microsoft accessdate 8 april 2016 ref at sigir06 ref cite web url http www sigir2006 org title sigir 2006 publisher accessdate 8 april 2016 ref and exploratory search and hci ref cite web url http research microsoft com ryenw esi index html title chi 2007 workshop exploratory search and hci publisher microsoft accessdate 8 april 2016 ref at chi07 ref cite web url http www chi2007 org title chi 2007 reach beyond welcome publisher accessdate 8 april 2016 ref in order to meet with the experts in human computer interaction in march 2008 an information processing and management special issue ref cite web url http www sciencedirect com science journal 03064573 title information processing management publisher accessdate 8 april 2016 ref ref ryen w white gary marchionini gheorghe muresan 2008 evaluating exploratory search systems introduction to special topic issue of information processing and management vol 44 issue 2 2008 pp nbsp 433 436 ref focused particularly on the challenges of evaluating exploratory search given the reduced assumptions that can be made about scenarios of use in june 2008 the national science foundation sponsored an invitational workshop to identify a research agenda for exploratory search and similar fields for the coming years ref cite web url http www ils unc edu isss workshop title moved publisher accessdate 8 april 2016 ref research challenges important scenarios with the majority of research in the information retrieval community focusing on typical keyword search scenarios one challenge for exploratory search is to further understand the scenarios of use for when keyword search is not sufficient an example scenario often used to motivate the research by mspace ref http mspace fm mspace ref states if a user does not know much about classical music how should they even begin to find a piece that they might like designing new interfaces with one of the motivations being to support users when keyword search is not enough some research has focused on identifying alternative user interfaces and interaction models that support the user in different ways an example is faceted classification faceted search which presents diverse category style options to the users so that they can choose from a list instead of guess a possible keyword query many of the human computer information retrieval interactive forms of search including faceted browser s are being considered for their support of exploratory search conditions computational cognitive models of exploratory search have been developed to capture the cognitive complexities involved in exploratory search model based dynamic presentation of information cues are proposed to facilitate exploratory search performance ref fu w t kannampalill t g kang r 2010 http portal acm org citation cfm id 1719970 1719998 facilitating exploratory search by model based navigational cues in proceedings of the acm international conference on intelligent user interface 199 208 ref evaluating interfaces as the tasks and goals involved with exploratory search are largely undefined or unpredictable it is very hard to evaluate systems with the measures often used in information retrieval accuracy was typically used to show that a user had found a correct answer but when the user is trying to summarize a domain of information the correct answer is near impossible to identify if not entirely subjective for example possible hotels to stay in paris in exploration it is also arguable that spending more time where time efficiency is typically desirable researching a topic shows that a system provides increased support for investigation finally and perhaps most importantly giving study participants a well specified task could immediately prevent them from exhibiting exploratory behavior cn date april 2016 models of exploratory search behavior there have been recent when date april 2016 attempts to develop a process model of exploratory search behavior especially in social information system e g see models of collaborative tagging ref citation doi 10 1145 1460563 1460600 last1 fu first1 wai tat title the microstructures of social tagging a rational model journal proceedings of the acm 2008 conference on computer supported cooperative work pages 66 72 date april 2008 url http portal acm org citation cfm id 1460600 isbn 978 1 60558 007 4 ref ref citation last1 fu first1 wai tat title a semantic imitation model of social tagging journal proceedings of the ieee conference on social computing pages 66 72 date aug 2009 url http www humanfactors illinois edu reports paperspdfs ieeesocialcom09 a 20semantic 20imitation 20model 20of 20social 20tag 20choices 20 2 pdf ref the process model assumes that user generated information cues such as social tags can act as navigational cues that facilitate exploration of information that others have found and shared with other users on a social information system such as social bookmarking system these models provided extension to existing process model of information search that characterizes information seeking behavior in traditional fact retrievals using search engines ref citation last1 fu first1 wai tat last2 pirolli first2 peter title snif act a cognitive model of user navigation on the world wide web journal human computer interaction pages 335 412 year 2007 url http portal acm org citation cfm id 1466608 volume 22 ref ref kitajima m blackmon m h polson p g 2000 a comprehension based model of web navigation and its application to web usability analysis in s mc donald y waern g cockton eds people and computers xiv usability or else new york springer verlag ref ref miller c s remington r w 2004 modeling information navigation implications for information architecture human computer interaction 19 225 271 ref recent when date april 2016 development in exploratory search is often concentrated in predicting users search intents in interaction with the user ref citation last1 ruotsalo first1 tuukka last2 athukorala first2 kumaripaba last3 glowacka first3 dorota last4 konuyshkova first4 ksenia last5 oulasvrita first5 antti last6 kaipiainen first6 samuli last7 kaski first7 samuel last8 jacucci first8 giulio title supporting exploratory search tasks with interactive user modeling journal proceedings of the 76th annual meeting of the american society for information science and technology asis t year 2013 ref such predictive user modeling also referred as intent modeling can help users to get accustomed to a body of domain knowledge and help users to make sense of the potential directions to be explored around their initial often vague expression of information needs ref citation last1 ruotsalo first1 tuukka last2 peltonen first2 jaakko last3 eugster first3 manuel j a last4 glowacka first4 dorota last5 konuyshkova first5 ksenia last6 athukorala first6 kumaripaba last7 kosunen first7 ilkka last8 reijonen first8 aki last9 myllym\xc3\xa4ki first9 petri last10 kaski first10 samuel last11 jacucci first11 giulio title directing exploratory search with interactive intent modeling journal proceedings of the acm conference of information and knowledge management cikm year 2013 ref ref citation last1 glowacka first1 dorota last2 ruotsalo first2 tuukka last3 konuyshkova first3 ksenia last4 athukorala first4 kumaripaba last5 kaski first5 samuel last6 jacucci first6 giulio title directing exploratory search reinforcement learning from user interactions with keywords journal proceedings of the acm conference of intelligent user interfaces iui url http dl acm org citation cfm id 2449413 pages 117 128 year 2013 ref major figures key figures including experts from both information seeking and human computer interaction are says who date april 2016 marcia bates nicholas belkin ref cite web url http comminfo rutgers edu belkin title nick s home page publisher accessdate 17 april 2016 ref gary marchionini ref cite web url http ils unc edu march title gary s home page publisher accessdate 8 april 2016 ref m c schraefel ref cite web url http users ecs soton ac uk mc title m c schraefel design for innovation creativity discovery publisher accessdate 8 april 2016 ref ryen white ref cite web url http research microsoft com ryenw title ryen w white publisher microsoft accessdate 8 april 2016 ref references references sources white r w kules b drucker s m and schraefel m c 2006 supporting exploratory search introduction to special section of communications of the acm vol 49 issue 4 2006 pp nbsp 36 39 ryen w white gary marchionini gheorghe muresan 2008 evaluating exploratory search systems introduction to special topic issue of information processing and management vol 44 issue 2 2008 pp nbsp 433 436 ryen w white and resa a roth 2009 exploratory search beyond the query response paradigm san rafael ca morgan and claypool p papadakos s kopidaki n armenatzoglou and y tzitzikas 2009 exploratory web searching with dynamic taxonomies and results clustering 13th european conference on digital libraries ecdl 09 corfu greece sep oct 2009 defaultsort exploratory search category human computer interaction category information retrieval genres category information science'
b'multiple issues original research date june 2015 refimprove date june 2015 cleanup date november 2010 external links date january 2012 expertise finding is the use of tools for finding and assessing individual expertise with particular focus on scientific expertise importance of expertise it can be argued that human expertise is more valuable than capital means of production or intellectual property contrary to expertise all other aspects of capitalism are now relatively generic access to capital is global as is access to means of production for many areas of manufacturing intellectual property can be similarly licensed furthermore expertise finding is also a key aspect of institutional memory as without its experts an institution is effectively decapitated however finding and licensing expertise the key to the effective use of these resources remain much harder starting with the very first step finding expertise that you can trust until very recently finding expertise required a mix of individual social and collaborative practices a haphazard process at best mostly it involved contacting individuals one trusts and asking them for referrals while hoping that one s judgment about those individuals is justified and that their answers are thoughtful in the last fifteen years a class of knowledge management software has emerged to facilitate and improve the quality of expertise finding termed expertise locating systems these software range from social network service social networking systems to knowledge base s some software like those in the social networking realm rely on users to connect each other thus using social filtering to act as recommender system recommender systems at the other end of the spectrum are specialized knowledge base s that rely on experts to populate a specialized type of database with their self determined areas of expertise and contributions and do not rely on user recommendations hybrids that feature expert populated content in conjunction with user recommendations also exist and are arguably more valuable for doing so still other expertise knowledge bases rely strictly on external manifestations of expertise herein termed gated objects e g citation impact s for scientific papers or data mining approaches wherein many of the work products of an expert are collated such systems are more likely to be free of user introduced biases e g http researchscorecard com researchscorecard though the use of computational methods can introduce other biases more recently linkedin expertise search introduces a hybrid approach based on user generated data e g member profiles community based signals e g recommendations and skill endorsements and personalized signals e g social connection between searcher and results ref name 0 cite journal last ha thuc first viet last2 venkataraman first2 ganesh last3 rodriguez first3 mario last4 sinha first4 shakti last5 sundaram first5 senthil last6 guo first6 lin date 2016 02 15 title personalized expertise search at linkedin url http arxiv org abs 1602 04572 journal arxiv 1602 04572 cs ref given required linkedin skills skills and other types of information need like location and industries the system allows recruiters to search for hiring candidates amongst more than 450 million linkedin members examples of the systems outlined above are listed in table 1 table 1 a classification of expertise location systems class wikitable border 1 type application domain data source examples social networking professional networking user generated and community generated linkedin ref name 0 scientific literature identifying publications with strongest research impact third party generated science citation index thomson reuters http www thomsonreuters com products services science science products a z science citation index scientific literature expertise search software arnetminer http arnetminer org knowledge base private expertise database user generated http www mitre org news the edge june 98 third html mitre expert finder mitre corporation mit expertfinder ref 3 decisiv search matters expertise recommind software company recommind inc http www profinda com profinda profinda ltd https skillhive com skillhive intunex tacit software oracle corporation http www guruscan nl guruscan guruscan social expert guide knowledge base publicly accessible expertise database user generated http expertisefinder com expertise finder ref http expertisefinder com ref community of science expertise http expertise cos com researcherid thomson reuters http www thomsonreuters com products services scientific researcherid knowledge base private expertise database third party generated http www mitre org news the edge june 98 third html mitre expert finder mitre corporation mit expertfinder ref 3 mindserver expertise recommind inc tacit software knowledge base publicly accessible expertise database third party generated http researchscorecard com researchscorecard researchscorecard inc http authoratory com authoratory com http biomedexperts com biomedexperts collexis holdings inc http www hcarknowledgemesh com knowledgemesh hershey center for applied research http med stanford edu profiles community academic profiles stanford school of medicine https web archive org web 20081120175851 http www researchcrossroads org researchcrossroads org innolyst inc blog search engine s third party generated technorati http technorati com technical problems a number of interesting problems follow from the use of expertise finding systems the matching of questions from non expert to the database of existing expertise is inherently difficult especially when the database does not store the requisite expertise this problem grows even more acute with increasing ignorance on the part of the non expert due to typical search problems involving use of keywords to search unstructured data that are not semantically normalized as well as variability in how well an expert has set up their descriptive content pages improved question matching is one reason why third party semantically normalized systems such as http researchscorecard com researchscorecard and biomedexperts should be able to provide better answers to queries from non expert users avoiding expert fatigue due to too many questions requests from users of the system ref 1 finding ways to avoid gaming of the system to reap unjustified expertise credibility infer expertise on implicit skills since users typically do not declare all of the skills they have it is important to infer their implicit skills that are highly related their explicit ones the inference step can significantly improve precision and recall recall in expertise finding expertise ranking means of classifying and ranking expertise and therefore experts become essential if the number of experts returned by a query is greater than a handful this raises the following social problems associated with such systems how can expertise be assessed objectively is that even possible what are the consequences of relying on unstructured social assessments of expertise such as user recommendations how does one distinguish authority authoritativeness as a proxy metric of expertise from simple popularity which is often a function of one s ability to express oneself coupled with a good social sense what are the potential consequences of the social or professional stigma associated with the use of an authority ranking such as used in http technorati com technorati and http researchscorecard com researchscorecard how to make expertise ranking personalized to each individual searcher this is particularly important for recruiting purpose since given the same skills recruiters from different companies industries locations might have different preferences on candidates ref name 0 sources of data for assessing expertise many types of data sources have been used to infer expertise they can be broadly categorized based on whether they measure raw contributions provided by the expert or whether some sort of filter is applied to these contributions unfiltered data sources that have been used to assess expertise in no particular ranking order user recommendations help desk tickets what the problem was and who fixed it e mail traffic between users documents whether private or on the web particularly publications user maintained web pages reports technical marketing etc filtered data sources that is contributions that require approval by third parties grant committees referees patent office etc are particularly valuable for measuring expertise in a way that minimizes biases that follow from popularity or other social factors patent s particularly if issued scientific publications issued grants failed grant proposals are rarely know beyond the authors clinical trial s product launches pharmaceutical drugs approaches for creating expertise content manual either by experts themselves e g https skillhive com skillhive or by a curator http expertisefinder com expertise finder automated e g using software agent s e g mit s http web media mit edu lieber lieberary expert finder expert finder intro html expertfinder and the http wiki foaf project org expertfinder expertfinder initiative or a combination of agents and human curation e g http researchscorecard com researchscorecard in industrial expertise search engines e g linkedin there are many signals coming into the ranking functions such as user generated content e g profiles community generated content e g recommendations and skills endorsements and personalized signals e g social connections moreover user queries might contain many other aspects rather required expertise such as locations industries or companies thus traditional information retrieval features like text matching are also important learning to rank is typically used to combine all of these signals together into a ranking function ref name 0 interesting expertise systems over the years in no particular order http www guruscan nl guruscan autonomy s idol askme http expertisefinder com expertise finder tacit knowledge systems activenet triviumsoft s see k mit s http web media mit edu lieber lieberary expert finder expert finder intro html expertfinder ref 3 mitre s ref 1 http www mitre org news the edge june 98 third html expert finder mitre s xpertnet arnetminer ref 2 dataware ii knowledge directory thomson s tool hewlett packard s connex microsoft s spud project http www profinda com profinda http www xperscore com xperscore http intunex fi skillhive skillhive linkedin ref name 0 conferences http expertfinder info pickme2008 the expertfinder initiative references reflist ackerman mark and mcdonald david 1998 just talk to me a field study of expertise location proceedings of the 1998 acm conference on computer supported cooperative work hughes gareth and crowder richard 2003 experiences in designing highly adaptable expertise finder systems proceedings of the detc conference 2003 maybury m d amore r house d 2002 awareness of organizational expertise international journal of human computer interaction 14 2 199 217 maybury m d amore r house d 2000 automating expert finding international journal of technology research management 43 6 12 15 maybury m d amore r and house d december 2001 expert finding for collaborative virtual environments communications of the acm 14 12 55 56 in ragusa j and bochenek g eds special section on collaboration virtual design environments maybury m d amore r and house d 2002 automated discovery and mapping of expertise in ackerman m cohen a pipek v and wulf v eds beyond knowledge management sharing expertise cambridge mit press mattox d m maybury et al 1999 enterprise expert and knowledge discovery proceedings of the 8th international conference on human computer interactions hci international 99 munich germany tang j zhang j yao l li j zhang l and su z 2008 arnetminer extraction and mining of academic social networks proceeding of the 14th acm sigkdd international conference on knowledge discovery and data mining viavacqua a 1999 agents for expertise location proceedings of the 1999 aaai spring symposium on intelligent agents in cyberspace stanford ca category evaluation methods category metrics category analysis category impact assessment category knowledge sharing category library science category information retrieval genres category science studies'
b'multiple issues coi date december 2015 notability date december 2015 orphan date june 2016 noisy text analytics is a process of information extraction whose goal is to automatically extract structured or semistructured information from noisy text noisy unstructured text data while text analytics is a growing and mature field that has great value because of the huge amounts of data being produced processing of noisy text is gaining in importance because a lot of common applications produce noisy text data noisy unstructured text data is found in informal settings such as online chat text messaging text messages e mail s message boards newsgroups blogs wikis and web pages also text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition contains processing noise text produced under such circumstances is typically highly noisy containing spelling errors abbreviation s non standard words false starts repetitions missing punctuation s missing letter case information pause filling words such as um and uh and other texting and speech disfluencies such text can be seen in large amounts in contact centre business contact centers chat room s optical character recognition ocr of text documents short message service sms text etc documents with historical language can also be considered noisy with respect to today s knowledge about the language such text contains important historical religious ancient medical knowledge that is useful the nature of the noisy text produced in all these contexts warrants moving beyond traditional text analysis techniques techniques for noisy text analysis missing punctuation and the use of non standard words can often hinder standard natural language processing tools such as part of speech tagging and parsing techniques to both learn from the noisy data and then to be able to process the noisy data are only now being developed possible source of noisy text world wide web poorly written text is found in web pages online chat blogs wikis discussion forum s newsgroups most of these data are unstructured and the style of writing is very different from say well written news articles analysis for the web data is important because they are sources for market buzz analysis market review trend estimation etc also because of the large amount of data it is necessary to find efficient methods of information extraction statistical classification classification automatic summarization and analysis of these data contact centre business contact centers this is a general term for help desks information lines and customer service centers operating in domains ranging from computer sales and support to mobile phones to apparels on an average a person in the developed world interacts at least once a week with a contact center agent a typical contact center agent handles over a hundred calls per day they operate in various modes such as voice online chat and e mail the contact center industry produces gigabytes of data in the form of e mails chat logs voice conversation transcription linguistics transcription s customer feedback etc a bulk of the contact center data is voice conversations transcription of these using state of the art automatic speech recognition results in text with 30 40 word error rate further even written modes of communication like online chat between customers and agents and even the interactions over email tend to be noisy analysis of contact center data is essential for customer relationship management customer satisfaction analysis call modeling customer profiling agent profiling etc and it requires sophisticated techniques to handle poorly written text printed documents many libraries government organizations and national defence organizations have vast repositories of hard copy documents to retrieve and process the content from such documents they need to be processed using optical character recognition in addition to printed text these documents may also contain handwritten annotations ocred text can be highly noisy depending on the font size quality of the print etc it can range from 2 3 word error rate s to as high as 50 60 word error rate s handwritten annotations can be particularly hard to decipher and error rates can be quite high in their presence text messaging short messaging service sms language usage over computer mediated discourses like chats emails and sms texts significantly differs from the standard form of the language an urge towards shorter message length facilitating faster typing and the need for semantic clarity shape the structure of this non standard form known as the texting language references http www springerlink com content ql711884654q p c6beb20b8dfa4389b5e4daf2dd63618e pi 0 special issue on noisy text analytics international journal on document analysis and recognition 2007 springer guest editors craig knoblock daniel lopresti shourya roy and l venkata subramaniam vol 10 no 3 4 december 2007 http arxiv org abs 0810 0332 wong w liu w bennamoun m enhanced integrated scoring for cleaning dirty texts in ijcai workshop on analytics for noisy unstructured text data and 2007 hyderabad india l v subramaniam s roy t a faruquie s negi a survey of types of text noise and techniques to handle noisy text in third workshop on analytics for noisy unstructured text data and 2009 references see also text analytics information extraction computational linguistics natural language processing named entity recognition text mining automatic summarization statistical classification data quality category artificial intelligence applications category natural language processing category computational linguistics category information retrieval genres category statistical natural language processing'
b'areas where information retrieval techniques are employed include the entries are in alphabetical order within each category general applications of information retrieval digital libraries information filtering recommender systems media search blog search image retrieval 3d retrieval music information retrieval music retrieval news search speech retrieval video retrieval search engines site search desktop search enterprise search federated search mobile search social search web search engine web search domain specific applications of information retrieval expert search finding genomic information retrieval geographic information retrieval information retrieval for chemical structures information retrieval in software engineering legal information retrieval vertical search other retrieval methods methods techniques in which information retrieval techniques are employed include adversarial information retrieval automatic summarization multi document summarization compound term processing cross language information retrieval cross lingual retrieval document classification spam filtering question answering see also information retrieval defaultsort information retrieval applications category information retrieval genres'
b'unreferenced date january 2012 audio mining is a technique by which the content of an audio signal can be automatically analysed and searched it is most commonly used in the field of speech recognition automatic speech recognition where the analysis tries to identify any speech within the audio the audio will typically be processed by a speech recognition system in order to identify word or phoneme units that are likely to occur in the spoken content this information may either be used immediately in pre defined searches for keywords or phrases a real time word spotting system or the output of the speech recogniser may be stored in an index file one or more audio mining index files can then be loaded at a later date in order to run searches for keywords or phrases the results of a search will normally be in terms of hits which are regions within files that are good matches for the chosen keywords the user may then be able to listen to the audio corresponding to these hits in order to verify if a correct match was found audio mining systems used in the field of speech recognition are often divided into two groups those that use large vocabulary continuous speech recogniser s lvcsr and those that use phonetic recognition musical audio mining also known as music information retrieval relates to the identification of perceptually important characteristics of a piece of music such as melodic harmonic or rhythmic structure searches can then be carried out to find pieces of music that are similar in terms of their melodic harmonic and or rhythmic characteristics see also speech analytics category speech recognition category music information retrieval category information retrieval genres category computational linguistics'
b'coi date july 2014 original research date july 2014 use dmy dates date february 2012 multimedia information retrieval mmir or mir is a research discipline of computer science that aims at extracting semantic information from multimedia data sources ref name eidenberger h eidenberger fundamental media understanding atpress 2011 p 1 ref fv date july 2014 data sources include directly perceivable media such as content media and publishing audio image and video indirectly perceivable sources such as written language text biosignals as well as not perceivable sources such as bioinformation stock prices etc the methodology of mmir can be organized in three groups methods for the summarization of media content feature extraction the result of feature extraction is a description methods for the filtering of media descriptions for example elimination of data redundancy redundancy methods for the categorization of media descriptions into classes feature extraction methods feature extraction is motivated by the sheer size of multimedia objects as well as their redundancy and possibly noisiness ref name eidenberger rp 2 fv date july 2014 generally two possible goals can be achieved by feature extraction summarization of media content methods for summarization include in the audio domain for example mel frequency cepstrum mel frequency cepstral coefficients zero crossings rate short time energy in the visual domain color histograms ref a del bimbo visual information retrieval morgan kaufmann 1999 ref such as the mpeg 7 scalable color descriptor can be used for summarization detection of patterns by auto correlation and or cross correlation patterns are recurring media chunks that can either be detected by comparing chunks over the media dimensions time space etc or comparing media chunks to templates e g face templates phrases typical methods include linear predictive coding in the audio biosignal domain ref hg kim n moreau t sikora mpeg 7 audio and beyond wiley 2005 ref texture description in the visual domain and n grams in text information retrieval merging and filtering methods multimedia information retrieval implies that multiple channels are employed for the understanding of media content ref ms lew ed principles of visual information retrieval springer 2001 ref each of this channels is described by media specific feature transformations the resulting descriptions have to be merged to one description per media object merging can be performed by simple concatenation if the descriptions are of fixed size variable sized descriptions as they frequently occur in motion description have to be normalized to a fixed length first frequently used methods for description filtering include factor analysis e g by pca singular value decomposition e g as latent semantic indexing in text retrieval and the extraction and testing of statistical moments advanced concepts such as the kalman filter are used for merging of descriptions categorization methods generally all forms of machine learning can be employed for the categorization of multimedia descriptions ref name eidenberger rp 125 fv date july 2014 though some methods are more frequently used in one area than another for example hidden markov models are state of the art in speech recognition while dynamic time warping a semantically related method is state of the art in gene sequence alignment the list of applicable classifiers includes the following metric approaches cluster analysis vector space model minkowski distances dynamic alignment nearest neighbor methods k nearest neighbors algorithm k means self organizing map risk minimization support vector regression support vector machine linear discriminant analysis density based methods bayes nets markov process es mixture models neural networks perceptron associative memories spiking nets heuristics decision trees random forests etc the selection of the best classifier for a given problem test set with descriptions and class labels so called ground truth can be performed automatically for example using the weka data miner open problems the quality of mmir systems ref jc nordbotten http nordbotten com adm adm book mirs frame htm multimedia information retrieval systems retrieved 14 october 2011 ref depends heavily on the quality of the training data discriminative descriptions can be extracted from media sources in various forms machine learning provides categorization methods for all types of data however the classifier can only be as good as the given training data on the other hand it requires considerable effort to provide class labels for large databases the future success of mmir will depend on the provision of such data ref h eidenberger frontiers of media understanding atpress 2012 ref the annual trecvid competition is currently one of the most relevant sources of high quality ground truth related areas mmir provides an overview over methods employed in the areas of information retrieval ref h eidenberger professional media understanding atpress 2012 ref ref cite journal last raieli first roberto date title introducing multimedia information retrieval to libraries url http leo cineca it index php jlis article view 11530 journal jlis it volume 7 issue 3 pages 9 42 doi 10 4403 jlis it 11530 access date 8 october 2016 ref methods of one area are adapted and employed on other types of media multimedia content is merged before the classification is performed mmir methods are therefore usually reused from other areas such as bioinformatics bioinformation analysis biosignal biosignal processing content based image retrieval content based image and video retrieval facial recognition system face recognition music information retrieval audio and music classification speech recognition technical analysis technical chart analysis video browsing video browsing information retrieval text information retrieval the journal of multimedia information retrieval ref http www springer com computer journal 13735 journal of multimedia information retrieval springer 2011 retrieved 21 october 2011 ref documents the development of mmir as a research discipline that is independent of these areas see also handbook of multimedia information retrieval ref h eidenberger handbook of multimedia information retrieval atpress 2012 ref for a complete overview over this research discipline references reflist category information retrieval genres'
b'refimprove date january 2016 multi document summarization is an automatic procedure aimed at information extraction extraction of information from multiple texts written about the same topic the resulting summary report allows individual users such as professional information consumers to quickly familiarize themselves with information contained in a large cluster of documents in such a way multi document summarization systems are complementing the news aggregators performing the next step down the road of coping with information overload key benefits multi document summarization creates information reports that are both concise and comprehensive with different opinions being put together outlined every topic is described from multiple perspectives within a single document while the goal of a brief summary is to simplify information search and cut the time by pointing to the most relevant source documents comprehensive multi document summary should itself contain the required information hence limiting the need for accessing original files to cases when refinement is required automatic summaries present information extracted from multiple sources algorithmically without any editorial touch or subjective human intervention thus making it completely unbiased technological challenges the multi document summarization task has turned out to be much more complex than automatic summarization summarizing a single document even a very large one this difficulty arises from inevitable thematic diversity within a large set of documents a good summarization technology aims to combine the main themes with completeness readability and conciseness document understanding conferences ref cite web url http www nlpir nist gov projects duc index html title document understanding conferences website nlpir nist gov date 2014 09 09 accessdate 2016 01 10 ref conducted annually by nist have developed sophisticated evaluation criteria for techniques accepting the multi document summarization challenge an ideal multi document summarization system does not simply shorten the source texts but presents information organized around the key aspects to represent a wider diversity of views on the topic when such quality is achieved an automatic multi document summary is perceived more like an overview of a given topic the latter implies that such text compilations should also meet other basic requirements for an overview text compiled by a human the multi document summary quality criteria are as follows clear structure including an outline of the main content from which it is easy to navigate to the full text sections text within sections is divided into meaningful paragraphs gradual transition from more general to more specific thematic aspects good readability the latter point deserves additional note special care is taken in order to ensure that the automatic overview shows no paper unrelated communication noise information noise from the respective documents e g web pages no dangling references to what is not mentioned or explained in the overview no text breaks across a sentence no semantic redundancy information theory redundancy real life systems the multi document summarization technology is now coming of age a view supported by a choice of advanced web based systems that are currently available ultimate research assistant ref cite web url http ultimate research assistant com title generate research report publisher ultimate research assistant date accessdate 2016 01 10 ref performs text mining on internet search results to help summarize and organize them and make it easier for the user to perform online research specific text mining techniques used by the tool include concept extraction text summarization hierarchical concept clustering e g automated taxonomy generation and various visualization techniques including tag clouds and mind maps iresearch reporter ref cite web url http www iresearch reporter com title iresearch reporter service website iresearch reporter com date accessdate 2016 01 10 ref commercial text extraction and text summarization system free demo site accepts user entered query passes it on to google search engine retrieves multiple relevant documents produces categorized easily readable natural language summary reports covering multiple documents in retrieved set all extracts linked to original documents on the web post processing entity extraction event and relationship extraction text extraction extract clustering linguistic analysis multi document full text natural language processing categorization rules clustering linguistic analysis text summary construction tool set newsblaster ref http newsblaster cs columbia edu webarchive url https web archive org web 20130416065538 http newsblaster cs columbia edu date april 16 2013 ref is a system that helps users find news that is of the most interest to them the system automatically collects clusters categorizes and summarizes news from several sites on the web cnn reuters fox news etc on a daily basis and it provides users an interface to browse the results newsinessence ref http www newsinessence com webarchive url https web archive org web 20110411005726 http www newsinessence com date april 11 2011 ref may be used to retrieve and summarize a cluster of articles from the web it can start from a uniform resource locator url and retrieve documents that are similar or it can retrieve documents that match a given set of keywords newsinessence also downloads news articles daily and produces news clusters from them newsfeed researcher ref cite web url http newsfeedresearcher com title news feed researcher 124 general stuff website newsfeedresearcher com date accessdate 2016 01 10 ref is a news portal performing continuous automatic summarization of documents initially clustered by the news aggregators e g google news newsfeed researcher is backed by a free online engine covering major events related to business technology u s and international news this tool is also available in on demand mode allowing a user to build a summaries on selected topics scrape this ref http www scrapethis com webarchive url https web archive org web 20090919054723 http www scrapethis com date september 19 2009 ref is like a search engine but instead of providing links to the most relevant websites based on a query it scrapes the pertinent information off of the relevant websites and provides the user with a consolidated multi document summary along with dictionary definitions images and videos jistweb ref http www jastatechnologies com productlist html webarchive url https web archive org web 20130529112318 http www jastatechnologies com productlist html date may 29 2013 ref is a query specific multiple document summariser the simplish simplifying summarizing tool ref cite web url http simplish org title simplish basic english tool publisher the goodwill consortium date accessdate 2016 02 12 ref performs automatic multi lingual multi document summarization this tool does not need training of any kind and works by generating ideograms that represent the meaning of each sentence and then summarizes using two user supplied parameters equivalence when are two sentences to be considered equivalent and relevance how long is the desired summary as auto generated multi document summaries increasingly resemble the overviews written by a human their use of extracted text snippets may one day face copyright issues in relation to the fair use copyright concept bibliography g\xc3\xbcnes erkan and dragomir r radev lexrank graph based centrality as salience in text summarization journal of artificial intelligence research jair 2004 http clair si umich edu radev papers lprj pdf dragomir r radev hongyan jing malgorzata sty\xc5\x9b and daniel tam centroid based summarization of multiple documents information processing and management 40 919 938 december 2004 http clair si umich edu radev papers centroid pdf kathleen r mckeown and dragomir r radev generating summaries of multiple news articles in proceedings acm conference on research and development in information retrieval sigir 95 pages 74 82 seattle washington july 1995 http clair si umich edu radev papers sigir95 pdf c y lin e hovy from single to multi document summarization a prototype system and its evaluation in proceedings of the acl pp nbsp 457 464 2002 kathleen mckeown rebecca j passonneau david k elson ani nenkova julia hirschberg do summaries help a task based evaluation of multi document summarization sigir 05 salvador brazil august 15 19 2005 http www cs columbia edu ani papers f98 mckeown pdf r barzilay n elhadad k r mckeown inferring strategies for sentence ordering in multidocument news summarization journal of artificial intelligence research v 17 pp nbsp 35 55 2002 m soubbotin s soubbotin trade off between factors influencing quality of the summary document understanding workshop duc vancouver b c canada october 9 10 2005 http duc nist gov pubs 2005papers freetext sergei pdf c ravindranath chowdary and p sreenivasa kumar esum an efficient system for query specific multi document summarization in ecir advances in information retrieval pp nbsp 724 728 springer berlin heidelberg 2009 see also automatic summarization text mining news aggregators references reflist external links http www nlpir nist gov projects duc index html document understanding conferences http www1 cs columbia edu nlp projects html columbia nlp projects http lada si umich edu 8080 clair nie1 nie cgi newsinessence web based news summarization natural language processing defaultsort multi document summarization category natural language processing category information retrieval genres'
b'multiple issues refimprove date august 2012 cleanup date september 2009 in text retrieval full text search refers to techniques for searching a single computer stored document or a collection in a full text database full text search is distinguished from searches based on metadata or on parts of the original texts represented in databases such as titles abstracts selected sections or bibliographical references in a full text search a search engine examines all of the words in every stored document as it tries to match search criteria for example text specified by a user full text searching techniques became common in online bibliographic databases in the 1990s verify source date october 2008 many websites and application programs such as word processing software provide full text search capabilities some web search engines such as altavista employ full text search techniques while others index only a portion of the web pages examined by their indexing systems ref in practice it may be difficult to determine how a given search engine works the search algorithms actually employed by web search services are seldom fully disclosed out of fear that web entrepreneurs will use search engine optimization techniques to improve their prominence in retrieval lists ref indexing when dealing with a small number of documents it is possible for the full text search engine to directly scan the contents of the documents with each information retrieval query a strategy called serial memory processing serial scanning this is what some tools such as grep do when searching however when the number of documents to search is potentially large or the quantity of search queries to perform is substantial the problem of full text search is often divided into two tasks indexing and searching the indexing stage will scan the text of all the documents and build a list of search terms often called an search index index but more correctly named a concordance publishing concordance in the search stage when performing a specific query only the index is referenced rather than the text of the original documents ref name capabilities of full text search system http www lucidimagination com full text search capabilities of full text search system webarchive url https web archive org web 20101223192214 http www lucidimagination com full text search date december 23 2010 ref the indexer will make an entry in the index for each term or word found in a document and possibly note its relative position within the document usually the indexer will ignore stop words such as the and and that are both common and insufficiently meaningful to be useful in searching some indexers also employ language specific stemming on the words being indexed for example the words drives drove and driven will be recorded in the index under the single concept word drive the precision vs recall tradeoff image full text search results png 150px thumb right diagram of a low precision low recall search recall measures the quantity of relevant results returned by a search while precision is the measure of the quality of the results returned recall is the ratio of relevant results returned to all relevant results precision is the number of relevant results returned to the total number of results returned the diagram at right represents a low precision low recall search in the diagram the red and green dots represent the total population of potential search results for a given search red dots represent irrelevant results and green dots represent relevant results relevancy is indicated by the proximity of search results to the center of the inner circle of all possible results shown those that were actually returned by the search are shown on a light blue background in the example only 1 relevant result of 3 possible relevant results was returned so the recall is a very low ratio of 1 3 or 33 the precision for the example is a very low 1 4 or 25 since only 1 of the 4 results returned was relevant ref name isbn1430215941 cite book last coles first michael year 2008 title pro full text search in sql server 2008 edition version 1 publisher apress apress publishing company isbn 1 4302 1594 1 ref due to the ambiguities of natural language full text search systems typically includes options like stop words to increase precision and stemming to increase recall controlled vocabulary controlled vocabulary searching also helps alleviate low precision issues by tag metadata tagging documents in such a way that ambiguities are eliminated the trade off between precision and recall is simple an increase in precision can lower overall recall while an increase in recall lowers precision ref name yuwonolee cite conference first yuwono last b author2 lee d l title search and ranking algorithms for locating resources on the world wide web pages 164 publisher 12th international conference on data engineering icde 96 year 1996 ref see also precision and recall false positive problem free text searching is likely to retrieve many documents that are not relevance relevant to the intended search question such documents are called false positives see type i and type ii errors type i error type i error the retrieval of irrelevant documents is often caused by the inherent ambiguity of natural language in the sample diagram at right false positives are represented by the irrelevant results red dots that were returned by the search on a light blue background clustering techniques based on bayesian inference bayesian algorithms can help reduce false positives for a search term of bank clustering can be used to categorize the document data universe into financial institution place to sit place to store etc depending on the occurrences of words relevant to the categories search terms or a search result can be placed in one or more of the categories this technique is being extensively deployed in the electronic discovery e discovery domain clarify date january 2012 performance improvements the deficiencies of free text searching have been addressed in two ways by providing users with tools that enable them to express their search questions more precisely and by developing new search algorithms that improve retrieval precision improved querying tools index term keyword s document creators or trained indexers are asked to supply a list of words that describe the subject of the text including synonyms of words that describe this subject keywords improve recall particularly if the keyword list includes a search word that is not in the document text field restricted search some search engines enable users to limit free text searches to a particular field computer science field within a stored record computer science data record such as title or author boolean query boolean queries searches that use boolean logic boolean operators for example tt encyclopedia logical conjunction and online negation not encarta tt can dramatically increase the precision of a free text search the tt and tt operator says in effect do not retrieve any document unless it contains both of these terms the tt not tt operator says in effect do not retrieve any document that contains this word if the retrieval list retrieves too few documents the tt or tt operator can be used to increase recall information retrieval recall consider for example tt encyclopedia and online logical disjunction or internet not encarta tt this search will retrieve documents about online encyclopedias that use the term internet instead of online this increase in precision is very commonly counter productive since it usually comes with a dramatic loss of recall ref studies have repeatedly shown that most users do not understand the negative impacts of boolean queries http eprints cs vt edu archive 00000112 ref phrase search a phrase search matches only those documents that contain a specified phrase such as tt wikipedia the free encyclopedia tt concept search a search that is based on multi word concepts for example compound term processing this type of search is becoming popular in many e discovery solutions concordance search a concordance search produces an alphabetical list of all principal words that occur in a plain text text with their immediate context proximity search text proximity search a phrase search matches only those documents that contain two or more words that are separated by a specified number of words a search for tt wikipedia within2 free tt would retrieve only those documents in which the words tt wikipedia and free tt occur within two words of each other regular expression a regular expression employs a complex but powerful querying syntax that can be used to specify retrieval conditions with precision fuzzy search will search for document that match the given terms and some variation around them using for instance edit distance to threshold the multiple variation wildcard character wildcard search a search that substitutes one or more characters in a search query for a wildcard character such as an asterisk for example using the asterisk in a search query tt s n tt will find sin son sun etc in a text improved search algorithms the pagerank algorithm developed by google gives more prominence to documents to which other web page s have linked ref cite patent inventor last page inventor first lawrence publication date 1 9 1998 issue date 9 4 2001 title method for node ranking in a linked database country code us description a method assigns importance ranks to nodes in a linked database such as any database of documents containing citations the world wide web or any other hypermedia database the rank assigned to a document is calculated from the ranks of documents citing it in addition the rank of a document is patent number 6285999 postscript bot inserted parameter either remove it or change its value to for the cite to end in a as necessary inconsistent citations ref see search engine for additional examples software the following is a partial list of available software products whose predominant purpose is to perform full text indexing and searching some of these are accompanied with detailed descriptions of their theory of operation or internal algorithms which can provide additional insight into how full text search may be accomplished col float free and open source software please do not add web links or products which do not have wikipedia articles they will be summarily deleted basex clusterpoint clusterpoint database elasticsearch ht dig ht dig kinosearch lemur project lemur indri lucene mnogosearch searchdaimon sphinx search engine sphinx swish e xapian apache solr col float break proprietary software please do not add web links or products which do not have wikipedia articles they will be summarily deleted algolia autonomy corporation azure search bar ilan responsa project brainware brs search concept searching limited dieselpoint dtsearch endeca exalead funnelback fast search transfer inktomi company inktomi dan wagner locayta locayta rebranded to attraqt in 2014 lucid imagination marklogic sap hana ref http www martechadvisor com news databases big data sap adds hanabased software packages to iot portfolio ref swiftype thunderstone software llc viv\xc3\xadsimo col float end notes reflist see also pattern matching and string matching compound term processing enterprise search information extraction information retrieval faceted search list of enterprise search vendors webcrawler first fts engine search engine indexing how search engines generate indices to support full text searching defaultsort full text search category text editor features category information retrieval genres'
b'dragomir r radev is a university of michigan computer science professor and columbia university computer science adjunct professor working on natural language processing and information retrieval from january 2017 he will join yale university as a professor of computer science he is currently working on the fields of open domain question answering multi document summarization and the application of nlp in bioinformatics and political science radev received his phd in computer science from columbia university in 1999 he is the secretary of http www aclweb org association for computational linguistics acl 2006 present and associate editor of http www jair org jair awards as naclo founder radev shared the linguistic society of america 2011 http www lsadc org info lsa awards cfm linguistics language and the public award he is the co winner of the http polmeth wustl edu about php page awards gosnell prize 2006 in 2015 he was named a fellow of the association for computing machinery for contributions to natural language processing and computational linguistics ref citation url http www acm org press room news releases 2015 fellows 2015 title acm fellows named for computing innovations that are advancing technology in the digital age publisher association for computing machinery year 2015 accessdate 2015 12 10 ref iol radev has served as the coach and led the us national team in the international linguistics olympiad international linguistics olympiad iol to several gold medals http www nsf gov news news summ jsp cntn id 112073 http www nsf gov news news summ jsp cntn id 109891 books puzzles in logic languages and computation 2013 ref cite web url http www springer com education 26 language linguistics book 978 3 642 34371 1 title puzzles in logic languages and computation date accessdate website publisher last first ref mihalcea and radev 2011 http www cambridge org gb knowledge isbn item5980387 site locale en gb graph based methods for nlp and ir selected papers sigir 1995 generating summaries of multiple news articles anlp 1997 building a generation knowledge source using internet accessible newswire computational linguistics 1998 generating natural language summaries from multiple on line sources acl 1998 learning correlations between linguistic indicators and semantic constraints reuse of context dependent descriptions of entities anlp 2000 ranking suspected answers to natural language questions using predictive annotation cikm 2001 mining the web for answers to natural language questions aaai 2002 towards cst enhanced summarization acl 2003 evaluation challenges in large scale multi document summarization the mead project information processing and management 2004 centroid based summarization of multiple documents j of artificial intelligence research 2004 lexrank graph based lexical centrality as salience in text summarization j of the american association of information science and technology 2005 probabilistic question answering on the web communications of the acm 2005 newsinessence summarizing online news topics emnlp 2007 semi supervised classification for extracting protein interaction sentences using dependency parsing bioinformatics 2008 identifying gene disease associations using centrality on a literature mined gene interaction network ieee intelligent systems 2008 natural language processing and the web naacl 2009 generating surveys of scientific paradigms nucleic acids research 2009 michigan molecular interactions r2 from interacting proteins to pathways j of the american association of information science and technology 2009 visual overviews for discovering key papers and influences across research fronts kdd 2010 divrank the interplay of prestige and diversity in information networks american j of political science 2010 how to analyze political attention with minimal assumptions and costs arxiv 2011 the effect of linguistic constraints on the large scale organization of language j of biomedical semantics 2011 mining of vaccine associated ifn gamma gene interaction networks using the vaccine ontology external links http www nsf gov news news summ jsp cntn id 112073 team usa brings home the linguistics gold http www eecs umich edu eecs about articles 2011 radev lsa11 html dragomir radev co founders recognized as naclo receives linguistics language and the public award http www eecs umich edu eecs about articles 2010 radev linguistics html dragomir radev coaches us linguistics team to multiple wins http www eecs umich edu eecs about articles 2009 radev acm dm html dragomir radev honored as acm distinguished scientist http www eecs umich edu eecs etc news shownews cgi 428 prof dragomir radev receives gosnell prize references reflist after listing your sources please cite them using inline citations and place them after the information they cite please see http en wikipedia org wiki wikipedia refb for instructions on how to add citations defaultsort radev dragomir r category year of birth missing living people category living people category columbia school of engineering and applied science alumni category american computer scientists category university of michigan faculty category natural language processing category information retrieval researchers category fellows of the association for computing machinery'
b'infobox scientist name karen sp\xc3\xa4rck jones image karen sp\xc3\xa4rck jpg caption karen sp\xc3\xa4rck jones in 2002 birth date birth date 1935 8 26 df y birth place huddersfield yorkshire death date death date and age 2007 4 4 1935 8 26 df y death place willingham cambridgeshire residence united kingdom nationality british field computer science work institution university of cambridge computer laboratory alma mater university of cambridge doctoral advisor richard braithwaite ref name odnb cite web title jones karen ida boalth sp\xc3\xa4rck 1935 2007 computer scientist url http www oxforddnb com view article 98729 work oxford dictionary of national biography publisher oxford university press accessdate 5 october 2014 ref thesis title synonymy and semantic classi\xef\xac\x81cation thesis year 1964 ref cite book author karen sp\xc3\xa4rck jones title synonymy and semantic classification thesis published as a book publisher edinburgh university press series edinburgh information technology series volume 1 year 1986 ref doctoral students known for work on information retrieval and natural language processing in particular her probabilistic model of document and text retrieval prizes acl lifetime achievement award bcs lovelace medal acm aaai allen newell award acm sigir salton award american society for information science and technology s award of merit religion spouse roger needham website url http www cl cam ac uk archive ksj21 karen sp\xc3\xa4rck jones fellow of the british academy fba 26 august 1935 4 april 2007 was a united kingdom british computer scientist ref cite journal last1 tait first1 j i title karen sp\xc3\xa4rck jones doi 10 1162 coli 2007 33 3 289 journal computational linguistics volume 33 issue 3 pages 289 291 year 2007 pmid pmc ref ref cite journal last1 robertson first1 s last2 tait first2 j doi 10 1002 asi 20784 title karen sp\xc3\xa4rck jones journal journal of the american society for information science and technology volume 59 issue 5 pages 852 year 2008 pmid pmc ref personal life karen ida boalth sp\xc3\xa4rck jones was born in huddersfield yorkshire england her father was owen jones a lecturer in chemistry and her mother was ida sp\xc3\xa4rck a norway norwegian who moved to britain during world war ii they left norway on one of the last boats out after the german invasion in 1940 ref name odnb sp\xc3\xa4rck jones was educated at a grammar school in huddersfield and then girton college cambridge from 1953 to 1956 reading history with an additional final year in moral sciences philosophy she briefly became a school teacher before moving into computer science during her career in computer science she campaigned hard for more women to enter computing ref name odnb she was married to fellow cambridge computer scientist roger needham until his death in 2003 she died 4 april 2007 at willingham cambridgeshire willingham in cambridgeshire career she worked at the cambridge language research unit from the late 1950s ref cite web url http www cl cam ac uk misc obituaries sparck jones title computer laboratory obituary ref then at university of cambridge cambridge s cambridge university computer laboratory computer laboratory from 1974 and retired in 2002 holding the post of professor of computers and information which she was awarded in 1999 ref name odnb she continued to work in the computer laboratory until shortly before her death her main research interests since the late 1950s were natural language processing and information retrieval ref name doi10 1108 eb026526 cite journal last1 sp\xc3\xa4rck jones first1 k authorlink1 karen sp\xc3\xa4rck jones doi 10 1108 eb026526 title a statistical interpretation of term specificity and its application in retrieval journal journal of documentation volume 28 pages 11 21 year 1972 url http www emeraldinsight com doi abs 10 1108 eb026526 pmid pmc ref ref cite journal editor1 last tait editor1 first john i title charting a new course natural language processing and information retrieval essays in honour of karen sp\xc3\xa4rck jones doi 10 1007 1 4020 3467 9 series the kluwer international series on information retrieval volume 16 year 2005 isbn 1 4020 3343 5 pmid pmc ref one of her most important contributions was the concept of inverse document frequency idf weighting in information retrieval which she introduced in a 1972 paper ref name doi10 1108 eb026526 ref name idf cite journal last1 sp\xc3\xa4rck jones first1 k authorlink1 karen sp\xc3\xa4rck jones title index term weighting doi 10 1016 0020 0271 73 90043 0 journal information storage and retrieval volume 9 issue 11 pages 619 633 year 1973 pmid pmc ref idf is used in most search engines today usually as part of the tf idf weighting scheme ref cite book last1 maybury first1 m t chapter karen sp\xc3\xa4rck jones and summarization doi 10 1007 1 4020 3467 9 7 title charting a new course natural language processing and information retrieval series the kluwer international series on information retrieval volume 16 pages 99 10 year 2005 isbn 1 4020 3343 5 pmid pmc ref there is an annual british computer society bcs lecture named in her honour ref cite web title karen sp\xc3\xa4rck jones lecture url http academy bcs org ksj work bcs academy of computing publisher british computer society accessdate 3 october 2013 ref honours fellow of the british academy of which she was vice president in 2000 02 fellow of aaai fellow of eccai president of the association for computational linguistics in 1994 awards gerard salton award 1988 asis t award of merit 2002 association for computational linguistics acl lifetime achievement award 2004 ref cite web title acl lifetime achievement award recipients url http aclweb org aclwiki index php title acl lifetime achievement award recipients website acl wiki publisher association for computational linguistics acl accessdate 16 august 2014 ref british computer society bcs lovelace medal 2007 acm aaai allen newell award 2006 karen sp\xc3\xa4rck jones award to commemorate her achievements the karen sp\xc3\xa4rck jones award was created in 2008 by the british computer society bcs and its information retrieval specialist group bcs irsg which is sponsored by microsoft research ref http irsg bcs org ksjaward php microsoft bcs bcs irsg karen sp\xc3\xa4rck jones award an award to commemorate karen sp\xc3\xa4rck jones ref the recipients are 2016 jaime teevan 2015 jordan boyd graber emine yilmaz 2014 ryen white 2013 eugene agichtein 2012 diane kelly computer scientist 2011 no award was made 2010 evgeniy gabrilovich 2009 mirella lapata references reflist further reading http spectrum ieee org may07 5063 computer science a woman s work ieee spectrum may 2007 external links http www cl cam ac uk misc obituaries sparck jones video video natural language and the information layer karen sp\xc3\xa4rck jones march 2007 http www cl cam ac uk misc obituaries sparck jones university of cambridge obituary http news independent co uk people obituaries article2441969 ece obituary the independent 12 april 2007 dead link date april 2014 http www telegraph co uk news main jhtml view details grid xml news 2007 04 12 db1201 xml obituary the daily telegraph 12 april 2007 dead link date april 2014 http www timesonline co uk tol comment obituaries article1968942 ece obituary the times 22 june 2007 subscription required s start s ach succession box before makoto nagao title acl lifetime achievement award after martin kay years 2004 s end authority control defaultsort sparck jones karen category 1935 births category 2007 deaths category alumni of girton college cambridge category british computer scientists category women computer scientists category fellows of the british academy category fellows of the association for the advancement of artificial intelligence category fellows of newnham college cambridge category fellows of wolfson college cambridge category members of the university of cambridge computer laboratory category people from huddersfield category deaths from cancer in england category information retrieval researchers category british women scientists category artificial intelligence researchers category 20th century women scientists'
b'file maarten de rijke clef 2011 cropped jpg thumb maarten de rijke 2011 maarten de rijke born 1 august 1961 is a netherlands dutch computer scientist his work initially focused on modal logic and knowledge representation but since the early years of the 21st century he has worked mainly in information retrieval his work is supported by grants from the nederlandse organisatie voor wetenschappelijk onderzoek nwo public private partnerships and the european commission under the sixth and seventh framework programmes biography maarten de rijke was born in vlissingen he studied philosophy msc 1989 and mathematics msc 1990 and wrote a phd thesis defended in 1993 on extended modal logics under the supervision of johan van benthem logician johan van benthem de rijke worked as a postdoc at the centrum wiskunde informatica before becoming a warwick research fellow at the university of warwick he joined the university of amsterdam in 1998 and was appointed professor of information processing and internet at the informatics institute of the university of amsterdam in 2004 ref name mdr11bio http staff science uva nl mdr bio bio of maarten de rijke at the university of amsterdam retrieved 16 march 2011 ref he leads the information and language processing group ref http ilps science uva nl information and language processing group ref at the university of amsterdam the intelligent systems lab amsterdam ref http isla science uva nl intelligent systems lab amsterdam within the informatics institute of the university of amsterdam ref and the center for creation content and technology ref http www ccct uva nl center for creation content and technology at the university of amsterdam ref work during the first ten years of his scientific career maarten de rijke worked on formal and applied aspects of modal logic at the start of the 21st century de rijke switched to information retrieval he has since worked on xml retrieval question answering expert finding and social media analysis publications maarten de rijke has published more than 600 papers and books ref name mdr11pubs http staff science uva nl mdr publications list of publications of maarten de rijke at the university of amsterdam retrieved 16 march 2011 ref references reflist http albumacademicum uva nl cgi b bib bib idx type simple lang en c ap rgn1 entirerecord q1 rijke x 0 y 0 cc ap view reslist sort achternaam fmt long page reslist size 1 start 14 prof dr m de rijke 1961 at the university of amsterdam album academicum website external links http staff science uva nl mdr home page defaultsort rijke maarten de category 1961 births category living people category dutch computer scientists category university of amsterdam alumni category university of amsterdam faculty category people from vlissingen category information retrieval researchers'
b'infobox scientist name gerard salton birth date birth date 1927 03 08 birth place nuremberg death date death date and age 1995 08 28 1927 03 08 death place fields information retrieval workplaces cornell university alma mater harvard university thesis title an automatic data processing system for public utility revenue accounting thesis url http hollis harvard edu itemid 7clibrary m aleph 7c003918090 thesis year 1958 doctoral advisor howard aiken doctoral students amit singhal known for the father of information retrieval ref name father ir br gerard salton award gerard a gerry salton 8 march 1927 in nuremberg 28 august 1995 was a professor of computer science at cornell university salton was perhaps the leading computer scientist working in the field of information retrieval during his time and the father of information retrieval ref name father ir cite web url http www cs cornell edu gries 40brochure pg24 25 pdf title the father of information retrieval last1 first1 last2 first2 date website cs cornell edu publisher quote a founding member of the department and the father of information retrieval access date 10 march 2015 ref his group at cornell developed the smart information retrieval system which he initiated when he was at harvard salton was born gerhard anton sahlmann on march 8 1927 in nuremberg germany he received a bachelor s 1950 and master s 1952 degree in mathematics from brooklyn college and a ph d from harvard university harvard in applied mathematics in 1958 the last of howard aiken s doctoral students and taught there until 1965 when he joined cornell university and co founded its department of computer science salton was perhaps most well known for developing the now widely used vector space model for information retrieval ref cite journal last1 salton first1 g authorlink1 gerard salton last2 wong first2 a last3 yang first3 c s doi 10 1145 361219 361220 title a vector space model for automatic indexing journal communications of the acm volume 18 issue 11 pages 613 year 1975 pmid pmc ref in this model both documents and queries are represented as vectors of term counts and the similarity between a document and a query is given by the cosine between the term vector and the document vector in this paper he also introduced tf idf or term frequency inverse document frequency a model in which the score of a term in a document is the ratio of the number of terms in that document divided by the frequency of the number of documents in which that term occurs the concept of inverse document frequency a measure of specificity had been introduced in 1972 by karen sp\xc3\xa4rck jones karen sparck jones ref cite journal last1 sp\xc3\xa4rck jones first1 k authorlink1 karen sp\xc3\xa4rck jones doi 10 1108 eb026526 title a statistical interpretation of term specificity and its application in retrieval journal journal of documentation volume 28 pages 11 21 year 1972 url http www emeraldinsight com doi abs 10 1108 eb026526 pmid pmc ref later in life he became interested in automatic text summarization and analysis ref cite journal last1 salton first1 g authorlink1 gerard salton last2 allan first2 j last3 buckley first3 c last4 singhal first4 a title automatic analysis theme generation and summarization of machine readable texts doi 10 1126 science 264 5164 1421 journal science volume 264 issue 5164 pages 1421 1426 year 1994 pmid 17838425 pmc ref as well as automatic hypertext generation ref cite web url http www cs cornell edu info department annual95 faculty salton html title gerard salton publisher cs cornell edu date accessdate 2013 09 14 ref he published over 150 research articles and 5 books during his life salton was editor in chief of the communications of the acm and the journal of the acm and chaired special interest group on information retrieval sigir he was an associate editor of the acm transactions on information systems he was an list of fellows of the association for computing machinery acm fellow elected 1995 ref name fellow acm cite web url http awards acm org award winners salton 2316166 cfm title gerard salton acm fellows 1995 last1 first1 last2 first2 date website acm org publisher quote contributions over 30 years to information organization and retrieval access date 10 march 2015 ref received an award of merit from the american society for information science 1989 and was the first recipient of the sigir award for outstanding contributions to study of information retrieval 1983 now called the gerard salton award bibliography salton automatic information organization and retrieval 1968 cite book author gerard salton title a theory of indexing publisher society for industrial and applied mathematics year 1975 page 56 and michael j mcgill introduction to modern information retrieval 1983 isbn 0 07 054484 0 cite book author gerard salton title automatic text processing publisher addison wesley publishing company year 1989 page 530 isbn 0 201 12227 8 http www informatik uni trier de ley db indices a tree s salton gerard html dblp bibliography g salton a wong and c s yang 1975 http www cs uiuc edu class fa05 cs511 spring05 other papers p613 salton pdf a vector space model for automatic indexing communications of the acm vol 18 nr 11 pages 613 620 article in which a vector space model was presented see also list of pioneers in computer science references reflist external links http www cs cornell edu info department annual96 beginning salton html in memoriam http blog tomevslin com 2006 01 search down mem html fractals of change search down memory lane http www ideals uiuc edu bitstream 2142 1697 2 dubin748764 pdf the most influential paper gerard salton never wrote this 2004 library trends paper by david dubin serves as a historical review of the metamorphosis of the term discrimination value model tdv into the vector space model as an information retrieval model vsm as an ir model this paper calls into question what the information retrieval research community believed salton s vector space model was originally intended to model what much later became an information retrieval model was originally a data centric mathematical computational model used as an explanatory device in addition dubin s paper points out that a 1975 salton paper oft cited does not exist but is probably a combination of two other papers neither of which actually refers to the vsm as an ir model authority control defaultsort salton gerard category 1927 births category 1995 deaths category american computer scientists category harvard university alumni category harvard university faculty category cornell university faculty category fellows of the association for computing machinery category guggenheim fellows category information retrieval researchers'
b'infobox scientist name cyril cleverdon image caption birth date birth date 1914 9 9 df y birth place bristol united kingdom uk death date death date and age 1997 12 4 1914 9 9 df y death place cranfield united kingdom uk residence united kingdom nationality british field computer science work institution cranfield institute of technology known for work on the evaluation of information retrieval systems prizes professional award of the special libraries association 1962 award of merit of the american society for information science 1971 the gerard salton award of the special interest group on information retrieval of the association for computing machinery 1991 cyril cleverdon 9 september 1914 4 december 1997 was a united kingdom british librarian and computer scientist who is best known for his work on the evaluation of information retrieval systems cyril cleverdon was born in bristol england he worked at the bristol libraries from 1932 to 1938 and from 1938 to 1946 he was the librarian of the engine division of the bristol aeroplane co ltd in 1946 he was appointed librarian of the college of aeronautics at cranfield later the cranfield institute of technology and cranfield university where he served until his retirement in 1979 the last two years as professor of information transfer studies with the help of nsf funding cleverdon started a series of projects in 1957 that lasted for about 10 years in which he and his colleagues set the stage for information retrieval research in the cranfield project retrieval experiments were conducted on test databases in a controlled laboratory like setting the aim of the research was to improve the retrieval effectiveness of information retrieval systems by developing better indexing languages and methods the components of the experiments were a collection of documents a set of user requests or queries and a set of relevance judgments that is a set of documents judged to be relevance information retrieval relevant to each query together these components form an information retrieval test collection the test collection serves as a standard for testing retrieval approaches and the success of each approach is measured in terms of two measures precision information retrieval precision and recall information retrieval recall test collections and evaluation measures based on precision and recall are driving forces behind modern research on search systems cleverdon s approach formed a blueprint for the successful text retrieval conference series that began in 1992 not only did cleverdon s cranfield studies introduce experimental research into computer science the outcomes of the project also established the basis of the automatic indexing as done in today s search engine s essentially cleverdon found that the use of single terms from the documents achieved the best retrieval performance as opposed to manually assigned thesaurus terms synonyms etc these results were very controversial at the time in the cranfield 2 report cleverdon said this conclusion is so controversial and so unexpected that it is bound to throw considerable doubt on the methods which have been used a complete recheck has failed to reveal any discrepancies there is no other course except to attempt to explain the results which seem to offend against every canon on which we were trained as librarians cyril cleverdon also ran for many years the cranfield conferences which provided a major international forum for discussion of ideas and research in information retrieval this function was taken over by the special interest group on information retrieval sigir conferences in the 1970s references cite journal author cyril cleverdon title report on the testing and analysis of an investigation into the comparative efficiency of indexing systems publisher the college of aeronautics cranfield year 1960 url http www sigir org museum pdfs report on the testing and analysis of an investigation into the comparative efficiency of indexing systems pdfs frontmatter pdf cyril cleverdon and michael keen factors determining the performance of indexing systems volume 2 the college of aeronautics cranfield 1966 stephen robertson in memoriam cyril w cleverdon journal of the american society for information science 49 10 866 1998 defaultsort cleverdon cyril category 1914 births category 1997 deaths category british computer scientists category english librarians category people associated with cranfield university category people from bristol category information retrieval researchers'
b'more footnotes date september 2012 infobox scientist name stephen robertson image image size 100px residence united kingdom nationality british field computer science alma mater cambridge city university university college london doctoral advisor b c bertie brookes doctoral students ayse g\xc3\xb6ker andrew macfarlane xiangji jimmy huang olga vechtomova murat karamuftuoglu micheline beaulieu efthimis efthimiadis anna ritchie jagadeesh gorla known for work on information retrieval and inverse document frequency prizes gerard salton award 2000 tony kent strix award 1998 acm fellow 2013 website url http staff city ac uk sb317 stephen robertson is a united kingdom british computer scientist he is known for his work on information retrieval ref cite journal doi 10 1002 asi 4630270302 title relevance weighting of search terms journal journal of the american society for information science volume 27 issue 3 pages 129 year 1976 last1 robertson first1 s e authorlink1 stephen robertson computer scientist last2 sp\xc3\xa4rck jones first2 k authorlink2 karen sp\xc3\xa4rck jones ref and the okapi bm25 weighting model ref cite journal doi 10 1016 s0306 4573 00 00015 7 title a probabilistic model of information retrieval development and comparative experiments part 1 journal information processing management volume 36 issue 6 pages 779 808 year 2000 last1 sp\xc3\xa4rck jones first1 k authorlink1 karen sp\xc3\xa4rck jones last2 walker first2 s last3 robertson first3 s e authorlink3 stephen robertson computer scientist ref ref cite journal doi 10 1016 s0306 4573 00 00016 9 title a probabilistic model of information retrieval development and comparative experiments part 2 journal information processing management volume 36 issue 6 pages 809 840 year 2000 last1 sp\xc3\xa4rck jones first1 k authorlink1 karen sp\xc3\xa4rck jones last2 walker first2 s last3 robertson first3 s e authorlink3 stephen robertson computer scientist ref after completing his undergraduate degree in mathematics at cambridge university cambridge university he took an ms at city university london city university and then worked for aslib he then studied for his phd at university college london under the renowned statistician and scholar b c brookes he then returned to city university working there from 1978 until 1998 in the department of information science continuing as a part time professor and subsequently as professor emeritus he is also a fellow of girton college cambridge girton college cambridge university from 1998 to 2013 he worked in the cambridge laboratory of microsoft research where he led a group investigating core search processes such as term weighting document scoring and ranking algorithms combining evidence from different sources and metrics and methods for the evaluation and optimisation of search much of his work has contributed to the microsoft web search engine search engine bing search engine bing he participated a number of times in the text retrieval conference trec conference references reflist external links cite book last1 robertson first1 stephen last2 zaragoza first2 hugo title the probabilistic relevance framework bm25 and beyond date 2009 publisher now publishers inc isbn 978 1 60198 308 4 url http staff city ac uk sb317 papers foundations bm25 review pdf defaultsort robertson stephen category british computer scientists category alumni of university college london category fellows of girton college cambridge category living people category alumni of city university of london category academics of city university of london category information retrieval researchers'
b'w bruce croft is a distinguished professor of computer science at the university of massachusetts amherst whose work focuses on information retrieval ref cite web last croft first w bruce title biography url http ciir cs umass edu personnel croftbio pdf accessdate november 4 2009 ref he is the founder of the center for intelligent information retrieval and served as the editor in chief of acm transactions on information systems from 1995 to 2002 he was also a member of the united states national research council national research council http sites nationalacademies org cstb index htm computer science and telecommunications board from 2000 to 2003 since 2015 he is the dean of the college of information and computer sciences at the university of massachusetts amherst he was chair of the umass amherst computer science department from 2001 to 2007 bruce croft formed the center for intelligent information retrieval ciir in 1991 since when he and his students have worked with more than 90 industry and government partners on research and technology projects and have produced more than 900 papers bruce croft has made major contributions to most areas of information retrieval including pioneering work in clustering passage retrieval sentence retrieval and distributed search one of the most important areas of work for croft relates to ranking functions and retrieval models where he has led the development of one of the major approaches to modeling search language modelling in later years croft also led the way in the development of feature based ranking functions croft and his research group have also developed a series of search engines inquery the lemur toolkit indri and galago these search engines are open source and offer unique capabilities that are not replicated in other research retrieval platforms source consequently they are downloaded by hundreds of researchers world wide as a consequence of his work croft is one of the most cited researchers in information retrieval education croft earned a bachelor s degree with honors in 1973 and a master s degree in computer science in 1974 from monash university in melbourne melbourne australia he earned his ph d in computer science from the university of cambridge in 1979 and joined the university of massachusetts amherst university of massachusetts amherst faculty later that year honors and awards croft has received several prestigious awards including acm fellow in 1997 american society for information science and technology research award in 2000 gerard salton award a lifetime achievement award from acm sigir in 2003 tony kent strix award tony kent strix award in 2013 ieee computer society technical achievement award in 2014 http sigir org awards best student paper awards best student paper award from sigir in 1997 and 2005 http sigir org awards test of time awards test of time award from sigir for his papers published in 1990 1995 1996 1998 2001 many other publications are short listed as the best paper award in sigir and cikm references references external links http ciir cs umass edu personnel croft html faculty homepage defaultsort croft w bruce category american computer scientists category fellows of the association for computing machinery category university of massachusetts amherst faculty category year of birth missing living people category living people category information retrieval researchers compu bio stub'
b'use dmy dates date march 2014 use british english date march 2014 multiple issues blp sources date january 2012 more footnotes date january 2012 infobox scientist name cornelis joost van rijsbergen image c j van rijsbergen jpg image size caption c j keith van rijsbergen birth date birth year and age 1943 birth place rotterdam residence citizenship nationality fields information retrieval workplaces monash university university of glasgow alma mater university of western australia university of cambridge doctoral advisor academic advisors doctoral students notable students known for author abbrev bot author abbrev zoo influences influenced awards signature filename only footnotes c j keith van rijsbergen freng ref name fellow cite web title list of fellows url http www raeng org uk about us people council committees the fellowship list of fellows ref cornelis joost van rijsbergen born 1943 is a professor of computer science and the leader of the glasgow information retrieval group based at the university of glasgow he is one of the founders of modern information retrieval and the author of the seminal monograph information retrieval and of the textbook the geometry of information retrieval he was born in rotterdam and educated in the netherlands indonesia namibia and australia his first degree is in mathematics from the university of western australia and in 1972 he completed a phd in computer science at the university of cambridge he spent three years lecturing in information retrieval and artificial intelligence at monash university before returning to university of cambridge cambridge to hold a royal society information research fellowship in 1980 he was appointed to the chair of computer science at university college dublin from there he moved in 1986 to glasgow university since 2007 he has been chairman of the scientific board of the information retrieval facility awards and honors in 2003 he was inducted as a fellow of the association for computing machinery in 2004 he was awarded the tony kent strix award in 2004 he was appointed a fellow ref name fellow of the royal academy of engineering ref name fellow in 2006 he was awarded the gerard salton award for quantum haystacks see also f1 score references reflist external links http www dcs gla ac uk keith c j keith van rijsbergen the university of glasgow http ir dcs gla ac uk glasgow information retrieval group http www dcs gla ac uk keith preface html information retrieval book c j van rijsbergen 1979 http www ir facility org information retrieval facility worldcat id id lccn n83 236586 http www alanmacfarlane com ancestors rijsbergen htm keith van rijsbergen interviewed by alan macfarlane 15 july 2009 film authority control defaultsort rijsbergen c j van category 1943 births category living people category dutch computer scientists category fellows of the association for computing machinery category people from rotterdam category university of western australia alumni category information retrieval researchers netherlands scientist stub compu scientist stub'
b'infobox scientist name susan t dumais image susan dumais jpg image size 200px caption susan dumais in 2009 in her office at microsoft research birth date birth place maine united states us death date death place nationality american fields computer science workplaces microsoft research alma mater indiana university br bates college doctoral advisor doctoral students known for human computer interaction br information retrieval website url http research microsoft com sdumais awards acm w athena lecturer award 2014 susan dumais is an american computer scientist who is a leader in the field of information retrieval and has been a significant contributor to microsoft s search technologies ref cite news title 100 top women in seattle tech url http www bizjournals com seattle blog techflash 2009 05 top 100 women in seattle tech 44225472 html accessdate 23 february 2016 newspaper puget sound business journal date 8 may 2009 ref according to mary jane irwin who heads the athena lecture awards committee her sustained contributions have shaped the thinking and direction of human computer interaction and information retrieval ref cite news last burns first jay title microsoft s susan dumais 75 is a big reason why computer wise you find what you seek url https www bates edu news 2014 05 01 microsoft susan dumais 75 accessdate 23 february 2016 newspaper bates news date 28 october 2015 ref biography susan dumais is a distinguished scientist at microsoft and deputy managing director of the microsoft research lab in redmond she is also an affiliate professor at the university of washington information school before joining microsoft in 1997 dumais was a researcher at bellcore now telcordia technologies where she and her colleagues conducted research into what is now called the vocabulary problem in information retrieval ref cite journal title the vocabulary problem in human system communication journal communications of the acm author george furnas g w furnas thomas landauer t k landauer l m gomez s t dumais volume 30 pages 964 971 year 1987 url http citeseer ist psu edu furnas87vocabulary html doi 10 1145 32206 32212 issue 11 ref their study demonstrated through a variety of experiments that different people use different vocabulary to describe the same thing and that even choosing the best term to describe something is not enough for others to find it one implication of this work is that because the author of a document may use different vocabulary than someone searching for the document traditional information retrieval methods will have limited success dumais and the other bellcore researchers then began investigating ways to build search systems that avoided the vocabulary problem the result was their invention of latent semantic indexing ref cite journal url http lsi research telcordia com lsi papers jasis90 pdf title indexing by latent semantic analysis author scott deerwester s deerwester susan dumais george furnas g w furnas thomas landauer t k landauer richard harshman r harshman journal journal of the american society for information science volume 41 issue 6 pages 391 407 year 1990 doi 10 1002 sici 1097 4571 199009 41 6 391 aid asi1 3 0 co 2 9 ref awards in 2006 dumais was inducted as a fellow of the association for computing machinery in 2009 she received the gerard salton award an information retrieval lifetime achievement award in 2011 she was inducted to the national academy of engineering for innovation and leadership in organizing accessing and interacting with information in 2014 dumais received the athena lecturer award for fundamental contributions to computer science ref cite news last knies first rob title dumais receives athena lecturer award url http blogs technet com b inside microsoft research archive 2014 04 08 dumais receives athena lecturer award aspx accessdate 28 april 2014 newspaper inside microsoft research date april 2014 ref and the tony strix award for sustained contributions that are both innovative and practical with significant impact ref cite web title the winner of the 2014 tony kent strix award is dr susan dumais url http www ukeig org uk awards tony kent strix accessdate 17 september 2014 ref in 2015 she was inducted into the american academy of arts and sciences ref cite news last tice first lindsay title lewiston native inducted into american academy of arts and sciences url http www sunjournal com news lewiston auburn 0001 11 30 lewiston native inducted american academy arts and sciences 1808943 accessdate 23 february 2016 newspaper lewinston auburn sun journal date 28 october 2015 ref references reflist external links http research microsoft com sdumais home page at microsoft research defaultsort dumais susan category people in information technology category fellows of the association for computing machinery category microsoft employees category living people category women computer scientists category university of washington faculty category information retrieval researchers'
b'norbert fuhr born 1956 is a professor of computer science and the leader of the duisburg information engineering group based at the university of duisburg essen germany education his first degree is in technical computer science which he got from the electrical engineering department of the technical university of darmstadt in 1980 and in 1986 he finished his phd dr ing in the computer science department of the same university on probabilistic indexing and retrieval ref name fuhr1986 citation author fuhr norbert publisher fachinformationszentrum karlsruhe title probabilistisches indexing und retrieval year 1986 ref profession he held a postdoc position in darmstadt until 1991 when he was appointed associate professor in the computer science department of the technical university of dortmund since 2002 he is a full professor at the university of duisburg essen honors and awards fuhr s dissertation was awarded the gerhard pietsch award of the german society of documentation in 1987 in 2012 he received the gerard salton award ref name fuhr2012 citation author fuhr norbert journal sigir 12 proceedings of the 35th international acm sigir conference on research and development in information retrieval title salton award lecture information retrieval as engineering science pages 1 2 year 2012 doi 10 1145 2348283 2348285 ref references reflist external links http www is inf uni due de staff fuhr html norbert fuhr university of duisburg essen authority control defaultsort fuhr norbert category german computer scientists category 1956 births category living people category university of duisburg essen faculty category technical university of dortmund faculty category technische universit\xc3\xa4t darmstadt alumni category information retrieval researchers compu bio stub'
b'infobox scientist name jaime teevan image caption birth date birth year and age 1976 birth place death date death place nationality residence fields computer science br human computer interaction br information retrieval work institution microsoft research alma mater massachusetts institute of technology br yale university known for doctoral advisor david karger awards tr35 2009 br borg early career award 2014 br karen sp\xc3\xa4rck jones award 2016 website url http teevan org jaime teevan is an american computer scientist known for her research in human computer interaction and information retrieval she is particularly known for the work she has done on personalized search according to the technology review teevan is a leader in using data about people s knowledge preferences and habits to help them manage information ref name tr35 cite news last kleiner first kurt title tr35 jaime teevan 32 url http www technologyreview com tr35 profile aspx cand t trid 778 accessdate 10 march 2011 newspaper technology review date august 2009 ref biography teevan received and a bachelor of science b s in computer science from yale university and a ph d and s m from mit ref http www csail mit edu teevan work publications theses phd thesis pdf ref ref http www csail mit edu teevan work publications theses masters thesis pdf ref she is currently a researcher at microsoft research and an affiliate professor at the university of washington there she co authored the first book on collaborative information seeking ref cite book last morris first meredith ringel and teevan jaime title collaborative search who what where when why and how year 2010 publisher morgan and claypool publishers isbn 1 60845 121 6 url http www amazon com dp 1608451216 ref she also edited a book on personal information management pim ref cite book editor jones william editor2 teevan jaime title personal information management year 2007 publisher university of washington press isbn 0 295 98737 5 url http www amazon com dp 0295987375 ref edited a special issue of communications of the acm on the topic and organized workshops on pim software pim and query log analysis she has published numerous technical papers including several best papers and was chair of the web search and data mining wsdm 2012 conference awards teevan was named a technology review tr35 2009 young innovator for her research on personalized search ref name tr35 and received the cra w borg early career award beca in 2014 ref name borg cite news last knies first rob title researcher teevan wins borg early career award url http blogs technet com b inside microsoft research archive 2014 04 22 researcher teevan wins borg early career award aspx accessdate 28 april 2014 newspaper inside microsoft research date april 2014 ref in 2016 she received the karen sp\xc3\xa4rck jones award from the british computer society for her technically strong and exceptionally creative contributions to the intersection of information retrieval user experience and social media ref http irsg bcs org ksjaward php ref personal teevan is married to alexander hehmeyer ref cite news title weddings jaime teevan alexander hehmeyer url http www nytimes com 2002 06 16 style weddings jaime teevan alexander hehmeyer html accessdate 14 september 2015 newspaper new york times date june 16 2002 ref the couple live in bellevue washington and have four children ref cite news last vanderkam first laura title women with big jobs and big families balancing really isn t that hard url http fortune com 2015 06 06 women with big jobs and big families balancing really isnt that hard accessdate 14 september 2015 newspaper fortune date 6 june 2015 ref teevan is an advocate for helping researchers successfully integrate parenthood and academic efforts ref name borg references references external links http teevan org professional home page defaultsort teevan jaime category people in information technology category information retrieval researchers category human computer interaction researchers category women computer scientists category microsoft employees category living people category yale university alumni category massachusetts institute of technology alumni category university of washington faculty category 1976 births'
b'infobox programming language name km paradigm knowledge representation generation year designer developer latest release version latest release date turing complete typing implementations dialects influenced by krl programming language krl influenced km the knowledge machine is a knowledge frame frame based language used for knowledge representation work it has first order logic semantics and includes machinery for reasoning including selection by description unification classification and reasoning about actions its origins were the theo language and krl programming language krl and is implemented in lisp programming language lisp external links http www cs utexas edu users mfkb rkf km html km the knowledge machine an ontology editor for the km language http www algo be ref projects htm kmgen kmgen category declarative programming languages category knowledge representation category common lisp software compu lang stub'
b'the cutter expansive classification system is a library classification system devised by charles ammi cutter the system was the basis for the top categories of the library of congress classification ref lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 p 226 ref history of the expansive classification charles ammi cutter 1837 ndash 1903 inspired by the decimal classification of his contemporary melvil dewey and with dewey s initial encouragement developed his own classification scheme for the winchester town library and then the boston athenaeum ref lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 p 208 ref at which he served as librarian for twenty four years he began work on it around the year 1880 publishing an overview of the new system in 1882 the same classification would later be used but with a different notation also devised by cutter at the cary memorial library cary library in lexington massachusetts ref cutter c a https books google com books id l10oaaaayaaj pg pa1 expansive classification part i the first six classifications boston c a cutter 1891 93 p 1 ref many libraries found this system too detailed and complex for their needs and cutter received many requests from librarians at small libraries who wanted the classification adapted for their collections he devised the expansive classification in response to meet the needs of growing libraries and to address some of the complaints of his critics ref for the expansive classification as a response to cutter s critics see miksa francis l ed charles ammi cutter library systematizer littleton co libraries unlimited 1977 p 58 for the expansive classification as a response to the growing needs of libraries see miksa above and also lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 p 209 the above issues are also discussed by cutter in his https books google com books id l10oaaaayaaj pg pa1 expansive classification part i the first six classifications boston c a cutter 1891 93 ref cutter completed and published an introduction and schedules for the first six classifications of his new system https books google com books id l10oaaaayaaj pg pa1 expansive classification part i the first six classifications but his work on the seventh was interrupted by his death in 1903 ref lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 p 210 ref the cutter expansive classification although adopted by comparatively few libraries mostly in new england citation needed date august 2011 has been called one of the most logical and scholarly of american classifications citation needed date august 2011 library historian leo e lamontagne writes blockquote cutter produced the best classification of the nineteenth century while his system was less scientific than that of j p lesley its other key features notation specificity and versatility make it deserving of the praise it has received ref lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 p 215 ref blockquote its top level divisions served as a basis for the library of congress classification which also took over some of its features ref lamontagne leo e american library classification with special reference to the library of congress hamden connecticut shoe string press 1961 p 226 ref it did not catch on as did dewey s system because cutter died before it was completely finished making no provision for the kind of development necessary as the bounds of knowledge expanded and scholarly emphases changed throughout the twentieth century ref https journals ala org index php lrts article view 5419 6654 ref structure of the expansive classification the expansive classification uses seven separate schedules each designed to be used by libraries of different sizes after the first each schedule was an expansion of the previous one ref miksa francis l ed charles ammi cutter library systematizer littleton co libraries unlimited 1977 p 58 ref and cutter provided instructions for how a library might change from one expansion to another as it grows ref cutter c a https books google com books id l10oaaaayaaj pg pa1 expansive classification part i the first six classifications boston c a cutter 1891 93 p 21 23 ref summary of the expansive classification schedules first classification the first classification is meant for only the very smallest libraries the first classification has only seven top level classes and only eight classes in all a works of reference and general works which include several of the following sections and so could not go in any one b outline of philosophy philosophy and outline of religion religion e biography f outline of history history and outline of geography geography and travels h outline of social science social sciences l outline of natural science natural sciences and the arts arts y outline of linguistics language and outline of literature literature yf outline of fiction fiction further classifications further expansions add more top level classes and subdivisions many subclasses arranged systematically with common divisions such as those by geography and language following a consistent system throughout ref https archive org details cu31924092476229 ref by the fifth classification all the letters of the alphabet are in use for top level classes these are a general works b outline of philosophy philosophy c outline of christianity christianity and outline of judaism judaism d ecclesiastical history e biography f outline of history history universal history g outline of geography geography and travels h outline of social science social sciences i demotics outline of sociology sociology j civics government outline of political science political science k legislation l outline of science science and the arts arts together m natural history n outline of botany botany o outline of zoology zo\xc3\xb6logy p outline of anthropology anthropology and ethnology q outline of medicine medicine r useful arts outline of technology technology s constructive arts outline of engineering engineering and outline of construction building t outline of manufacturing manufactures and handicrafts u outline of military science and technology art of war v recreative arts outline of sports sports outline of games games outline of festivals festivals w outline of the visual arts art x english language y english and american literature z book arts these schedules were not meant to be fixed but were to be adapted to meet the needs of each library for example books on the english language may be put in x and books on language in general in a subclass of x or this can be reversed the first option is less logical but results in shorter marks for most english language libraries ref cutter c a https books google com books id l10oaaaayaaj pg pa1 expansive classification part i the first six classifications boston c a cutter 1891 93 p 27 ref how expansive classification call numbers are constructed expand section citations and corrections date august 2011 most call numbers in the expansive classification follow conventions offering clues to the book s subject the first line represents the subject the second the author and perhaps title the third and fourth dates of editions indications of translations and critical works on particular books or authors all numbers in the expansive classification are or should be shelved as if in decimal order size of volumes is indicated by points pluses or slashes or for some subjects a numerical geographical subdivision follows the classification letters on the first line the number 83 stands for the united states mdash hence f83 is u s history g83 u s travel ju83 u s politics wp83 u s painting geographical numbers are often further expanded decimally to represent more specific areas sometimes followed by a capital letter indicating a particular city the second line usually represents the author s name by a capital letter plus one or more numbers arranged decimally this may be followed by the first letter or letters of the title in lower case and or sometimes the letters a b c indicating other printings of the same title when appropriate the second line may begin with a form number mdash e g 1 stands for history and criticism of a subject 2 for a bibliography 5 for a dictionary 6 for an atlas or maps 7 for a periodical 8 for a society or university publication 9 for a collection of works by different authors on the third line a capital y indicates a work about the author or book represented by the first two lines and a capital e for english mdash other letters are used for other languages indicates a translation into english if both criticism and translation apply to a single title the number expands into four lines cutter numbers cutter codes expand section examples and additional citations date august 2011 one of the features adopted by other systems including library of congress is the cutter number it is an alphanumeric device to code text so that it can be arranged in alphabetical order using the fewest characters it contains one or two initial letters and arabic numbers treated as a decimal to construct a cutter number a cataloguer consults a cutter table as required by the classification rules although cutter numbers are mostly used for coding the names of authors the system can be used for titles subjects geographic areas and more class wikitable cutter table 2 3 4 5 6 7 8 9 s a ch e h i m p t u w z qu a e i o r t y other consonants a e i o r u y vowels b d l m n p r s t u y additional letters a d e h i l m o p s t v w z initial letters qa qt are assigned q2 q29 while entries beginning with numerals have a cutter number a12 a19 therefore sorting before the first a entry ref cite web title lc cutter tables url http staff library mun ca staff toolbox tables lccutter htm website queen elizabeth ii libraries publisher memorial university of newfoundland accessdate 14 august 2014 deadurl bot unknown archiveurl https web archive org web 20140814173419 http staff library mun ca staff toolbox tables lccutter htm archivedate 14 august 2014 df ref so to make the three digit cutter number for cutter you would start with c then looking under other consonants find that u gives the number 8 and under additional letters t is 8 giving a cutter number of c88 notes reflist references bliss henry evelyn the organization of knowledge in libraries and the subject approach to books 2nd ed new york h w wilson 1939 cutter charles a rules for a dictionary catalog w p cutter ed 4th ed washington d c government printing office 1904 london the library association 1962 cutter william parker charles ammi cutter chicago american library association 1931 ann arbor mi university microfilms 1969 foster william e charles ammi cutter a memorial sketch library journal 28 1903 697 704 hufford jon r the pragmatic basis of catalog codes has the user been ignored cataloging and classification quarterly 14 1991 27 38 immroth john philip cutter charles ammi encyclopedia of library and information science allen kent and harold lancour ed 47 vols new york m dekker 1968 lamontagne leo e american library classification with special reference to the library of congress hamden ct shoe string press 1961 slavis dobrica cutt x an expert system for automatic assignment of cutter numbers cataloging and classification quarterly vol 22 no 2 1996 tauber maurice f and edith wise classification systems ralph r shaw librarian ralph r shaw ed the state of the library art new brunswick nj rutgers u graduate school of library service 1961 1 528 external links http catalog bostonathenaeum org cutterguide html the boston athenaeum s guide to the classification system developed by cutter for their collection http www forbeslibrary org research index php n main cutterclassification forbes library s outline of cutter s expansive classification system http www forbeslibrary org pathfinders shelvingrules pdf a brief guide to the expansive classification from forbes library http digital library unt edu permalink meta dc 1048 1 rules for a dictionary catalog by charles a cutter fourth edition hosted by the http digital library unt edu unt libraries digital collections http www loc gov aba pcc 053 table html library of congress guidelines for using the lc online shelflist and formulating a literary author number cutter table http www oclc org dewey support program default htm dewey cutter program library classification systems category library cataloging and classification category knowledge representation'
b'meta content framework mcf is a specification of a content format for structuring metadata about web site s and other data history mcf was developed by ramanathan v guha at apple advanced technology group apple computer s advanced technology group between 1995 and 1997 rooted in knowledge representation and reasoning knowledge representation systems such as cycl krl programming language krl and knowledge interchange format kif it sought to describe objects their attributes and the relationships between them ref name hammersley cite book publisher o reilly isbn 978 0 596 00383 8 last hammersley first ben title content syndication with rss location sebastopol date 2003 page 2 ref one application of mcf was hotsauce also developed by guha while at apple it generated a 3d computer graphics 3d visualization graphic visualization of a web site s table of contents based on mcf descriptions by late 1996 a few hundred sites were creating mcf files and apple hotsauce allowed users to browse these mcf representations in 3d ref name hammersley when the research project was discontinued guha left apple for netscape communications corporation netscape where in collaboration with tim bray he adapted mcf to use xml ref cite conference publisher w3c last guha first r v author2 tim bray title meta content framework using xml accessdate 2014 09 14 date 1997 06 06 url http www w3 org tr note mcf xml ref ref cite web last1 guha first1 r v last2 bray first2 tim title meta content framework using xml work netscape accessdate 2015 12 12 date 1997 06 13 url http developer netscape com mcf html deadurl yes archiveurl https web archive org web 19970615144715 http developer netscape com mcf html archivedate june 15 1997 ref and created the first version of the resource description framework rdf ref cite web last andreessen first marc title innovators of the net r v guha and rdf work netscape accessdate 2014 09 14 date 1999 01 08 url http wp netscape com columns techvision innovators rg html deadurl yes archiveurl https web archive org web 20080205163659 http wp netscape com columns techvision innovators rg html archivedate february 5 2008 ref references reflist external links http www textuality com mcf mcf tutorial html mcf tutorial using xml syntax http www guha com mcf guha mcf site http downlode org etext mcf towards a theory of metacontent html the metacontent concept category knowledge representation category apple inc software compu ai stub'
b'colon classification cc is a system of library classification developed by s r ranganathan it was the first ever faceted classification faceted or analytico synthetic taxonomic classification classification the first edition was published in 1933 since then six more editions have been published it is especially used in library libraries in india its name colon classification comes from the use of colon punctuation colons to separate facets in class numbers however many other classification schemes some of which are completely unrelated also use colons and other punctuation in various functions they should not be confused with colon classification in cc facets describe personality the most specific subject matter energy space and time pmest these facets are generally associated with every item in a library and so form a reasonably universal sorting system ref gopinath m a colon classification its theory and practice library herald 26 1 2 1987 1 3 ref as an example the subject research in the cure of tuberculosis of lungs by x ray conducted in india in 1950 would be categorized as medicine lungs tuberculosis treatment x ray research india 1950 this is summarized in a specific call number l 45 421 6 253 f 44 n5 organization the colon classification uses 42 main classes that are combined with other letters numbers and marks in a manner resembling the library of congress classification to sort a publication facets cc uses five primary categories or facets to further specify the sorting of a publication collectively they are called pmest nowiki nowiki personality the most specific or focal subject nowiki nowiki matter or property the substance properties or materials of the subject nowiki nowiki energy including the processes operations and activities nowiki nowiki space which relates to the geographic location of the subject nowiki nowiki time which refers to the dates or seasons of the subject classes the following are the main classes of cc with some subclasses the main method used to sort the subclass using the pmest scheme and examples showing application of pmest z generalia 1 universe of knowledge 2 library science 3 book science 4 journalism b mathematics b2 algebra c physics d engineering e chemistry f technology g biology h geology hx mining i botany j agriculture j1 horticulture j2 feed j3 food j4 stimulant j5 oil j6 drug j7 fabric j8 dye k zoology kz animal husbandry l medicine lz3 pharmacology lz5 pharmacopoeia m useful arts m7 textiles material work \xce\xb4 spiritual experience and mysticism religion entity problem n fine arts nd sculpture nn engraving nq painting nr music o literature p linguistics q religion r philosophy s psychology t education u geography v history w political science x economics y sociology yz social work z law example a common example of the colon classification is research in the cure of the tuberculosis of lungs by x ray conducted in india in 1950s main classification is medicine medicine within medicine the lungs are the main concern medicine lungs the property of the lungs is that they are afflicted with tuberculosis medicine lungs tuberculosis the tuberculosis is being performed on that is the intent is to cure treatment medicine lungs tuberculosis treatment the matter that we are treating the tuberculosis with are x rays medicine lungs tuberculosis treatment x ray and this discussion of treatment is regarding the research phase medicine lungs tuberculosis treatment x ray research this research is performed within a geographical space namely india medicine lungs tuberculosis treatment x ray research india during the time of 1950 medicine lungs tuberculosis treatment x ray research india 1950 and translating into the codes listed for each subject and facet the classification becomes l 45 421 6 253 f 44 n5 see also bliss bibliographic classification subject documents universal decimal classification references reflist 2 http www essessreference com servlet esgetbiblio bno 000374 colon classification 6th edition by dr s r ranganathan published by ess ess publications delhi india chan lois mai cataloging and classification an introduction 2nd ed new york mcgraw hill c1994 isbn 0 07 010506 5 external links http www iskoi org doc colon htm more detail about the colon classification at isko italia library classification systems category classification systems category knowledge representation category library cataloging and classification'
b'the suggested upper merged ontology or sumo is an upper ontology information science upper ontology intended as a foundation ontology computer science ontology for a variety of computer information processing systems it was originally developed by the teknowledge corporation and now is maintained by http www articulatesoftware com articulate software sumo is open source sumo originally concerned itself with meta level concepts general entities that do not belong to a specific problem domain and thereby would lead naturally to a categorization scheme for encyclopedias it has now been considerably expanded to include a mid level ontology and dozens of domain ontologies sumo was first released in december 2000 it defines a hierarchy of sumo classes and related rules and relationships these are formulated in a version of the language suo kif which has a lisp like syntax a map mathematics mapping from wordnet synsets to sumo has also been defined sumo is organized for interoperability of automated reasoning engine s to maximize compatibility logical schema schema designers can try to assure that their naming convention s use the same meanings as sumo for identical words for example agent or process sumo has an associated open source sigma knowledge engineering environment see also semantic translation upper ontology external links http www ontologyportal org main page for sumo http suo ieee org home page of the ieee standard upper ontology working group the http sigmakee sourceforge net sigma reasoning system for sumo http 54 183 42 206 8080 sigma browse jsp kb sumo online browser for sumo http www adampease org professional adam pease current technical editor of the standard category java platform software category knowledge representation category ontology information science category open data category knowledge bases compu ai stub'
b'logic forms are simple first order logic knowledge representation s of natural language sentences formed by the conjunction of concept predicates related through shared arguments each noun verb adjective adverb pronoun preposition and conjunction generates a predicate logic forms can be decorated with word sense s to word sense disambiguation disambiguate the semantics of the word there are two types of predicates events are marked with e and entities are marked with x the shared arguments connect the subjects and objects of verbs and prepositions together example input output might look like this input the earth provides the food we eat every day output earth n 1 span style color 008800 x1 span provide v 2 span style color 888800 e1 span span style color 008800 x1 span span style color 880000 x2 span food n 1 span style color 880000 x2 span we span style color 000088 x3 span eat v 1 span style color 880088 e2 span span style color 000088 x3 span span style color 880000 x2 span span style color 008888 x4 span day n 1 span style color 008888 x4 span logic forms are used in some natural language processing techniques such as question answering as well as in inference both for database systems and qa systems evaluations http www senseval org senseval 3 in 2004 introduced a webarchive url https web archive org web 20050902115653 site http www cs iusb edu vasile logic indexlf html date september 2 2005 title logic form identification task references cite book author vasile rus title logic form for wordnet glosses url http www engr smu edu vasile rus02 phdthesis ps publisher ph d thesis southern methodist university year 2002 most information in the article derived from vasile s work cite journal author vasile rus and dan moldovan title high performance logic form transformation journal international journal for tools with artificial intelligence ieee computer society ieee press date september 2002 volume 11 issue 3 pages 437 454 url http www worldscinet com ijait 11 1103 s0218213002000976 html cite conference author dan moldovan and vasile rus url http engr smu edu vasile acl2001 ps title logic form transformation of wordnet and its applicability to question answering booktitle proceedings of acl 2001 toulouse france year 2001 pages cite conference author jerry r hobbs title overview of the tacitus project booktitle computational linguistics year 1986 pages 12 3 cite conference author vasile rus url http acl ldc upenn edu acl2004 senseval pdf rus pdf title a first evaluation of logic form identification systems booktitle senseval 3 third international workshop on the evaluation of systems for the semantic analysis of text year 2004 pages format pdf category natural language processing category computational linguistics category knowledge representation ling stub'
b'mergefrom faceted search date january 2015 faceted classification is a classification scheme used in organizing knowledge into a systematic order a faceted classification uses semantic categories either general or subject specific that are combined to create the full classification entry many library classification systems use a combination of a fixed enumerative taxonomy of concepts with subordinate facets that further refine the topic definition there are two primary types of classification used for information organization enumerative and faceted an enumerative classification contains a full set of entries for all concepts ref name lcsh citation publisher libraries unlimited isbn 1591581540 publication place westport conn title library of congress subject headings url http openlibrary org books ol3311856m library of congress subject headings author lois mai chan publication date 2005 id 1591581540 ref a faceted classification system uses a set of semantically cohesive categories that are combined as needed to create an expression of a concept in this way the faceted classification is not limited to already defined concepts while this makes the classification quite flexible it also makes the resulting expression of topics complex ref name sven citation publisher mit press isbn 0262194333 publication place cambridge mass title the intellectual foundation of information organization url http openlibrary org books ol44967m the intellectual foundation of information organization author elaine svenonius publication date 2000 id 0262194333 ref to the extent possible facets represent clearly defined mutually exclusive and collectively exhaustive aspects properties or characteristics of a class or specific subject ref name taylor taylor a g 1992 introduction to cataloging and classification 8th ed englewood colorado libraries unlimited ref some commonly used general purpose facets are time place and form ref name chan there are few purely faceted classifications the best known of these is the colon classification of s r ranganathan a general knowledge classification for libraries some other faceted classifications are specific to special topics such as the art and architecture thesaurus and the faceted classification of occupational safety and health topics created by d j foskett for the international labour organization ref name coyle many library classifications combine the enumerative and faceted classification techniques the dewey decimal classification the library of congress classification and the universal decimal classification all make use of facets at various points in their enumerated classification schedules the allowed facets vary based on the subject area of the classification these facets are recorded as tables that represent recurring types of subdivisions within subject areas there are general facets that can be used wherever appropriate such as geographic subdivisions of the topic other tables are applied only to specific areas of the schedules facets can be combined to create a complex subject statement ref name chan arlene taylor describes faceted classification using an analogy if one thinks of each of the faces of a cut and polished diamond as a facet for the whole diamond one can picture a classification notation that has small notations standing for subparts of the whole topic strung together to create a complete classification notation ref cite book last1 taylor first1 arlene g year 2004 title the organization of information location westport ct publisher libraries unlimited ref faceted classifications exhibit many of the same problems as classifications based on a hierarchy in particular some concepts could belong in more than one facet so their placement in the classification may appear to be arbitrary to the classifier it also tends to result in a complex notation because each facet must be distinguishable as recorded ref name sven retrieval search in systems with faceted classification can enable a user to navigate information along multiple paths corresponding to different orderings of the facets this contrasts with traditional taxonomies in which the hierarchy of categories is fixed and unchanging ref name star s l 1998 star s l 1998 fall grounded classification grounded theory and faceted classification electronic version library trends 47 2 218 ref it is also possible to use facets to filter search results to more quickly find desired results examples of faceted classifications colon classification for library materials the colon classification developed by s r ranganathan is an example of general faceted classification designed to be applied to all library materials in the colon classification system a book is assigned a set of values from each independent facet ref garfield e 1984 february a tribute to s r ranganathan the father of indian library science essays of an information scientist 7 37 44 ref this facet formula uses punctuation marks and symbols placed between the facets to connect them colon classification was named after its use of the colon as the primary symbol in its notation ref chan l m 1994 cataloging and classification new york mcgraw hill inc ref ref http www essessreference com servlet esgetbiblio bno 000374 colon classification 6th edition by dr s r ranganathan published by ess publications delhi india ref ranganathan stated that hierarchical classification schemes like the dewey decimal classification ddc or the library of congress subject headings are too limiting and finite to use for modern classification and that many items can pertain information to more than one subject he organized his classification scheme into 42 classes each class can be categorized according to particular characteristics that he called facets ranganathan said that there are five fundamental categories that can be used to demonstrate the facets of a subject personality material energy space and time he called this the pmest formula ref ranganathan s r 1987 colon classification 7th ed revised and edited by m a gopinath bangalore sarada ranganathan endowment for library science 1987 ref personality is the most specific or focal subject matter is the substance properties or materials of the subject energy includes the processes operations and activities space relates to the geographic location of the subject time refers to the dates or seasons of the subject universal decimal classification another example of a faceted classification scheme is the universal decimal classification udc the udc is considered to be a complex multilingual classification that can be used in all fields of knowledge ref about universal decimal classification and the udc consortium 2006 retrieved november 30 2013 from http www udcc org about htm ref the universal decimal classification scheme was created at the end of the nineteenth century by belgian bibliographers paul otlet and henri la fontaine the goal of their system was to create an index that would be able to record knowledge even if it is stored in non conventional ways including materials in notebooks and ephemera they also wanted their index to organize material systematically instead of alphabetically ref batty d 2003 universal decimal classification encyclopedia of library and information science ref the udc has an overall taxonomy of knowledge that is extended with a number of facets such as language form place and time each facet has its own symbol in the notation such as for language 02 for materials for subordinate concepts ref name chan cite book publisher the scarecrow press inc isbn 978 0 8108 5944 9 title cataloging and classification url http openlibrary org books ol9558667m cataloging and classification last chan first lois mai edition third publication date 2007 page 321 id 0810859440 ref faceted classification for occupational safety and health douglas john foskett d j foskett a member of the classification research group in london developed classification of occupational safety and health materials for the library of the international labour organization ref name coyle cite journal last1 coyle first1 karen title a faceted classification for occupational safety and health journal special libraries date 1975 volume 66 issue 5 6 pages 256 9 ref ref name foskett cite book last1 foskett first1 d j title proceedings of the international conference on scientific information chapter construction of a faceted classification for a special subject date 1959 publisher national science foundation isbn 0 309 57421 8 pages 867 888 ref after a study of the literature in the field he created the classification with the following facets facet a occupational safety and health general facet b special classes of workers industries facet c sources of hazards fire machinery etc facet d industrial accidents and diseases facet e preventive measures protection facet f organisation administration notation was solely alphabetic with the sub facets organized hierarchically using extended codes such as g industrial equipment and processes ge machines ref name foskett art and architecture thesaurus aat while not strictly a classification system the art and architecture thesaurus aat uses facets similar to those of ranganathan s colon classification associated concepts e g philosophy physical attributes styles and periods agents people organizations activities similar to ranganathan s energy materials similar to ranganathan s matter objects similar to ranganathan s personality ref name denton cite web url https www miskatonic org library facet web howto html author william denton title how to make a faceted classification and put it on the web ref comparison between faceted and single hierarchical classification hierarchical classification refers to the classification of objects using one single hierarchical taxonomy faceted classification may actually employ hierarchy in one or more of its facets but allows for the use of more than one taxonomy to classify objects faceted classification systems allow the assignment of multiple classifications to an object and enable those classifications to be applied by searchers in multiple ways rather than in a single predetermined order multiple facets may be used as a first step in a search process ref name categories facets and browsable facets sirovich jaimie 2011 categories facets and browsable facets from http www uxmatters com mt archives 2011 08 categories facetsand browsable facets php ref for example one may start from language or subject hierarchical classification systems are developed classes that are subdivided from the most general subjects to the most specific ref reitz joan m 2004 dictionary for library and information science westport ct libraries unlimited ref faceted classification systems allow for the combination of facets to filter software filter the set of objects rapidly in addition the facets can be used to address multiple classification criteria ref godert winfried f 1991 facet classification in online retrieval international classification 18 98 109 ref a faceted system focuses on the important essential or persistent characteristics of content objects helping it to be useful for categorization of fine grained rapidly changing repositories in faceted classification systems one does not have to know the name of the category into which an object is placed a priori a controlled vocabulary is presented with the number of documents matching each vocabulary term new facets may be created at any time without disruption of a single hierarchy or reorganizing other facets faceted classification systems make few assumptions about the scope and organization of the domain it is difficult to break a faceted classification schema ref adkisson hiedi p 2005 use of faceted classification retrieved december 1 2013 from http www webdesignpractices com navigation facets html ref see also classification research group controlled vocabulary findability folksonomy information architecture tag metadata universal decimal classification references reflist colwidth 35em external links http eprints soton ac uk 271488 how to reuse a faceted classification and put it on the semantic web category knowledge representation category library cataloging and classification'
b'expand russian \xd0\xbc\xd0\xb5\xd0\xb4\xd0\xb8\xd1\x86\xd0\xb8\xd0\xbd\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9 \xd0\xb0\xd0\xbb\xd0\xb3\xd0\xbe\xd1\x80\xd0\xb8\xd1\x82\xd0\xbc date september 2015 original research date october 2007 file assessment and treatment algorithm for overweight and obesity png thumb 450px a medical algorithm for assessment and treatment of overweight and obesity a medical algorithm is any computation formula statistical survey nomogram or look up table useful in healthcare medical algorithm s include decision tree approaches to healthcare treatment e g if symptom s a b and c are evident then use treatment x and also less clear cut tools aimed at reducing or defining uncertainty scope medical algorithms are part of a broader field which is usually fit under the aims of medical informatics and medical decision making medical decisions occur in several areas of medical activity including medical test selection diagnosis therapy and prognosis and automatic control of medical equipment in relation to logic based and artificial neural network based clinical decision support system which are also computer applications to the medical decision making field algorithms are less complex in architecture data structure and user interface medical algorithms are not necessarily implemented using digital computers in fact many of them can be represented on paper in the form of diagrams nomographs etc examples a wealth of medical information exists in the form of published medical algorithms these algorithms range from simple calculation s to complex outcome prediction s most clinician s use only a small subset routinely examples of medical algorithms are calculators e g an on line or stand alone calculator for body mass index bmi when stature and body weight are given flowcharts e g a wiktionary binary binary decision tree for deciding what is the etiology of chest pain look up table s e g for looking up food energy and nutritional contents of foodstuffs nomogram s e g a moving circular slide to calculate body surface area or drug dosages a common class of algorithms are embedded in guidelines on the choice of treatments produced by many national state financial and local healthcare organisations and provided as knowledge resources for day to day use and for induction of new physicians a field which has gained particular attention is the choice of medications for psychiatric conditions in the united kingdom guidelines or algorithms for this have been produced by most of the circa 500 primary care trusts substantially all of the circa 100 secondary care psychiatric units and many of the circa 10 000 general practices in the us there is a national federal initiative to provide them for all states and by 2005 six states were adapting the approach of the texas medication algorithm project or otherwise working on their production a grammar the arden syntax exists for describing algorithms in terms of medical logic module s an approach such as this should allow exchange of mlms between doctors and establishments and enrichment of the common stock of tools purpose the intended purpose of medical algorithms is to improve and standardize decisions made in the delivery of medical care medical algorithms assist in standardizing selection and application of treatment regimens with algorithm automation intended to reduce potential introduction of errors some attempt to predict the outcome for example icu scoring systems critical care scoring systems computerized health diagnostics algorithms can provide timely clinical decision support improve adherence to evidence based medicine evidence based guideline medical guidelines and be a resource for education and research medical algorithms based on best practice can assist everyone involved in delivery of standardized treatment via a wide range of clinical care providers many are presented as clinical trial protocol protocol s and it is a key task in training to ensure people step outside the protocol when necessary in our present state of knowledge generating hints and producing guidelines may be less satisfying to the authors but more appropriate cautions in common with most science and medicine algorithms whose contents are not wholly available for scrutiny and open to improvement should be regarded with suspicion computation s obtained from medical algorithms should be compared with and tempered by clinical knowledge and physician judgment see also consensus medical evidence based medicine journal club medical guideline medical informatics odds algorithm treatment guidelines from the medical letter further reading cite journal title automated medical algorithms issues for medical errors first1 kathy a last1 johnson first2 john r last2 svirbely first3 m g last3 sriram first4 jack w last4 smith first5 gareth last5 kantor first6 jorge raul last6 rodriguez journal journal of the american medical informatics association pmc 419420 doi 10 1197 jamia m1228 volume 9 issue 6 suppl 1 pages s56 s57 date november 2002 external links http www alternativementalhealth com articles fieldmanual htm alternativementalhealth com alternative health medical evaluation field manual lorrin m koran md stanford university medical center 1991 category health informatics category algorithms category knowledge representation'
b'the nippon decimal classification ndc also called the nippon decimal system is a system of library classification developed for mainly japanese language books maintained by the japan library association since 1956 it is based on the dewey decimal classification dewey decimal system the system is based upon using each successive digit to divide into nine divisions with the digit zero used for those not belonging to any of the divisions main classes the system is made up of ten categories 000 general 100 philosophy 200 history 300 social sciences 400 natural sciences 500 technology and engineering 600 industry and commerce 700 arts 800 language 900 literature description of the classes 000 general 010 libraries library and information science library information science 020 books bibliography 030 encyclopaedia s 040 general collected essays 050 general periodical literature serial publications 060 organizations 070 journalism newspapers 080 general collections 090 rare books local collections special collections 100 philosophy 110 special treatises on philosophy 120 oriental philosophy 130 western philosophy 140 psychology 150 ethics morals 160 religion 170 shintoism 180 buddhism 190 christianity 200 history 210 history of japan 220 history of asia and the orient 230 history of europe and the west 240 history of africa 250 history of north america 260 history of south america 270 history of oceania polar region s 280 biography 290 geography topography travel 300 social sciences 310 politics 320 law 330 economics 340 finance 350 statistics 360 sociology 370 education 380 customs folklore ethnology 390 national defence military science 400 natural sciences 410 mathematics 420 physics 430 chemistry 440 astronomy space science 450 earth science 460 biology 470 botany 480 zoology 490 medicine pharmacology 500 technology engineering 510 construction civil engineering 520 architecture 530 mechanical engineering nuclear engineering 540 electrical engineering electrical electronic engineering 550 maritime naval engineer ing 560 metal mining engineering 570 chemical technology 580 manufacturing 590 domestic science domestic arts and sciences 600 industry and commerce 610 agriculture 620 horticulture 630 sericulture silk industry 640 animal husbandry 650 forestry 660 fishing 670 commerce 680 transportation traffic 690 communications 700 arts 710 plastic arts sculpture 720 painting calligraphy 730 engraving 740 photography printing 750 craft 760 music dance 770 theatre motion pictures 780 sports physical education 790 recreation amusements 800 language 810 japanese language japanese 820 chinese language chinese other oriental languages 830 english language english 840 german language german 850 french language french 860 spanish language spanish 870 italian language italian 880 russian language russian 890 other languages 900 literature 910 japanese literature 920 chinese literature other oriental literature 930 english literature english american literature 940 german literature 950 french literature 960 spanish literature 970 italian literature 980 russian literature russian soviet literature 990 other language literature external links http www jla or jp index e html japan library association http www asahi net or jp ax2s kmtn ref ndc e ndc html cyberlibrarian library classification systems category library cataloging and classification category knowledge representation category classification systems'
b'the works of aristotle in philosophy ontic from the greek language greek lang grc \xe1\xbd\x84\xce\xbd genitive lang grc \xe1\xbd\x84\xce\xbd\xcf\x84\xce\xbf\xcf\x82 of that which is is physical real or factual existence ontic describes what is there as opposed to the nature or properties of that being to illustrate roger bacon observing that all languages are built upon a common grammar stated that they share a foundation of ontically anchored linguistic structures martin heidegger posited the concept of sorge or caring as the fundamental concept of the intentionality intentional being and presupposed an ontological significance that distinguishes ontology ontological being from mere thinghood of an ontic being he uses the german language german word dasein for a being that is capable of ontology that is recursivity recursively comprehending property philosophy properties of the very fact of its own being for heidegger ontical signifies concrete specific realities whereas ontological signifies deeper underlying structures of reality ontological objects or subjects have an ontical dimension but they also include aspects of being like self awareness evolutionary vestiges future potentialities and networks of relationship ref cite web title ontico ontological distinction url http www blackwellreference com public tocnode id g9781405106795 chunk g978140510679516 ss1 33 publisher blackwell reference accessdate 26 february 2015 ref ref cite web last1 duffy first1 michael title the ontological and the ontic url http mikejohnduff blogspot com 2007 08 ontological html accessdate 26 february 2015 ref nicolai hartmann distinguishes among ontology ontics and metaphysics i ontology concerns the categorical analysis of entities by means of the knowledge categories able to classify them ii ontics refers to a pre categorical and pre objectual connection which is best expressed in the relation to transcendent acts and iii metaphysics is that part of ontics or that part of ontology which concerns the residue of being that cannot be rationalized further according to categories usage in philosophy of science harald atmanspacher writes extensively about the philosophy of science especially as it relates to chaos theory determinism causality causation and stochastic process stochasticity he explains that ontic states describe all properties of a physical system exhaustively exhaustive in this context means that an ontic state is precisely the way it is without any reference to epistemic knowledge or ignorance ref autonumber in an earlier paper atmanspacher portrays the difference between an epistemic perspective of a system and an ontic perspective philosophical discourse traditionally distinguishes between ontology and epistemology and generally enforces this distinction by keeping the two subject areas separated however the relationship between the two areas is of central importance to physics and philosophy of physics for instance many measurement related problems force us to consider both our knowledge of the classical mechanics states and observables of a system epistemic perspective and its states and observables independent of such knowledge ontic perspective this applies to quantum quantum systems in particular ref autonumber usage in philosophy of critical realism the united kingdom british philosopher roy bhaskar who is closely associated with the philosophical cultural movement movement of critical realism philosophy of the social sciences critical realism writes i differentiate the ontic ontical etc from the ontological i employ the former to refer to whatever pertains to being generally rather than some distinctively philosophical or scientific theory of it ontology so that in this sense that of the ontic sub 1 sub we can speak of the ontic presuppositions of a work of art a joke or a strike as much as a epistemology theory of knowledge and within this rubric to the intransitive object philosophy object s of some specific historically determinate scientific investigation or set of such investigations the ontic sub 2 sub the ontic sub 2 sub is always specified and only identified by its relation as the intransitive object s of some or other denumerable set of particular transitive process es of enquiry it is cognitive process and level specific whereas the ontological like the ontic sub 1 sub is not ref autonumber ruth groff offers this expansion of bhaskar s note above ontic sub 2 sub is an abstract way of denoting the object domain of a particular scientific area field or inquiry e g molecules feature in the ontic sub 2 sub of chemistry he s just saying that the scientific undertaking itself is not one of the objects of said most narrowly construed immediate object domain so chemistry itself is not part of the ontic sub 2 sub of chemistry see also ding an sich noumenon and the thing in itself ding an sich ontologism physical ontology substance theory references reflist note autonumber atmanspacher dr h and primas h 2003 2005 epistemic and ontic quantum reality realities in khrennikov a ed foundations of probability and physics american institute of physics 2005 pp 49 ndash 61 originally published in time quantum and information edited by lutz castell and otfried ischebeck springer berlin 2003 pp 301 ndash 321 note autonumber atmanspacher harald 2001 determinism is ontic determinability is epistemic http philsci archive pitt edu archive 00000939 00 determ pdf university of pittsburgh archives note autonumber bhaskar r a 1986 scientific realism and human emancipation london verso pp 36 and 37 as quoted by howard engelskirchen in the http archives econ utah edu archives bhaskar 2001m11 msg00015 htm bhaskar mailing list archive continental philosophy wiktionary category concepts in metaphysics category knowledge representation category martin heidegger category modal logic category ontology category philosophy of science category reality'
b'a guideline execution engine is a computer program which can interpret a guideline medical clinical guideline represented in a computerized format and perform actions towards the user of an electronic medical record a guideline execution engine needs to communicate with a host clinical information system virtual medical record vmr is one possible interface which can be used the engine s main function is to manage instances of executed guidelines of individual patients delivering the inferred engine recommendations or impacts to the host clinical information system has to carefully respect current workflow of the clinicians physicians nurses clerks etc architecture of guideline execution engine the following modules are generally needed for any engine interface to clinical information system new guidelines loading module guideline interpreter module clinical events parser alert recommendations dispatch guideline interchange format the guideline interchange format glif is computer representation format for clinical guideline s ref cite web url http mis hevra haifa ac il morpeleg intermed title guideline representation page glif 2 0 3 4 3 5 specifications work stanford university school of medicine intermed collaboratory ref represented guidelines can be executed using a guideline execution engine the format has several versions as it has been improved in 2003 glif3 was introduced use of third party workflow engine as a guideline execution engine some commercial electronic health record systems use a workflow engine to execute clinical guidelines retroguide ref name eval cite journal last1 huser first1 v last2 narus first2 s p last3 rocha first3 r a doi 10 1016 j jbi 2009 06 001 title evaluation of a flowchart based ehr query system a case study of retroguide\xe2\x98\x86 journal journal of biomedical informatics volume 43 issue 1 pages 41 50 year 2010 pmid 19560553 pmc 2840619 ref and healthflow ref name hf2010 citation pmc 3079703 title implementation of workflow engine technology to deliver basic clinical decision support functionality journal bmc med res methodol year 2011 volume 11 page 43 doi 10 1186 1471 2288 11 43 pmid 21477364 vauthors huser v rasmussen lv oberg r starren jb ref are examples of such an approach see also electronic medical record clinical practice guideline medical algorithm arden syntax healthcare workflow glif retroguide references references external links cite journal vauthors wang d peleg m tu sw etal title design and implementation of the glif3 guideline execution engine journal j biomed inform volume 37 issue 5 pages 305 18 date october 2004 pmid 15488745 doi 10 1016 j jbi 2004 06 002 url http linkinghub elsevier com retrieve pii s1532046404000668 http bmir stanford edu file asset index php 940 bmir 2004 1008 pdf pdf cite journal vauthors ram p berg d tu s etal title executing clinical practice guidelines using the sage execution engine journal stud health technol inform volume 107 issue pt 1 pages 251 5 year 2004 pmid 15360813 cite journal vauthors tu sw campbell j musen ma title the structure of guideline recommendations a synthesis journal amia annu symp proc volume issue pages 679 83 year 2003 pmid 14728259 pmc 1480008 http bmir stanford edu file asset index php 1511 bmir 2003 0966 pdf pdf cite journal vauthors tu sw musen ma title a flexible approach to guideline modeling journal proc amia symp volume issue pages 420 4 year 1999 pmid 10566393 pmc 2232509 http bmir stanford edu file asset index php 211 bmir 1999 0789 pdf pdf category health informatics category knowledge representation'
b'infobox technology standard title rdf 1 1 concepts and abstract syntax status published w3c recommendation year started 1997 editors richard cyganiak david wood markus lanthaler base standards uri related standards rdfs web ontology language owl rule interchange format rif rdfa domain semantic web abbreviation rdf website url http www w3 org tr 2014 rec rdf11 concepts 20140225 the resource description framework rdf is a family of world wide web consortium w3c specification s ref cite web url http www dblab ntua gr bikakis xmlsemanticwebw3ctimeline pdf title xml and semantic web w3c standards timeline date 2012 02 04 ref originally designed as a metadata data model it has come to be used as a general method for conceptual description or modeling of information that is implemented in web resource s using a variety of syntax notations and data serialization formats it is also used in knowledge management applications rdf was adopted as a w3c recommendation in 1999 the rdf 1 0 specification was published in 2004 the rdf 1 1 specification in 2014 overview the rdf data model ref http www w3 org tr pr rdf syntax resource description framework rdf model and syntax specification ref is similar to classical conceptual modeling approaches such as entity relationship model entity relationship or class diagram s it is based upon the idea of making statement programming statement s about resource computer science resource s in particular web resource s expressions known as semantic triple triples triples are so named because they follow a var subject var var predicate var var object var structure the var subject var denotes the resource and the var predicate var denotes traits or aspects of the resource and expresses a relationship between the var subject var and the var object var for example one way to represent the notion the sky has the color blue in rdf is as the triple a subject grammar subject denoting the sky a predicate grammar predicate denoting has the color and an object grammar object denoting blue therefore rdf swaps var object var for var subject var in contrast to the typical approach of an entity attribute value model in object oriented design entity sky attribute color and value blue rdf is an abstract model with several serialization serialization formats i e file formats so the particular encoding for resources or triples varies from format to format this mechanism for describing resources is a major software componentry component in the w3c s semantic web activity an evolutionary stage of the world wide web in which automated software can store exchange and use machine readable information distributed throughout the web in turn enabling users to deal with the information with greater efficiency and certainty rdf s simple data model and ability to model disparate abstract concepts has also led to its increasing use in knowledge management applications unrelated to semantic web activity a collection of rdf statements intrinsically represents a glossary of graph theory labeled directed multi graph this theoretically makes an rdf data model better suited to certain kinds of knowledge representation than other relational model relational or ontology computer science ontological models however in practice rdf data is often persisted in rdbms relational database or native representations also called triplestore s or quad stores if context i e the named graph is also persisted for each rdf triple ref http sw deri org 2005 02 dexa yars pdf optimized index structures for querying rdf from the web andreas harth stefan decker 3rd latin american web congress buenos aires argentina october 31 to november 2 2005 pp 71 80 ref shex or shape expressions ref http www w3 org 2001 sw wiki shex shape expressions language ref is a language for expressing constraints on rdf graphs it includes the cardinality constraints from open services for lifecycle collaboration oslc resource shapes and dublin core description set profiles as well as logical connectives for disjunction and polymorphism as rdfs and web ontology language owl demonstrate one can build additional ontology language s upon rdf history the initial rdf design intended to build a vendor neutral and operating system independent system of metadata ref name press release 1997 cite news last first title world wide web consortium publishes public draft of resource description framework work w3c location cambridge ma date 1997 10 03 url http www w3 org press rdf ref derived from the w3c s platform for internet content selection pics an early web content labelling system ref name lash but the project was also shaped by ideas from dublin core and from the meta content framework mcf ref name press release 1997 which had been developed during 1995 1997 by ramanathan v guha at apple computer apple and tim bray at netscape communications corporation netscape ref cite book publisher o reilly isbn 0 596 00881 3 last hammersley first ben title developing feeds with rss and atom pages 2 3 location sebastopol date 2005 ref a first public draft of rdf appeared in october 1997 ref cite web last1 lassila first1 ora last2 swick first2 ralph r title resource description framework rdf model and syntax work w3c accessdate 2015 11 24 date 1997 10 02 url http www w3 org tr wd rdf syntax 971002 ref ref cite web last swick first ralph title resource description framework rdf work w3c accessdate 2015 11 24 date 1997 12 11 url http www13 w3 org rdf overview html deadurl yes archiveurl https web archive org web 19980214043631 http www13 w3 org rdf overview html archivedate february 14 1998 ref issued by a w3c working group that included representatives from ibm microsoft netscape nokia reuters softquad software softquad and the university of michigan ref name lash cite news last lash first alex title w3c takes first step toward rdf spec work cnet news accessdate 2015 11 28 date 1997 10 03 url http news cnet com 2100 1001 203893 html deadurl yes archiveurl https web archive org web 20110616023126 http news cnet com 2100 1001 203893 html archivedate june 16 2011 ref the w3c published a specification of rdf s data model and an xml serialization as a recommendation in february 1999 ref cite web url http www w3 org tr 1999 rec rdf syntax 19990222 title resource description framework rdf model and syntax specification date 22 feb 1999 accessdate 5 may 2014 ref two persistent misunderstandings developed around rdf at this time firstly from the mcf influence and the rdf resource description acronym the idea that rdf was specifically for use in representing metadata secondly that rdf was an xml format rather than rdf being a data model and only the rdf xml serialisation being xml based rdf saw little take up in this period but there was significant work carried out in bristol around ilrt at bristol university and hp labs and also in boston at mit rss 1 0 and foaf ontology foaf became exemplar applications for rdf in this period the recommendation of 1999 was replaced in 2004 by a set of six specifications the rdf primer ref citation publisher w3c last1 manola first1 frank last2 miller first2 eric title rdf primer accessdate 2015 11 21 date 2004 02 10 url http www w3 org tr 2004 rec rdf primer 20040210 ref rdf concepts and abstract ref citation publisher w3c last1 klyne first1 graham last2 carroll first2 jeremy j title resource description framework rdf concepts and abstract syntax accessdate 2015 11 21 date 2004 02 10 url http www w3 org tr 2004 rec rdf concepts 20040210 ref rdf xml syntax specification revised ref citation publisher w3c last beckett first dave title rdf xml syntax specification revised accessdate 2015 11 21 date 2004 02 10 url http www w3 org tr 2004 rec rdf syntax grammar 20040210 ref rdf semantics ref citation last hayes first patrick title rdf semantics accessdate 2015 11 21 date 2014 02 10 url http www w3 org tr 2004 rec rdf mt 20040210 ref rdf vocabulary description language 1 0 ref citation publisher w3c last1 brickley first1 dan last2 guha first2 r v title rdf vocabulary description language 1 0 rdf schema w3c recommendation 10 february 2004 accessdate 2015 11 21 date 2004 02 10 url http www w3 org tr 2004 rec rdf schema 20040210 ref and the rdf test cases ref citation publisher w3c last1 grant first1 jan last2 beckett first2 dave title rdf test cases accessdate 2015 11 21 date 2004 02 10 url http www w3 org tr 2004 rec rdf testcases 20040210 ref this series was superseded in 2014 by the following six rdf 1 1 documents rdf 1 1 primer ref citation publisher w3c last1 schreiber first1 guus last2 raimond first2 yves title rdf 1 1 primer accessdate 2015 11 22 date 2014 06 24 url http www w3 org tr 2014 note rdf11 primer 20140624 ref rdf 1 1 concepts and abstract syntax ref citation publisher w3c last1 cyganiak first1 richard last2 wood first2 david last3 lanthaler first3 markus title rdf 1 1 concepts and abstract syntax accessdate 2015 11 22 date 2014 02 25 url http www w3 org tr 2014 rec rdf11 concepts 20140225 ref rdf 1 1 xml syntax ref citation publisher w3c last1 gandon first1 fabien last2 schreiber first2 guus title rdf 1 1 xml syntax accessdate 2015 11 22 date 2014 02 25 url http www w3 org tr rdf syntax grammar ref rdf 1 1 semantics ref citation publisher w3c last1 hayes first1 patrick j last2 patel schneider first2 peter f title rdf 1 1 semantics accessdate 2015 11 22 date 2014 02 25 url http www w3 org tr 2014 rec rdf11 mt 20140225 ref rdf schema 1 1 ref citation publisher w3c last1 brickley first1 dan last2 guha first2 r v title rdf schema 1 1 accessdate 2015 11 22 date 2014 02 25 url http www w3 org tr rdf schema ref and rdf 1 1 test cases ref citation publisher w3c last1 kellogg first1 gregg last2 lanthaler first2 markus title rdf 1 1 test cases accessdate 2015 11 22 date 2014 02 25 url http www w3 org tr 2014 note rdf11 testcases 20140225 ref rdf topics rdf vocabulary the vocabulary defined by the rdf specification is as follows ref name rdfschema cite web url http www w3 org tr rdf schema title rdf vocabulary description language 1 0 rdf schema publisher w3c date 2004 02 10 accessdate 2011 01 05 ref classes rdf code rdf xmlliteral code the class of xml literal values code rdf property code the class of properties code rdf statement code the class of rdf statements code rdf alt code code rdf bag code code rdf seq code containers of alternatives unordered containers and ordered containers code rdfs container code is a super class of the three code rdf list code the class of rdf lists code rdf nil code an instance of code rdf list code representing the empty list rdfs code rdfs resource code the class resource everything code rdfs literal code the class of literal values e g string literal string s and integer s code rdfs class code the class of classes code rdfs datatype code the class of rdf datatypes code rdfs container code the class of rdf containers code rdfs containermembershipproperty code the class of container membership properties code rdf 1 code code rdf 2 code all of which are sub properties of code rdfs member code properties rdf code rdf type code an instance of code rdf property code used to state that a resource is an instance of a class code rdf first code the first item in the subject rdf list code rdf rest code the rest of the subject rdf list after code rdf first code code rdf value code idiomatic property used for structured values code rdf subject code the subject of the subject rdf statement code rdf predicate code the predicate of the subject rdf statement code rdf object code the object of the subject rdf statement code rdf statement code code rdf subject code code rdf predicate code code rdf object code are used for reification knowledge representation reification see statement reification and context below rdfs code rdfs subclassof code the subject is a subclass of a class code rdfs subpropertyof code the subject is a subproperty of a property code rdfs domain code a domain of the subject property code rdfs range code a range of the subject property code rdfs label code a human readable name for the subject code rdfs comment code a description of the subject resource code rdfs member code a member of the subject resource code rdfs seealso code further information about the subject resource code rdfs isdefinedby code the definition of the subject resource this vocabulary is used as a foundation for rdf schema where it is extended serialization formats infobox file format name rdf 1 1 turtle serialization icon extension ttl mime text turtle ref cite web url http www w3 org tr turtle h2 sec mediareg title rdf 1 1 turtle terse rdf triple language publisher w3c date 9 jan 2014 accessdate 2014 02 22 ref owner world wide web consortium standard http www w3 org tr turtle rdf 1 1 turtle terse rdf triple language release date and age 2014 01 09 free yes infobox file format name rdf xml serialization icon image xml svg 100px extension rdf mime application rdf xml ref cite web url http tools ietf org html rfc3870 title application rdf xml media type registration page 2 publisher ietf date september 2004 accessdate 2011 01 08 ref owner world wide web consortium standard http www w3 org tr 2004 rec rdf concepts 20040210 concepts and abstract syntax release date and age 2004 02 10 free yes several common serialization serialization formats are in use including turtle syntax turtle ref name turtle cite web title rdf 1 1 turtle terse rdf triple language url http www w3 org tr turtle date 9 january 2014 publisher w3c ref a compact human friendly format n triples ref name n triples cite web title rdf 1 1 n triples a line based syntax for an rdf graph date 9 january 2014 url http www w3 org tr n triples publisher w3c ref a very simple easy to parse line based format that is not as compact as turtle n quads ref cite web title n quads extending n triples with context date 2012 06 25 url http sw deri org 2008 07 n quads ref ref name n quads cite web title rdf 1 1 n quads date january 2014 url http www w3 org tr n quads publisher w3c ref a superset of n triples for serializing multiple rdf graphs json ld ref name json ld cite web title json ld 1 0 a json based serialization for linked data url http www w3 org tr json ld publisher w3c ref a json based serialization n3 or notation3 a non standard serialization that is very similar to turtle but has some additional features such as the ability to define inference rules rdf xml ref name rdf xml cite web title rdf 1 1 xml syntax date 25 february 2014 url http www w3 org tr rdf syntax grammar publisher w3c ref an xml based syntax that was the first standard format for serializing rdf rdf xml is sometimes misleadingly called simply rdf because it was introduced among the other w3c specifications defining rdf and it was historically the first w3c standard rdf serialization format however it is important to distinguish the rdf xml format from the abstract rdf model itself although the rdf xml format is still in use other rdf serializations are now preferred by many rdf users both because they are more human friendly ref name rdf xml syntax criticism cite web title problems of the rdf syntax url http milicicvuk com blog 2011 07 21 problems of the rdf syntax publisher vuk mili\xc4\x8di\xc4\x87 ref and because some rdf graphs are not representable in rdf xml due to restrictions on the syntax of xml qname s with a little effort virtually any arbitrary xml may also be interpreted as rdf using grddl pronounced griddle gleaning resource descriptions from dialects of languages rdf triples may be stored in a type of database called a triplestore resource identification the subject of an rdf statement is either a uniform resource identifier uri or a blank node both of which denote web resource resource s resources indicated by blank node s are called anonymous resources they are not directly identifiable from the rdf statement the predicate is a uri which also indicates a resource representing a relationship the object is a uri blank node or a unicode string literal as of rdf 1 1 resources are identified by iri s iri is a generalization of uri ref rdf 1 1 concepts and abstract syntax https www w3 org tr rdf11 concepts ref in semantic web applications and in relatively popular applications of rdf like rss file format rss and foaf software foaf friend of a friend resources tend to be represented by uris that intentionally denote and can be used to access actual data on the world wide web but rdf in general is not limited to the description of internet based resources in fact the uri that names a resource does not have to be dereferenceable at all for example a uri that begins with http and is used as the subject of an rdf statement does not necessarily have to represent a resource that is accessible via http nor does it need to represent a tangible network accessible resource such a uri could represent absolutely anything however there is broad agreement that a bare uri without a symbol which returns a 300 level coded response when used in an http get request should be treated as denoting the internet resource that it succeeds in accessing therefore producers and consumers of rdf statements must agree on the semantics of resource identifiers such agreement is not inherent to rdf itself although there are some controlled vocabularies in common use such as dublin core metadata which is partially mapped to a uri space for use in rdf the intent of publishing rdf based ontologies on the web is often to establish or circumscribe the intended meanings of the resource identifiers used to express data in rdf for example the uri blockquote code nowiki http www w3 org tr 2004 rec owl guide 20040210 wine merlot nowiki code blockquote is intended by its owners to refer to the class of all merlot red wines by vintner i e instances of the above uri each represent the class of all wine produced by a single vintner a definition which is expressed by the owl ontology itself an rdf document in which it occurs without careful analysis of the definition one might erroneously conclude that an instance of the above uri was something physical instead of a type of wine note that this is not a bare resource identifier but is rather a uniform resource identifier uri reference uri reference containing the character and ending with a fragment identifier statement reification and context the body of knowledge modeled by a collection of statements may be subjected to reification knowledge representation reification in which each statement that is each triple subject predicate object altogether is assigned a uri and treated as a resource about which additional statements can be made as in jane says that john is the author of document x reification is sometimes important in order to deduce a level of confidence or degree of usefulness for each statement in a reified rdf database each original statement being a resource itself most likely has at least three additional statements made about it one to assert that its subject is some resource one to assert that its predicate is some resource and one to assert that its object is some resource or literal more statements about the original statement may also exist depending on the application s needs borrowing from concepts available in logic and as illustrated in graphical notations such as conceptual graphs and topic map s some rdf model implementations acknowledge that it is sometimes useful to group statements according to different criteria called situations contexts or scopes as discussed in articles by rdf specification co editor graham klyne ref http www ninebynine org rdfnotes rdfcontexts html contexts for rdf information modelling ref ref http www ninebynine org rdfnotes usingcontextswithrdf html circumstance provenance and partial knowledge ref for example a statement can be associated with a context named by a uri in order to assert an is true in relationship as another example it is sometimes convenient to group statements by their source which can be identified by a uri such as the uri of a particular rdf xml document then when updates are made to the source corresponding statements can be changed in the model as well implementation of scopes does not necessarily require fully reified statements some implementations allow a single scope identifier to be associated with a statement that has not been assigned a uri itself ref http uche ogbuji net tech akara nodes 2003 01 01 scopes the concept of 4suite rdf scopes ref ref http librdf org notes contexts html redland rdf library contexts ref likewise named graphs in which a set of triples is named by a uri can represent context without the need to reify the triples ref http www w3 org 2004 03 trix named graphs ref query and inference languages main rdf query language the predominant query language for rdf graphs is sparql sparql is an sql like language and a w3c recommendation recommendation of the w3c as of january 15 2008 an example of a sparql query to show country capitals in africa using a fictional ontology source lang sparql prefix ex http example com exampleontology select capital country where x ex cityname capital ex iscapitalof y y ex countryname country ex isincontinent ex africa source other non standard ways to query rdf graphs include rdql precursor to sparql sql like versa compact syntax non sql like solely implemented in 4suite python programming language python rql one of the first declarative languages for uniformly querying rdf schemas and resource descriptions implemented in rdfsuite ref name rql cite web title the rdf query language rql url http 139 91 183 30 9090 rdf rql index html work the ics forth rdfsuite publisher ics forth ref serql part of sesame framework sesame xul has a template element in which to declare rules for matching data in rdf xul uses rdf extensively for databinding examples example 1 rdf description of a person named eric miller ref name rdf primer cite web url http www w3 org tr rdf primer title rdf primer publisher w3c accessdate 2009 03 13 ref the following example is taken from the w3c website ref name rdf primer describing a resource with statements there is a person identified by nowiki http www w3 org people em contact me nowiki whose name is eric miller whose email address is e miller123 at example changed for security purposes and whose title is dr image rdf graph for eric miller png thumb an rdf graph describing eric miller ref name rdf primer the resource nowiki http www w3 org people em contact me nowiki is the subject the objects are eric miller with a predicate whose name is nowiki mailto e miller123 nowiki at example with a predicate whose email address is and dr with a predicate whose title is the subject is a uri the predicates also have uris for example the uri for each predicate whose name is is nowiki http www w3 org 2000 10 swap pim contact fullname nowiki whose email address is is nowiki http www w3 org 2000 10 swap pim contact mailbox nowiki whose title is is nowiki http www w3 org 2000 10 swap pim contact personaltitle nowiki in addition the subject has a type with uri nowiki http www w3 org 1999 02 22 rdf syntax ns type nowiki which is person with uri nowiki http www w3 org 2000 10 swap pim contact person nowiki therefore the following subject predicate object rdf triples can be expressed nowiki http www w3 org people em contact me http www w3 org 2000 10 swap pim contact fullname nowiki eric miller nowiki http www w3 org people em contact me http www w3 org 2000 10 swap pim contact mailbox mailto e miller123 at example nowiki nowiki http www w3 org people em contact me http www w3 org 2000 10 swap pim contact personaltitle nowiki dr nowiki http www w3 org people em contact me http www w3 org 1999 02 22 rdf syntax ns type http www w3 org 2000 10 swap pim contact person nowiki in standard n triples format this rdf can be written as source lang turtle http www w3 org people em contact me http www w3 org 2000 10 swap pim contact fullname eric miller http www w3 org people em contact me http www w3 org 2000 10 swap pim contact mailbox mailto e miller123 at example http www w3 org people em contact me http www w3 org 2000 10 swap pim contact personaltitle dr http www w3 org people em contact me http www w3 org 1999 02 22 rdf syntax ns type http www w3 org 2000 10 swap pim contact person source equivalently it can be written in standard turtle syntax format as source lang turtle prefix eric http www w3 org people em contact prefix contact http www w3 org 2000 10 swap pim contact prefix rdf http www w3 org 1999 02 22 rdf syntax ns eric me contact fullname eric miller eric me contact mailbox mailto e miller123 at example eric me contact personaltitle dr eric me rdf type contact person source or it can be written in rdf xml format as source lang xml enclose div xml version 1 0 encoding utf 8 rdf rdf xmlns contact http www w3 org 2000 10 swap pim contact xmlns eric http www w3 org people em contact xmlns rdf http www w3 org 1999 02 22 rdf syntax ns rdf description rdf about http www w3 org people em contact me contact fullname eric miller contact fullname rdf description rdf description rdf about http www w3 org people em contact me contact mailbox rdf resource mailto e miller123 at example rdf description rdf description rdf about http www w3 org people em contact me contact personaltitle dr contact personaltitle rdf description rdf description rdf about http www w3 org people em contact me rdf type rdf resource http www w3 org 2000 10 swap pim contact person rdf description rdf rdf source example 2 the postal abbreviation for new york certain concepts in rdf are taken from logic and linguistics where subject predicate and subject predicate object structures have meanings similar to yet distinct from the uses of those terms in rdf this example demonstrates in the english language statement new york has the postal abbreviation ny new york would be the subject has the postal abbreviation the predicate and ny the object encoded as an rdf triple the subject and predicate would have to be resources named by uris the object could be a resource or literal element for example in the n triples form of rdf the statement might look like source lang turtle urn x states new 20york http purl org dc terms alternative ny source in this example nowiki urn x states new 20york nowiki is the uri for a resource that denotes the us state new york state new york nowiki http purl org dc terms alternative nowiki is the uri for a predicate whose human readable definition can be found at here ref http dublincore org documents dcmi terms index shtml terms alternative dcmi metadata terms dublincore org retrieved on 2014 05 30 ref and ny is a literal string note that the uris chosen here are not standard and don t need to be as long as their meaning is known to whatever is reading them example 3 a wikipedia article about tony benn in a like manner given that nowiki http en wikipedia org wiki tony benn nowiki identifies a particular resource regardless of whether that uri could be traversed as a hyperlink or whether the resource is actually the wikipedia article about tony benn to say that the title of this resource is tony benn and its publisher is wikipedia would be two assertions that could be expressed as valid rdf statements in the n triples form of rdf these statements might look like the following source lang turtle http en wikipedia org wiki tony benn http purl org dc elements 1 1 title tony benn http en wikipedia org wiki tony benn http purl org dc elements 1 1 publisher wikipedia source to an english speaking person the same information could be represented simply as blockquote the title of this resource which is published by wikipedia is tony benn blockquote however rdf puts the information in a formal way that a machine can understand the purpose of rdf is to provide an semantics encoding encoding and interpretation mechanism so that resource computer science resources can be described in a way that particular software can understand it in other words so that software can access and use information that it otherwise couldn t use both versions of the statements above are wordy because one requirement for an rdf resource as a subject or a predicate is that it be unique the subject resource must be unique in an attempt to pinpoint the exact resource being described the predicate needs to be unique in order to reduce the chance that the idea of title or publisher will be ambiguous to software working with the description if the software recognizes nowiki http purl org dc elements 1 1 title nowiki a specific definition for the concept of a title established by the dublin core metadata initiative it will also know that this title is different from a land title or an honorary title or just the letters t i t l e put together the following example written in turtle shows how such simple claims can be elaborated on by combining multiple rdf vocabularies here we note that the primary topic of the wikipedia page is a person whose name is tony benn source lang turtle prefix rdf http www w3 org 1999 02 22 rdf syntax ns prefix foaf http xmlns com foaf 0 1 prefix dc http purl org dc elements 1 1 http en wikipedia org wiki tony benn dc publisher wikipedia dc title tony benn foaf primarytopic a foaf person foaf name tony benn source applications dbpedia extracts facts from wikipedia articles and publishes them as rdf data creative commons uses rdf to embed license information in web pages and mp3 files foaf software foaf friend of a friend designed to describe person people their interests and interconnections haystack pim haystack client semantic web browser from mit cs ai lab ref http groups csail mit edu haystack haystack ref ideas group developing a formal ontology components 4d ontology for enterprise architecture using rdf as the encoding ref http www ideasgroup org the ideas group website ref microsoft shipped a product connected services framework ref http www microsoft com serviceproviders solutions connectedservicesframework mspx connected services framework ref which provides rdf based profile management capabilities musicbrainz publishes information about music albums ref http wiki musicbrainz org rdf rdf on musicbrainz wiki ref nepomuk framework nepomuk an open source software specification for a social semantic desktop uses rdf as a storage format for collected metadata nepomuk is mostly known because of its integration into the kde software compilation 4 kde sc 4 desktop environment press association is a news agency in the uk they use ontologies to dynamically identify and link their nosql data to do semantic publishing but in a dynamic rules based way that creates custom content on the fly ref http www datalanguage com blog 2012 05 17 ontology driven software engineering ref rdf site summary one of several rss file format rss languages for publishing information about updates made to a web page it is often used for disseminating news article summaries and sharing weblog content simple knowledge organization system skos a kr representation intended to support vocabulary thesaurus applications sioc sioc semantically interlinked online communities designed to describe online communities and to create connections between internet based discussions from message boards weblogs and mailing lists ref http sioc project org sioc semantically interlinked online communities ref smart m3 provides an infrastructure for using rdf and specifically uses the ontology agnostic nature of rdf to enable heterogeneous mashing up of information ref oliver ian honkola jukka ziegler jurgen 2008 dynamic localized space based semantic webs iadis www internet 2008 proceedings p 426 iadis press isbn 978 972 8924 68 3 ref some uses of rdf include research into social networking it will also help people in business fields understand better their relationships with members of industries that could be of use for product placement ref an rdf approach for discovering the relevant semantic associations in a social network by thushar a k and p santhi thilagam ref it will also help scientists understand how people are connected to one another rdf is being used to have a better understanding of road traffic patterns this is because the information regarding traffic patterns is on different websites and rdf is used to integrate information from different sources on the web before the common methodology was using keyword searching but this method is problematic because it does not consider synonyms this is why ontologies are useful in this situation but one of the issues that comes up when trying to efficiently study traffic is that to fully understand traffic concepts related to people streets and roads must be well understood since these are human concepts they require the addition of fuzzy logic this is because values that are useful when describing roads like slipperiness are not precise concepts and cannot be measured this would imply that the best solution would incorporate both fuzzy logic and ontology ref traffic information retrieval based on fuzzy ontology and rdf on the semantic web by jun zhai yi yu yiduo liang and jiatao jiang 2008 ref see also notations for rdf trig syntax trig trix syntax trix rdf xml rdfa json ld similar concepts entity attribute value model graph theory an rdf model is a labeled directed multi graph website parse template tag metadata tagging scicrunch semantic network other unsorted associative model of data business intelligence 2 0 bi 2 0 dataportability eu open data portal folksonomy lsid life science identifiers swoogle universal networking language unl references reflist 2 further reading http www w3 org rdf w3c s rdf at w3c specifications guides and resources http www w3 org tr 2004 rec rdf mt 20040210 rdf semantics specification of semantics and complete systems of inference rules for both rdf and rdfs external links commons category resource description framework dmoz reference libraries library and information science technical services cataloguing metadata rdf semantic web w3c standards data exchange authority control category resource description framework category knowledge representation category world wide web consortium standards category xml category xml based standards category metadata category semantic web category bibliography file formats'
b'use dmy dates date may 2014 cds isis is a software package for generalised information storage and retrieval systems developed maintained and disseminated by unesco it was first released in 1985 and since then over 20 000 license licences have been issued by unesco and a worldwide network of distributors it is particularly suited to bibliographical applications and is used for the library catalog catalogues of many small and medium sized library libraries versions have been produced in arabic chinese english french german portuguese russian and spanish amongst other languages unesco makes the software available free for non commercial purposes though distributors are allowed to charge for their expenses cds isis is an acronym which stands for computerised documentation service integrated set of information systems in 2003 it was stated that this package is accepted by libraries in the developing countries as a standard software for information system development ref national science foundation of sri lanka cds isis library software last update 10 january 2003 http www nsf ac lk slstic isis htm accessed 20 june 2007 ref the original cds isis ran on an ibm mainframe computer mainframe and was designed in the mid 1970s under mr giampaolo del bigio for unesco s computerized documentation system cds it was based on the internal isis integrated set of information systems at the international labour organization in geneva in 1985 a version was produced for mini and microcomputers programmed in pascal it ran on an ibm pc under ms dos ref buxton andrew and hopkinson alan the cds isis handbook london library association 1994 ref winisis the microsoft windows windows version first demonstrated in 1995 may run on a single computer or in a local area network a javaisis client server component was designed in 2000 allowing remote database management system database management over the internet from microsoft windows windows linux and apple macintosh macintosh computers furthermore genisis allows the user to produce html web forms for cds isis database searching the isis dll provides an api for developing cds isis based applications the openisis library developed independently from 2002 to 2004 provided another api for developing cds isis like applications the most recent effort towards a completely renewed free and open source software foss unicode implementation of cds isis is the j isis project developed by unesco since 2005 and currently maintained by mr jean claude dauphin see also idis software idis is a tool for direct data exchange between cds isis and idams external links http kenai com projects j isis j isis new unesco java cds isis software http portal unesco org ci en ev php url id 2071 url do do topic url section 201 html cds isis database software unesco http lists iccisis org international list hosted from 2010 by the iccisis international coordination committee on isis https listserv surfnet nl archives cds isis html archives of cds isis nic surfnet nl discontinued in 2010 http openisis org discontinued http sourceforge net projects isis discontinued http pecl php net package isis php extension for reading cds isis databases references reflist category knowledge representation category proprietary database management systems'
b'infobox person name john f sowa image image size caption birth name john florian sowa birth date birth date and age mf yes 1940 1 1 birth place death date death place death cause resting place residence croton on hudson new york nationality other names known for conceptual graph s education massachusetts institute of technology bs 1962 harvard university ma 1966 vrije universiteit brussel phd 1999 alma mater employer occupation computer scientist boards religion spouse cora angier sowa children parents relations callsign awards signature website url http www jfsowa com jfsowa com john florian sowa born 1940 is an american computer scientist an expert in artificial intelligence and computer design and the inventor of conceptual graph s ref kecheng liu 2000 semiotics in information systems engineering p 54 states conceptual graphs are devised as a language of knowledge representation by sowa 1984 based on philosophy psychology and linguistics knowledge in conceptual graph form is highly structured by modelling specialised facts that can be subjected to generalised reasoning ref ref marite kirikova 2002 information systems development advances in methodologies components and management p 194 states the original theory of conceptual graphs was introduced by sowa sowa 1984 a conceptual graph is a finite connected bipartite graph it includes notions of concepts relations and actors ref biography sowa received a bs in mathematics from massachusetts institute of technology in 1962 an ma in applied mathematics from harvard university in 1966 and a phd in computer science from the vrije universiteit brussel in 1999 on a dissertation titled knowledge representation logical philosophical and computational foundations ref andreas tolk lakhmi c jain 2011 intelligent based systems engineering p xxi ref sowa spent most of his professional career at international business machines ibm which started in 1962 at ibm s applied mathematics group over the decades he has researched and developed emerging fields of computer science from compiler programming languages and system architecture ref name soza92 john f sowa and john zachman 1992 http www research ibm com journal sj 313 sowa pdf extending and formalizing the framework for information systems architecture in ibm systems journal vol 31 no 3 1992 p 590 616 ref to artificial intelligence and knowledge representation in the 1990s sowa was associated with ibm educational center in new york over the years he taught courses at the ibm systems research institute binghamton university stanford university linguistic society of america and universit\xc3\xa9 du qu\xc3\xa9bec \xc3\xa0 montr\xc3\xa9al he is a fellow of the association for the advancement of artificial intelligence after early retirement at ibm sowa in 2001 cofounded vivomind intelligence inc with arun k majumdar with this company he was developing data mining and database technology more specific high level ontology ontologies for artificial intelligence and automated natural language understanding currently sowa is working with http kyndi com kyndi inc also founded by majumdar john sowa is married to the philologist cora angier sowa ref cora angier sowa 1984 traditional themes and the homeric hymns p iv ref and they live in croton on hudson new york work sowa s research interest since the 1970s were in the field of artificial intelligence expert systems and database query linked to natural languages ref name soza92 in his work he combines ideas from numerous disciplines and eras modern and ancient for example applying ideas from aristotle the medieval scholastics to alfred north whitehead and including logical schema database schema theory and incorporating the model of analogy of islamic scholar ibn taymiyyah in his works ref http www jfsowa com pubs analog htm analogical reasoning ref conceptual graph main conceptual graph sowa invented conceptual graphs a graphic notation for logic and natural language based on the structures in semantic network s and on the existential graph s of charles sanders peirce charles s peirce he published the concept in the 1976 article conceptual graphs for a data base interface in the ibm journal of research and development ref cite journal last sowa authorlink first john f date july 1976 title conceptual graphs for a data base interface journal ibm journal of research and development volume 20 issue 4 pages 336 357 url http www research ibm com journal rd 204 ibmrd2004e pdf ref harv doi 10 1147 rd 204 0336 ref he further explained in the 1983 book conceptual structures information processing in mind and machine in the 1980s this theory has been adopted by a number of research and development groups throughout the world ref name soza92 international conferences on conceptual graphs have been held for over a decade since before 1992 citation needed date november 2012 anchor law of standards sowa s law of standards in 1991 sowa first stated his law of standards whenever a major organization develops a new system as an official technical standard standard for x the primary result is the widespread adoption of some simpler system as a de facto standard for x ref http www jfsowa com computer standard htm law of standards ref like gall s law the law of standards is essentially an argument in favour of underspecification examples include the introduction of pl i resulting in cobol and fortran becoming the de facto standards for scientific and business programming the introduction of algol 68 resulting in pascal programming language pascal becoming the de facto standard for academic programming the introduction of the ada programming language ada language resulting in c programming language c becoming the de facto standard for united states department of defense dod programming the introduction of os 2 resulting in microsoft windows windows becoming the de facto standard for desktop os the introduction of x 400 resulting in smtp becoming the de facto standard for electronic mail the introduction of x 500 resulting in ldap becoming the de facto standard for directory services publications 1984 conceptual structures information processing in mind and machine the systems programming series addison wesley ref http conceptualstructures org conceptual structures home page retrieved nov 23 2012 ref 1991 principles of semantic networks morgan kaufmann cite journal editor1 last mineau editor1 first guy w editor2 last moulin editor2 first bernard editor3 last sowa editor3 first john f editor3 link john f sowa title conceptual graphs for knowledge representation doi 10 1007 3 540 56979 0 series lecture notes in computer science lncs volume 699 year 1993 isbn 978 3 540 56979 4 1994 international conference on conceptual structures 2nd 1994 college park md conceptual structures current practices second international conference on conceptual structures iccs 94 college park maryland usa august 16 20 1994 proceedings william m tepfenhart judith p dick john f sowa eds cite journal editor1 last ellis editor1 first gerard editor2 last levinson editor2 first robert editor3 last rich editor3 first william editor4 last sowa editor4 first john f editor4 link john f sowa doi 10 1007 3 540 60161 9 title conceptual structures applications implementation and theory series lecture notes in computer science lncs volume 954 year 1995 isbn 978 3 540 60161 6 cite journal editor1 last lukose editor1 first dickson editor2 last delugach editor2 first harry editor3 last keeler editor3 first mary editor4 last searle editor4 first leroy editor5 last sowa editor5 first john editor5 link john f sowa doi 10 1007 bfb0027865 title conceptual structures fulfilling peirce s dream series lecture notes in computer science lncs volume 1257 year 1997 isbn 3 540 63308 1 2000 knowledge representation logical philosophical and computational foundations brooks cole publishing co pacific grove ref http www jfsowa com krbook knowledge representation logical philosophical and computational foundations at jfsowa com retrieved nov 23 2012 ref articles a selection ref dblp name john f sowa ref cite journal last1 sowa first1 j f author1 link john f sowa title conceptual graphs for a data base interface doi 10 1147 rd 204 0336 journal ibm journal of research and development volume 20 issue 4 pages 336 357 date july 1976 cite journal last1 sowa first1 j f author1 link john f sowa last2 zachman first2 j a doi 10 1147 sj 313 0590 title extending and formalizing the framework for information systems architecture journal ibm systems journal volume 31 issue 3 pages 590 616 year 1992 1992 http www jfsowa com cg cgif htm conceptual graph summary in t e nagle et al eds conceptual structures current research and practice chichester ellis horwood 1995 top level ontological categories in international journal of human computer studies vol 43 iss 5 6 nov 1995 pp nbsp 669 685 2006 semantic networks in encyclopedia of cognitive science john wiley sons references reflist external links wikiquote http www jfsowa com john f sowa homepage authority control defaultsort sowa john category 1940 births category artificial intelligence researchers category knowledge representation category living people category people from croton on hudson new york category harvard university alumni category binghamton university faculty'
b'information science the philosophy of information pi is the area of research that studies conceptual issues arising at the intersection of computer science information science information technology and philosophy it includes the critical investigation of the conceptual nature and basic principles of information including its dynamics utilisation and sciences the elaboration and application of information theoretic and computational methodologies to philosophical problems ref luciano floridi http www blackwellpublishing com pci downloads introduction pdf what is the philosophy of information metaphilosophy 2002 33 1 2 ref history the philosophy of information pi has evolved from the philosophy of artificial intelligence logic of information cybernetics social theory ethics and the study of language and information logic of information the logic of information also known as the logical theory of information considers the information content of logical sign semiotics sign s and expressions along the lines initially developed by charles sanders peirce cybernetics one source for the philosophy of information can be found in the technical work of norbert wiener alan turing though his work has a wholly different origin and theoretical framework william ross ashby claude shannon warren weaver and many other scientists working on computing and information theory back in the early 1950s see the main article on cybernetics some important work on information and communication was done by gregory bateson and his colleagues study of language and information later contributions to the field were made by fred dretske jon barwise brian cantwell smith and others the center for the study of language and information center for the study of language and information csli was founded at stanford university in 1983 by philosophers computer scientists linguists and psychologists under the direction of john perry philosopher john perry and jon barwise p i more recently this field has become known as the philosophy of information the expression was coined in the 1990s by luciano floridi who has published prolifically in this area with the intention of elaborating a unified and coherent conceptual frame for the whole subject citation needed date april 2015 definitions of information the concept information has been defined by several theorists peirce charles s peirce s theory of information was embedded in his wider theory of symbolic communication he called the semeiotic now a major part of semiotics for peirce information integrates the aspects of sign s and expression mathematics expressions separately covered by the concepts of denotation and extension semantics extension on the one hand and by connotation and comprehension logic comprehension on the other shannon and weaver claude e shannon for his part was very cautious the word information has been given different meanings by various writers in the general field of information theory it is likely that at least a number of these will prove sufficiently useful in certain applications to deserve further study and permanent recognition it is hardly to be expected that a single concept of information would satisfactorily account for the numerous possible applications of this general field shannon 1993 p nbsp 180 full citation needed date april 2015 thus following shannon weaver supported a tripartite analysis of information in terms of 1 technical problems concerning the quantification of information and dealt with by shannon s theory 2 semantic problems relating to meaning and truth and 3 what he called influential problems concerning the impact and effectiveness of information on human behaviour which he thought had to play an equally important role and these are only two early examples of the problems raised by any analysis of information a map of the main senses in which one may speak of information is provided by http plato stanford edu entries information semantic the stanford encyclopedia of philosophy article the previous paragraphs are based on it bateson gregory bateson defined information as a difference that makes a difference ref http plato acadiau ca courses educ reid papers pme25 ws4 sem html extract from steps to an ecology of mind ref which is based on donald m mackay information is a distinction that makes a difference ref the philosophy of information luciano floridi chapter 4 oxford university press usa march 8 2011 asin 0199232385 http www amazon com philosophy information luciano floridi dp 0199232385 ref floridi according to luciano floridi citation needed date april 2015 four kinds of mutually compatible phenomena are commonly referred to as information information about something e g a train timetable information as something e g dna or fingerprints information for something e g algorithms or instructions information in something e g a pattern or a constraint the word information is commonly used so metaphorically or so abstractly that the meaning is unclear philosophical directions computing and philosophy recent creative advances and efforts in computing such as semantic web ontology engineering knowledge engineering and modern artificial intelligence provide philosophy with fertile notions new and evolving subject matters methodologies and models for philosophical inquiry while computer science brings new opportunities and challenges to traditional philosophical studies and changes the ways philosophers understand foundational concepts in philosophy further major progress in computer science would only be feasible when philosophy provides sound foundations for areas such as bioinformatics software engineering knowledge engineering and ontologies classical topics in philosophy namely mind consciousness experience reasoning knowledge truth morality and creativity are rapidly becoming common concerns and foci of investigation in computer science e g in areas such as agent computing software agents and intelligent mobile agent technologies citation needed date december 2012 according to luciano floridi ref luciano floridi http www philosophyofinformation net publications pdf oppi pdf open problems in the philosophy of information metaphilosophy 35 4 554 582 revised version of the herbert a simon lecture on computing and philosophy given at carnegie mellon university in 2001 with http ethics sandiego edu video cap cmu2001 floridi index html realvideo ref one can think of several ways for applying computational methods towards philosophical matters conceptual experiments in silico as an innovative extension of an ancient tradition of thought experiment a trend has begun in philosophy to apply computational computer model modeling schemes to questions in logic epistemology philosophy of science philosophy of biology philosophy of mind and so on digital physics pancomputationalism or the computational universe theory pancomputationalism by this view computational and informational concepts are considered to be so powerful that given the right level of abstraction anything in the world could be modeled and represented as a computational system and any process could be simulated computationally then however pancomputationalists have the hard task of providing credible answers to the following two questions how can one avoid blurring all differences among systems what would it mean for the system under investigation not to be an information system informational system or a computational system if computation is the same as information processing information and society numerous philosophers and other thinkers have carried out philosophical studies of the social and cultural aspects of electronically mediated information albert borgmann holding onto reality the nature of information at the turn of the millennium chicago university press 1999 mark poster the mode of information chicago press 1990 luciano floridi the informational nature of reality fourth international european conference on computing and philosophy 2006 dragvoll campus ntnu norwegian university for science and technology trondheim norway 22 24 june 2006 see also col begin col break barwise prize complex system digital divide digital philosophy digital physics game theory freedom of information informatics academic field informatics col break information information art information ethics information theory international association for computing and philosophy logic of information col break philosophy of artificial intelligence philosophy of computer science philosophy of technology philosophy of thermal and statistical physics physical information relational quantum mechanics social informatics statistical mechanics col end notes reflist further reading luciano floridi http www blackwellpublishing com pci downloads introduction pdf what is the philosophy of information metaphilosophy 33 1 2 123 145 reprinted in t w bynum and j h moor eds 2003 cyberphilosophy the intersection of philosophy and computing oxford new york blackwell ed 2004 http www blackwellpublishing com pci default htm the blackwell guide to the philosophy of computing and information oxford new york blackwell greco g m paronitti g turilli m and floridi l 2005 http www wolfson ox ac uk floridi pdf htdpi pdf how to do philosophy informationally lecture notes on artificial intelligence 3782 pp nbsp 623 634 external links library resources box cite sep url id information title information last adriaans first peter editor last zalta editor first edward n date autumn 2013 cite sep url id information semantic title semantic conceptions of information last floridi first luciano editor last zalta editor first edward n date spring 2015 http web comlab ox ac uk oucl research areas ieg ieg site the oxford university research group on the philosophy of information luciano floridi https web archive org web 20060820223325 http academicfeeds friwebteknologi org index php id 28 where are we in the philosophy of information university of bergen norway podcast dated 21 06 06 navboxes list philosophy topics philosophy of language philosophy of mind philosophy of science category philosophy by topic inf category philosophy of artificial intelligence category knowledge representation'
b'findability is a term for the ease with which information contained on a website can be found both from outside the website using search engine s and the like and by users already on the website ref cite journal url title information architecture author1 jacob elin k author2 loehrlein aaron date 2009 journal annual review of information science and technology doi 10 1002 aris 2009 1440430110 pmid access date publication date ref although findability has relevance outside the world wide web the term is usually used in that context most relevant websites do not come up in the top results because designers and engineers do not cater to the way ranking algorithms work currently ref cite book title ambient findability last morville first peter publisher oreilly year 2005 isbn 978 0 596 00765 2 location sebastopol ca pages quote via ref its importance can be determined from the first law of e commerce which states if the user can t find the product the user can t buy the product ref cite web url http www nngroup com reports ecommerce title e commerce user experience high level strategy nielsen norman group date 2001 accessdate website publisher ref as of december 2014 out of 10 3 billion monthly google searches by internet users in the united states an estimated 78 are made to research products and services online ref cite web url http www cmocouncil org facts stats categories php category internet marketing title internet marketing date accessdate website publisher ref findability encompasses aspects of information architecture user interface design accessibility and search engine optimization seo among others introduction findability is similar to but different from discoverability which is defined as the ability of something especially a piece of content or information to be found it is different from web search in that the word find refers to locating something in a known space while search is in an unknown space or not in an expected location ref name every page mark baker the author of every page is page one ref name every page cite book title every page is page one last baker first mark publisher xml press year 2013 isbn 978 1937434281 location pages ref mentions that findability is a content problem not a search problem ref cite web last1 baker first1 mark title findability is a content problem not a search problem url http everypageispageone com 2013 05 28 findability is a content problem not a search problem website every page is page one accessdate 2015 04 25 ref even when the right content is present users often find themselves deep within the content of a website but not in the right place he further adds that findability is intractable perfect findability is unattainable but we need to focus on reducing the effort for finding that a user would have to do for themselves findability can be divided into external findability and on site findability based on where the customers need to find the information history heather lutze is thought to have created the term in the early 2000s ref cite web url http www huffingtonpost com liz wainger the shtickiness factor b 3471675 html title the shtickiness factor last1 wainger first1 liz publisher the huffington post date 20 june 2013 accessdate 12 september 2013 ref the popularization of the term findability for the web is usually credited to peter morville citation needed date april 2015 in 2005 he defined it as the ability of users to identify an appropriate web site and navigate the pages of the site to discover and retrieve relevant information resources though it appears to have been first coined in a public context referring to the web and information retrieval by alkis papadopoullos in a 2005 article entitled findability ref cite journal author alkis papadopoulos title the key to enterprise search journal km world date april 1 2005 url http news business vlex com vid findability key to enterprise search 62406335 ref ref though the word has been used to mean ease of finding information since at least 1943 see urban a avery the findability of the law chicago bar record 24 272 april 1943 reprinted in the journal of the american judicature society 27 25 http heinonline org hol landingpage collection journals handle hein journals judica27 div 12 id page ref external findability external findability is the domain of internet marketing and search engine optimization search engine optimization seo tactics several factors affect external findability ref cite web title findability factors found url http www econtentstrategies com article findabilityfactorsfoundfinal econtent 200701 pdf ref search engine indexing as the very first step webpages need to be found by indexing crawler in order to be shown in the search results it would be helpful to avoid factors that may lead to webpages being ignored by indexing crawlers those factors may include elements that require user interaction such as entering log in credentials algorithms for indexing vary by the search engine which means the number of webpages of a website successfully being indexed may be very different between google and yahoo s search engines also in countries like china great firewall government policies could significantly influence the indexing algorithms in this case local knowledge about laws and policies could be valuable ref cite web title online marketing in china url http chineseseoshifu com china online marketing ref page descriptions in search results now that the webpages are successfully indexed by web crawlers and show in the search results with decent ranking the next step is to attract customers to click the link to the web pages however the customers can t see the whole web pages at this point they can only see an excerpt of the webpage s content and metadata therefore displaying meaningful information in a limited space usually a couple of sentences in search results is important for increasing click traffic of the webpages and thus the findability of the web content on your webpages keyword matching at a semantic level terminology used by the searcher and the content producer be different bridging the gap between the terms used by customers and developers is helpful for making web content more findable to more potential content consumers on site findability on site findability is concerned with the ability of a potential customer to find what they are looking for within a specific site more than 90 percent of customers use internal searches in a website compared to browsing of those only 50 percent find what they are looking for ref name findability solution cite web title the findability solution url http marriottschool byu edu strategy docs thefindabilitysolution strategywhitepaper pdf ref improving the quality of on site searches highly improves the business of the website several factors affect findability on a website site search if searchers within a site do not find what they are looking for they tend to leave rather than browse through the website users who had successful site searches are twice as likely to ultimately convert ref name findability solution related links and products user experience can be enhanced by trying to understand the needs of the customer and provide suggestions for other related information site match to customer needs and preferences site design content creation and recommendations are major factors for affecting the customer experience cross device experience with the rise of computing devices other than desktop computers companies like microsoft have focused more on smoothing the transition between devices to increase customer satisfaction ref cite web url http research microsoft com en us projects courier title cross device user experiences date accessdate website publisher ref evaluation and measures baseline findability is the existing findability before changes are made in order to improve it this is measured by participants who represent the customer base of the website who try to locate a sample set of items using the existing navigation of the website ref cite book title customer analytics for dummies last sauro first jeff publisher john wiley sons year isbn 978 1 118 93759 4 location pages url http www wiley com wileycda wileytitle productcd 1118937597 html ref ref cite web url http www measuringu com blog measure findability php title how to measure findability date accessdate website publisher ref in order to evaluate how easily information can be found by searching a site using a search engine or information retrieval system retrievability measures were developed and similarly navigability measures now measure ease of information access through browsing a site e g pagerank mnav infoscent see information foraging information foraging etc findability also can be evaluated via the following techniques usability testing conducted to find out how and why users navigate through a website to accomplish tasks tree testing an information architecture based technique to determine if critical information can be found on the website card sorting closed card sorting a usability technique based on information architecture for evaluating the strength of categories click testing accounts for the implicit data collected through clicks on the user interface ref cite web url http www nngroup com articles navigation ia tests title low findability and discoverability four testing methods to identify the causes date july 6 2014 accessdate website publisher ref beyond findability findability sciences defines a findability index in terms of each user s influence context and sentiments for seamless search current websites focus on a combination of structured hypertext based information architectures and rich internet application enabled visualization techniques ref cite journal url http journalofia org volume2 issue1 03 spagnolo title beyond findability search enhanced information architecture for content intensive rich internet applications date 2010 journal doi pmid access date ref see also information retrieval knowledge mining search engine optimization subject documents usability user interface references reflist further reading morville p 2005 ambient findability sebastopol ca o reilly wurman r s 1996 information architects new york graphis external links http findability org findability org a collection of links to people software organizations and content related to findability http semanticstudios com publications semantics 000007 php the age of findability article http www useit com alertbox search keywords html use old words when writing for findability article on the findability impact of a site s choice of words http buildingfindablewebsites com building findable websites web standards seo and beyond book http www findabilityformula com the findability formula the easy non technical guide to search engine marketing by heather lutze category web design category knowledge representation category information science category information architecture'
b'conceptual graphs cgs are a formalism for knowledge representation in the first published paper on cgs john f sowa harv sowa 1976 used them to represent the conceptual schema s used in database system s the first book on cgs harv sowa 1984 applied them to a wide range of topics in artificial intelligence computer science and cognitive science since 1984 the model has been developed along three main directions a graphical interface for first order logic in this approach a formula in first order logic predicate calculus is represented by a labeled graph a linear notation called the conceptual graph interchange format cgif has been standardized in the iso standard for common logic image cat on mat svg thumb 250px elsie the cat is sitting on a mat the diagram on the right is an example of the display form for a conceptual graph each box is called a concept node and each oval is called a relation node in cgif this cg would be represented by the following statement cat elsie sitting x mat y agent x elsie location x y in cgif brackets enclose the information inside the concept nodes and parentheses enclose the information inside the relation nodes the letters x and y which are called coreference labels show how the concept and relation nodes are connected in the common logic interchange format clif those letters are mapped to variables as in the following statement exists x sitting y mat and cat elsie agent x elsie location x y as this example shows the asterisks on the coreference labels x and y in cgif map to existentially quantified variables in clif and the question marks on x and y map to bound variables in clif a universal quantifier represented every z in cgif would be represented forall z in clif reasoning can be done by translating graphs into logical formulas then applying a logical inference engine diagrammatic calculus of logics another research branch continues the work on existential graph s of charles sanders peirce which were one of the origins of conceptual graphs as proposed by sowa in this approach developed in particular by dau harv dau 2003 conceptual graphs are conceptual diagram s rather than graphs in the sense of graph theory and reasoning operations are performed by operations on these diagrams graph based knowledge representation and reasoning model key features of gbkr the graph based knowledge representation and reasoning model developed by chein and mugnier and the montpellier group harv chein mugnier 2009 can be summarized as follows all kinds of knowledge ontology rules constraints and facts are labeled graphs which provide an intuitive and easily understandable means to represent knowledge reasoning mechanisms are based on graph notions basically the classical notion of graph homomorphism this allows in particular to link basic reasoning problems to other fundamental problems in computer science problems concerning conjunctive queries in relational databases constraint satisfaction problem the formalism is logically founded i e it has a semantics in first order logic and the inference mechanisms are sound and complete with respect to deduction in first order logic from a computational viewpoint the graph homomorphism notion was recognized in the 1990s as a central notion and complexity results and efficient algorithms have been obtained in several domains cogitant and cogui are tools that implement the gbkr model cogitant is a library of c classes that implement most of the gbkr notions and reasoning mechanisms cogui is a graphical user interface dedicated to the construction of a gbkr knowledge base it integrates cogitant and among numerous functionalities it contains a translator from gbkr to rdf s and conversely sentence generalization and generalization diagrams sentence generalization and generalization diagrams can be defined as a special sort of conceptual graphs which can be constructed automatically from syntactic parse tree s and support semantic classification task harv galitsky et al 2010 similarity measure between syntactic parse trees can be done as a generalization operation on the lists of sub trees of these trees the diagrams are representation of mapping between the syntax generalization level and semantics generalization level anti unification of logic forms generalization diagrams are intended to be more accurate semantic representation than conventional conceptual graphs for individual sentences because only syntactic commonalities are represented at semantic level see also resource description framework rdf sparql graph query language semantic network knowledge representation chunking psychology concept map conceptual schema diagrammatic reasoning references cite book last chein first michel last2 mugnier first2 marie laure year 2009 title graph based knowledge representation computational foundations of conceptual graphs publisher springer url http www lirmm fr gbkrbook isbn 978 1 84800 285 2 ref harv doi 10 1007 978 1 84800 286 9 cite journal last dau first f year 2003 title the logic system of concept graphs with negation and its relationship to predicate logic journal lecture notes in computer science volume 2892 publisher springer isbn ref harv cite journal last sowa authorlink john sowa first john f date july 1976 title conceptual graphs for a data base interface journal ibm journal of research and development volume 20 issue 4 pages 336 357 url http www research ibm com journal rd 204 ibmrd2004e pdf ref harv doi 10 1147 rd 204 0336 cite book last sowa first john f year 1984 title conceptual structures information processing in mind and machine location reading ma publisher addison wesley isbn 978 0 201 14472 7 ref harv cite journal last galitsky first boris last2 dobrocsi first2 gabor last3 de la rosa first3 josep lluis last4 kuznetsov first4 sergei o year 2010 title from generalization of syntactic parse trees to conceptual graphs journal lecture notes in computer science volume 6208 publisher springer isbn url http dl acm org citation cfm id 1881190 ref harv cite journal title conceptual graphs for the analysis and generation of sentences first1 paola last1 velardi first2 maria teresa last2 pazienza first3 mario last3 de giovanetti journal ibm journal of research and development volume 32 number 2 date march 1988 pages 251 267 publisher ibm corp riverton nj usa doi 10 1147 rd 322 0251 external links http conceptualstructures org conceptual structures home page old site http conceptualgraphs org conceptual graphs home page http www informatik uni trier de ley db conf iccs index html yearly international conferences iccs http www jfsowa com cg index htm conceptual graphs on john f sowa s website category knowledge representation category diagrams category application specific graphs'
b'duplication dupe frame artificial intelligence a frame language is a technology used for knowledge representation in artificial intelligence frames are stored as ontology information science ontologies of set theory sets and subsets of the frame artificial intelligence frame concepts they are similar to class hierarchies in object oriented languages although their fundamental design goals are different frames are focused on explicit and intuitive representation of knowledge whereas objects focus on encapsulation object oriented programming encapsulation and information hiding frames originated in ai research and objects primarily in software engineering however in practice the techniques and capabilities of frame and object oriented languages overlap significantly description early work on frames was inspired by psychological research going back to the 1930s that indicated people use stored stereotypical knowledge to interpret and act in new cognitive situations ref cite book last bartlett first f c title remembering a study in experimental and social psychology year 1932 publisher cambridge university press location cambridge england ref the term frame was first used by marvin minsky as a paradigm to understand visual reasoning and natural language processing ref cite book last minsky first marvin title the psychology of computer vision year 1975 publisher mcgraw hill location new york pages 211 277 editor pat winston chapter a framework for representing knowledge ref in these and many other types of problems the potential solution space for even the smallest problem is huge for example extracting the phonemes from a raw audio stream or detecting the edges of an object things which seem trivial to humans are actually quite complex in fact how difficult they really were was probably not fully understood until ai researchers began to investigate the complexity of getting computers to solve them the initial notion of frames or scripts as they were also called is that they would establish the context for a problem and in so doing automatically reduce the possible search space significantly the idea was also adopted by schank and abelson who used it to illustrate how an ai system could process common human interactions such as ordering a meal at a restaurant ref cite book last schank first roger title scripts plans goals and understanding year 1977 publisher lawrence erlbaum location hillsdale new jersey author2 r p abelson ref these interactions were standardized as frames with slots that stored relevant information about each frame slots are analogous to object properties in object oriented modeling and to relations in entity relation models slots often had default values but also required further refinement as part of the execution of each instance of the scenario i e the execution of a task such as ordering at a restaurant was controlled by starting with a basic instance of the frame and then instantiating and refining various values as appropriate essentially the abstract frame represented an object class and the frame instances an object instance in this early work the emphasis was primarily on the static data descriptions of the frame various mechanisms were developed to define the range of a slot default values etc however even in these early systems there were procedural capabilities one common technique was to use triggers similar to the database concept of triggers attached to slots a trigger was simply procedural code that was attached to a slot the trigger could fire either before and or after a slot value was accessed or modified as with object classes frames were organized in subsumption relation subsumption hierarchies for example a basic frame might be ordering at a restaurant an instance of that would be joe goes to mcdonalds a specialization essentially a subclass computer science subclass of the restaurant frame would be a frame for ordering at a fancy restaurant the fancy restaurant frame would inherit all the default values from the restaurant frame but also would either add more slots or change one or more of the default values e g expected price range for the specialized frame ref cite book last feigenbaum first edward title the handbook of artificial intelligence volume iii publisher addison wesley isbn 0201118114 pages 216 222 url https archive org stream handbookofartific01barr page 156 mode 2up author2 avron barr date september 1 1986 ref ref cite journal last bobrow first d g author2 terry winograd title an overview of krl a knowledge representation language journal cognitive science year 1977 volume 1 pages 3 46 doi 10 1207 s15516709cog0101 2 ref much of the early frame language research e g schank and abelson had been driven by findings from experimental psychology and attempts to design knowledge representation tools that corresponded to the patterns humans were thought to use to function in daily tasks these researchers were less interested in mathematical formality since they believed such formalisms were not necessarily good models for the way the average human conceptualizes the world the way humans use language for example is often far from truly logical similarly in linguistics charles j fillmore in the mid 1970s started working on his theory of frame semantics linguistics frame semantics which later would lead to computational resources like framenet ref cite news last lakoff first george title charles fillmore discoverer of frame semantics dies in sf at 84 he figured out how framing works url http www huffingtonpost com george lakoff charles fillmore discover b 4807590 html accessdate 7 march 2014 newspaper the huffington post date 18 february 2014 ref frame semantics was motivated by reflections on human language and human cognition researchers such as ron brachman on the other hand wanted to give ai researchers the mathematical formalism and computational power that were associated with logic their aim was to map the frame classes slots constraints and rules in a frame language to set theory and logic one of the benefits of this approach is that the validation and even creation of the models could be automated using theorem provers and other automated reasoning capabilities the drawback was that it could be more difficult to initially specify the model in a language with a formal semantics this evolution also illustrates a classic divide in ai research known as the neats vs scruffies the neats were researchers who placed the most value on mathematical precision and formalism which could be achieved via first order logic and set theory the scruffies were more interested in modeling knowledge in representations that were intuitive and psychologically meaningful to humans ref cite book last crevier first daniel title ai the tumultuous search for artificial intelligence year 1993 publisher basic books location new york isbn 0 465 02997 3 page 168 ref the most notable of the more formal approaches was the kl one language ref cite journal last brachman first ron title a structural paradigm for representing knowledge journal bolt beranek and neumann technical report year 1978 issue 3605 ref kl one later went on to spawn several subsequent frame languages the formal semantics of languages such as kl one gave these frame languages a new type of automated reasoning capability known as the deductive classifier classifier the classifier is an engine that analyzes the various declarations in the frame language the definition of sets subsets relations etc the classifier can then automatically deduce various additional relations and can detect when some parts of a model are inconsistent with each other in this way many of the tasks that would normally be executed by forward or backward chaining in an inference engine can instead be performed by the classifier ref cite journal last macgregor first robert title using a description classifier to enhance knowledge representation journal ieee expert date june 1991 volume 6 issue 3 url http ieeexplore ieee org xpl login jsp tp arnumber 87683 url http 3a 2f 2fieeexplore ieee org 2fxpls 2fabs all jsp 3farnumber 3d87683 accessdate 10 november 2013 doi 10 1109 64 87683 pages 41 46 ref this technology is especially valuable in dealing with the internet it is an interesting result that the formalism of languages such as kl one can be most useful dealing with the highly informal and unstructured data found on the internet on the internet it is simply not feasible to require all systems to standardize on one data model it is inevitable that terminology will be used in multiple inconsistent forms the automatic classification capability of the classifier engine provides ai developers with a powerful toolbox to help bring order and consistency to a very inconsistent collection of data i e the internet the vision for an enhanced internet where pages are ordered not just by text keywords but by classification of concepts is known as the semantic web classification technology originally developed for frame languages is a key enabler of the semantic web ref cite journal last berners lee first tim author2 james hendler author3 ora lassila title the semantic web a new form of web content that is meaningful to computers will unleash a revolution of new possibilities journal scientific american date may 17 2001 url http www cs umd edu golbeck lbsc690 semanticweb html doi 10 1038 scientificamerican0501 34 volume 284 pages 34 43 deadurl yes archiveurl https web archive org web 20130424071228 http www cs umd edu 7egolbeck lbsc690 semanticweb html archivedate 2013 04 24 df ref ref cite web last horridge first mathew title prot\xc3\xa9g\xc3\xa9 owl tutorial a step by step guide to modelling in owl using the popular prot\xc3\xa9g\xc3\xa9 owl tools url http 130 88 198 11 tutorials protegeowltutorial work manchester university publisher manchester university accessdate 9 december 2013 ref the neats vs scruffies divide also emerged in semantic web research culminating in the creation of the linking open data community their focus was on exposing data on the web rather than modeling example a simple example of concepts modeled in a frame language is the foaf ontology friend of a friend foaf ontology defined as part of the semantic web as a foundation for social networking and calendar systems the primary frame in this simple example is a person example slots are the person s email home page phone etc the interests of each person can be represented by additional frames describing the space of business and entertainment domains the slot knows links each person with other persons default values for a person s interests can be inferred by the web of people they are friends of ref cite web title foaf url http semanticweb org wiki foaf website http semanticweb org accessdate 7 june 2014 ref implementations the earliest frame based languages were custom developed for specific research projects and were not packaged as tools to be re used by other researchers just as with expert system inference engine s researchers soon realized the benefits of extracting part of the core infrastructure and developing general purpose frame languages that were not coupled to specific applications one of the first general purpose frame languages was krl ref cite journal last bobrow first d g author2 terry winograd title an overview of krl a knowledge representation language journal cognitive science year 1977 volume 1 pages 3 46 doi 10 1207 s15516709cog0101 2 ref one of the most influential early frame languages was kl one ref cite journal last brachman first ron title a structural paradigm for representing knowledge journal bolt beranek and neumann technical report year 1978 issue 3605 ref kl one spawned several subsequent frame languages one of the most widely used successors to kl one was the loom ontology loom language developed by robert macgregor at the information sciences institute ref cite journal last macgregor first robert title using a description classifier to enhance knowledge representation journal ieee expert date june 1991 volume 6 issue 3 url http ieeexplore ieee org xpl login jsp tp arnumber 87683 url http 3a 2f 2fieeexplore ieee org 2fxpls 2fabs all jsp 3farnumber 3d87683 accessdate 10 november 2013 doi 10 1109 64 87683 pages 41 46 ref in the 1980s artificial intelligence generated a great deal of interest in the business world fueled by expert systems this led to the development of many commercial products for the development of knowledge based systems these early products were usually developed in lisp and integrated constructs such as if then rules for logical reasoning with frame hierarchies for representing data one of the most well known of these early lisp knowledge base tools was the knowledge engineering environment kee from intellicorp software intellicorp kee provided a full frame language with multiple inheritance slots triggers default values and a rule engine that supported backward and forward chaining as with most early commercial versions of ai software kee was originally deployed in lisp programming language lisp on lisp machine platforms but was eventually ported to pcs and unix workstations ref cite journal last mettrey first william title an assessment of tools for building large knowledge based systems journal ai magazine year 1987 volume 8 issue 4 url http www aaai org ojs index php aimagazine article viewarticle 625 ref the research agenda of the semantic web spawned a renewed interest in automatic classification and frame languages an example is the web ontology language owl standard for describing information on the internet owl is a standard to provide a semantic layer on top of the internet the goal is that rather than organizing the web using keywords as most applications e g google do today the web can be organized by concepts organized in an ontology the name of the owl language itself provides a good example of the value of a semantic web if one were to search for owl using the internet today most of the pages retrieved would be on the bird owl rather than the standard web ontology language owl with a semantic web it would be possible to specify the concept web ontology language and the user would not need to worry about the various possible acronyms or synonyms as part of the search likewise the user would not need to worry about homonyms crowding the search results with irrelevant data such as information about birds of prey as in this simple example in addition to owl various standards and technologies that are relevant to the semantic web and were influenced by frame languages include ontology inference layer oil and darpa agent markup language daml the prot\xc3\xa9g\xc3\xa9 software protege open source software tool from stanford university provides an ontology editing capability that is built on owl and has the full capabilities of a classifier ref cite web last horridge first mathew title prot\xc3\xa9g\xc3\xa9 owl tutorial a step by step guide to modelling in owl using the popular prot\xc3\xa9g\xc3\xa9 owl tools url http 130 88 198 11 tutorials protegeowltutorial work manchester university publisher manchester university accessdate 9 december 2013 ref comparison of frames and objects frame languages have a significant overlap with object oriented languages the terminologies and goals of the two communities were different but as they moved from the academic world and labs to the commercial world developers tended to not care about philosophical issues and focused primarily on specific capabilities taking the best from either camp regardless of where the idea began what both paradigms have in common is a desire to reduce the distance between concepts in the real world and their implementation in software as such both paradigms arrived at the idea of representing the primary software objects in taxonomies starting with very general types and progressing to more specific types the following table illustrates the correlation between standard terminology from the object oriented and frame language communities class wikitable frame terminology oo terminology frame object class slot object property or attribute trigger accessor and mutator methods method e g loom kee method the primary difference between the two paradigms was in the degree that encapsulation was considered a major requirement for the object oriented paradigm encapsulation was one of the if not the most critical requirement the desire to reduce the potential interactions between software components and hence manage large complex systems was a key driver of object oriented technology for the frame language camp this requirement was less critical than the desire to provide a vast array of possible tools to represent rules constraints and programming logic in the object oriented world everything is controlled by methods and the visibility of methods so for example accessing the data value of an object property must be done via an accessor method this method controls things such as validating the data type and constraints on the value being retrieved or set on the property in frame languages these same types of constraints could be handled in multiple ways triggers could be defined to fire before or after a value was set or retrieved rules could be defined that managed the same types of constraints the slots themselves could be augmented with additional information called facets in some languages again with the same type of constraint information the other main differeniator between frame and oo languages was multiple inheritance allowing a frame or class to have two or more superclasses for frame languages multiple inheritance was a requirement this follows from the desire to model the world the way humans do human conceptualizations of the world seldom fall into rigidly defined non overlapping taxonomies for many oo languages especially in the later years of oo single inheritance was either strongly desired or required multiple inheritance was seen as a possible step in the analysis phase to model a domain but something that should be eliminated in the design and implementation phases in the name of maintaining encapsulation and modularity ref cite web title the unified modeling language url http www essentialstrategies com publications modeling uml htm work essentialstrategies com publisher essential strategies inc accessdate 10 december 2013 year 1999 quote in your author s experience nearly all examples that appear to require multiple inheritance or multiple type hierarchies can be solved by attacking the model from a different direction ref although the early frame languages such as krl did not include message passing driven by the demands of developers most of the later frame languages e g loom kee included the ability to define messages on frames ref cite journal last mettrey first william title an assessment of tools for building large knowledge based systems journal ai magazine year 1987 volume 8 issue 4 url http www aaai org ojs index php aimagazine article viewarticle 625 ref on the object oriented side standards have also emerged that provide essentially the equivalent functionality that frame languages provided albeit in a different format and all standardized on object libraries for example the object management group has standardized specifications for capabilities such as associating test data and constraints with objects analogous to common uses for facets in frames and to constraints in frame languages such as loom and for integrating rule engines ref cite web last macgregor first robert title retrospective on loom url http www isi edu isd loom papers macgregor loom retrospective html work isi edu publisher information sciences institute accessdate 10 december 2013 date august 13 1999 ref ref cite web title omg formal specifications url http www omg org spec work omg org publisher object management group accessdate 10 december 2013 ref see also description logic deductive classifier first order logic knowledge base knowledge based system ontology language semantic networks references reflist additional references marvin minsky http web media mit edu minsky papers frames frames html a framework for representing knowledge mit ai laboratory memo 306 june 1974 daniel g bobrow terry winograd ftp reports stanford edu pub cstr reports cs tr 76 581 cs tr 76 581 pdf an overview of krl a knowledge representation language stanford artificial intelligence laboratory memo aim 293 1976 r bruce roberts and ira p goldstein ftp publications ai mit edu ai publications pdf aim 408 pdf the frl primer 1977 r bruce roberts and ira p goldstein ftp publications ai mit edu ai publications pdf aim 409 pdf the frl manual 1977 cite journal last1 brachman first1 r last2 schmolze first2 j year 1985 title an overview of the kl one knowledge representation system url journal cognitive science volume 9 issue pages 171 216 doi 10 1016 s0364 0213 85 80014 8 cite journal last1 fikes first1 r e last2 kehler first2 t year 1985 title the role of frame based representation in knowledge representation and reasoning url journal communications of the acm volume 28 issue 9 pages 904 920 doi 10 1145 4284 4285 peter clark bruce porter km the knowledge machine 2 0 users manual http www cs utexas edu users mfkb rkf km html peter d karp http www ai sri com pub list 236 the design space of frame knowledge representation systems technical note 520 artificial intelligence center sri international 1992 external links http www cs umbc edu 771 papers nebel html frame based systems http www ai sri com gfp spec paper paper html the generic frame protocol http protege stanford edu the prot\xc3\xa9g\xc3\xa9 ontology editor http www csee umbc edu courses 771 current presentations frames pdf intro presentation to frame languages category artificial intelligence category knowledge engineering category knowledge representation'
b'brinkler classification is the library classification system of bartol brinkler described in his article the geographical approach to materials in the library of congress subject headings ref brinkler bartol the geographical approach to materials in the library of congress subject headings report of a study project s l s n 1960 accession no oclc 3853830 ref the geographical aspect of a subject may be conveyed through three types of headings labeled a b and c heading a uses a primary topical description with geographical subdivisions e g art paris type b uses a place name for the main heading with a topical subdivision e g paris description c headings use a geographical description of a phrase e g paris literature brinkler explores what type of heading is more useful to a patron and he finds that it depends on the level of familiarity a patron has with a topic and what approach they take when searching for resources on their topic ideally readers will either be looking for everything on a particular topic or everything regarding a particular place bartol brinkler investigates a system of classification that will best serve these two ideal types of patrons he finds working with type a headings will best assist a patron who is more topic oriented while using type b headings is preferable for those who are primarily interested in one place however this is problematic in practice one possibility is to assign type a and type b headings to every resource but the cataloguing cost would be high a system that aids readers regardless of their approach to a topic involves using cross references e g canada botany see botany canada admitting that see and see also references would require more work on the part of librarians bartol brinkler notes that librarians must keep in mind readers do not have the same knowledge of classification and do need all the help they can get citation needed date march 2008 references reflist brinkler bartol the geographical approach to materials in the library of congress subject headings library resources technical services 6 no 1 winter 1962 49 64 external links http hcl harvard edu libraries widener harvard university widener library http www loc gov catdir cpso lcco lcco html library of congress classification outline http www princeton edu paw memorials memorials 1930s memorials 1937 html princeton alumni weekly memorials 1937 category library cataloging and classification category knowledge representation category classification systems'
b'simple knowledge organization system skos is a w3c recommendation designed for representation of thesaurus information retrieval thesauri classification scheme s taxonomy general taxonomies authority control subject heading systems or any other type of structured controlled vocabulary skos is part of the semantic web family of standards built upon resource description framework rdf and rdf schema rdfs and its main objective is to enable easy publication and use of such vocabularies as linked data history desire ii project 1997 ndash 2000 the most direct ancestor to skos was the rdf thesaurus work undertaken in the second phase of the eu desire project ref name desire project citation publication date august 7 2000 title desire development of a european service for information on research and education publisher desire consortium url http www desire org archiveurl https web archive org web 20110725230823 http www desire org archivedate july 25 2011 ref citation needed reason the desire project reference does not appear to directly address the skos ancestry statement made here date august 2012 motivated by the need to improve the user interface and usability of multi service browsing and searching ref name desire deliverable d 36b citation title desire research deliverables d3 1 publisher desire consortium url http www desire org docs research deliverables d3 6 d36b html archiveurl https web archive org web 20080509135041 http www desire org html research deliverables d3 6 d36b archivedate may 9 2008 ref a basic rdf vocabulary for thesauri was http www desire org results discovery rdfthesschema html produced as noted later in the http www w3 org 2001 sw europe plan workpackages live esw wp 8 html swad europe workplan the desire work was adopted and further developed in the sosig and limber projects a version of the desire sosig implementation was described in w3c s ql 98 workshop motivating early work on rdf rule and query languages http www w3 org tands ql ql98 pp queryservice html a query and inference service for rdf ref http www w3 org tands ql ql98 pp queryservice html a query and inference service for rdf ref limber 1999 ndash 2001 skos built upon the output of the language independent metadata browsing of european resources limber project funded by the european community and part of the information society technologies programme in the limber project cclrc further developed an resource description framework rdf thesaurus interchange format ref http journals tdl org jodi article viewarticle 34 35 miller k matthews b 2001 having the right connections the limber project journal of digital information 1 8 5 february ref which was demonstrated on the european language social science thesaurus http www cessda org results html query elsst elsst at the uk data archive as a multilingual version of the english language humanities and social science electronic thesaurus hasset which was planned to be used by the council of european social science data archives http www cessda org cessda swad europe 2002 ndash 2004 skos as a distinct initiative began in the swad europe project bringing together partners from both desire sosig ilrt and limber cclrc who had worked with earlier versions of the schema it was developed in the thesaurus activity work package in the semantic web advanced development for europe swad europe project ref http www w3 org 2001 sw europe swad europe ref swad europe was funded by the european community and part of the information society technologies programme the project was designed to support w3c s semantic web activity through research demonstrators and outreach efforts conducted by the five project partners ercim the http www ilrt bris ac uk ilrt at bristol university hp labs cclrc and stilo ref http www stilo com stilo home page ref the first release of skos core and skos mapping were published at the end of 2003 along with other deliverables on rdf encoding of multilingual thesauri ref http www w3c rl ac uk swad deliverables 8 3 html swad europe deliverable 8 3 rdf encoding of multilingual thesauri ref and thesaurus mapping ref http www w3c rl ac uk swad deliverables 8 4 html swad europe deliverable 8 4 inter thesaurus mapping ref semantic web activity 2004 ndash 2005 following the termination of swad europe skos effort was supported by the w3c semantic web activity ref http www w3 org 2001 sw w3c semantic web activity ref in the framework of the best practice and deployment working group ref http www w3 org 2004 03 thes tf mission w3c semantic web best practice and deployment working group porting thesauri task force ref during this period focus was put both on consolidation of skos core and development of practical guidelines for porting and publishing thesauri for the semantic web development as w3c recommendation 2006 ndash 2009 the skos main published documents the skos core guide ref http www w3 org tr swbp skos core guide skos core guide w3c working draft 2 november 2005 ref the skos core vocabulary specification ref http www w3 org tr swbp skos core spec skos core vocabulary specification w3c working draft 2 november 2005 ref and the quick guide to publishing a thesaurus on the semantic web ref http www w3 org tr swbp thesaurus pubguide quick guide to publishing a thesaurus on the semantic web w3c working draft 17 may 2005 ref were developed through the w3c working draft process principal editors of skos were alistair miles ref http purl org net aliman alistair miles home page ref initially dan brickley ref http danbri org dan brickley home page ref and sean bechhofer ref http www cs man ac uk seanb me sean bechhofer home page ref the semantic web deployment working group ref http www w3 org 2006 07 swd w3c semantic web deployment working group ref chartered for two years may 2006 april 2008 has put in its charter to push skos forward on the w3c recommendation track the roadmap projects skos as a candidate recommendation by the end of 2007 and as a proposed recommendation in the first quarter of 2008 the main issues to solve are determining its precise scope of use and its articulation with other rdf languages and standards used in libraries such as dublin core ref http isegserv itd rl ac uk public skos press dc2006 camera ready paper pdf skos requirements for standardization the paper by alistair miles presented in october 2006 at the international conference on dublin core and metadata applications ref ref http purl org net retrieval retrieval and the semantic web incorporating a theory of retrieval using structured vocabularies dissertation on the theory of retrieval using structured vocabularies by alistair miles ref formal release 2009 on august 18 2009 w3c released the new standard that builds a bridge between the world of knowledge organization systems including thesauri classifications subject headings taxonomies and folksonomy folksonomies and the linked data community bringing benefits to both libraries museums newspapers government portals enterprises social networking applications and other communities that manage large collections of books historical artifacts news reports business glossaries blog entries and other items can now use skos ref http www w3 org tr 2009 rec skos reference 20090818 simple knowledge organization system skos ref to leverage the power of linked data historical view of components skos was originally designed as a modular and extensible family of languages organized as skos core skos mapping and skos extensions and a metamodel the entire specification is now complete within the namespace http www w3 org 2004 02 skos core http www w3 org 2004 02 skos core overview in addition to the reference itself the http www w3 org tr 2009 note skos primer 20090818 skos primer a w3c working group note summarizes the simple knowledge organization system the skos ref http www w3 org tr skos reference skos reference ref defines the classes and properties sufficient to represent the common features found in a standard thesaurus it is based on a concept centric view of the vocabulary where primitive objects are not terms but abstract notions represented by terms each skos concept is defined as an web resource rdf resource each concept can have rdf properties attached including one or more preferred index term s at most one in each natural language alternative terms or synonym s definitions and notes with specification of their language concepts can be organized in hierarchy hierarchies using broader narrower relationships or linked by non hierarchical associative relationships concepts can be gathered in concept schemes to provide consistent and structured sets of concepts representing whole or part of a controlled vocabulary element categories the principal element categories of skos are concepts labels notations semantic relations mapping properties and collections the associated concepts are listed in the table below border 1 class wikitable skos vocabulary organized by theme concepts labels notation documentation semantic relations mapping properties collections concept preflabel note broader broadmatch collection conceptscheme altlabel changenote narrower narrowmatch orderedcollection inscheme hiddenlabel definition related relatedmatch member hastopconcept notation editorialnote broadertransitive closematch memberlist topconceptof example narrowertransitive exactmatch historynote semanticrelation mappingrelation scopenote concepts the skos vocabulary is based on concepts concepts are the units of thought ideas meanings or objects and events instances or categories which underlie many knowledge organization systems as such concepts exist in the mind as abstract entities which are independent of the terms used to label them in skos a code concept code based on the owl code class code is used to represent items in a knowledge organization system terms ideas meanings etc or such a system s conceptual or organizational structure a code conceptscheme code is analogous to a vocabulary thesaurus or other way of organizing concepts skos does not constrain a concept to be within a particular scheme nor does it provide any way to declare a complete scheme there is no way to say the scheme consists only of certain members a topconcept is one of the upper concept s in a hierarchical scheme labels and notations each skos code label code is a string of unicode characters optionally with language tags that are associated with a concept the code preflabel code is the preferred human readable string maximum one per language tag while code altlabel code can be used for alternative strings and code hiddenlabel code can be used for strings that are useful to associate but not meant for humans to read a skos code notation code is similar to a label but the literal string has a datatype like integer float or date the datatype can even be made up see http www w3 org tr skos reference l2613 6 5 1 notations typed literals and datatypes in the skos reference the notation is useful for classification codes and other strings not recognizable as words documentation the documentation or note properties provide basic information about skos concepts all the concepts are considered a type of code skos note code they just provide more specific kinds of information the property code definition code for example should contain a full description of the subject resource more specific note types can be defined in a skos extension if desired a query for code lt a gt skos note code will obtain all the notes about lt a gt including definitions examples and scope history and change and editorial documentation any of these skos documentation properties can refer to several object types a literal e g a string a resource node that has its own properties or a reference to another document for example using a uri this enables the documentation to have its own metadata like creator and creation date specific guidance on skos documentation properties can be found in the skos primer http www w3 org tr 2009 note skos primer 20090818 secdocumentation documentary notes semantic relations skos semantic relations are intended to provide ways to declare relationships between concepts within a concept scheme while there are no restrictions precluding their use with two concepts from separate schemes this is discouraged because it is likely to overstate what can be known about the two schemes and perhaps link them inappropriately the property code related code simply makes an association relationship between two concepts no hierarchy or generality relation is implied the properties code broader code and code narrower code are used to assert a direct hierarchical link between two concepts the meaning may be unexpected the relation code lt a gt broader lt b gt code means that a has a broader concept called b hence that b is broader than a narrower follows in the same pattern while the casual reader might expect broader and narrower to be transitive properties skos does not declare them as such rather the properties code broadertransitive code and code narrowertransitive code are defined as transitive super properties of broader and narrower these super properties are by convention not used in declarative skos statements instead when a broader or narrower relation is used in a triple the corresponding transitive super property also holds and transitive relations can be inferred and queried using these super properties mapping skos mapping properties are intended to express matching exact or fuzzy of concepts from one concept scheme to another and by convention are used only to connect concepts from different schemes the concepts code relatedmatch code code broadmatch code and code narrowmatch code are a convenience with the same meaning as the semantic properties code related code code broader code and code narrower code see previous section regarding the meanings of broader and narrower the property relatedmatch makes a simple associative relationship between two concepts when concepts are so closely related that they can generally be used interchangeably code exactmatch code is the appropriate property exactmatch relations are transitive unlike any of the other match relations the code closematch code property that indicates concepts that only sometimes can be used interchangeably and so it is not a transitive property concept collections the concept collections code collection code code orderedcollection code are labeled and or ordered code orderedcollection code groups of skos concepts collections can be nested and can have defined uris or not which is known as a blank node neither a skos code concept code nor a code conceptscheme code may be a collection nor vice versa and skos semantic relations can only be used with a concept not a collection the items in a collection can not be connected to other skos concepts through the collection node individual relations must be defined to each concept in the collection community and participation all development work is carried out via the mailing list which is a completely open and publicly archived ref http lists w3 org archives public public esw thes public esw thes w3 org online archive archives of mailing list used for skos development ref mailing list devoted to discussion of issues relating to knowledge organisation systems information retrieval and the semantic web anyone may participate informally in the development of skos by joining the discussions on public esw thes w3 org informal participation is warmly welcomed anyone who works for a http www w3 org consortium join w3c member organisation may formally participate in the development process by joining the http www w3 org 2006 07 swd semantic web deployment working group this entitles individuals to edit specifications and to vote on publication decisions applications some important vocabularies have been migrated into skos format and are available in the public domain including eurovoc agrovoc and gemet library of congress subject headings lcsh also support the skos format ref http id loc gov authorities about html about the library of congress authorities ref skos has been used as the language for the thesauri used in the swed environmental directory ref http www swed org uk swed semantic web environmental directory ref developed in the swad europe project framework a way to convert thesauri to skos ref http thesauri cs vu nl eswc06 a method to convert thesauri to skos ref with examples including the medical subject headings mesh thesaurus has been outlined by the vrije universiteit amsterdam subject classification using darwin information typing architecture dita and skos has been developed by ibm ref http www 128 ibm com developerworks xml library x dita10 subject classification using darwin information typing architecture dita and skos by ibm developerworks ref skos is used to represent geographical feature types in the geonames ontology tools https github com esciencecenter thesaurex thesaurex is an open source web based skos editor it is limited to broader narrower relations among concepts and offers tree based interaction and with thesauri and drag drop creation of new thesauri based on a master thesaurus mondeca s http www mondeca com products itm intelligent topic manager itm is a full featured skos compliant solution for managing taxonomies thesauri and other controlled vocabularies http pactols frantiq fr opentheso opentheso is an open source web based thesaurus management system compliant with iso 25964 2011 and iso 25964 2 2012 standards information and documentation thesauri and interoperability with other vocabularies it offers skos and csv exports and imports rest and soap web services and manages persistent identifiers ark it has been developed at the french national center for scientific research since 2007 it is currently used by the french archaeological libraries network http www frantiq fr frantiq and by research teams and by the hospices civils de lyon as a collaborative thesaurus management tool it can be dowloaded on https github com frantiq opentheso github http openskos org openskos is a web service based approach to publication management and use of vocabulary data that can be mapped to skos its source code is available on https github com catchplus openskos github it includes crud like restful operations on skos concepts and a web based editor for searching and editing concepts it was developed by http picturae com picturae and funded by the dutch heritage fond http www catchplus nl catchplus tematres vocabulary server ref http www vocabularyserver com tematres is a web tool to manage formal and linguistic representations of knowledge ref is an open source web based vocabulary server for managing controlled vocabularies taxonomies and thesauruses http sourceforge net projects tematres tematres provides complete export of vocabularies into skos core in addition to zthes topicmaps mads dublin core vdex bs 8723 sitemap sql and text thmanager ref http thmanager sourceforge net thmanager an open source tool for creating and visualizing skos rdf vocabularies ref is a java programming language java open source software open source application for creating and visualizing skos vocabularies the w3c provides an experimental on line validation service ref http www w3 org 2004 02 skos core validation skos core validation service ref skos files can also be imported and edited in rdf owl editors such as protege software prot\xc3\xa9g\xc3\xa9 and swoop developed by maryland information and network dynamics lab semantic web agents project mindswap ref http www mindswap org 2004 swoop swoop a hypermedia based featherweight owl ontology editor developed by mindswap maryland information and network dynamics lab semantic web agents project ref skos synonyms can be transformed from wordnet rdf format using an xslt style sheet see http www w3 org tr wordnet rdf w3c rdf poolparty ref http www poolparty biz poolparty is a thesaurus management system and a skos editor for the semantic web ref is a commercial quality thesaurus management system and a skos editor for the semantic web including text analysis functionalities and linked data capabilities qskos ref https github com cmader qskos qskos is an open source tool for skos vocabulary quality assessment ref is an open source tool for performing quality assessment of skos vocabularies by checking against a quality issue catalog skosed ref http code google com p skoseditor skosed skos plugin for protege 4 ref is an open source plug in for the prot\xc3\xa9g\xc3\xa9 4 ref http www co ode org downloads protege x prot\xc3\xa9g\xc3\xa9 4 prot\xc3\xa9g\xc3\xa9 4 owl editor ref web ontology language owl ontology editor that supports authoring skos vocabularies skosed has an accompanying skos api ref http skosapi sourceforge net skos java api java api for skos ref written in java that can be used to build skos based applications model futures skos exporter ref http www modelfutures com software model futures excel skos exporter ref for microsoft excel allows simple vocabularies to be developed as indented excel spreadsheets and exported as skos rdf beta version lexaurus ref http www vocman com lexaurus is an enterprise thesaurus management system and multi format editor ref is an enterprise thesaurus management system and multi format editor its extensive api includes full revision management skos is one of its many supported formats topbraid enterprise vocabulary net evn ref http www topquadrant com solutions ent vocab net html topbraid evn ref is a web based solution for simplified development and management of interconnected controlled vocabularies it supports collaboration on defining and linking enterprise vocabularies taxonomies thesauri and ontologies used for information integration customization and search http www dataharmony com products thesaurus master html thesaurus master for creating developing and maintaining taxonomies and thesauri is part of access innovations http www dataharmony com data harmony knowledge management software line it offers skos compliant export http www cognitum eu semantics fluenteditor fluent editor 2014 an ontology editor which allows to work and edit directly owl annotations and skos annotations will processed also for referenced ontologies as well as imported exported to owl rdf and can be processed on the server https trial smartlogic com s4trials smartlogic semaphore ontology editor a skos and skos xl based ontology editor which allows creating models based strictly on the skos standards data there are publicly available skos data sources skos datasets wiki ref http www w3 org 2001 sw wiki skos datasets skos datasets ref the w3c recommends using this list of publicly available skos data sources most data found in this wiki can be used for commercial and research applications relationships with other standards metamodel the skos metamodel is broadly compatible with the data model of iso 25964 1 thesauri for information retrieval this data model can be viewed and downloaded from the website for iso 25964 ref name niso org http www niso org schemas iso25964 iso 25964 the international standard for thesauri and interoperability with other vocabularies ref file skos metamodel png thumb alt alt text semantic model of the information elements of skos skos and thesaurus standards skos development has involved experts from both rdf and library community and skos intends to allow easy migration of thesauri defined by standards such as niso z39 19 2005 ref http www niso org standards niso standards z39 19 2005 guidelines for the construction format and management of monolingual controlled vocabularies ref or iso 25964 ref name niso org skos and other semantic web standards skos is intended to provide a way to make a legacy of concept schemes available to semantic web applications simpler than the more complex ontology language web ontology language owl owl is intended to express complex conceptual structures which can be used to generate rich metadata and support inference tools however constructing useful web ontologies is demanding in terms of expertise effort and cost in many cases this type of effort might be superfluous or unsuited to requirements and skos might be a better choice the extensibility of rdf makes possible further incorporation or extension of skos vocabularies into more complex vocabularies including owl ontologies see also glossary knowledge representation metadata registry references reflist 2 external links http www w3 org tr skos reference skos simple knowledge organization system reference http www w3 org 2004 02 skos w3c skos home page http www w3 org tr 2009 note skos primer 20090818 w3c simple knowledge organization system primer http www idealliance org proceedings xtech05 papers 03 04 01 presentation of skos at xtech 2005 conference http www w3 org news 2009 item35 w3c invites implementations of skos simple knowledge organization system reference primer also published http demo semantic web at 8080 skosservices index skos validator and zthes converter semantic web w3c standards category knowledge representation category semantic web category school of computer science university of manchester'
b'refimprove date april 2016 attempto controlled english ace is a controlled natural language i e a subset of standard english grammar english with a restricted syntax and restricted semantics described by a small set of construction and interpretation rules ref cite conference author1 norbert e fuchs author2 kaarel kaljurand author3 gerold schneider title attempto controlled english meets the challenges of knowledge representation reasoning interoperability and user interfaces booktitle flairs 2006 date 2006 url http attempto ifi uzh ch site publications papers flairs0601fuchsn pdf format pdf ref it has been under development at the university of zurich since 1995 in 2013 ace version 6 7 was announced ref http attempto ifi uzh ch site news ref ace can serve as knowledge representation specification language specification and query language and is intended for professionals who want to use formal notations and formal methods but may not be familiar with them though ace appears perfectly natural it can be read and understood by any speaker of english it is in fact a formal language ace and its related tools have been used in the fields of requirements analysis software specifications theorem proving automatic summarization text summaries ontologies rules querying health informatics medical documentation and planning here are some simple examples every woman is a human a woman is a human a man tries on a new tie if the tie pleases his wife then the man buys it ace construction rules require that each noun be introduced by a determiner a every no some at least 5 ace interpretation rules decide that 1 is interpreted as universal quantification universally quantified while 2 is interpreted as existential quantification existentially quantified sentences like women are human do not follow ace syntax and are consequently not valid interpretation rules resolve the deixis anaphoric reference anaphoric references in 3 the tie and it of the second sentence refer to a new tie of the first sentence while his and the man of the second sentence refer to a man of the first sentence thus an ace text is a coherent entity of anaphorically linked sentences the attempto parsing engine ape translates ace texts unambiguously into discourse representation theory discourse representation structures drs that use a variant of the language of first order logic ref cite conference author1 norbert e fuchs author2 kaarel kaljurand author3 tobias kuhn title discourse representation structures for ace 6 6 booktitle technical report ifi 2010 0010 department of informatics university of zurich date 2010 url http attempto ifi uzh ch site pubs papers drs report 66 pdf format pdf ref a drs can be further translated into other formal languages for instance acerules with various semantics ref cite conference author tobias kuhn title acerules executing rules in controlled natural language booktitle first international conference on web reasoning and rule systems rr 2007 year 2007 url http attempto ifi uzh ch site pubs papers kuhn07acerules pdf format pdf ref web ontology language owl ref cite conference author1 kaarel kaljurand author2 norbert e fuchs title verbalizing owl in attempto controlled english booktitle owl experiences and directions owled 2007 year 2007 url http attempto ifi uzh ch site pubs papers owled2007 kaljurand pdf format pdf ref and semantic web rule language swrl translating an ace text into a fragment of first order logic allows users to inference reason about the text for instance to formal verification verify to formal verification validate and to information retrieval query it ace in a nutshell unreferenced section date may 2013 as an overview of the current version 6 6 of ace this section briefly describes the vocabulary gives an account of the syntax summarises the handling of ambiguity explains the processing of anaphoric references vocabulary the vocabulary of ace comprises predefined function words e g determiners conjunctions predefined phrases e g it is false that it is possible that content words e g nouns verbs adjectives adverbs grammar the grammar of ace defines and constrains the form and the meaning of ace sentences and texts ace s grammar is expressed as a set of http attempto ifi uzh ch site docs ace constructionrules html construction rules the meaning of sentences is described as a small set of http attempto ifi uzh ch site docs ace interpretationrules html interpretation rules a http attempto ifi uzh ch site docs ace troubleshooting html troubleshooting guide describes how to use ace and how to avoid pitfalls ace texts an ace text is a sequence of declarative sentences that can be anaphorically interrelated furthermore ace supports questions and commands simple sentences a simple sentence asserts that something is the case a fact an event a state the temperature is 2 \xc2\xb0c a customer inserts 2 cards a card and a code are valid simple ace sentences have the following general structure subject verb complements adjuncts every sentence has a subject and a verb complements direct and indirect objects are necessary for transitive verbs insert something and ditransitive verbs give something to somebody whereas adjuncts adverbs prepositional phrases are optional all elements of a simple sentence can be elaborated upon to describe the situation in more detail to further specify the nouns customer and card we could add adjectives a trusted customer inserts two valid cards possessive nouns and of prepositional phrases john s customer inserts a card of mary or variables as appositions john inserts a card a other modifications of nouns are possible through relative sentences a customer who is trusted inserts a card that he owns which are described below since they make a sentence composite we can also detail the insertion event e g by adding an adverb a customer inserts some cards manually or equivalently a customer manually inserts some cards or by adding prepositional phrases a customer inserts some cards into a slot we can combine all of these elaborations to arrive at john s customer who is trusted inserts a valid card of mary manually into a slot a composite sentences composite sentences are recursively built from simpler sentences through coordination linguistics coordination subordination linguistics subordination quantification linguistics quantification and negation note that ace composite sentences overlap with what linguists call compound sentences and complex sentences coordination coordination by and is possible between sentences and between phrases of the same syntactic type a customer inserts a card and the machine checks the code there is a customer who inserts a card and who enters a code a customer inserts a card and enters a code an old and trusted customer enters a card and a code note that the coordination of the noun phrases a card and a code represents a plural object coordination by or is possible between sentences verb phrases and relative clauses a customer inserts a card or the machine checks the code a customer inserts a card or enters a code a customer owns a card that is invalid or that is damaged coordination by and and or is governed by the standard binding order of logic i e and binds stronger than or commas can be used to override the standard binding order thus the sentence a customer inserts a visacard or inserts a mastercard and inserts a code means that the customer inserts a visacard and a code or alternatively a mastercard and a code subordination there are four constructs of subordination relative sentences if then sentences modality and sentence subordination relative sentences starting with who which and that allow to add detail to nouns a customer who is trusted inserts a card that he owns with the help of if then sentences we can specify conditional or hypothetical situations if a card is valid then a customer inserts it note the anaphoric reference via the pronoun it in the then part to the noun phrase a card in the if part modality allows us to express possibility and necessity a trusted customer can must insert a card it is possible necessary that a trusted customer inserts a card sentence subordination comes in various forms it is true false that a customer inserts a card it is not provable that a customer inserts a card a clerk believes that a customer inserts a card quantification quantification allows us to speak about all objects of a certain class universal quantification or to denote explicitly the existence of at least one object of this class existential quantification the textual occurrence of a universal or existential quantifier opens its scope that extends to the end of the sentence or in coordinations to the end of the respective coordinated sentence to express that all involved customers insert cards we can write every customer inserts a card this sentence means that each customer inserts a card that may or may not be the same as the one inserted by another customer to specify that all customers insert the same card however unrealistic that situation seems we can write a card is inserted by every customer or equivalently there is a card that every customer inserts to state that every card is inserted by a customer we write every card is inserted by a customer or somewhat indirectly for every card there is a customer who inserts it negation negation allows us to express that something is not the case a customer does not insert a card a card is not valid to negate something for all objects of a certain class one uses no no customer inserts more than 2 cards or there is no there is no customer who inserts a card to negate a complete statement one uses sentence negation it is false that a customer inserts a card these forms of negation are logical negations i e they state that something is provably not the case negation as failure states that a state of affairs cannot be proved i e there is no information whether the state of affairs is the case or not it is not provable that a customer inserts a card queries ace supports two forms of queries yes no queries and wh queries yes no queries ask for the existence or non existence of a specified situation if we specified a customer inserts a card then we can ask does a customer insert a card to get a positive answer note that interrogative sentences always end with a question mark with the help of wh queries i e queries with query words we can interrogate a text for details of the specified situation if we specified a trusted customer inserts a valid card manually in the morning in a bank we can ask for each element of the sentence with the exception of the verb who inserts a card which customer inserts a card what does a customer insert how does a customer insert a card when does a customer enter a card where does a customer enter a card queries can also be constructed by a sequence of declarative sentences followed by one interrogative sentence for example there is a customer and there is a card that the customer enters does a customer enter a card commands ace also supports commands some examples john go to the bank john and mary wait every dog bark a brother of john give a book to mary a command always consists of a noun phrase the addressee followed by a comma followed by an uncoordinated verb phrase furthermore a command has to end with an exclamation mark constraining ambiguity to constrain the ambiguity of full natural language ace employs three simple means some ambiguous constructs are not part of the language unambiguous alternatives are available in their place all remaining ambiguous constructs are interpreted deterministically on the basis of a small number of interpretation rules users can either accept the assigned interpretation or they must rephrase the input to obtain another one avoidance of ambiguity in natural language relative sentences combined with coordinations can introduce ambiguity a customer inserts a card that is valid and opens an account in ace the sentence has the unequivocal meaning that the customer opens an account as reflected by the paraphrase a card is valid a customer inserts the card the customer opens an account to express the alternative though not very realistic meaning that the card opens an account the relative pronoun that must be repeated thus yielding a coordination of relative sentences a customer inserts a card that is valid and that opens an account this sentence is unambiguously equivalent in meaning to the paraphrase a card is valid the card opens an account a customer inserts the card interpretation rules not all ambiguities can be safely removed from ace without rendering it artificial to deterministically interpret otherwise syntactically correct ace sentences we use a small set of interpretation rules for example if we write a customer inserts a card with a code then with a code attaches to the verb inserts but not to a card however this is probably not what we meant to say to express that the code is associated with the card we can employ the interpretation rule that a relative sentence always modifies the immediately preceding noun phrase and rephrase the input as a customer inserts a card that carries a code yielding the paraphrase a card carries a code a customer inserts the card or to specify that the customer inserts a card and a code as a customer inserts a card and a code anaphoric references usually ace texts consist of more than one sentence a customer enters a card and a code if a code is valid then simplemat accepts a card to express that all occurrences of card and code should mean the same card and the same code ace provides anaphoric references via the definite article a customer enters a card and a code if the code is valid then simplemat accepts the card during the processing of the ace text all anaphoric references are replaced by the most recent and most specific accessible noun phrase that agrees in gender and number as an example of most recent and most specific suppose an ace parser is given the sentence a customer enters a red card and a blue card then the card is correct refers to the second card while the red card is correct refers to the first card noun phrases within if then sentences universally quantified sentences negations modality and subordinated sentences cannot be referred to anaphorically from subsequent sentences i e such noun phrases are not accessible from the following text thus for each of the sentences if a customer owns a card then they enter it every customer enters a card a customer does not enter a card a customer can enter a card a clerk believes that a customer enters a card we cannot refer to a card with the card is correct anaphoric references are also possible via personal pronouns a customer enters a card and a code if it is valid then simplemat accepts the card or via variables a customer enters a card x and a code y if y is valid then simplemat accepts x anaphoric references via definite articles and variables can be combined a customer enters a card x and a code y if the code y is valid then simplemat accepts the card x note that proper names like simplemat always refer to the same object see also gellish natural language processing knowledge representation natural language programming structured english cleartalk another machine readable knowledge representation language inform 7 a programming language with english syntax references reflist external links http attempto ifi uzh ch project attempto category controlled english category knowledge representation category controlled natural languages category natural language processing category natural language parsing'
b'the national library of medicine nlm classification system is a library classification library indexing system covering the fields of medicine and preclinical basic sciences the national library of medicine nlm classification is patterned after the library of congress classification library of congress lc classification system alphabet alphabetical letters denote broad subject categories which are subdivided by numbers ref name nlm factsheet cite web title fact sheet nlm classification work url https www nlm nih gov pubs factsheets nlmclassif html date 2005 07 15 accessdate 2007 05 12 ref for example qw 279 would indicate a book on an aspect of microbiology or immunology the one or two letter alphabetical codes in the nlm classification use a limited range of letters only qs qz and w wz this allows the nlm system to co exist with the larger lc coding scheme as neither of these ranges are used in the lc system there are however three pre existing codes in the lc system which overlap with the nlm human anatomy qm microbiology qr and medicine r to avoid further confusion these three codes are not used in the nlm the headings for the individual schedules letters or letter pairs are given in brief form e g qw microbiology and immunology wg cardiovascular system and together they provide an outline of the subjects covered by the nlm classification headings are interpreted broadly and include the physiology physiological system the specialties connected with them the regions of the body chiefly concerned and subordinate related fields the nlm system is hierarchical and within each schedule division by organ anatomy organ usually has priority each main schedule as well as some sub sections begins with a group of form numbers ranging generally from 1 49 which classify materials by publication type e g dictionary dictionaries atlas es laboratory manuals etc the main schedules qs qz w wy and wz excluding the range wz 220 270 classify works published after 1913 the 19th century schedule is used for works published 1801 1913 and wz 220 270 is used to provide century groupings for works published before 1801 overview of the nlm classification categories preclinical sciences qs human anatomy qt physiology qu biochemistry qv pharmacology qw microbiology immunology qx parasitology qy clinical pathology qz pathology medicine and related subjects w health professions wa public health wb practice of medicine wc communicable diseases wd disorders of systemic metabolic or environmental origin etc we musculoskeletal system wf respiratory system wg cardiovascular system wh hemic and lymphatic systems wi digestive system wj urogenital system wk endocrine system wl nervous system wm psychiatry wn radiology diagnostic imaging wo surgery wp gynecology wq obstetrics wr dermatology ws pediatrics wt geriatrics chronic disease wu dentistry oral surgery wv otolaryngology ww ophthalmology wx hospitals other health facilities wy nursing wz history of medicine 19th century schedule see also dewey decimal classification colon classification library of congress classification universal decimal classification references see http en wikipedia org wiki wikipedia footnotes for a discussion of different citation methods and how to generate footnotes using the ref ref tags and the reflist template reflist refbegin usgovernment sourceurl http wwwcf nlm nih gov class the nlm classification 2005 refend category classification systems category knowledge representation category library cataloging and classification'
b'unreferenced stub date december 2009 the korean decimal classification kdc is a system of library classification used in south korea the main classes are the same as in the dewey decimal classification but these are in a different order natural sciences 400 technology and engineering 500 arts 600 language 700 main classes 000 general 100 philosophy 200 religion 300 social sciences 400 natural sciences 500 technology and engineering 600 arts 700 language 800 literature 900 history category library cataloging and classification category knowledge representation category classification systems category libraries in north korea category libraries in south korea library classification systems library stub'
b'multiple issues underlinked date january 2013 more footnotes date february 2011 semantic interoperability is the ability of computer systems to exchange data with unambiguous shared meaning semantic interoperability is a requirement to enable machine computable logic inferencing knowledge discovery and data federation between information systems ref ncoic https www ncoic org technology deliverables scope scope https www ncoic org home network centric operations industry consortium 2008 ref semantic interoperability is therefore concerned not just with the packaging of data syntax but the simultaneous transmission of the meaning with the data semantics this is accomplished by adding data about the data metadata linking each data element to a controlled shared vocabulary the meaning of the data is transmitted with the data itself in one self describing information package that is independent of any information system it is this shared vocabulary and its associated links to an ontology which provides the foundation and capability of machine interpretation inferencing and logic syntactic interoperability is a prerequisite for semantic interoperability syntactic interoperability refers to the packaging and transmission mechanisms for data in healthcare hl7 has been in use for over thirty years which predates the internet and web technology and uses the pipe character as a data delimiter the current internet standard for document markup is xml which uses as a data delimiter the data delimiters convey no meaning to the data other than to structure the data without a data dictionary to translate the contents of the delimiters the data remains meaningless while there are many attempts at creating data dictionaries and information models to associate with these data packaging mechanisms none have been practical to implement this has only perpetuated the ongoing babelization of data and inability to exchange of data with meaning since the introduction of the semantic web concept by tim berners lee in 1999 ref cite book last berners lee first tim authorlink tim berners lee author2 fischetti mark title tim berners lee weaving the web weaving the web publisher harpersanfrancisco year 1999 pages chapter 12 isbn 978 0 06 251587 2 nopp true ref there has been growing interest and application of the w3c world wide web consortium wwwc standards to provide web scale semantic data exchange federation and inferencing capabilities semantic as a function of syntactic interoperability syntactic interoperability provided by for instance xml or the sql standards is a pre requisite to semantic it involves a common data format and common protocol to structure any data so that the manner of processing the information will be interpretable from the structure it also allows detection of syntactic errors thus allowing receiving systems to request resending of any message that appears to be garbled or incomplete no semantic communication is possible if the syntax is garbled or unable to represent the data however information represented in one syntax may in some cases be accurately translated into a different syntax where accurate translation of syntaxes is possible systems using different syntaxes may also interoperate accurately in some cases the ability to accurately translate information among systems using different syntaxes may be limited to one direction when the formalisms used have different levels of expressivity ability to express information a single ontology containing representations of every term used in every application is generally considered impossible because of the rapid creation of new terms or assignments of new meanings to old terms however though it is impossible to anticipate every concept that a user may wish to represent in a computer there is the possibility of finding some finite set of primitive concept representations that can be combined to create any of the more specific concepts that users may need for any given set of applications or ontologies having a foundation ontology also called upper ontology that contains all those primitive elements would provide a sound basis for general semantic interoperability and allow users to define any new terms they need by using the basic inventory of ontology elements and still have those newly defined terms properly interpreted by any other computer system that can interpret the basic foundation ontology whether the number of such primitive concept representations is in fact finite or will expand indefinitely is a question under active investigation if it is finite then a stable foundation ontology suitable to support accurate and general semantic interoperability can evolve after some initial foundation ontology has been tested and used by a wide variety of users at the present time no foundation ontology has been adopted by a wide community so such a stable foundation ontology is still in the future words and meanings one persistent misunderstanding recurs in discussion of semantics the confusion of words and meanings the meanings of words change sometimes rapidly but a formal language such as used in an ontology can encode the meanings semantics of concepts in a form that does not change in order to determine what is the meaning of a particular word or term in a database for example it is necessary to label each fixed concept representation in an ontology with the word s or term s that may refer to that concept when multiple words refer to the same fixed concept in language this is called synonymy when one word is used to refer to more than one concept that is called ambiguity ambiguity and synonymy are among the factors that make computer understanding of language very difficult the use of words to refer to concepts the meanings of the words used is very sensitive to the context and the purpose of any use for many human readable terms the use of ontologies in supporting semantic interoperability is to provide a fixed set of concepts whose meanings and relations are stable and can be agreed to by users the task of determining which terms in which contexts each database is a different context then is separated from the task of creating the ontology and must be taken up by the designer of a database or the designer of a form for data entry or the developer of a program for language understanding when a word used in some interoperability context changes its meaning then to preserve interoperability it is necessary to change the pointer to the ontology element s that specifies the meaning of that word knowledge representation requirements and languages a knowledge representation language may be sufficiently expressive to describe nuances of meaning in well understood fields there are at least five levels of complexity of these specify date june 2014 for general semi structured data one may use a general purpose language such as xml ref http www cs umd edu projects plus shoe pubs extreme2000 pdf xml as a tool for semantic interoperability semantic interoperability on the web jeff heflin and james hendler ref languages with the full power of first order predicate logic may be required for many tasks human languages are highly expressive but are considered too ambiguous to allow the accurate interpretation desired given the current level of human language technology in human languages the same word may be used to refer to different concepts ambiguity and the same concept may be referred to by different words synonymy prior agreement not required confusing section date february 2016 semantic interoperability may be distinguished from other forms of interoperability by considering whether the information transferred has in its communicated form all of the meaning required for the receiving system to interpret it correctly even when the algorithms used by the receiving system are unknown to the sending system consider sending one number if that number is intended to be the sum of money owed by one company to another it implies some action or lack of action on the part of both those who send it and those who receive it it may be correctly interpreted if sent in response to a specific request and received at the time and in the form expected this correct interpretation does not depend only on the number itself which could represent almost any of millions of types of quantitative measure rather it depends strictly on the circumstances of transmission that is the interpretation depends on both systems expecting that the algorithms in the other system use the number in exactly the same sense and it depends further on the entire envelope of transmissions that preceded the actual transmission of the bare number by contrast if the transmitting system does not know how the information will be used by other systems it is necessary to have a shared agreement on how information with some specific meaning out of many possible meanings will appear in a communication for a particular task one solution is to standardize a form such as a request for payment that request would have to encode in standardized fashion all of the information needed to evaluate it such as the agent owing the money the agent owed the money the nature of the action giving rise to the debt the agents goods services and other participants in that action the time of the action the amount owed and currency in which the debt is reckoned the time allowed for payment the form of payment demanded and other information when two or more systems have agreed on how to interpret the information in such a request they can achieve semantic interoperability for that specific type of transaction for semantic interoperability generally it is necessary to provide standardized ways to describe the meanings of many more things than just commercial transactions and the number of concepts whose representation needs to be agreed upon are at a minimum several thousand ontology research how to achieve semantic interoperability for more than a few restricted scenarios is currently a matter of research and discussion for the problem of general semantic interoperability some form of foundation ontology upper ontology is required that is sufficiently comprehensive to provide the defining concepts for more specialized ontologies in multiple domains over the past decade more than ten foundation ontologies have been developed but none have as yet been adopted by a wide user base the need for a single comprehensive all inclusive ontology to support semantic interoperability can be avoided by designing the common foundation ontology as a set of basic primitive concepts that can be combined to create the logical descriptions of the meanings of terms used in local domain ontologies or local databases this tactic is based on the principle that if pre style white space pre wrap 1 the meanings and usage of the primitive ontology elements in the foundation ontology are agreed on and 2 the ontology elements in the domain ontologies are constructed as logical combinations of the elements in the foundation ontology pre then pre style white space pre wrap the intended meanings of the domain ontology elements can be computed automatically using an fol reasoner by any system that accepts the meanings of the elements in the foundation ontology and has both the foundation ontology and the logical specifications of the elements in the domain ontology pre therefore pre style white space pre wrap any system wishing to interoperate accurately with another system need transmit only the data to be communicated plus any logical descriptions of terms used in that data that were created locally and are not already in the common foundation ontology pre this tactic then limits the need for prior agreement on meanings to only those ontology elements in the common foundation ontology fo based on several considerations this is likely to be fewer than 10 000 elements types and relations in practice together with the fo focused on representations of the primitive concepts a set of domain extension ontologies to the fo with elements specified using the fo elements will likely also be used such pre existing extensions will ease the cost of creating domain ontologies by providing existing elements with the intended meaning and will reduce the chance of error by using elements that have already been tested domain extension ontologies may be logically inconsistent with each other and that needs to be determined if different domain extensions are used in any communication whether use of such a single foundation ontology can itself be avoided by sophisticated mapping techniques among independently developed ontologies is also under investigation importance the practical significance of semantic interoperability has been measured by several studies that estimate the cost in lost efficiency due to lack of semantic interoperability one study ref http content healthaffairs org cgi content full hlthaff w5 10 dc1 jan walker eric pan douglas johnston julia adler milstein david w bates and blackford middleton the value of healthcare information exchange and interoperability health affairs 19 january 2005 ref focusing on the lost efficiency in the communication of healthcare information estimated that us 77 8 billion per year could be saved by implementing an effective interoperability standard in that area other studies of the construction industry ref http www bfrl nist gov oae publications gcrs 04867 pdf microsoft word 08657 final rpt 8 2 04 doc bot generated title ref and of the automobile manufacturing supply chain ref http www nist gov director prog ofc report99 1 pdf ref estimate costs of over us 10 billion per year due to lack of semantic interoperability in those industries in total these numbers can be extrapolated to indicate that well over us 100 billion per year is lost because of the lack of a widely used semantic interoperability standard in the us alone there has not yet been a study about each policy field that might offer big cost savings applying semantic interoperability standards but to see which policy fields are capable of profiting from semantic interoperability see interoperability in general such policy fields are egovernment health security and many more the eu also set up the semantic interoperability centre europe in june 2007 see also interoperability interoperability generally semantic computing upper ontology computer science discussion of using an upper ontology conceptual interoperability levels of conceptual interoperability a discussion describing an interoperability spectrum in the context of exchange of modeling and simulation information in which semantic interoperability is not defined as fully independent of context as described here udef universal data element framework external links http colab cim3 net cgi bin wiki pl ontologytaxonomycoordinatingwg ontacglossary the ontacwg glossary other definitions of semantic interoperability http marinemetadata org guides vocabs cvchooseimplement cvsemint mmi guide achieving semantic interoperability references reflist 2 category knowledge representation category technical communication category information science category ontology information science category computing terminology category telecommunication theory category interoperability'
b'an attribute value system is a basic knowledge representation framework comprising a table with columns designating attributes also known as properties predicates features dimensions characteristics field computer science fields headers or independent variables depending on the context and row database rows designating objects also known as entities instances exemplars elements record computer science records or dependent variables each table cell therefore designates the value also known as state of a particular attribute of a particular object example of attribute value system below is a sample attribute value system it represents 10 objects rows and five features columns in this example the table contains only integer values in general an attribute value system may contain any kind of data numeric or otherwise an attribute value system is distinguished from a simple feature list representation in that each feature in an attribute value system may possess a range of values e g feature math p 1 math below which has domain of 0 1 2 rather than simply being present or absent harv barsalou hale 1993 class wikitable style text align center width 30 border 1 sample attribute value system object math p 1 math math p 2 math math p 3 math math p 4 math math p 5 math math o 1 math 1 2 0 1 1 math o 2 math 1 2 0 1 1 math o 3 math 2 0 0 1 0 math o 4 math 0 0 1 2 1 math o 5 math 2 1 0 2 1 math o 6 math 0 0 1 2 2 math o 7 math 2 0 0 1 0 math o 8 math 0 1 2 2 1 math o 9 math 2 1 0 2 2 math o 10 math 2 0 0 1 0 other terms used for attribute value system attribute value systems are pervasive throughout many different literatures and have been discussed under many different names flat data spreadsheet attribute value system ziarko shan 1996 information system zdzislaw pawlak pawlak 1981 classification system ziarko 1998 knowledge representation system wong ziarko 1986 information table yao yao 2002 object predicate table watanabe 1985 aristotelian table watanabe 1985 simple frames harv barsalou hale 1993 first normal form database see also bayes networks entity attribute value model joint distribution knowledge representation wikibooks optimal classification optimal classification in wikibooks rough set triplestore references cite book last1 barsalou given1 lawrence w surname2 hale given2 christopher r year 1993 chapter components of conceptual representation from feature lists to recursive frames editor iven van mechelen editor2 james hampton editor3 ryszard s michalski editor4 peter theuns title categories and concepts theoretical views and inductive data analysis pages 97 144 edition publisher academic press place london url accessdate ref harv postscript none cite book last pawlak first zdzis\xc5\x82aw authorlink zdzislaw pawlak title rough sets theoretical aspects of reasoning about data publisher kluwer year 1991 location dordrecht cite journal last ziarko first wojciech last2 shan first2 ning title a method for computing all maximally general rules in attribute value systems journal computational intelligence volume 12 issue 2 pages 223 234 year 1996 doi 10 1111 j 1467 8640 1996 tb00260 x ref harv cite journal last pawlak first zdzis\xc5\x82aw last2 shan first2 ning title information systems theoretical foundations journal information systems volume 6 issue 3 pages 205 218 year 1981 doi 10 1016 0306 4379 81 90023 5 ref harv cite journal last wong first s k m last2 ziarko first2 wojciech last3 ye first3 r li title comparison of rough set and statistical methods in inductive learning journal international journal of man machine studies volume 24 pages 53 72 year 1986 ref harv cite conference first yao last j t author2 yao y y title induction of classification rules by granular computing booktitle proceedings of the third international conference on rough sets and current trends in computing tsctc 02 pages 331 338 publisher springer verlag year 2002 location london uk cite book last watanabe first satosi title pattern recognition human and mechanical publisher john wiley sons year 1985 location new york cite conference first wojciech last ziarko title rough sets as a methodology for data mining booktitle rough sets in knowledge discovery 1 methodology and applications pages 554 576 editor polkowski lech editor2 skowron andrzej publisher physica verlag year 1998 location heidelberg category knowledge representation category specific models'
